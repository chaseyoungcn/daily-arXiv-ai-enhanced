{"id": "2506.08188", "pdf": "https://arxiv.org/pdf/2506.08188", "abs": "https://arxiv.org/abs/2506.08188", "authors": ["Wenlong Meng", "Shuguo Fan", "Chengkun Wei", "Min Chen", "Yuwei Li", "Yuanchao Zhang", "Zhikun Zhang", "Wenzhi Chen"], "title": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "categories": ["cs.CR", "cs.CL"], "comment": "Accepted to USENIX Security'25", "summary": "In this paper, we introduce GradEscape, the first gradient-based evader\ndesigned to attack AI-generated text (AIGT) detectors. GradEscape overcomes the\nundifferentiable computation problem, caused by the discrete nature of text, by\nintroducing a novel approach to construct weighted embeddings for the detector\ninput. It then updates the evader model parameters using feedback from victim\ndetectors, achieving high attack success with minimal text modification. To\naddress the issue of tokenizer mismatch between the evader and the detector, we\nintroduce a warm-started evader method, enabling GradEscape to adapt to\ndetectors across any language model architecture. Moreover, we employ novel\ntokenizer inference and model extraction techniques, facilitating effective\nevasion even in query-only access.\n  We evaluate GradEscape on four datasets and three widely-used language\nmodels, benchmarking it against four state-of-the-art AIGT evaders.\nExperimental results demonstrate that GradEscape outperforms existing evaders\nin various scenarios, including with an 11B paraphrase model, while utilizing\nonly 139M parameters. We have successfully applied GradEscape to two real-world\ncommercial AIGT detectors. Our analysis reveals that the primary vulnerability\nstems from disparity in text expression styles within the training data. We\nalso propose a potential defense strategy to mitigate the threat of AIGT\nevaders. We open-source our GradEscape for developing more robust AIGT\ndetectors.", "AI": {"tldr": "This paper presents GradEscape, a gradient-based method to attack AI-generated text detectors. It solves undifferentiable computation in text through weighted embeddings and adapts to various detector architectures using warm-started evader method. Evaluated on four datasets and three language models, it surpasses state-of-the-art evaders with fewer parameters and successfully attacks real-world commercial detectors.", "motivation": "The motivation is to develop an effective method to attack AI-generated text (AIGT) detectors by overcoming challenges such as the discrete nature of text and tokenizer mismatch between evader and detector.", "method": "GradEscape constructs weighted embeddings for detector input to address the undifferentiable computation problem and updates its model parameters based on feedback from victim detectors. It uses a warm-started evader method to adapt to different language model architectures and employs tokenizer inference and model extraction techniques for effective evasion.", "result": "GradEscape outperforms existing evaders across various scenarios, including when using an 11B paraphrase model, while only utilizing 139M parameters. It has been successfully applied to two real-world commercial AIGT detectors.", "conclusion": "The primary vulnerability of AIGT detectors lies in the disparity of text expression styles within training data. The authors propose a defense strategy and open-source GradEscape to help develop more robust AIGT detectors."}}
{"id": "2506.08192", "pdf": "https://arxiv.org/pdf/2506.08192", "abs": "https://arxiv.org/abs/2506.08192", "authors": ["Jared Claypoole", "Steven Cheung", "Ashish Gehani", "Vinod Yegneswaran", "Ahmad Ridley"], "title": "Interpreting Agent Behaviors in Reinforcement-Learning-Based Cyber-Battle Simulation Platforms", "categories": ["cs.CR", "cs.LG"], "comment": null, "summary": "We analyze two open source deep reinforcement learning agents submitted to\nthe CAGE Challenge 2 cyber defense challenge, where each competitor submitted\nan agent to defend a simulated network against each of several provided\nrules-based attack agents. We demonstrate that one can gain interpretability of\nagent successes and failures by simplifying the complex state and action spaces\nand by tracking important events, shedding light on the fine-grained behavior\nof both the defense and attack agents in each experimental scenario. By\nanalyzing important events within an evaluation episode, we identify patterns\nin infiltration and clearing events that tell us how well the attacker and\ndefender played their respective roles; for example, defenders were generally\nable to clear infiltrations within one or two timesteps of a host being\nexploited. By examining transitions in the environment's state caused by the\nvarious possible actions, we determine which actions tended to be effective and\nwhich did not, showing that certain important actions are between 40% and 99%\nineffective. We examine how decoy services affect exploit success, concluding\nfor instance that decoys block up to 94% of exploits that would directly grant\nprivileged access to a host. Finally, we discuss the realism of the challenge\nand ways that the CAGE Challenge 4 has addressed some of our concerns.", "AI": {"tldr": "This paper analyzes two open source deep reinforcement learning agents used in a cyber defense challenge, demonstrating methods to interpret agent successes and failures by simplifying state/action spaces and tracking important events. It identifies patterns in infiltration/clearing events, evaluates action effectiveness, examines decoy service impacts, and discusses the realism of the challenge.", "motivation": "To understand and interpret the successes and failures of deep reinforcement learning agents in defending a simulated network against attack agents in the CAGE Challenge 2.", "method": "Simplify complex state and action spaces and track important events within evaluation episodes to analyze the behavior of both defense and attack agents.", "result": "Defenders can generally clear infiltrations within one or two timesteps after exploitation. Certain actions are found to be between 40% and 99% ineffective. Decoy services block up to 94% of exploits that would grant privileged access.", "conclusion": "The analysis provides insights into the interpretation of agent behaviors in cyber defense scenarios, highlighting the importance of certain actions and the effectiveness of decoy services. The authors also discuss the realism of the challenge and improvements made in CAGE Challenge 4."}}
{"id": "2506.08218", "pdf": "https://arxiv.org/pdf/2506.08218", "abs": "https://arxiv.org/abs/2506.08218", "authors": ["Alan Mills", "Jonathan White", "Phil Legg"], "title": "gh0stEdit: Exploiting Layer-Based Access Vulnerability Within Docker Container Images", "categories": ["cs.CR"], "comment": null, "summary": "Containerisation is a popular deployment process for application-level\nvirtualisation using a layer-based approach. Docker is a leading provider of\ncontainerisation, and through the Docker Hub, users can supply Docker images\nfor sharing and re-purposing popular software application containers. Using a\ncombination of in-built inspection commands, publicly displayed image layer\ncontent, and static image scanning, Docker images are designed to ensure end\nusers can clearly assess the content of the image before running them. In this\npaper we present \\textbf{\\textit{gh0stEdit}}, a vulnerability that\nfundamentally undermines the integrity of Docker images and subverts the\nassumed trust and transparency they utilise. The use of gh0stEdit allows an\nattacker to maliciously edit Docker images, in a way that is not shown within\nthe image history, hierarchy or commands. This attack can also be carried out\nagainst signed images (Docker Content Trust) without invalidating the image\nsignature. We present two use case studies for this vulnerability, and showcase\nhow gh0stEdit is able to poison an image in a way that is not picked up through\nstatic or dynamic scanning tools. Our attack case studies highlight the issues\nin the current approach to Docker image security and trust, and expose an\nattack method which could potentially be exploited in the wild without being\ndetected. To the best of our knowledge we are the first to provide detailed\ndiscussion on the exploit of this vulnerability.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u53d1\u73b0\u5e76\u5c55\u793a\u4e86\u4e00\u79cd\u540d\u4e3agh0stEdit\u7684\u6f0f\u6d1e\uff0c\u8be5\u6f0f\u6d1e\u53ef\u4ee5\u6076\u610f\u4fee\u6539Docker\u955c\u50cf\u800c\u4e0d\u7559\u4e0b\u75d5\u8ff9\uff0c\u751a\u81f3\u5bf9\u5df2\u7b7e\u540d\u955c\u50cf\u4e5f\u6709\u6548\u3002\u901a\u8fc7\u4e24\u4e2a\u653b\u51fb\u6848\u4f8b\u7814\u7a76\uff0c\u63ed\u793a\u4e86Docker\u955c\u50cf\u5728\u5b89\u5168\u548c\u4fe1\u4efb\u673a\u5236\u4e0a\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524dDocker\u955c\u50cf\u7684\u5b89\u5168\u6027\u548c\u900f\u660e\u6027\u4f9d\u8d56\u4e8e\u5176\u5386\u53f2\u8bb0\u5f55\u3001\u5c42\u7ea7\u7ed3\u6784\u548c\u547d\u4ee4\u663e\u793a\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u6f5c\u5728\u6df1\u5c42\u6b21\u7be1\u6539\u7684\u6709\u6548\u68c0\u6d4b\u624b\u6bb5\u3002", "method": "\u5229\u7528gh0stEdit\u6f0f\u6d1e\uff0c\u53ef\u4ee5\u5728\u4e0d\u88ab\u56fe\u50cf\u5386\u53f2\u3001\u5c42\u6b21\u7ed3\u6784\u6216\u547d\u4ee4\u663e\u793a\u7684\u60c5\u51b5\u4e0b\u6076\u610f\u7f16\u8f91Docker\u955c\u50cf\uff0c\u5e76\u4e14\u4e0d\u4f1a\u4f7f\u5df2\u7b7e\u540d\u56fe\u50cf\u7684\u7b7e\u540d\u5931\u6548\u3002", "result": "\u6210\u529f\u5c55\u793a\u4e86\u4e24\u79cd\u4f7f\u7528gh0stEdit\u8fdb\u884c\u955c\u50cf\u6295\u6bd2\u7684\u6848\u4f8b\uff0c\u8fd9\u4e9b\u7be1\u6539\u65e0\u6cd5\u901a\u8fc7\u9759\u6001\u6216\u52a8\u6001\u626b\u63cf\u5de5\u5177\u68c0\u6d4b\u5230\u3002", "conclusion": "gh0stEdit\u66b4\u9732\u4e86Docker\u955c\u50cf\u5b89\u5168\u4e0e\u4fe1\u4efb\u673a\u5236\u4e2d\u7684\u91cd\u5927\u7f3a\u9677\uff0c\u53ef\u80fd\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u88ab\u5229\u7528\u800c\u4e0d\u88ab\u5bdf\u89c9\uff0c\u8fd9\u662f\u9996\u6b21\u5bf9\u6b64\u6f0f\u6d1e\u8fdb\u884c\u8be6\u7ec6\u8ba8\u8bba\u3002"}}
{"id": "2506.08252", "pdf": "https://arxiv.org/pdf/2506.08252", "abs": "https://arxiv.org/abs/2506.08252", "authors": ["Amisha Srivastava", "Samit S. Miftah", "Hyunmin Kim", "Debjit Pal", "Kanad Basu"], "title": "PoSyn: Secure Power Side-Channel Aware Synthesis", "categories": ["cs.CR", "cs.AR"], "comment": null, "summary": "Power Side-Channel (PSC) attacks exploit power consumption patterns to\nextract sensitive information, posing risks to cryptographic operations crucial\nfor secure systems. Traditional countermeasures, such as masking, face\nchallenges including complex integration during synthesis, substantial area\noverhead, and susceptibility to optimization removal during logic synthesis. To\naddress these issues, we introduce PoSyn, a novel logic synthesis framework\ndesigned to enhance cryptographic hardware resistance against PSC attacks. Our\nmethod centers on optimal bipartite mapping of vulnerable RTL components to\nstandard cells from the technology library, aiming to minimize PSC leakage. By\nutilizing a cost function integrating critical characteristics from both the\nRTL design and the standard cell library, we strategically modify mapping\ncriteria during RTL-to-netlist conversion without altering design\nfunctionality. Furthermore, we theoretically establish that PoSyn minimizes\nmutual information leakage, strengthening its security against PSC\nvulnerabilities. We evaluate PoSyn across various cryptographic hardware\nimplementations, including AES, RSA, PRESENT, and post-quantum cryptographic\nalgorithms such as Saber and CRYSTALS-Kyber, at technology nodes of 65nm, 45nm,\nand 15nm. Experimental results demonstrate a substantial reduction in success\nrates for Differential Power Analysis (DPA) and Correlation Power Analysis\n(CPA) attacks, achieving lows of 3% and 6%, respectively. TVLA analysis further\nconfirms that synthesized netlists exhibit negligible leakage. Additionally,\ncompared to conventional countermeasures like masking and shuffling, PoSyn\nsignificantly lowers attack success rates, achieving reductions of up to 72%,\nwhile simultaneously enhancing area efficiency by as much as 3.79 times.", "AI": {"tldr": "Power Side-Channel (PSC) attacks use power consumption patterns to extract sensitive information. Traditional countermeasures face challenges. This paper introduces PoSyn, a novel logic synthesis framework designed to enhance cryptographic hardware resistance against PSC attacks. It centers on optimal bipartite mapping of vulnerable RTL components to standard cells from the technology library and utilizes a cost function integrating critical characteristics from both the RTL design and the standard cell library. Experimental results demonstrate a substantial reduction in success rates for Differential Power Analysis (DPA) and Correlation Power Analysis (CPA) attacks.", "motivation": "Traditional countermeasures for PSC attacks face challenges including complex integration during synthesis, substantial area overhead, and susceptibility to optimization removal during logic synthesis.", "method": "PoSyn is a novel logic synthesis framework that uses optimal bipartite mapping of vulnerable RTL components to standard cells from the technology library. It utilizes a cost function integrating critical characteristics from both the RTL design and the standard cell library.", "result": "Experimental results demonstrate a substantial reduction in success rates for Differential Power Analysis (DPA) and Correlation Power Analysis (CPA) attacks, achieving lows of 3% and 6%, respectively. TVLA analysis further confirms that synthesized netlists exhibit negligible leakage. Additionally, compared to conventional countermeasures like masking and shuffling, PoSyn significantly lowers attack success rates, achieving reductions of up to 72%, while simultaneously enhancing area efficiency by as much as 3.79 times.", "conclusion": "PoSyn enhances cryptographic hardware resistance against PSC attacks by minimizing mutual information leakage and strategically modifying mapping criteria during RTL-to-netlist conversion without altering design functionality."}}
{"id": "2506.08026", "pdf": "https://arxiv.org/pdf/2506.08026", "abs": "https://arxiv.org/abs/2506.08026", "authors": ["Xibai Wang"], "title": "TIP-Search: Time-Predictable Inference Scheduling for Market Prediction under Uncertain Load", "categories": ["cs.AI", "cs.LG", "cs.SY", "eess.SY", "q-fin.CP"], "comment": null, "summary": "This paper proposes TIP-Search, a time-predictable inference scheduling\nframework for real-time market prediction under uncertain workloads. Motivated\nby the strict latency demands in high-frequency financial systems, TIP-Search\ndynamically selects a deep learning model from a heterogeneous pool, aiming to\nmaximize predictive accuracy while satisfying per-task deadline constraints.\nOur approach profiles latency and generalization performance offline, then\nperforms online task-aware selection without relying on explicit input domain\nlabels. We evaluate TIP-Search on three real-world limit order book datasets\n(FI-2010, Binance BTC/USDT, LOBSTER AAPL) and demonstrate that it outperforms\nstatic baselines with up to 8.5% improvement in accuracy and 100% deadline\nsatisfaction. Our results highlight the effectiveness of TIP-Search in robust\nlow-latency financial inference under uncertainty.", "AI": {"tldr": "This paper proposes TIP-Search, a framework for real-time market prediction which can improve accuracy by 8.5% and ensure 100% deadline satisfaction.", "motivation": "Strict latency demands in high-frequency financial systems motivate the need for a time-predictable inference scheduling framework.", "method": "TIP-Search dynamically selects deep learning models from a heterogeneous pool based on offline profiling of latency and generalization performance, with online task-aware selection not needing explicit input domain labels.", "result": "TIP-Search outperforms static baselines with up to 8.5% improvement in accuracy and achieves 100% deadline satisfaction when evaluated on three real-world datasets.", "conclusion": "TIP-Search is effective for robust low-latency financial inference under uncertain workloads."}}
{"id": "2506.08018", "pdf": "https://arxiv.org/pdf/2506.08018", "abs": "https://arxiv.org/abs/2506.08018", "authors": ["Fei Li", "Song Liu", "Weiguo Wu", "Shiqiang Nie", "Jinyu Wang"], "title": "KVmix: Gradient-Based Layer Importance-Aware Mixed-Precision Quantization for KV Cache", "categories": ["cs.LG", "cs.AI", "03B65 ((Primary))", "I.2.7"], "comment": "14 pages, 8 figures, 4 tables", "summary": "The high memory demands of the Key-Value (KV) Cache during the inference of\nLarge Language Models (LLMs) severely restrict their deployment in\nresource-constrained platforms. Quantization can effectively alleviate the\nmemory pressure caused by KV Cache. However, existing methods either rely on\nstatic one-size-fits-all precision allocation or fail to dynamically prioritize\ncritical KV in long-context tasks, forcing memory-accuracy-throughput\ntradeoffs. In this work, we propose a novel mixed-precision quantization method\nfor KV Cache named KVmix. KVmix leverages gradient-based importance analysis to\nevaluate how individual Key and Value projection matrices affect the model\nloss, enabling layer-specific bit-width allocation for mix-precision\nquantization. It dynamically prioritizes higher precision for important layers\nwhile aggressively quantizing less influential ones, achieving a tunable\nbalance between accuracy and efficiency. KVmix also introduces a dynamic\nlong-context optimization strategy that adaptively keeps full-precision KV\npairs for recent pivotal tokens and compresses older ones, achieving\nhigh-quality sequence generation with low memory usage. Additionally, KVmix\nprovides efficient low-bit quantization and CUDA kernels to optimize\ncomputational overhead. On LLMs such as Llama and Mistral, KVmix achieves\nnear-lossless inference performance with extremely low quantization\nconfiguration (Key 2.19bit Value 2.38bit), while delivering a remarkable 4.9x\nmemory compression and a 5.3x speedup in inference throughput.", "AI": {"tldr": "In this paper, KVmix is proposed to address the memory demands of the Key-Value (KV) Cache during LLM inference via a novel mixed-precision quantization method. It achieves near-lossless inference performance with significant memory compression and speedup.", "motivation": "The motivation of this work is to alleviate the high memory demands of the Key-Value (KV) Cache during the inference of Large Language Models (LLMs), particularly in resource-constrained platforms. Existing methods either use static precision allocation or fail to dynamically prioritize critical KV in long-context tasks, leading to suboptimal tradeoffs between memory, accuracy, and throughput.", "method": "The proposed method, KVmix, is a novel mixed-precision quantization approach for KV Cache. It uses gradient-based importance analysis to evaluate the impact of individual Key and Value projection matrices on model loss, allowing layer-specific bit-width allocation. Additionally, KVmix introduces a dynamic long-context optimization strategy that keeps full-precision KV pairs for recent pivotal tokens and compresses older ones. Efficient low-bit quantization and CUDA kernels are also provided to reduce computational overhead.", "result": "On LLMs such as Llama and Mistral, KVmix achieves near-lossless inference performance with an extremely low quantization configuration (Key 2.19bit, Value 2.38bit). It delivers a remarkable 4.9x memory compression and a 5.3x speedup in inference throughput.", "conclusion": "KVmix successfully addresses the memory challenges associated with KV Cache during LLM inference by providing a tunable balance between accuracy and efficiency. Its dynamic prioritization and efficient quantization techniques make it suitable for deployment in resource-constrained environments."}}
{"id": "2506.08320", "pdf": "https://arxiv.org/pdf/2506.08320", "abs": "https://arxiv.org/abs/2506.08320", "authors": ["Vivek Vaidya", "Aditya Patwardhan", "Ashish Kundu"], "title": "How Good LLM-Generated Password Policies Are?", "categories": ["cs.CR", "cs.AI"], "comment": "11 pages, 2 Tables, 9 figures, 3 Algorithms", "summary": "Generative AI technologies, particularly Large Language Models (LLMs), are\nrapidly being adopted across industry, academia, and government sectors, owing\nto their remarkable capabilities in natural language processing. However,\ndespite their strengths, the inconsistency and unpredictability of LLM outputs\npresent substantial challenges, especially in security-critical domains such as\naccess control. One critical issue that emerges prominently is the consistency\nof LLM-generated responses, which is paramount for ensuring secure and reliable\noperations.\n  In this paper, we study the application of LLMs within the context of\nCybersecurity Access Control Systems. Specifically, we investigate the\nconsistency and accuracy of LLM-generated password policies, translating\nnatural language prompts into executable pwquality.conf configuration files.\nOur experimental methodology adopts two distinct approaches: firstly, we\nutilize pre-trained LLMs to generate configuration files purely from natural\nlanguage prompts without additional guidance. Secondly, we provide these models\nwith official pwquality.conf documentation to serve as an informative baseline.\nWe systematically assess the soundness, accuracy, and consistency of these\nAI-generated configurations. Our findings underscore significant challenges in\nthe current generation of LLMs and contribute valuable insights into refining\nthe deployment of LLMs in Access Control Systems.", "AI": {"tldr": "Generative AI, especially LLMs, despite their strengths in natural language processing, face challenges with output inconsistency and unpredictability. This paper examines the use of LLMs for generating password policies in Cybersecurity Access Control Systems, assessing soundness, accuracy, and consistency through two approaches.", "motivation": "To address the inconsistency and unpredictability issues of LLM outputs, particularly focusing on their application in security-critical domains such as access control systems.", "method": "The study uses two methods to generate password policies: one involves using pre-trained LLMs with only natural language prompts, and the other provides the models with official pwquality.conf documentation as guidance.", "result": "The research found significant challenges with the current generation of LLMs when generating configurations, highlighting areas that need improvement.", "conclusion": "LLMs present substantial challenges in consistency and reliability for access control systems, necessitating further refinement before deployment in such critical domains."}}
{"id": "2506.08098", "pdf": "https://arxiv.org/pdf/2506.08098", "abs": "https://arxiv.org/abs/2506.08098", "authors": ["Akash Vishwakarma", "Hojin Lee", "Mohith Suresh", "Priyam Shankar Sharma", "Rahul Vishwakarma", "Sparsh Gupta", "Yuvraj Anupam Chauhan"], "title": "Cognitive Weave: Synthesizing Abstracted Knowledge with a Spatio-Temporal Resonance Graph", "categories": ["cs.AI"], "comment": null, "summary": "The emergence of capable large language model (LLM) based agents necessitates\nmemory architectures that transcend mere data storage, enabling continuous\nlearning, nuanced reasoning, and dynamic adaptation. Current memory systems\noften grapple with fundamental limitations in structural flexibility, temporal\nawareness, and the ability to synthesize higher-level insights from raw\ninteraction data. This paper introduces Cognitive Weave, a novel memory\nframework centered around a multi-layered spatio-temporal resonance graph\n(STRG). This graph manages information as semantically rich insight particles\n(IPs), which are dynamically enriched with resonance keys, signifiers, and\nsituational imprints via a dedicated semantic oracle interface (SOI). These IPs\nare interconnected through typed relational strands, forming an evolving\nknowledge tapestry. A key component of Cognitive Weave is the cognitive\nrefinement process, an autonomous mechanism that includes the synthesis of\ninsight aggregates (IAs) condensed, higher-level knowledge structures derived\nfrom identified clusters of related IPs. We present comprehensive experimental\nresults demonstrating Cognitive Weave's marked enhancement over existing\napproaches in long-horizon planning tasks, evolving question-answering\nscenarios, and multi-session dialogue coherence. The system achieves a notable\n34% average improvement in task completion rates and a 42% reduction in mean\nquery latency when compared to state-of-the-art baselines. Furthermore, this\npaper explores the ethical considerations inherent in such advanced memory\nsystems, discusses the implications for long-term memory in LLMs, and outlines\npromising future research trajectories.", "AI": {"tldr": "This paper introduces Cognitive Weave, a novel memory framework based on a multi-layered spatio-temporal resonance graph (STRG) that manages information as insight particles interconnected through typed relational strands. It includes a cognitive refinement process for synthesizing higher-level knowledge structures and shows significant improvements in long-horizon planning tasks, question-answering scenarios, and dialogue coherence.", "motivation": "The motivation of this paper is to address the limitations of current memory systems in terms of structural flexibility, temporal awareness, and the ability to synthesize higher-level insights from raw interaction data for capable large language model (LLM) based agents.", "method": "The method involves introducing Cognitive Weave, which utilizes a multi-layered spatio-temporal resonance graph (STRG) to manage information as semantically rich insight particles (IPs). These IPs are dynamically enriched via a semantic oracle interface (SOI) and interconnected through typed relational strands. The system also features a cognitive refinement process for synthesizing insight aggregates (IAs).", "result": "Experimental results show a 34% average improvement in task completion rates and a 42% reduction in mean query latency compared to state-of-the-art baselines in long-horizon planning tasks, evolving question-answering scenarios, and multi-session dialogue coherence.", "conclusion": "Cognitive Weave demonstrates marked enhancement over existing approaches in various tasks and raises important ethical considerations for advanced memory systems in LLMs, while outlining future research trajectories."}}
{"id": "2506.08019", "pdf": "https://arxiv.org/pdf/2506.08019", "abs": "https://arxiv.org/abs/2506.08019", "authors": ["Andrew Wells", "Geraldine Henningsen", "Brice Bolane Tchinde Kengne"], "title": "Gridding Forced Displacement using Semi-Supervised Learning", "categories": ["cs.LG", "cs.CV", "cs.CY"], "comment": null, "summary": "We present a semi-supervised approach that disaggregates refugee statistics\nfrom administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan\nAfrican countries. By integrating UNHCR's ProGres registration data with\nsatellite-derived building footprints from Google Open Buildings and location\ncoordinates from OpenStreetMap Populated Places, our label spreading algorithm\ncreates spatially explicit refugee statistics at high granularity.This\nmethodology achieves 92.9% average accuracy in placing over 10 million refugee\nobservations into appropriate grid cells, enabling the identification of\nlocalized displacement patterns previously obscured in broader regional and\nnational statistics. The resulting high-resolution dataset provides a\nfoundation for a deeper understanding of displacement drivers.", "AI": {"tldr": "This paper proposes a semi-supervised method to disaggregate refugee statistics from administrative boundaries to 0.5-degree grid cells across 25 Sub-Saharan African countries, achieving 92.9% average accuracy.", "motivation": "The motivation of this paper is to provide high granularity and spatially explicit refugee statistics by disaggregating the data from administrative boundaries, which can help identify localized displacement patterns previously obscured in broader regional and national statistics.", "method": "The method involves integrating UNHCR's ProGres registration data with satellite-derived building footprints from Google Open Buildings and location coordinates from OpenStreetMap Populated Places. A label spreading algorithm is then used to create spatially explicit refugee statistics at high granularity.", "result": "This methodology achieves 92.9% average accuracy in placing over 10 million refugee observations into appropriate grid cells.", "conclusion": "The resulting high-resolution dataset provides a foundation for a deeper understanding of displacement drivers."}}
{"id": "2506.08330", "pdf": "https://arxiv.org/pdf/2506.08330", "abs": "https://arxiv.org/abs/2506.08330", "authors": ["Kato Mivule", "Kenneth Hopkinson"], "title": "Distortion Search, A Web Search Privacy Heuristic", "categories": ["cs.CR"], "comment": "11 pages, 11 figures, Future Technologies Conference (FTC) 2017", "summary": "Search engines have vast technical capabilities to retain Internet search\nlogs for each user and thus present major privacy vulnerabilities to both\nindividuals and organizations in revealing user intent. Additionally, many of\nthe web search privacy enhancing tools available today require that the user\ntrusts a third party, which make confidentiality of user intent even more\nchallenging. The user is left at the mercy of the third party without the\ncontrol over his or her own privacy. In this article, we suggest a user-centric\nheuristic, Distortion Search, a web search query privacy methodology that works\nby the formation of obfuscated search queries via the permutation of query\nkeyword categories, and by strategically applying k-anonymised web navigational\nclicks on URLs and Ads to generate a distorted user profile and thus providing\nspecific user intent and query confidentiality. We provide empirical results\nvia the evaluation of distorted web search queries in terms of retrieved search\nresults and the resulting web ads from search engines. Preliminary experimental\nresults indicate that web search query and specific user intent privacy might\nbe achievable from the user side without the involvement of the search engine\nor other third parties.", "AI": {"tldr": "\u901a\u8fc7\u7528\u6237\u4e2d\u5fc3\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5Distortion Search\uff0c\u53ef\u4ee5\u5728\u4e0d\u4f9d\u8d56\u641c\u7d22\u5f15\u64ce\u6216\u5176\u4ed6\u7b2c\u4e09\u65b9\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\u548c\u7279\u5b9a\u7528\u6237\u610f\u56fe\u7684\u9690\u79c1\u4fdd\u62a4\u3002", "motivation": "\u5f53\u524d\u641c\u7d22\u5f15\u64ce\u80fd\u591f\u8bb0\u5f55\u7528\u6237\u7684\u641c\u7d22\u65e5\u5fd7\uff0c\u5b58\u5728\u6cc4\u9732\u7528\u6237\u610f\u56fe\u7684\u91cd\u5927\u9690\u79c1\u6f0f\u6d1e\u3002\u6b64\u5916\uff0c\u73b0\u6709\u7684\u8bb8\u591a\u7f51\u7edc\u641c\u7d22\u9690\u79c1\u589e\u5f3a\u5de5\u5177\u9700\u8981\u7528\u6237\u4fe1\u4efb\u7b2c\u4e09\u65b9\uff0c\u589e\u52a0\u4e86\u7528\u6237\u610f\u56fe\u4fdd\u5bc6\u7684\u96be\u5ea6\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDistortion Search\u7684\u7528\u6237\u4e2d\u5fc3\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df7\u6dc6\u641c\u7d22\u5173\u952e\u8bcd\u7c7b\u522b\u3001\u5e94\u7528k-\u533f\u540d\u5316\u7684\u7f51\u7edc\u70b9\u51fb\u7b56\u7565\uff0c\u751f\u6210\u626d\u66f2\u7684\u7528\u6237\u753b\u50cf\u4ee5\u4fdd\u62a4\u7528\u6237\u610f\u56fe\u548c\u67e5\u8be2\u9690\u79c1\u3002", "result": "\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u8bc4\u4f30\u88ab\u626d\u66f2\u7684\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\u5728\u68c0\u7d22\u7ed3\u679c\u548c\u76f8\u5173\u5e7f\u544a\u65b9\u9762\u7684\u8868\u73b0\uff0c\u8bc1\u660e\u4e86\u5728\u7528\u6237\u7aef\u5b9e\u73b0\u7f51\u7edc\u641c\u7d22\u67e5\u8be2\u548c\u7279\u5b9a\u7528\u6237\u610f\u56fe\u9690\u79c1\u4fdd\u62a4\u7684\u53ef\u80fd\u6027\u3002", "conclusion": "Distortion Search\u65b9\u6cd5\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u4f9d\u8d56\u641c\u7d22\u5f15\u64ce\u6216\u7b2c\u4e09\u65b9\u7684\u9690\u79c1\u4fdd\u62a4\u624b\u6bb5\uff0c\u589e\u5f3a\u4e86\u7528\u6237\u5bf9\u81ea\u8eab\u9690\u79c1\u7684\u63a7\u5236\u80fd\u529b\u3002"}}
{"id": "2506.08119", "pdf": "https://arxiv.org/pdf/2506.08119", "abs": "https://arxiv.org/abs/2506.08119", "authors": ["Subhrangshu Nandi", "Arghya Datta", "Nikhil Vichare", "Indranil Bhattacharya", "Huzefa Raja", "Jing Xu", "Shayan Ray", "Giuseppe Carenini", "Abhi Srivastava", "Aaron Chan", "Man Ho Woo", "Amar Kandola", "Brandon Theresa", "Francesco Carbone"], "title": "SOP-Bench: Complex Industrial SOPs for Evaluating LLM Agents", "categories": ["cs.AI"], "comment": "Under review", "summary": "Large Language Models (LLMs) demonstrate impressive general-purpose reasoning\nand problem-solving abilities. However, they struggle with executing complex,\nlong-horizon workflows that demand strict adherence to Standard Operating\nProcedures (SOPs), a critical requirement for real-world industrial automation.\nDespite this need, there is a lack of public benchmarks that reflect the\ncomplexity, structure, and domain-specific nuances of SOPs. To address this, we\npresent three main contributions. First, we introduce a synthetic data\ngeneration framework to create realistic, industry-grade SOPs that rigorously\ntest the planning, reasoning, and tool-use capabilities of LLM-based agents.\nSecond, using this framework, we develop SOP-Bench, a benchmark of over 1,800\ntasks across 10 industrial domains, each with APIs, tool interfaces, and\nhuman-validated test cases. Third, we evaluate two prominent agent\narchitectures: Function-Calling and ReAct Agents, on SOP-Bench, observing\naverage success rates of only 27% and 48%, respectively. Remarkably, when the\ntool registry is much larger than necessary, agents invoke incorrect tools\nnearly 100% of the time. These findings underscore a substantial gap between\ncurrent agentic capabilities of LLMs and the demands of automating real-world\nSOPs. Performance varies significantly by task and domain, highlighting the\nneed for domain-specific benchmarking and architectural choices before\ndeployment. SOP-Bench is publicly available at\nhttp://sop-bench.s3-website-us-west-2.amazonaws.com/. We also release the\nprompts underpinning the data generation framework to support new\ndomain-specific SOP benchmarks. We invite the community to extend SOP-Bench\nwith SOPs from their industrial domains.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6267\u884c\u590d\u6742\u7684\u3001\u9700\u8981\u4e25\u683c\u9075\u5faa\u6807\u51c6\u64cd\u4f5c\u7a0b\u5e8f\uff08SOP\uff09\u7684\u5de5\u4f5c\u6d41\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e09\u4e2a\u8d21\u732e\uff1a1) \u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\u4ee5\u521b\u5efa\u73b0\u5b9e\u7684\u884c\u4e1a\u7ea7SOP\uff1b2) SOP-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u8d85\u8fc71,800\u4e2a\u4efb\u52a1\uff1b3) \u5bf9\u4e24\u79cd\u4ee3\u7406\u67b6\u6784\u8fdb\u884c\u8bc4\u4f30\uff0c\u53d1\u73b0\u5f53\u524dLLM\u7684\u4ee3\u7406\u80fd\u529b\u4e0e\u5b9e\u9645\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u6027\u80fd\u56e0\u4efb\u52a1\u548c\u9886\u57df\u800c\u5f02\uff0c\u5f3a\u8c03\u4e86\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u548c\u67b6\u6784\u9009\u62e9\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c55\u793a\u4e86\u5f3a\u5927\u7684\u901a\u7528\u63a8\u7406\u548c\u95ee\u9898\u89e3\u51b3\u80fd\u529b\uff0c\u4f46\u5728\u9700\u8981\u4e25\u683c\u9075\u5b88\u6807\u51c6\u64cd\u4f5c\u7a0b\u5e8f\uff08SOP\uff09\u7684\u590d\u6742\u3001\u957f\u671f\u5de5\u4f5c\u6d41\u7a0b\u4e2d\u8868\u73b0\u4e0d\u4f73\u3002\u6b64\u5916\uff0c\u7f3a\u4e4f\u53cd\u6620SOP\u590d\u6742\u6027\u3001\u7ed3\u6784\u548c\u9886\u57df\u7279\u5b9a\u7ec6\u5fae\u5dee\u522b\u7684\u516c\u5f00\u57fa\u51c6\u3002", "method": "1. \u63d0\u51fa\u5408\u6210\u6570\u636e\u751f\u6210\u6846\u67b6\u4ee5\u521b\u5efa\u73b0\u5b9e\u7684\u884c\u4e1a\u7ea7SOP\uff1b2. \u4f7f\u7528\u8be5\u6846\u67b6\u5f00\u53d1SOP-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5305\u542b\u8d85\u8fc71,800\u4e2a\u8de810\u4e2a\u5de5\u4e1a\u9886\u57df\u7684\u4efb\u52a1\uff0c\u6bcf\u4e2a\u4efb\u52a1\u90fd\u914d\u6709API\u3001\u5de5\u5177\u63a5\u53e3\u548c\u4eba\u5de5\u9a8c\u8bc1\u7684\u6d4b\u8bd5\u7528\u4f8b\uff1b3. \u5728SOP-Bench\u4e0a\u8bc4\u4f30Function-Calling\u548cReAct Agents\u4e24\u79cd\u4ee3\u7406\u67b6\u6784\u7684\u6027\u80fd\u3002", "result": "Function-Calling\u548cReAct Agents\u7684\u5e73\u5747\u6210\u529f\u7387\u5206\u522b\u4e3a27%\u548c48%\u3002\u5f53\u5de5\u5177\u6ce8\u518c\u8868\u8fdc\u5927\u4e8e\u5fc5\u8981\u65f6\uff0c\u4ee3\u7406\u51e0\u4e4e100%\u8c03\u7528\u9519\u8bef\u5de5\u5177\u3002\u8fd9\u8868\u660e\u5f53\u524dLLM\u7684\u4ee3\u7406\u80fd\u529b\u4e0e\u81ea\u52a8\u5316\u771f\u5b9e\u4e16\u754cSOP\u7684\u9700\u6c42\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002\u6027\u80fd\u56e0\u4efb\u52a1\u548c\u9886\u57df\u800c\u5f02\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u5728\u90e8\u7f72\u524d\u8fdb\u884c\u9886\u57df\u7279\u5b9a\u57fa\u51c6\u6d4b\u8bd5\u548c\u67b6\u6784\u9009\u62e9\u7684\u5fc5\u8981\u6027\u3002SOP-Bench\u53ca\u5176\u6570\u636e\u751f\u6210\u6846\u67b6\u7684\u63d0\u793a\u5df2\u516c\u5f00\u53d1\u5e03\uff0c\u9080\u8bf7\u793e\u533a\u6269\u5c55SOP-Bench\u4ee5\u6db5\u76d6\u66f4\u591a\u5de5\u4e1a\u9886\u57df\u7684SOP\u3002"}}
{"id": "2506.08020", "pdf": "https://arxiv.org/pdf/2506.08020", "abs": "https://arxiv.org/abs/2506.08020", "authors": ["Zi-Ying Chen", "Chuan-Xian Ren", "Hong Yan"], "title": "Bi-level Unbalanced Optimal Transport for Partial Domain Adaptation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Partial domain adaptation (PDA) problem requires aligning cross-domain\nsamples while distinguishing the outlier classes for accurate knowledge\ntransfer. The widely used weighting framework tries to address the outlier\nclasses by introducing the reweighed source domain with a similar label\ndistribution to the target domain. However, the empirical modeling of weights\ncan only characterize the sample-wise relations, which leads to insufficient\nexploration of cluster structures, and the weights could be sensitive to the\ninaccurate prediction and cause confusion on the outlier classes. To tackle\nthese issues, we propose a Bi-level Unbalanced Optimal Transport (BUOT) model\nto simultaneously characterize the sample-wise and class-wise relations in a\nunified transport framework. Specifically, a cooperation mechanism between\nsample-level and class-level transport is introduced, where the sample-level\ntransport provides essential structure information for the class-level\nknowledge transfer, while the class-level transport supplies discriminative\ninformation for the outlier identification. The bi-level transport plan\nprovides guidance for the alignment process. By incorporating the label-aware\ntransport cost, the local transport structure is ensured and a fast computation\nformulation is derived to improve the efficiency. Extensive experiments on\nbenchmark datasets validate the competitiveness of BUOT.", "AI": {"tldr": "This paper proposes a Bi-level Unbalanced Optimal Transport (BUOT) model for Partial Domain Adaptation (PDA), which simultaneously characterizes sample-wise and class-wise relations in a unified transport framework.", "motivation": "The current weighting frameworks used in PDA have limitations in modeling the sample-wise relations, insufficient exploration of cluster structures, and sensitivity to inaccurate prediction causing confusion on outlier classes.", "method": "The BUOT model introduces a cooperation mechanism between sample-level and class-level transport. Sample-level transport provides structure information for class-level knowledge transfer while class-level transport supplies discriminative information for outlier identification. The model incorporates label-aware transport cost ensuring local transport structure and deriving fast computation formulation.", "result": "Extensive experiments on benchmark datasets validate the competitiveness of BUOT.", "conclusion": "The proposed BUOT model addresses the limitations of current methods by simultaneously characterizing sample-wise and class-wise relations, providing guidance for the alignment process, and improving efficiency."}}
{"id": "2506.08336", "pdf": "https://arxiv.org/pdf/2506.08336", "abs": "https://arxiv.org/abs/2506.08336", "authors": ["Li Changjiang", "Liang Jiacheng", "Cao Bochuan", "Chen Jinghui", "Wang Ting"], "title": "Your Agent Can Defend Itself against Backdoor Attacks", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": null, "summary": "Despite their growing adoption across domains, large language model\n(LLM)-powered agents face significant security risks from backdoor attacks\nduring training and fine-tuning. These compromised agents can subsequently be\nmanipulated to execute malicious operations when presented with specific\ntriggers in their inputs or environments. To address this pressing risk, we\npresent ReAgent, a novel defense against a range of backdoor attacks on\nLLM-based agents. Intuitively, backdoor attacks often result in inconsistencies\namong the user's instruction, the agent's planning, and its execution. Drawing\non this insight, ReAgent employs a two-level approach to detect potential\nbackdoors. At the execution level, ReAgent verifies consistency between the\nagent's thoughts and actions; at the planning level, ReAgent leverages the\nagent's capability to reconstruct the instruction based on its thought\ntrajectory, checking for consistency between the reconstructed instruction and\nthe user's instruction. Extensive evaluation demonstrates ReAgent's\neffectiveness against various backdoor attacks across tasks. For instance,\nReAgent reduces the attack success rate by up to 90\\% in database operation\ntasks, outperforming existing defenses by large margins. This work reveals the\npotential of utilizing compromised agents themselves to mitigate backdoor\nrisks.", "AI": {"tldr": "ReAgent is a novel defense mechanism against backdoor attacks on LLM-based agents, employing a two-level approach to detect inconsistencies in the agent's actions and thoughts, significantly reducing attack success rates.", "motivation": "Large language model-powered agents face significant security risks from backdoor attacks during training and fine-tuning, which can lead to malicious operations when triggered.", "method": "ReAgent uses a two-level approach: at the execution level, it verifies consistency between the agent's thoughts and actions; at the planning level, it reconstructs the instruction based on the agent's thought trajectory and checks for consistency with the user's instruction.", "result": "ReAgent effectively reduces the attack success rate by up to 90% in database operation tasks, outperforming existing defenses.", "conclusion": "This work highlights the potential of using compromised agents themselves to mitigate backdoor risks."}}
{"id": "2506.08134", "pdf": "https://arxiv.org/pdf/2506.08134", "abs": "https://arxiv.org/abs/2506.08134", "authors": ["Qiyao Wei", "Samuel Holt", "Jing Yang", "Markus Wulfmeier", "Mihaela van der Schaar"], "title": "The AI Imperative: Scaling High-Quality Peer Review in Machine Learning", "categories": ["cs.AI", "cs.CY", "68T50, 68T07", "I.2.7; H.5.3"], "comment": "18 pages, 3 figures. Position paper", "summary": "Peer review, the bedrock of scientific advancement in machine learning (ML),\nis strained by a crisis of scale. Exponential growth in manuscript submissions\nto premier ML venues such as NeurIPS, ICML, and ICLR is outpacing the finite\ncapacity of qualified reviewers, leading to concerns about review quality,\nconsistency, and reviewer fatigue. This position paper argues that AI-assisted\npeer review must become an urgent research and infrastructure priority. We\nadvocate for a comprehensive AI-augmented ecosystem, leveraging Large Language\nModels (LLMs) not as replacements for human judgment, but as sophisticated\ncollaborators for authors, reviewers, and Area Chairs (ACs). We propose\nspecific roles for AI in enhancing factual verification, guiding reviewer\nperformance, assisting authors in quality improvement, and supporting ACs in\ndecision-making. Crucially, we contend that the development of such systems\nhinges on access to more granular, structured, and ethically-sourced peer\nreview process data. We outline a research agenda, including illustrative\nexperiments, to develop and validate these AI assistants, and discuss\nsignificant technical and ethical challenges. We call upon the ML community to\nproactively build this AI-assisted future, ensuring the continued integrity and\nscalability of scientific validation, while maintaining high standards of peer\nreview.", "AI": {"tldr": "Peer review in machine learning is facing challenges due to the increasing number of submissions and limited reviewer capacity. This paper argues for AI-assisted peer review as a solution, proposing a comprehensive ecosystem leveraging Large Language Models to assist authors, reviewers, and Area Chairs. The development of such systems requires access to structured peer review data and faces technical and ethical challenges.", "motivation": "The motivation behind this paper is the crisis of scale in peer review within machine learning, with exponential growth in manuscript submissions outpacing the capacity of qualified reviewers, leading to concerns about review quality, consistency, and reviewer fatigue.", "method": "The method involves advocating for an AI-augmented ecosystem that uses Large Language Models as collaborators rather than replacements for human judgment. Specific roles for AI are proposed in factual verification, guiding reviewer performance, assisting authors, and supporting decision-making for Area Chairs.", "result": "The result would be a more scalable and consistent peer review process, ensuring the integrity and high standards of scientific validation through AI assistance.", "conclusion": "The conclusion calls upon the ML community to proactively build an AI-assisted future for peer review, addressing technical and ethical challenges while maintaining high standards of peer review."}}
{"id": "2506.08021", "pdf": "https://arxiv.org/pdf/2506.08021", "abs": "https://arxiv.org/abs/2506.08021", "authors": ["Weihao Zou", "Weibing Feng", "Pin Wu"], "title": "FlowBERT: Prompt-tuned BERT for variable flow field prediction", "categories": ["cs.LG", "physics.flu-dyn"], "comment": null, "summary": "This study proposes a universal flow field prediction framework based on\nknowledge transfer\n  from large language model (LLM), addressing the high computational costs of\ntraditional\n  computational fluid dynamics (CFD) methods and the limited cross-condition\ntransfer capability\n  of existing deep learning models. The framework innovatively integrates\nProper Orthogonal\n  Decomposition (POD) dimensionality reduction with fine-tuning strategies for\npretrained LLM,\n  where POD facilitates compressed representation of flow field features while\nthe fine-tuned model\n  learns to encode system dynamics in state space. To enhance the model's\nadaptability to flow field\n  data, we specifically designed fluid dynamics-oriented text templates that\nimprove predictive\n  performance through enriched contextual semantic information. Experimental\nresults demonstrate\n  that our framework outperforms conventional Transformer models in few-shot\nlearning scenarios while\n  exhibiting exceptional generalization across various inflow conditions and\nairfoil geometries.\n  Ablation studies reveal the contributions of key components in the FlowBERT\narchitecture. Compared\n  to traditional Navier-Stokes equation solvers requiring hours of computation,\nour approach reduces\n  prediction time to seconds while maintaining over 90% accuracy. The developed\nknowledge transfer\n  paradigm establishes a new direction for rapid fluid dynamics prediction,\nwith potential\n  applications extending to aerodynamic optimization, flow control, and other\nengineering domains.", "AI": {"tldr": "This study proposes a flow field prediction framework based on knowledge transfer from large language models (LLMs), integrating Proper Orthogonal Decomposition (POD) and fine-tuning strategies for pretrained LLMs. Fluid dynamics-oriented text templates are used to improve performance. The framework outperforms conventional models in few-shot learning scenarios, generalizes well across various inflow conditions and geometries, and reduces prediction time significantly while maintaining high accuracy.", "motivation": "To address the high computational costs of traditional CFD methods and the limited cross-condition transfer capability of existing deep learning models.", "method": "The framework integrates Proper Orthogonal Decomposition (POD) dimensionality reduction with fine-tuning strategies for pretrained LLMs. Fluid dynamics-oriented text templates are specifically designed to enrich contextual semantic information.", "result": "The framework outperforms conventional Transformer models in few-shot learning scenarios, exhibits exceptional generalization across various inflow conditions and airfoil geometries, and reduces prediction time to seconds while maintaining over 90% accuracy.", "conclusion": "The developed knowledge transfer paradigm establishes a new direction for rapid fluid dynamics prediction with potential applications in aerodynamic optimization, flow control, and other engineering domains."}}
{"id": "2506.08445", "pdf": "https://arxiv.org/pdf/2506.08445", "abs": "https://arxiv.org/abs/2506.08445", "authors": ["Ji Hyuk Jung", "Mi Yeon Hong", "Ji Won Yoon"], "title": "GPS Spoofing Attacks on AI-based Navigation Systems with Obstacle Avoidance in UAV", "categories": ["cs.CR"], "comment": null, "summary": "Recently, approaches using Deep Reinforcement Learning (DRL) have been\nproposed to solve UAV navigation systems in complex and unknown environments.\nHowever, despite extensive research and attention, systematic studies on\nvarious security aspects have not yet been conducted. Therefore, in this paper,\nwe conduct research on security vulnerabilities in DRL-based navigation\nsystems, particularly focusing on GPS spoofing attacks against the system. Many\nrecent basic DRL-based navigation systems fundamentally share an efficient\nstructure. This paper presents an attack model that operates through GPS\nspoofing attacks briefly modeling the range of spoofing attack against EKF\nsensor fusion of PX4 autopilot, and combine this with the DRL-based system to\ndesign attack scenarios that are closer to reality. Finally, this paper\nexperimentally demonstrated that attacks are possible both in the basic DRL\nsystem and in attack models combining the DRL system with PX4 autopilot system.", "AI": {"tldr": "The paper explores security vulnerabilities in DRL-based UAV navigation systems, focusing on GPS spoofing attacks. It presents an attack model combining GPS spoofing with DRL systems and experimentally demonstrates the feasibility of such attacks.", "motivation": "To address the lack of systematic studies on security aspects in DRL-based UAV navigation systems, particularly concerning GPS spoofing attacks.", "method": "Develop an attack model that incorporates GPS spoofing against Extended Kalman Filter (EKF) sensor fusion in PX4 autopilot systems, combined with DRL-based navigation systems to create realistic attack scenarios.", "result": "Experimental results show that GPS spoofing attacks are possible both in basic DRL systems and in more complex systems integrated with PX4 autopilot.", "conclusion": "DRL-based UAV navigation systems are vulnerable to GPS spoofing attacks, highlighting the need for further research into securing these systems."}}
{"id": "2506.08150", "pdf": "https://arxiv.org/pdf/2506.08150", "abs": "https://arxiv.org/abs/2506.08150", "authors": ["Arvid Becker", "Pedro Cabalar", "Martin Di\u00e9guez", "Javier Romero", "Susana Hahn", "Torsten Schaub"], "title": "Compiling Metric Temporal Answer Set Programming", "categories": ["cs.AI", "cs.LO", "I.2.4; I.2.8"], "comment": null, "summary": "We develop a computational approach to Metric Answer Set Programming (ASP) to\nallow for expressing quantitative temporal constrains, like durations and\ndeadlines. A central challenge is to maintain scalability when dealing with\nfine-grained timing constraints, which can significantly exacerbate ASP's\ngrounding bottleneck. To address this issue, we leverage extensions of ASP with\ndifference constraints, a simplified form of linear constraints, to handle\ntime-related aspects externally. Our approach effectively decouples metric ASP\nfrom the granularity of time, resulting in a solution that is unaffected by\ntime precision.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u4e00\u79cd\u8ba1\u7b97\u65b9\u6cd5\u6765\u89e3\u51b3\u5ea6\u91cfASP\u95ee\u9898\uff0c\u5141\u8bb8\u8868\u8fbe\u5b9a\u91cf\u7684\u65f6\u95f4\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u5dee\u5206\u7ea6\u675f\u6269\u5c55ASP\u4ee5\u4fdd\u6301\u53ef\u6269\u5c55\u6027\uff0c\u4ece\u800c\u89e3\u51b3\u4e86\u65f6\u95f4\u7c92\u5ea6\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u5904\u7406\u5e26\u6709\u5b9a\u91cf\u65f6\u95f4\u7ea6\u675f\u7684\u903b\u8f91\u7f16\u7a0b\u95ee\u9898\uff0c\u540c\u65f6\u907f\u514d\u56e0\u7ec6\u7c92\u5ea6\u65f6\u95f4\u7ea6\u675f\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u91c7\u7528ASP\u7684\u5dee\u5206\u7ea6\u675f\u6269\u5c55\uff0c\u5c06\u4e0e\u65f6\u95f4\u76f8\u5173\u7684\u95ee\u9898\u5916\u90e8\u5316\u5904\u7406\uff0c\u4ece\u800c\u89e3\u8026\u5ea6\u91cfASP\u548c\u65f6\u95f4\u7c92\u5ea6\u3002", "result": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e0d\u53d7\u65f6\u95f4\u7cbe\u5ea6\u5f71\u54cd\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u95f4\u7c92\u5ea6\u5e26\u6765\u7684\u53ef\u6269\u5c55\u6027\u95ee\u9898\u3002", "conclusion": "\u6b64\u65b9\u6cd5\u4e3a\u5904\u7406\u5e26\u6709\u65f6\u95f4\u7ea6\u675f\u7684\u903b\u8f91\u7f16\u7a0b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u7ec6\u7c92\u5ea6\u65f6\u95f4\u7ea6\u675f\u5e26\u6765\u7684\u6311\u6218\u3002"}}
{"id": "2506.08022", "pdf": "https://arxiv.org/pdf/2506.08022", "abs": "https://arxiv.org/abs/2506.08022", "authors": ["Chenxi Liu", "Tianyi Xiong", "Ruibo Chen", "Yihan Wu", "Junfeng Guo", "Tianyi Zhou", "Heng Huang"], "title": "Modality-Balancing Preference Optimization of Large Multimodal Models by Adversarial Negative Mining", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CV"], "comment": null, "summary": "The task adaptation and alignment of Large Multimodal Models (LMMs) have been\nsignificantly advanced by instruction tuning and further strengthened by recent\npreference optimization. Yet, most LMMs still suffer from severe modality\nimbalance during reasoning, i.e., outweighing language prior biases over visual\ninputs, which bottlenecks their generalization to downstream tasks and causes\nhallucinations. However, existing preference optimization approaches for LMMs\ndo not focus on restraining the internal biases of their Large Language Model\n(LLM) backbones when curating the training data. Moreover, they heavily rely on\noffline data and lack the capacity to explore diverse responses adaptive to\ndynamic distributional shifts during training. Meanwhile, Group Relative Policy\nOptimization (GRPO), a recent method using online-generated data and verified\nrewards to improve reasoning capabilities, remains largely underexplored in LMM\nalignment. In this paper, we propose a novel preference learning framework,\nModality-Balancing Preference Optimization (MBPO), to address the modality\nimbalance in LMMs. MBPO constructs a more effective offline preference dataset\nby generating hard negatives, i.e., rejected responses misled by LLM biases due\nto limited usage of visual information, through adversarial perturbation of\ninput images. Moreover, MBPO leverages the easy-to-verify nature of close-ended\ntasks to generate online responses with verified rewards. GRPO is then employed\nto train the model with offline-online hybrid data. Extensive experiments\ndemonstrate that MBPO can enhance LMM performance on challenging\nvision-language tasks and effectively reduce hallucinations.", "AI": {"tldr": "The paper proposes Modality-Balancing Preference Optimization (MBPO), a new framework to address modality imbalance in Large Multimodal Models (LMMs). MBPO constructs an improved offline preference dataset with hard negatives and uses online responses with verified rewards, employing GRPO for training. Experiments show MBPO enhances LMM performance and reduces hallucinations.", "motivation": "Current methods for aligning LMMs do not sufficiently address the issue of modality imbalance, where language biases outweigh visual inputs. Additionally, existing approaches rely on offline data and lack adaptability to dynamic changes during training.", "method": "MBPO generates hard negatives by adversarially perturbing input images to create rejected responses due to LLM biases. It also uses close-ended tasks to generate online responses with verified rewards, combining these with the offline data for training via GRPO.", "result": "Experiments indicate that MBPO improves LMM performance on complex vision-language tasks and effectively decreases hallucinations.", "conclusion": "MBPO is an effective solution to modality imbalance in LMMs, enhancing their generalization capabilities and reducing inaccuracies."}}
{"id": "2506.08482", "pdf": "https://arxiv.org/pdf/2506.08482", "abs": "https://arxiv.org/abs/2506.08482", "authors": ["Xingshuo Han", "Chen Ling", "Shiyi Yao", "Haozhao Wang", "Hangcheng Liu", "Yutong Wu", "Shengmin Xu", "Changhai Ou", "Xinyi Huang", "Tianwei Zhang"], "title": "One Patch to Rule Them All: Transforming Static Patches into Dynamic Attacks in the Physical World", "categories": ["cs.CR"], "comment": null, "summary": "Numerous methods have been proposed to generate physical adversarial patches\n(PAPs) against real-world machine learning systems. However, each existing PAP\ntypically supports only a single, fixed attack goal, and switching to a\ndifferent objective requires re-generating and re-deploying a new PAP. This\nrigidity limits their practicality in dynamic environments like autonomous\ndriving, where traffic conditions and attack goals can change rapidly. For\nexample, if no obstacles are present around the target vehicle, the attack may\nfail to cause meaningful consequences.\n  To overcome this limitation, we propose SwitchPatch, a novel PAP that is\nstatic yet enables dynamic and controllable attack outcomes based on real-time\nscenarios. Attackers can alter pre-defined conditions, e.g., by projecting\ndifferent natural-color lights onto SwitchPatch to seamlessly switch between\nattack goals. Unlike prior work, SwitchPatch does not require re-generation or\nre-deployment for different objectives, significantly reducing cost and\ncomplexity. Furthermore, SwitchPatch remains benign when the enabling\nconditions are absent, enhancing its stealth.\n  We evaluate SwitchPatch on two key tasks: traffic sign recognition\n(classification and detection) and depth estimation. First, we conduct\ntheoretical analysis and empirical studies to demonstrate the feasibility of\nSwitchPatch and explore how many goals it can support using techniques like\ncolor light projection and occlusion. Second, we perform simulation-based\nexperiments and ablation studies to verify its effectiveness and\ntransferability. Third, we conduct outdoor tests using a Unmanned Ground\nVehicle (UGV) to confirm its robustness in the physical world. Overall,\nSwitchPatch introduces a flexible and practical adversarial strategy that can\nbe adapted to diverse tasks and real-world conditions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7269\u7406\u5bf9\u6297\u8865\u4e01SwitchPatch\uff0c\u5b83\u5728\u9759\u6001\u6761\u4ef6\u4e0b\u80fd\u4f9d\u636e\u5b9e\u65f6\u573a\u666f\u5b9e\u73b0\u52a8\u6001\u548c\u53ef\u63a7\u7684\u653b\u51fb\u6548\u679c\u3002\u901a\u8fc7\u6539\u53d8\u9884\u5b9a\u4e49\u6761\u4ef6\uff08\u5982\u6295\u5f71\u4e0d\u540c\u81ea\u7136\u8272\u5149\uff09\uff0c\u65e0\u9700\u91cd\u65b0\u751f\u6210\u6216\u90e8\u7f72\u5373\u53ef\u5207\u6362\u653b\u51fb\u76ee\u6807\uff0c\u540c\u65f6\u5728\u65e0\u542f\u7528\u6761\u4ef6\u4e0b\u4fdd\u6301\u826f\u6027\uff0c\u589e\u5f3a\u4e86\u9690\u853d\u6027\u3002\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u4ea4\u901a\u6807\u5fd7\u8bc6\u522b\u548c\u6df1\u5ea6\u4f30\u8ba1\u4efb\u52a1\u4e2d\u7684\u53ef\u884c\u6027\u3001\u6709\u6548\u6027\u548c\u7269\u7406\u4e16\u754c\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u7269\u7406\u5bf9\u6297\u8865\u4e01\uff08PAPs\uff09\u53ea\u80fd\u652f\u6301\u5355\u4e00\u56fa\u5b9a\u7684\u653b\u51fb\u76ee\u6807\uff0c\u5728\u52a8\u6001\u73af\u5883\u4e2d\uff08\u5982\u81ea\u52a8\u9a7e\u9a76\uff09\u5b9e\u7528\u6027\u53d7\u9650\u3002\u4f8b\u5982\uff0c\u5f53\u76ee\u6807\u8f66\u8f86\u5468\u56f4\u65e0\u969c\u788d\u7269\u65f6\uff0c\u653b\u51fb\u53ef\u80fd\u65e0\u6cd5\u4ea7\u751f\u6709\u610f\u4e49\u7684\u540e\u679c\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u7075\u6d3b\u7684PAP\u6765\u9002\u5e94\u4e0d\u540c\u7684\u653b\u51fb\u76ee\u6807\u548c\u73af\u5883\u53d8\u5316\u3002", "method": "\u63d0\u51faSwitchPatch\uff0c\u4e00\u79cd\u9759\u6001\u5374\u80fd\u591f\u6839\u636e\u5b9e\u65f6\u573a\u666f\u5b9e\u73b0\u52a8\u6001\u548c\u53ef\u63a7\u653b\u51fb\u7ed3\u679c\u7684\u65b0\u65b9\u6cd5\u3002\u901a\u8fc7\u6539\u53d8\u9884\u5b9a\u4e49\u6761\u4ef6\uff08\u5982\u6295\u5f71\u4e0d\u540c\u81ea\u7136\u8272\u5f69\u7684\u5149\uff09\uff0c\u53ef\u4ee5\u65e0\u7f1d\u5207\u6362\u653b\u51fb\u76ee\u6807\uff0c\u800c\u65e0\u9700\u91cd\u65b0\u751f\u6210\u6216\u90e8\u7f72\u65b0\u7684PAP\u3002\u6b64\u5916\uff0cSwitchPatch\u5728\u672a\u6fc0\u6d3b\u6761\u4ef6\u4e0b\u8868\u73b0\u4e3a\u826f\u6027\uff0c\u4ece\u800c\u589e\u5f3a\u4e86\u9690\u853d\u6027\u3002", "result": "1. \u7406\u8bba\u5206\u6790\u4e0e\u5b9e\u8bc1\u7814\u7a76\u8bc1\u660e\u4e86SwitchPatch\u7684\u53ef\u884c\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u53ef\u4ee5\u901a\u8fc7\u989c\u8272\u6295\u5f71\u548c\u906e\u6321\u7b49\u6280\u672f\u652f\u6301\u7684\u653b\u51fb\u76ee\u6807\u6570\u91cf\u3002\n2. \u6a21\u62df\u5b9e\u9a8c\u548c\u6d88\u878d\u7814\u7a76\u9a8c\u8bc1\u4e86SwitchPatch\u7684\u6709\u6548\u6027\u548c\u53ef\u8fc1\u79fb\u6027\u3002\n3. \u5728\u65e0\u4eba\u5730\u9762\u8f66\u8f86\uff08UGV\uff09\u4e0a\u7684\u6237\u5916\u6d4b\u8bd5\u8868\u660eSwitchPatch\u5728\u7269\u7406\u4e16\u754c\u4e2d\u7684\u9c81\u68d2\u6027\u3002\n\u6574\u4f53\u800c\u8a00\uff0cSwitchPatch\u5c55\u793a\u51fa\u9002\u5e94\u591a\u79cd\u4efb\u52a1\u548c\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u7684\u80fd\u529b\u3002", "conclusion": "SwitchPatch\u662f\u4e00\u79cd\u7075\u6d3b\u4e14\u5b9e\u7528\u7684\u5bf9\u6297\u7b56\u7565\uff0c\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u751f\u6210\u6216\u90e8\u7f72\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u591a\u76ee\u6807\u653b\u51fb\uff0c\u9002\u5e94\u591a\u6837\u5316\u7684\u4efb\u52a1\u548c\u73b0\u5b9e\u6761\u4ef6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u5927\u7684\u7075\u6d3b\u6027\u548c\u66f4\u4f4e\u7684\u6210\u672c\u3002"}}
{"id": "2506.08306", "pdf": "https://arxiv.org/pdf/2506.08306", "abs": "https://arxiv.org/abs/2506.08306", "authors": ["Tuan Truong", "Rithwik Sudharsan", "Yibo Yang", "Peter Xiangyuan Ma", "Ruihan Yang", "Stephan Mandt", "Joshua S. Bloom"], "title": "AstroCompress: A benchmark dataset for multi-purpose compression of astronomical data", "categories": ["cs.AI", "astro-ph.IM"], "comment": "ICLR 2025 conference paper. See reviews at\n  https://openreview.net/forum?id=kQCHCkNk7s", "summary": "The site conditions that make astronomical observatories in space and on the\nground so desirable -- cold and dark -- demand a physical remoteness that leads\nto limited data transmission capabilities. Such transmission limitations\ndirectly bottleneck the amount of data acquired and in an era of costly modern\nobservatories, any improvements in lossless data compression has the potential\nscale to billions of dollars worth of additional science that can be\naccomplished on the same instrument. Traditional lossless methods for\ncompressing astrophysical data are manually designed. Neural data compression,\non the other hand, holds the promise of learning compression algorithms\nend-to-end from data and outperforming classical techniques by leveraging the\nunique spatial, temporal, and wavelength structures of astronomical images.\nThis paper introduces AstroCompress: a neural compression challenge for\nastrophysics data, featuring four new datasets (and one legacy dataset) with\n16-bit unsigned integer imaging data in various modes: space-based,\nground-based, multi-wavelength, and time-series imaging. We provide code to\neasily access the data and benchmark seven lossless compression methods (three\nneural and four non-neural, including all practical state-of-the-art\nalgorithms). Our results on lossless compression indicate that lossless neural\ncompression techniques can enhance data collection at observatories, and\nprovide guidance on the adoption of neural compression in scientific\napplications. Though the scope of this paper is restricted to lossless\ncompression, we also comment on the potential exploration of lossy compression\nmethods in future studies.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u5f15\u5165AstroCompress\u6311\u6218\uff0c\u63d0\u4f9b\u56db\u4e2a\u65b0\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u4f20\u7edf\u6570\u636e\u96c6\uff0c\u4ee5\u53ca\u5bf9\u4e03\u79cd\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\uff08\u5305\u62ec\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff09\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5c55\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u65e0\u635f\u538b\u7f29\u6280\u672f\u5728\u5929\u6587\u89c2\u6d4b\u6570\u636e\u6536\u96c6\u4e2d\u7684\u6f5c\u529b\uff0c\u5e76\u4e3a\u79d1\u5b66\u5e94\u7528\u4e2d\u91c7\u7528\u795e\u7ecf\u538b\u7f29\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u5929\u6587\u89c2\u6d4b\u6570\u636e\u4f20\u8f93\u53d7\u9650\u4e8e\u7a7a\u95f4\u548c\u5730\u9762\u89c2\u6d4b\u7ad9\u7684\u51b7\u6697\u73af\u5883\u6761\u4ef6\uff0c\u8fd9\u9650\u5236\u4e86\u6570\u636e\u91c7\u96c6\u91cf\u3002\u6539\u8fdb\u65e0\u635f\u6570\u636e\u538b\u7f29\u6280\u672f\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u4eea\u5668\u6210\u672c\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u53ef\u89c2\u6d4b\u7684\u79d1\u5b66\u6570\u636e\u91cf\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86AstroCompress\u6311\u6218\uff0c\u5305\u542b\u56db\u4e2a\u65b0\u6570\u636e\u96c6\u548c\u4e00\u4e2a\u4f20\u7edf\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4e0d\u540c\u6a21\u5f0f\u768416\u4f4d\u65e0\u7b26\u53f7\u6574\u6570\u6210\u50cf\u6570\u636e\u3002\u540c\u65f6\uff0c\u7814\u7a76\u5bf9\u4e03\u79cd\u65e0\u635f\u538b\u7f29\u65b9\u6cd5\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u5305\u62ec\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u548c\u56db\u79cd\u975e\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff08\u6240\u6709\u5f53\u524d\u5b9e\u9645\u6700\u5148\u8fdb\u7684\u7b97\u6cd5\uff09\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u65e0\u635f\u795e\u7ecf\u538b\u7f29\u6280\u672f\u80fd\u591f\u63d0\u9ad8\u5929\u6587\u89c2\u6d4b\u7ad9\u7684\u6570\u636e\u91c7\u96c6\u80fd\u529b\uff0c\u4f18\u4e8e\u7ecf\u5178\u538b\u7f29\u65b9\u6cd5\uff0c\u5e76\u4e3a\u79d1\u5b66\u5e94\u7528\u4e2d\u91c7\u7528\u795e\u7ecf\u538b\u7f29\u63d0\u4f9b\u4e86\u5177\u4f53\u6307\u5bfc\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63a2\u8ba8\u4e86\u672a\u6765\u63a2\u7d22\u6709\u635f\u538b\u7f29\u65b9\u6cd5\u7684\u6f5c\u529b\u3002", "conclusion": "\u795e\u7ecf\u7f51\u7edc\u65e0\u635f\u538b\u7f29\u6280\u672f\u5728\u5929\u6587\u6570\u636e\u538b\u7f29\u9886\u57df\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u89c2\u6d4b\u6570\u636e\u7684\u91c7\u96c6\u6548\u7387\u3002\u5c3d\u7ba1\u672c\u6587\u4ec5\u9650\u4e8e\u65e0\u635f\u538b\u7f29\uff0c\u4f46\u6709\u635f\u538b\u7f29\u65b9\u6cd5\u5728\u672a\u6765\u7814\u7a76\u4e2d\u4e5f\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u7d22\u3002"}}
{"id": "2506.08027", "pdf": "https://arxiv.org/pdf/2506.08027", "abs": "https://arxiv.org/abs/2506.08027", "authors": ["Asit Mishra", "Dusan Stosic", "Simon Layton"], "title": "Recipes for Pre-training LLMs with MXFP8", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": null, "summary": "Precision scaling - using fewer bits to represent model parameters and\nrelated tensors during pre-training - has emerged as a compelling technique for\nimproving GPU efficiency without sacrificing accuracy. Microscaling (MX)\nformats in NVIDIA's latest Blackwell GPUs represent a major leap in enabling\nthis precision scaling aspect. These formats combine narrow floating-point data\ntypes with per-block scaling factors, offering a fine-grained approach to\nquantizing tensors.\n  Although MX-formats offer the promise of improved numeric stability compared\nto other reduced-precision representations, in practice they must be used\ncarefully in order to successfully converge an LLM on a multi-trillion token\ndataset. In this paper, we show that the rounding mode suggested in OCP\nspecification can lead to divergence when pre-training an LLM. We show an\nimproved rounding mode, which uses round-to-infinity to compute scaling\nfactors, enables successful pre-training in MXFP8 for an 8B model on 15T\ntokens.", "AI": {"tldr": "MX\u683c\u5f0f\u5728NVIDIA\u6700\u65b0\u7684Blackwell GPU\u4e2d\u5bf9\u4e8e\u7cbe\u5ea6\u7f29\u653e\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9700\u8c28\u614e\u4f7f\u7528\u4ee5\u786e\u4fddLLM\u5728\u5927\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u7684\u6536\u655b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\uff0c\u4f7f\u7528round-to-infinity\u8ba1\u7b97\u7f29\u653e\u56e0\u5b50\uff0c\u6210\u529f\u5b9e\u73b0\u4e868B\u6a21\u578b\u572815T\u6807\u8bb0\u4e0a\u7684MXFP8\u9884\u8bad\u7ec3\u3002", "motivation": "\u5c3d\u7ba1MX\u683c\u5f0f\u76f8\u8f83\u4e8e\u5176\u4ed6\u4f4e\u7cbe\u5ea6\u8868\u793a\u6cd5\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8c28\u614e\u4f7f\u7528\uff0c\u4ee5\u786e\u4fddLLM\u5728\u591a\u4e07\u4ebf\u6807\u8bb0\u6570\u636e\u96c6\u4e0a\u80fd\u591f\u6210\u529f\u6536\u655b\u3002", "method": "\u7814\u7a76\u4e86OCP\u89c4\u8303\u4e2d\u5efa\u8bae\u7684\u820d\u5165\u6a21\u5f0f\u53ef\u80fd\u5bfc\u81f4LLM\u9884\u8bad\u7ec3\u53d1\u6563\u7684\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u2014\u2014\u4f7f\u7528round-to-infinity\u8ba1\u7b97\u7f29\u653e\u56e0\u5b50\u3002", "result": "\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u4f7f\u5f978B\u6a21\u578b\u80fd\u591f\u572815T\u6807\u8bb0\u7684\u6570\u636e\u96c6\u4e0a\u6210\u529f\u8fdb\u884cMXFP8\u9884\u8bad\u7ec3\u3002", "conclusion": "\u6539\u8fdb\u7684\u820d\u5165\u6a21\u5f0f\u89e3\u51b3\u4e86OCP\u89c4\u8303\u4e2d\u539f\u59cb\u820d\u5165\u6a21\u5f0f\u53ef\u80fd\u5f15\u53d1\u7684\u53d1\u6563\u95ee\u9898\uff0c\u4e3a\u5728MXFP8\u4e2d\u6210\u529f\u9884\u8bad\u7ec3\u5927\u578b\u6a21\u578b\u63d0\u4f9b\u4e86\u652f\u6301\u3002"}}
{"id": "2506.08602", "pdf": "https://arxiv.org/pdf/2506.08602", "abs": "https://arxiv.org/abs/2506.08602", "authors": ["Tingzhi Li", "Xuefeng Liu"], "title": "WGLE:Backdoor-free and Multi-bit Black-box Watermarking for Graph Neural Networks", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Graph Neural Networks (GNNs) are increasingly deployed in graph-related\napplications, making ownership verification critical to protect their\nintellectual property against model theft. Fingerprinting and black-box\nwatermarking are two main methods. However, the former relies on determining\nmodel similarity, which is computationally expensive and prone to ownership\ncollisions after model post-processing such as model pruning or fine-tuning.\nThe latter embeds backdoors, exposing watermarked models to the risk of\nbackdoor attacks. Moreover, both methods enable ownership verification but do\nnot convey additional information. As a result, each distributed model requires\na unique trigger graph, and all trigger graphs must be used to query the\nsuspect model during verification. Multiple queries increase the financial cost\nand the risk of detection.\n  To address these challenges, this paper proposes WGLE, a novel black-box\nwatermarking paradigm for GNNs that enables embedding the multi-bit string as\nthe ownership information without using backdoors. WGLE builds on a key insight\nwe term Layer-wise Distance Difference on an Edge (LDDE), which quantifies the\ndifference between the feature distance and the prediction distance of two\nconnected nodes. By predefining positive or negative LDDE values for multiple\nselected edges, WGLE embeds the watermark encoding the intended information\nwithout introducing incorrect mappings that compromise the primary task. WGLE\nis evaluated on six public datasets and six mainstream GNN architectures along\nwith state-of-the-art methods. The results show that WGLE achieves 100%\nownership verification accuracy, an average fidelity degradation of 0.85%,\ncomparable robustness against potential attacks, and low embedding overhead.\nThe code is available in the repository.", "AI": {"tldr": "The paper introduces WGLE, a new black-box watermarking method for GNNs that embeds multi-bit strings as ownership information without using backdoors. It achieves 100% verification accuracy with minimal fidelity degradation.", "motivation": "Current fingerprinting and black-box watermarking methods for GNNs are either computationally expensive or expose watermarked models to backdoor attacks. Additionally, they do not convey additional information and require multiple queries, increasing financial cost and detection risk.", "method": "WGLE is based on Layer-wise Distance Difference on an Edge (LDDE), which quantifies the difference between feature distance and prediction distance of two connected nodes. By predefining positive or negative LDDE values for selected edges, WGLE embeds watermark encoding intended information without introducing incorrect mappings.", "result": "WGLE was evaluated on six public datasets and six GNN architectures. It achieved 100% ownership verification accuracy, an average fidelity degradation of 0.85%, comparable robustness against attacks, and low embedding overhead.", "conclusion": "WGLE offers a novel approach to watermark GNNs that overcomes limitations of existing methods by enabling multi-bit string embedding without backdoors, ensuring high verification accuracy and minimal performance impact."}}
{"id": "2506.08321", "pdf": "https://arxiv.org/pdf/2506.08321", "abs": "https://arxiv.org/abs/2506.08321", "authors": ["Manooshree Patel", "Rayna Bhattacharyya", "Thomas Lu", "Arnav Mehta", "Niels Voss", "Narges Norouzi", "Gireeja Ranade"], "title": "LeanTutor: A Formally-Verified AI Tutor for Mathematical Proofs", "categories": ["cs.AI", "cs.HC", "cs.LO"], "comment": null, "summary": "We present LeanTutor, a Large Language Model (LLM)-based tutoring system for\nmath proofs. LeanTutor interacts with the student in natural language, formally\nverifies student-written math proofs in Lean, generates correct next steps, and\nprovides the appropriate instructional guidance. LeanTutor is composed of three\nmodules: (i) an autoformalizer/proof-checker, (ii) a next-step generator, and\n(iii) a natural language feedback generator. The first module faithfully\nautoformalizes student proofs into Lean and verifies proof accuracy via\nsuccessful code compilation. If the proof has an error, the incorrect step is\nidentified. The next-step generator module outputs a valid next Lean tactic for\nincorrect proofs via LLM-based candidate generation and proof search. The\nfeedback generator module leverages Lean data to produce a\npedagogically-motivated natural language hint for the student user. To evaluate\nour system, we introduce PeanoBench, a human-written dataset derived from the\nNatural Numbers Game, consisting of 371 Peano Arithmetic proofs, where each\nnatural language proof step is paired with the corresponding logically\nequivalent tactic in Lean. The Autoformalizer correctly formalizes 57% of\ntactics in correct proofs and accurately identifies the incorrect step in 30%\nof incorrect proofs. In generating natural language hints for erroneous proofs,\nLeanTutor outperforms a simple baseline on accuracy and relevance metrics.", "AI": {"tldr": "The paper introduces LeanTutor, an LLM-based tutoring system for math proofs that interacts with students in natural language, verifies proofs, generates next steps, and provides instructional guidance. It consists of three modules: autoformalizer/proof-checker, next-step generator, and feedback generator. Evaluated using PeanoBench dataset, the Autoformalizer correctly formalizes 57% of tactics in correct proofs and identifies incorrect steps in 30% of incorrect proofs.", "motivation": "To create a tutoring system that can help students learn math proofs by interacting in natural language, verifying proofs, generating correct next steps, and providing appropriate instructional guidance.", "method": "LeanTutor is composed of three modules: (i) an autoformalizer/proof-checker that autoformalizes student proofs into Lean and verifies proof accuracy; (ii) a next-step generator that outputs a valid next Lean tactic for incorrect proofs via LLM-based candidate generation and proof search; and (iii) a natural language feedback generator that produces pedagogically-motivated hints for the student user.", "result": "The Autoformalizer correctly formalizes 57% of tactics in correct proofs and accurately identifies the incorrect step in 30% of incorrect proofs. LeanTutor outperforms a simple baseline on accuracy and relevance metrics when generating natural language hints for erroneous proofs.", "conclusion": "LeanTutor represents a significant advancement in AI-based educational tools for teaching mathematical proofs, effectively combining natural language interaction, formal verification, and pedagogical feedback."}}
{"id": "2506.08051", "pdf": "https://arxiv.org/pdf/2506.08051", "abs": "https://arxiv.org/abs/2506.08051", "authors": ["Mahmuda Sultana Mimi", "Md Monzurul Islam", "Anannya Ghosh Tusti", "Shriyank Somvanshi", "Subasish Das"], "title": "ST-GraphNet: A Spatio-Temporal Graph Neural Network for Understanding and Predicting Automated Vehicle Crash Severity", "categories": ["cs.LG"], "comment": null, "summary": "Understanding the spatial and temporal dynamics of automated vehicle (AV)\ncrash severity is critical for advancing urban mobility safety and\ninfrastructure planning. In this work, we introduce ST-GraphNet, a\nspatio-temporal graph neural network framework designed to model and predict AV\ncrash severity by using both fine-grained and region-aggregated spatial graphs.\nUsing a balanced dataset of 2,352 real-world AV-related crash reports from\nTexas (2024), including geospatial coordinates, crash timestamps, SAE\nautomation levels, and narrative descriptions, we construct two complementary\ngraph representations: (1) a fine-grained graph with individual crash events as\nnodes, where edges are defined via spatio-temporal proximity; and (2) a\ncoarse-grained graph where crashes are aggregated into Hexagonal Hierarchical\nSpatial Indexing (H3)-based spatial cells, connected through hexagonal\nadjacency. Each node in the graph is enriched with multimodal data, including\nsemantic, spatial, and temporal attributes, including textual embeddings from\ncrash narratives using a pretrained Sentence-BERT model. We evaluate various\ngraph neural network (GNN) architectures, such as Graph Convolutional Networks\n(GCN), Graph Attention Networks (GAT), and Dynamic Spatio-Temporal GCN\n(DSTGCN), to classify crash severity and predict high-risk regions. Our\nproposed ST-GraphNet, which utilizes a DSTGCN backbone on the coarse-grained H3\ngraph, achieves a test accuracy of 97.74\\%, substantially outperforming the\nbest fine-grained model (64.7\\% test accuracy). These findings highlight the\neffectiveness of spatial aggregation, dynamic message passing, and multi-modal\nfeature integration in capturing the complex spatio-temporal patterns\nunderlying AV crash severity.", "AI": {"tldr": "The paper presents ST-GraphNet, a spatio-temporal graph neural network framework that models and predicts automated vehicle (AV) crash severity using both fine-grained and region-aggregated spatial graphs. It achieves 97.74% test accuracy.", "motivation": "To advance urban mobility safety and infrastructure planning by understanding the spatial and temporal dynamics of AV crash severity.", "method": "Introduced ST-GraphNet which uses DSTGCN backbone on coarse-grained H3 graph with multimodal data including semantic, spatial, and temporal attributes.", "result": "Achieved 97.74% test accuracy, outperforming the best fine-grained model with 64.7% test accuracy.", "conclusion": "Spatial aggregation, dynamic message passing, and multi-modal feature integration are effective in capturing complex spatio-temporal patterns underlying AV crash severity."}}
{"id": "2506.08693", "pdf": "https://arxiv.org/pdf/2506.08693", "abs": "https://arxiv.org/abs/2506.08693", "authors": ["Andreas Happe", "J\u00fcrgen Cito"], "title": "On the Ethics of Using LLMs for Offensive Security", "categories": ["cs.CR"], "comment": null, "summary": "Large Language Models (LLMs) have rapidly evolved over the past few years and\nare currently evaluated for their efficacy within the domain of offensive\ncyber-security. While initial forays showcase the potential of LLMs to enhance\nsecurity research, they also raise critical ethical concerns regarding the\ndual-use of offensive security tooling.\n  This paper analyzes a set of papers that leverage LLMs for offensive\nsecurity, focusing on how ethical considerations are expressed and justified in\ntheir work. The goal is to assess the culture of AI in offensive security\nresearch regarding ethics communication, highlighting trends, best practices,\nand gaps in current discourse.\n  We provide insights into how the academic community navigates the fine line\nbetween innovation and ethical responsibility. Particularly, our results show\nthat 13 of 15 reviewed prototypes (86.6\\%) mentioned ethical considerations and\nare thus aware of the potential dual-use of their research. Main motivation\ngiven for the research was allowing broader access to penetration-testing as\nwell as preparing defenders for AI-guided attackers.", "AI": {"tldr": "This paper examines a collection of studies using Large Language Models (LLMs) in offensive security, focusing on the communication of ethical considerations within this research area. Results indicate that most reviewed prototypes acknowledge dual-use risks and provide motivations such as enhancing penetration-testing access and readiness against AI-based attacks.", "motivation": "To explore how ethical considerations are expressed and justified in research leveraging LLMs for offensive security.", "method": "Analysis of a set of papers utilizing LLMs in offensive security to assess the culture of AI in this research field concerning ethics communication.", "result": "86.6% of the reviewed prototypes mentioned ethical considerations, showing awareness of dual-use risks. Main motivations include improving access to penetration-testing and preparing defenders for AI-guided attackers.", "conclusion": "The academic community is navigating the balance between innovation and ethical responsibility in offensive security research with LLMs."}}
{"id": "2506.08332", "pdf": "https://arxiv.org/pdf/2506.08332", "abs": "https://arxiv.org/abs/2506.08332", "authors": ["Amur Ghose", "Andrew B. Kahng", "Sayak Kundu", "Zhiang Wang"], "title": "ORFS-agent: Tool-Using Agents for Chip Design Optimization", "categories": ["cs.AI"], "comment": null, "summary": "Machine learning has been widely used to optimize complex engineering\nworkflows across numerous domains. In the context of integrated circuit design,\nmodern flows (e.g., going from a register-transfer level netlist to physical\nlayouts) involve extensive configuration via thousands of parameters, and small\nchanges to these parameters can have large downstream impacts on desired\noutcomes - namely design performance, power, and area. Recent advances in Large\nLanguage Models (LLMs) offer new opportunities for learning and reasoning\nwithin such high-dimensional optimization tasks. In this work, we introduce\nORFS-agent, an LLM-based iterative optimization agent that automates parameter\ntuning in an open-source hardware design flow. ORFS-agent adaptively explores\nparameter configurations, demonstrating clear improvements over standard\nBayesian optimization approaches in terms of resource efficiency and final\ndesign metrics. Our empirical evaluations on two different technology nodes and\na range of circuit benchmarks indicate that ORFS-agent can improve both routed\nwirelength and effective clock period by over 13%, all while using 40% fewer\noptimization iterations. Moreover, by following natural language objectives to\ntrade off certain metrics for others, ORFS-agent demonstrates a flexible and\ninterpretable framework for multi-objective optimization. Crucially, RFS-agent\nis modular and model-agnostic, and can be plugged in to any frontier LLM\nwithout any further fine-tuning.", "AI": {"tldr": "The paper introduces ORFS-agent, an LLM-based optimization agent that automates parameter tuning in hardware design flows, showing improvements over Bayesian optimization.", "motivation": "To address the challenge of optimizing complex engineering workflows with thousands of parameters in integrated circuit design.", "method": "ORFS-agent adaptively explores parameter configurations using Large Language Models for iterative optimization.", "result": "Empirical evaluations show ORFS-agent improves routed wirelength and effective clock period by over 13%, with 40% fewer optimization iterations.", "conclusion": "ORFS-agent presents a flexible, interpretable framework for multi-objective optimization and is modular and model-agnostic."}}
{"id": "2506.08054", "pdf": "https://arxiv.org/pdf/2506.08054", "abs": "https://arxiv.org/abs/2506.08054", "authors": ["Yiming Wang", "Hao Peng", "Senzhang Wang", "Haohua Du", "Chunyang Liu", "Jia Wu", "Guanlin Wu"], "title": "STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation", "categories": ["cs.LG", "cs.AI"], "comment": "10 pages, 5 figures, 3 tables. Extended version of paper accepted at\n  IJCAI 2025", "summary": "Traffic data imputation is fundamentally important to support various\napplications in intelligent transportation systems such as traffic flow\nprediction. However, existing time-to-space sequential methods often fail to\neffectively extract features in block-wise missing data scenarios. Meanwhile,\nthe static graph structure for spatial feature propagation significantly\nconstrains the models flexibility in handling the distribution shift issue for\nthe nonstationary traffic data. To address these issues, this paper proposes a\nSpatioTemporal Attention Mixture of experts network named STAMImputer for\ntraffic data imputation. Specifically, we introduce a Mixture of Experts (MoE)\nframework to capture latent spatio-temporal features and their influence\nweights, effectively imputing block missing. A novel Low-rank guided Sampling\nGraph ATtention (LrSGAT) mechanism is designed to dynamically balance the local\nand global correlations across road networks. The sampled attention vectors are\nutilized to generate dynamic graphs that capture real-time spatial\ncorrelations. Extensive experiments are conducted on four traffic datasets for\nevaluation. The result shows STAMImputer achieves significantly performance\nimprovement compared with existing SOTA approaches. Our codes are available at\nhttps://github.com/RingBDStack/STAMImupter.", "AI": {"tldr": "The paper proposes STAMImputer, a SpatioTemporal Attention Mixture of experts network for traffic data imputation that significantly outperforms existing methods.", "motivation": "Existing time-to-space sequential methods fail to effectively extract features in block-wise missing data scenarios and static graph structure constrains the models flexibility in handling nonstationary traffic data.", "method": "STAMImputer uses a Mixture of Experts (MoE) framework to capture latent spatio-temporal features and their influence weights, and introduces a Low-rank guided Sampling Graph ATtention (LrSGAT) mechanism to dynamically balance local and global correlations across road networks.", "result": "STAMImputer achieves significantly better performance compared with existing state-of-the-art approaches when evaluated on four traffic datasets.", "conclusion": "STAMImputer is an effective method for traffic data imputation that addresses the limitations of existing methods."}}
{"id": "2506.08781", "pdf": "https://arxiv.org/pdf/2506.08781", "abs": "https://arxiv.org/abs/2506.08781", "authors": ["Saif E. Nouma", "Attila A. Yavuz"], "title": "Lightweight and High-Throughput Secure Logging for Internet of Things and Cold Cloud Continuum", "categories": ["cs.CR"], "comment": null, "summary": "The growing deployment of resource-limited Internet of Things (IoT) devices\nand their expanding attack surfaces demand efficient and scalable security\nmechanisms. System logs are vital for the trust and auditability of IoT, and\noffloading their maintenance to a Cold Storage-as-a-Service (Cold-STaaS)\nenhances cost-effectiveness and reliability. However, existing cryptographic\nlogging solutions either burden low-end IoT devices with heavy computation or\ncreate verification delays and storage inefficiencies at Cold-STaaS. There is a\npressing need for cryptographic primitives that balance security, performance,\nand scalability across IoT-Cold-STaaS continuum.\n  In this work, we present Parallel Optimal Signatures for Secure Logging\n(POSLO), a novel digital signature framework that, to our knowledge, is the\nfirst to offer constant-size signatures and public keys, near-optimal signing\nefficiency, and tunable fine-to-coarse-grained verification for log auditing.\nPOSLO achieves these properties through efficient randomness management,\nflexible aggregation, and multiple algorithmic instantiations. It also\nintroduces a GPU-accelerated batch verification framework that exploits\nhomomorphic signature aggregation to deliver ultra-fast performance. For\nexample, POSLO can verify 231 log entries per second on a mid-range consumer\nGPU (NVIDIA GTX 3060) while being significantly more compact than\nstate-of-the-art. POSLO also preserves signer-side efficiency, offering\nsubstantial battery savings for IoT devices, and is well-suited for the\nIoT-Cold-STaaS ecosystem.", "AI": {"tldr": "This paper proposes POSLO, a new digital signature framework that provides constant-size signatures and public keys, near-optimal signing efficiency, and scalable verification for secure logging in the IoT-Cold-STaaS ecosystem.", "motivation": "The motivation of this paper is to address the need for cryptographic primitives that balance security, performance, and scalability across the IoT-Cold-STaaS continuum. Existing solutions either burden low-end IoT devices with heavy computation or create verification delays and storage inefficiencies at Cold-STaaS.", "method": "POSLO achieves its properties through efficient randomness management, flexible aggregation, and multiple algorithmic instantiations. It introduces a GPU-accelerated batch verification framework that exploits homomorphic signature aggregation for ultra-fast performance.", "result": "POSLO can verify 231 log entries per second on a mid-range consumer GPU (NVIDIA GTX 3060) while being significantly more compact than state-of-the-art. It preserves signer-side efficiency, offering substantial battery savings for IoT devices.", "conclusion": "POSLO is well-suited for the IoT-Cold-STaaS ecosystem, providing a novel solution for secure logging with constant-size signatures and public keys, near-optimal signing efficiency, and tunable fine-to-coarse-grained verification."}}
{"id": "2506.08363", "pdf": "https://arxiv.org/pdf/2506.08363", "abs": "https://arxiv.org/abs/2506.08363", "authors": ["Jun Yin", "Jing Zhong", "Pengyu Zeng", "Peilin Li", "Miao Zhang", "Ran Luo", "Shuai Lu"], "title": "FloorplanMAE:A self-supervised framework for complete floorplan generation from partial inputs", "categories": ["cs.AI"], "comment": null, "summary": "In the architectural design process, floorplan design is often a dynamic and\niterative process. Architects progressively draw various parts of the floorplan\naccording to their ideas and requirements, continuously adjusting and refining\nthroughout the design process. Therefore, the ability to predict a complete\nfloorplan from a partial one holds significant value in the design process.\nSuch prediction can help architects quickly generate preliminary designs,\nimprove design efficiency, and reduce the workload associated with repeated\nmodifications. To address this need, we propose FloorplanMAE, a self-supervised\nlearning framework for restoring incomplete floor plans into complete ones.\nFirst, we developed a floor plan reconstruction dataset, FloorplanNet,\nspecifically trained on architectural floor plans. Secondly, we propose a floor\nplan reconstruction method based on Masked Autoencoders (MAE), which\nreconstructs missing parts by masking sections of the floor plan and training a\nlightweight Vision Transformer (ViT). We evaluated the reconstruction accuracy\nof FloorplanMAE and compared it with state-of-the-art benchmarks. Additionally,\nwe validated the model using real sketches from the early stages of\narchitectural design. Experimental results show that the FloorplanMAE model can\ngenerate high-quality complete floor plans from incomplete partial plans. This\nframework provides a scalable solution for floor plan generation, with broad\napplication prospects.", "AI": {"tldr": "FloorplanMAE is a self-supervised learning framework that can predict and generate complete floor plans from partial ones, enhancing architectural design efficiency.", "motivation": "In architectural design, creating floorplans is an iterative process requiring repeated modifications. Predicting a complete floorplan from a partial one could significantly improve design efficiency and reduce workload.", "method": "The study proposes FloorplanMAE which uses Masked Autoencoders (MAE) to reconstruct missing parts of floor plans. It involves developing a specific dataset, FloorplanNet, and employing a lightweight Vision Transformer (ViT) for training.", "result": "Experimental results indicate that FloorplanMAE can successfully generate high-quality complete floor plans from incomplete ones, showing promise for scalable floor plan generation.", "conclusion": "FloorplanMAE presents a valuable tool in architectural design, offering a scalable solution with significant potential applications in improving design processes."}}
{"id": "2506.08060", "pdf": "https://arxiv.org/pdf/2506.08060", "abs": "https://arxiv.org/abs/2506.08060", "authors": ["Asankhaya Sharma"], "title": "Eliciting Fine-Tuned Transformer Capabilities via Inference-Time Techniques", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models have transformed natural language processing, yet\nsupervised fine-tuning (SFT) remains computationally intensive. This paper\nformally proves that capabilities acquired through SFT can be approximated by a\nbase transformer model using inference-time techniques, specifically in-context\nlearning (ICL), without altering model parameters, under idealized assumptions\nincluding unbounded computational resources and access to the fine-tuning\ndataset. We extend these results to practical scenarios with finite context\nlengths and partial dataset access. For text generation tasks with fixed output\nlength $l$, datasets of size $\\mathrm{O}\\left( \\frac{m V}{\\varepsilon^2} \\log\n\\frac{m}{\\delta} \\right)$ or, with bounded context, $\\mathrm{O}\\left( \\frac{l\n\\log V}{\\varepsilon^2} \\log \\frac{1}{\\delta} \\right)$ suffice to approximate\nfine-tuned behavior across $m$ contexts within error $\\varepsilon$, where $V$\nis the vocabulary size and $\\delta$ is the failure probability. For linear\nclassification, datasets of size $\\mathrm{O}\\left( \\frac{d}{\\varepsilon}\n\\right)$ or, with fixed context, $\\mathrm{O}\\left( \\frac{1}{\\varepsilon^2} \\log\n\\frac{1}{\\delta} \\right)$ are sufficient, where $d$ is the input dimension.\nGrounded in the Turing completeness of transformers, these results provide a\ntheoretical foundation for resource-efficient deployment of large language\nmodels, with practical techniques like retrieval-augmented generation bridging\ntheory to real-world applications.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u80fd\u529b\u53ef\u4ee5\u901a\u8fc7\u63a8\u7406\u65f6\u7684\u6280\u672f\uff08\u5982\u60c5\u5883\u5b66\u4e60\uff09\u6765\u8fd1\u4f3c\u5b9e\u73b0\uff0c\u800c\u65e0\u9700\u6539\u53d8\u6a21\u578b\u53c2\u6570\u3002\u672c\u6587\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u548c\u8d44\u6e90\u9ad8\u6548\u90e8\u7f72\u7684\u65b9\u6cd5\u3002", "motivation": "\u76d1\u7763\u5fae\u8c03\uff08SFT\uff09\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u6765\u8bf4\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u56e0\u6b64\u7814\u7a76\u5982\u4f55\u901a\u8fc7\u5176\u4ed6\u65b9\u5f0f\u83b7\u5f97\u7c7b\u4f3c\u7684\u80fd\u529b\u662f\u5fc5\u8981\u7684\u3002", "method": "\u5728\u7406\u60f3\u5047\u8bbe\u4e0b\uff08\u65e0\u9650\u8ba1\u7b97\u8d44\u6e90\u548c\u8bbf\u95ee\u5fae\u8c03\u6570\u636e\u96c6\uff09\uff0c\u8bc1\u660e\u4e86\u901a\u8fc7\u60c5\u5883\u5b66\u4e60\u53ef\u4ee5\u8fd1\u4f3c\u83b7\u5f97SFT\u7684\u80fd\u529b\uff0c\u5e76\u6269\u5c55\u5230\u5b9e\u9645\u573a\u666f\u4e2d\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u90e8\u5206\u6570\u636e\u96c6\u8bbf\u95ee\u60c5\u51b5\u3002", "result": "\u5bf9\u4e8e\u6587\u672c\u751f\u6210\u4efb\u52a1\u548c\u7ebf\u6027\u5206\u7c7b\u4efb\u52a1\uff0c\u7ed9\u51fa\u4e86\u6240\u9700\u6570\u636e\u96c6\u5927\u5c0f\u7684\u7406\u8bba\u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u4e3a\u8d44\u6e90\u9ad8\u6548\u7684\u6a21\u578b\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u57fa\u4e8eTransformer\u7684\u56fe\u7075\u5b8c\u5907\u6027\uff0c\u672c\u6587\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8d44\u6e90\u9ad8\u6548\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u7ed3\u5408\u5b9e\u9645\u6280\u672f\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff0c\u53ef\u5c06\u7406\u8bba\u5e94\u7528\u4e8e\u73b0\u5b9e\u4e16\u754c\u3002"}}
{"id": "2506.08828", "pdf": "https://arxiv.org/pdf/2506.08828", "abs": "https://arxiv.org/abs/2506.08828", "authors": ["Mishall Al-Zubaidie"], "title": "Lightweight Electronic Signatures and Reliable Access Control Included in Sensor Networks to Prevent Cyber Attacks from Modifying Patient Data", "categories": ["cs.CR"], "comment": "22 pages, 11 figures, conference", "summary": "Digital terrorism is a major cause of securing patient/healthcare providers\ndata and information. Sensitive topics that may have an impact on a patient's\nhealth or even national security include patient health records and information\non healthcare providers. Health databases and data sets have been continually\nbreached by many, regular assaults, as well as local and remote servers\nequipped with wireless sensor networks (WSNs) in diverse locations. The problem\nwas addressed by some contemporary strategies that were created to stop these\nassaults and guarantee the privacy of patient data and information transferred\nand gathered by sensors. Nevertheless, the literature analysis outlines many\nindications of weakness that persist in these methods. This study suggests a\nnovel, reliable method that bolsters the information security and data gathered\nby sensors and kept on base station datasets. The proposed approach combines a\nnumber of security mechanisms, including symmetric cryptography for encryption,\nasymmetric cryptography for access control and signatures, and the Lesamnta-LW\nmethod in the signature process. Users' information is shielded from prying\neyes by the careful application of these measures and a sound approach.\nInvestigational comparisons, security studies, and thorough results show that\nthe suggested method is better than earlier methods.", "AI": {"tldr": "Digital terrorism poses a threat to patient and healthcare provider data. Current strategies have weaknesses. This study proposes a new method combining symmetric cryptography, asymmetric cryptography, and Lesamnta-LW for enhanced security. Experimental results show improvement over previous methods.", "motivation": "\u6570\u5b57\u6050\u6016\u4e3b\u4e49\u5bf9\u60a3\u8005\u548c\u533b\u7597\u63d0\u4f9b\u8005\u7684\u6570\u636e\u548c\u4fe1\u606f\u5b89\u5168\u6784\u6210\u4e86\u91cd\u5927\u5a01\u80c1\uff0c\u5c3d\u7ba1\u5df2\u6709\u7b56\u7565\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u8bb8\u591a\u5f31\u70b9\u3002", "method": "\u5c06\u5bf9\u79f0\u52a0\u5bc6\u3001\u975e\u5bf9\u79f0\u52a0\u5bc6\u548cLesamnta-LW\u7b7e\u540d\u65b9\u6cd5\u7ed3\u5408\u4f7f\u7528\uff0c\u4ee5\u52a0\u5f3a\u4f20\u611f\u5668\u6536\u96c6\u5e76\u5b58\u50a8\u5728\u57fa\u7ad9\u6570\u636e\u96c6\u4e2d\u7684\u4fe1\u606f\u5b89\u5168\u3002", "result": "\u5b9e\u9a8c\u5bf9\u6bd4\u3001\u5b89\u5168\u5206\u6790\u548c\u8be6\u7ec6\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u4f18\u4e8e\u4ee5\u524d\u7684\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53ef\u9760\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u79cd\u5b89\u5168\u673a\u5236\u6765\u589e\u5f3a\u4fe1\u606f\u548c\u6570\u636e\u7684\u5b89\u5168\u6027\u3002"}}
{"id": "2506.08390", "pdf": "https://arxiv.org/pdf/2506.08390", "abs": "https://arxiv.org/abs/2506.08390", "authors": ["Leheng Sheng", "An Zhang", "Zijian Wu", "Weixiang Zhao", "Changshuo Shen", "Yi Zhang", "Xiang Wang", "Tat-Seng Chua"], "title": "On Reasoning Strength Planning in Large Reasoning Models", "categories": ["cs.AI"], "comment": null, "summary": "Recent studies empirically reveal that large reasoning models (LRMs) can\nautomatically allocate more reasoning strengths (i.e., the number of reasoning\ntokens) for harder problems, exhibiting difficulty-awareness for better task\nperformance. While this automatic reasoning strength allocation phenomenon has\nbeen widely observed, its underlying mechanism remains largely unexplored. To\nthis end, we provide explanations for this phenomenon from the perspective of\nmodel activations. We find evidence that LRMs pre-plan the reasoning strengths\nin their activations even before generation, with this reasoning strength\ncausally controlled by the magnitude of a pre-allocated directional vector.\nSpecifically, we show that the number of reasoning tokens is predictable solely\nbased on the question activations using linear probes, indicating that LRMs\nestimate the required reasoning strength in advance. We then uncover that LRMs\nencode this reasoning strength through a pre-allocated directional vector\nembedded in the activations of the model, where the vector's magnitude\nmodulates the reasoning strength. Subtracting this vector can lead to reduced\nreasoning token number and performance, while adding this vector can lead to\nincreased reasoning token number and even improved performance. We further\nreveal that this direction vector consistently yields positive reasoning length\nprediction, and it modifies the logits of end-of-reasoning token </think> to\naffect the reasoning length. Finally, we demonstrate two potential applications\nof our findings: overthinking behavior detection and enabling efficient\nreasoning on simple problems. Our work provides new insights into the internal\nmechanisms of reasoning in LRMs and offers practical tools for controlling\ntheir reasoning behaviors. Our code is available at\nhttps://github.com/AlphaLab-USTC/LRM-plans-CoT.", "AI": {"tldr": "\u8fd1\u671f\u7814\u7a76\u8868\u660e\uff0c\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u53ef\u4ee5\u81ea\u52a8\u4e3a\u66f4\u96be\u7684\u95ee\u9898\u5206\u914d\u66f4\u591a\u7684\u63a8\u7406\u80fd\u529b\uff08\u5373\u63a8\u7406\u4ee4\u724c\u7684\u6570\u91cf\uff09\uff0c\u5c55\u73b0\u51fa\u5bf9\u4efb\u52a1\u6027\u80fd\u66f4\u597d\u7684\u96be\u5ea6\u611f\u77e5\u3002\u7136\u800c\uff0c\u8fd9\u79cd\u81ea\u52a8\u63a8\u7406\u5f3a\u5ea6\u5206\u914d\u73b0\u8c61\u7684\u5185\u5728\u673a\u5236\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u672c\u6587\u4ece\u6a21\u578b\u6fc0\u6d3b\u7684\u89d2\u5ea6\u89e3\u91ca\u4e86\u8fd9\u4e00\u73b0\u8c61\uff0c\u53d1\u73b0LRMs\u5728\u751f\u6210\u524d\u5c31\u5df2\u7ecf\u5728\u5176\u6fc0\u6d3b\u4e2d\u9884\u89c4\u5212\u4e86\u63a8\u7406\u5f3a\u5ea6\uff0c\u5e76\u4e14\u8be5\u5f3a\u5ea6\u7531\u4e00\u4e2a\u9884\u5206\u914d\u7684\u65b9\u5411\u5411\u91cf\u7684\u5927\u5c0f\u56e0\u679c\u63a7\u5236\u3002\u901a\u8fc7\u7ebf\u6027\u63a2\u9488\u4ec5\u6839\u636e\u95ee\u9898\u6fc0\u6d3b\u5c31\u53ef\u4ee5\u9884\u6d4b\u63a8\u7406\u4ee4\u724c\u7684\u6570\u91cf\uff0c\u8868\u660eLRMs\u63d0\u524d\u4f30\u8ba1\u4e86\u6240\u9700\u7684\u63a8\u7406\u5f3a\u5ea6\u3002\u6b64\u5916\uff0cLRMs\u901a\u8fc7\u5d4c\u5165\u5728\u6a21\u578b\u6fc0\u6d3b\u4e2d\u7684\u65b9\u5411\u5411\u91cf\u7f16\u7801\u6b64\u63a8\u7406\u5f3a\u5ea6\uff0c\u5411\u91cf\u7684\u5927\u5c0f\u8c03\u8282\u63a8\u7406\u5f3a\u5ea6\u3002\u51cf\u53bb\u8fd9\u4e2a\u5411\u91cf\u4f1a\u5bfc\u81f4\u63a8\u7406\u4ee4\u724c\u6570\u91cf\u548c\u6027\u80fd\u7684\u964d\u4f4e\uff0c\u800c\u589e\u52a0\u8fd9\u4e2a\u5411\u91cf\u5219\u4f1a\u589e\u52a0\u63a8\u7406\u4ee4\u724c\u6570\u91cf\u751a\u81f3\u63d0\u9ad8\u6027\u80fd\u3002\u6700\u540e\uff0c\u672c\u6587\u5c55\u793a\u4e86\u4e24\u4e2a\u6f5c\u5728\u5e94\u7528\uff1a\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\u68c0\u6d4b\u548c\u7b80\u5355\u95ee\u9898\u7684\u6709\u6548\u63a8\u7406\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u7ecf\u5e7f\u6cdb\u89c2\u5bdf\u5230\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u5177\u6709\u81ea\u52a8\u5206\u914d\u63a8\u7406\u5f3a\u5ea6\u7684\u73b0\u8c61\uff0c\u4f46\u5176\u80cc\u540e\u7684\u673a\u5236\u5c1a\u672a\u88ab\u6df1\u5165\u63a2\u8ba8\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4ece\u6a21\u578b\u6fc0\u6d3b\u7684\u89d2\u5ea6\u6765\u63ed\u793a\u8fd9\u79cd\u73b0\u8c61\u7684\u6210\u56e0\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3LRMs\u7684\u5de5\u4f5c\u539f\u7406\u5e76\u63d0\u4f9b\u63a7\u5236\u5176\u63a8\u7406\u884c\u4e3a\u7684\u5de5\u5177\u3002", "method": "\u4f5c\u8005\u9996\u5148\u4f7f\u7528\u7ebf\u6027\u63a2\u9488\u5206\u6790\u4e86LRMs\u5728\u751f\u6210\u524d\u7684\u6fc0\u6d3b\u60c5\u51b5\uff0c\u8bc1\u660e\u4e86\u63a8\u7406\u4ee4\u724c\u6570\u91cf\u53ef\u4ee5\u6839\u636e\u95ee\u9898\u6fc0\u6d3b\u8fdb\u884c\u9884\u6d4b\u3002\u63a5\u7740\uff0c\u7814\u7a76\u53d1\u73b0LRMs\u901a\u8fc7\u4e00\u4e2a\u9884\u5206\u914d\u7684\u65b9\u5411\u5411\u91cf\u5728\u6fc0\u6d3b\u4e2d\u7f16\u7801\u63a8\u7406\u5f3a\u5ea6\uff0c\u8be5\u5411\u91cf\u7684\u5927\u5c0f\u76f4\u63a5\u5f71\u54cd\u63a8\u7406\u5f3a\u5ea6\u3002\u5b9e\u9a8c\u901a\u8fc7\u589e\u51cf\u8fd9\u4e2a\u5411\u91cf\u9a8c\u8bc1\u4e86\u5176\u5bf9\u63a8\u7406\u4ee4\u724c\u6570\u91cf\u548c\u6027\u80fd\u7684\u5f71\u54cd\u3002\u6700\u540e\uff0c\u4f5c\u8005\u63ed\u793a\u4e86\u8be5\u65b9\u5411\u5411\u91cf\u5982\u4f55\u4fee\u6539\u63a8\u7406\u7ed3\u675f\u6807\u8bb0</think>\u7684logits\u4ee5\u5f71\u54cd\u63a8\u7406\u957f\u5ea6\uff0c\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u5b9e\u9645\u5e94\u7528\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u7ebf\u6027\u63a2\u9488\u53ef\u4ee5\u6210\u529f\u9884\u6d4b\u63a8\u7406\u4ee4\u724c\u6570\u91cf\uff0c\u8bc1\u5b9eLRMs\u786e\u5b9e\u63d0\u524d\u89c4\u5212\u4e86\u63a8\u7406\u5f3a\u5ea6\u3002\u540c\u65f6\uff0c\u589e\u51cf\u65b9\u5411\u5411\u91cf\u80fd\u591f\u663e\u8457\u6539\u53d8\u63a8\u7406\u4ee4\u724c\u6570\u91cf\u548c\u6027\u80fd\uff0c\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u4e86\u8be5\u5411\u91cf\u5bf9\u63a8\u7406\u5f3a\u5ea6\u7684\u8c03\u63a7\u4f5c\u7528\u3002", "conclusion": "\u672c\u6587\u4ece\u6a21\u578b\u6fc0\u6d3b\u7684\u89d2\u5ea6\u63ed\u793a\u4e86LRMs\u81ea\u52a8\u5206\u914d\u63a8\u7406\u5f3a\u5ea6\u7684\u673a\u5236\uff0c\u53d1\u73b0\u4e86\u9884\u5206\u914d\u65b9\u5411\u5411\u91cf\u5bf9\u63a8\u7406\u5f3a\u5ea6\u7684\u56e0\u679c\u63a7\u5236\u4f5c\u7528\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u8fc7\u5ea6\u601d\u8003\u884c\u4e3a\u68c0\u6d4b\u548c\u7b80\u5355\u95ee\u9898\u9ad8\u6548\u63a8\u7406\u4e2d\u7684\u6f5c\u5728\u5e94\u7528\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u7406\u89e3\u548c\u63a7\u5236LRMs\u7684\u63a8\u7406\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u548c\u5de5\u5177\u3002"}}
{"id": "2506.08062", "pdf": "https://arxiv.org/pdf/2506.08062", "abs": "https://arxiv.org/abs/2506.08062", "authors": ["Woosung Kim", "Jinho Lee", "Jongmin Lee", "Byung-Jun Lee"], "title": "FairDICE: Fairness-Driven Offline Multi-Objective Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": "Multi-objective Reinforcement Learning", "summary": "Multi-objective reinforcement learning (MORL) aims to optimize policies in\nthe presence of conflicting objectives, where linear scalarization is commonly\nused to reduce vector-valued returns into scalar signals. While effective for\ncertain preferences, this approach cannot capture fairness-oriented goals such\nas Nash social welfare or max-min fairness, which require nonlinear and\nnon-additive trade-offs. Although several online algorithms have been proposed\nfor specific fairness objectives, a unified approach for optimizing nonlinear\nwelfare criteria in the offline setting-where learning must proceed from a\nfixed dataset-remains unexplored. In this work, we present FairDICE, the first\noffline MORL framework that directly optimizes nonlinear welfare objective.\nFairDICE leverages distribution correction estimation to jointly account for\nwelfare maximization and distributional regularization, enabling stable and\nsample-efficient learning without requiring explicit preference weights or\nexhaustive weight search. Across multiple offline benchmarks, FairDICE\ndemonstrates strong fairness-aware performance compared to existing baselines.", "AI": {"tldr": "FairDICE is the first offline MORL framework that directly optimizes nonlinear welfare objective, showing strong fairness-aware performance in benchmarks.", "motivation": "Existing methods for optimizing policies in conflicting objectives often use linear scalarization which cannot capture fairness-oriented goals. While online algorithms have been proposed for specific fairness objectives, a unified approach for optimizing nonlinear welfare criteria in the offline setting remains unexplored.", "method": "FairDICE leverages distribution correction estimation to jointly account for welfare maximization and distributional regularization, enabling stable and sample-efficient learning without requiring explicit preference weights or exhaustive weight search.", "result": "Across multiple offline benchmarks, FairDICE demonstrates strong fairness-aware performance compared to existing baselines.", "conclusion": "FairDICE presents a novel approach to optimize nonlinear welfare criteria in the offline setting, providing strong fairness-aware performance."}}
{"id": "2506.08838", "pdf": "https://arxiv.org/pdf/2506.08838", "abs": "https://arxiv.org/abs/2506.08838", "authors": ["Yuchong Xie", "Wenhui Zhang", "Dongdong She"], "title": "ZTaint-Havoc: From Havoc Mode to Zero-Execution Fuzzing-Driven Taint Inference", "categories": ["cs.CR", "cs.SE"], "comment": "To appear on 34th ISSTA", "summary": "Fuzzing is a widely used technique for discovering software vulnerabilities,\nbut identifying hot bytes that influence program behavior remains challenging.\nTraditional taint analysis can track such bytes white-box, but suffers from\nscalability issue. Fuzzing-Driven Taint Inference (FTI) offers a black-box\nalternative, yet typically incurs significant runtime overhead due to extra\nprogram executions. We observe that the commonly used havoc mutation scheme in\nfuzzing can be adapted for lightweight FTI with zero extra executions. We\npresent a computational model of havoc mode, demonstrating that it can perform\nFTI while generating new test cases. Building on this, we propose ZTaint-Havoc,\na novel, efficient FTI with minimal overhead (3.84% on UniBench, 12.58% on\nFuzzBench). We further design an effective mutation algorithm utilizing the\nidentified hot bytes. Our comprehensive evaluation shows that ZTaint-Havoc,\nimplemented in AFL++, improves edge coverage by up to 33.71% on FuzzBench and\n51.12% on UniBench over vanilla AFL++, with average gains of 2.97% and 6.12% in\n24-hour fuzzing campaigns.", "AI": {"tldr": "The paper introduces ZTaint-Havoc, an efficient Fuzzing-Driven Taint Inference (FTI) method that operates with minimal overhead by adapting the havoc mutation scheme in fuzzing. It improves edge coverage significantly compared to vanilla AFL++ in fuzzing campaigns.", "motivation": "Fuzzing is crucial for finding software vulnerabilities, but identifying hot bytes influencing program behavior is challenging. Traditional taint analysis and existing FTI methods have limitations in scalability or runtime overhead.", "method": "The authors develop a computational model of the havoc mode in fuzzing, showing it can perform FTI while generating new test cases. They propose ZTaint-Havoc, which uses this model for efficient FTI with low overhead. An effective mutation algorithm utilizing identified hot bytes is also designed.", "result": "ZTaint-Havoc, implemented in AFL++, achieves significant improvements in edge coverage over vanilla AFL++. On FuzzBench, it improves coverage by up to 33.71% with an average gain of 2.97%, and on UniBench, it improves by up to 51.12% with an average gain of 6.12% in 24-hour fuzzing campaigns.", "conclusion": "ZTaint-Havoc offers an efficient way to perform FTI with minimal overhead, enhancing fuzzing effectiveness in terms of edge coverage."}}
{"id": "2506.08399", "pdf": "https://arxiv.org/pdf/2506.08399", "abs": "https://arxiv.org/abs/2506.08399", "authors": ["Jiachen Ma", "Zhanhui Zhou", "Chao Yang", "Chaochao Lu"], "title": "SafeCoT: Improving VLM Safety with Minimal Reasoning", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Ensuring safe and appropriate responses from vision-language models (VLMs)\nremains a critical challenge, particularly in high-risk or ambiguous scenarios.\nWe introduce SafeCoT, a lightweight, interpretable framework that leverages\nrule-based chain-of-thought (CoT) supervision to improve refusal behavior in\nVLMs. Unlike prior methods that rely on large-scale safety annotations or\ncomplex modeling, SafeCoT uses minimal supervision to help models reason about\nsafety risks and make context-aware refusals. Experiments across multiple\nbenchmarks show that SafeCoT significantly reduces overrefusal and enhances\ngeneralization, even with limited training data. Our approach offers a scalable\nsolution for aligning VLMs with safety-critical objectives.", "AI": {"tldr": "SafeCoT is a lightweight framework that improves refusal behavior in vision-language models by using rule-based chain-of-thought supervision, significantly reducing overrefusal and enhancing generalization.", "motivation": "There is a critical need to ensure safe and appropriate responses from vision-language models especially in high-risk or ambiguous scenarios. Current methods rely on large-scale safety annotations or complex modeling which can be resource-intensive.", "method": "The SafeCoT framework uses minimal, rule-based chain-of-thought (CoT) supervision to help models reason about safety risks and make context-aware refusals without needing large-scale safety annotations or complex modeling.", "result": "Experiments across multiple benchmarks indicate that SafeCoT significantly reduces overrefusal and enhances generalization even with limited training data.", "conclusion": "SafeCoT offers a scalable solution for aligning vision-language models with safety-critical objectives."}}
{"id": "2506.08063", "pdf": "https://arxiv.org/pdf/2506.08063", "abs": "https://arxiv.org/abs/2506.08063", "authors": ["Songqiao Hu", "Zeyi Liu", "Xiao He"], "title": "Lite-RVFL: A Lightweight Random Vector Functional-Link Neural Network for Learning Under Concept Drift", "categories": ["cs.LG", "cs.SY", "eess.SY"], "comment": "6 pages, 4 figures, accepted by the 2025 CAA Symposium on Fault\n  Detection, Supervision and Safety for Technical Processes (SAFEPROCESS 2025)", "summary": "The change in data distribution over time, also known as concept drift, poses\na significant challenge to the reliability of online learning methods. Existing\nmethods typically require model retraining or drift detection, both of which\ndemand high computational costs and are often unsuitable for real-time\napplications. To address these limitations, a lightweight, fast and efficient\nrandom vector functional-link network termed Lite-RVFL is proposed, capable of\nadapting to concept drift without drift detection and retraining. Lite-RVFL\nintroduces a novel objective function that assigns weights exponentially\nincreasing to new samples, thereby emphasizing recent data and enabling timely\nadaptation. Theoretical analysis confirms the feasibility of this objective\nfunction for drift adaptation, and an efficient incremental update rule is\nderived. Experimental results on a real-world safety assessment task validate\nthe efficiency, effectiveness in adapting to drift, and potential to capture\ntemporal patterns of Lite-RVFL. The source code is available at\nhttps://github.com/songqiaohu/Lite-RVFL.", "AI": {"tldr": "The paper proposes Lite-RVFL, a network that adapts to concept drift without detection or retraining by emphasizing recent data through an exponential weighting function. Experiments show its efficiency and effectiveness.", "motivation": "Existing methods for handling concept drift in online learning require model retraining or drift detection, which are computationally expensive and not suitable for real-time applications.", "method": "Lite-RVFL introduces an objective function that assigns exponentially increasing weights to new samples, allowing the model to adapt to concept drift without needing drift detection or retraining.", "result": "Experimental results on a real-world safety assessment task demonstrate the efficiency and effectiveness of Lite-RVFL in adapting to drift, as well as its potential to capture temporal patterns.", "conclusion": "Lite-RVFL is a lightweight, fast, and efficient solution for adapting to concept drift in online learning scenarios without requiring drift detection or retraining."}}
{"id": "2506.08866", "pdf": "https://arxiv.org/pdf/2506.08866", "abs": "https://arxiv.org/abs/2506.08866", "authors": ["Mordechai Guri"], "title": "SmartAttack: Air-Gap Attack via Smartwatches", "categories": ["cs.CR"], "comment": "Accepted to IEEE COMPSAC 2025 (SEPT)", "summary": "Air-gapped systems are considered highly secure against data leaks due to\ntheir physical isolation from external networks. Despite this protection,\nultrasonic communication has been demonstrated as an effective method for\nexfiltrating data from such systems. While smartphones have been extensively\nstudied in the context of ultrasonic covert channels, smartwatches remain an\nunderexplored yet effective attack vector.\n  In this paper, we propose and evaluate SmartAttack, a novel method that\nleverages smartwatches as receivers for ultrasonic covert communication in\nair-gapped environments. Our approach utilizes the built-in microphones of\nsmartwatches to capture covert signals in real time within the ultrasonic\nfrequency range of 18-22 kHz. Through experimental validation, we assess the\nfeasibility of this attack under varying environmental conditions, distances,\norientations, and noise levels. Furthermore, we analyze smartwatch-specific\nfactors that influence ultrasonic covert channels, including their continuous\npresence on the user's wrist, the impact of the human body on signal\npropagation, and the directional constraints of built-in microphones. Our\nfindings highlight the security risks posed by smartwatches in high-security\nenvironments and outline mitigation strategies to counteract this emerging\nthreat.", "AI": {"tldr": "SmartAttack uses smartwatches to receive ultrasonic signals for covert communication in air-gapped systems, demonstrating feasible data exfiltration under various conditions and discussing mitigation strategies.", "motivation": "To explore the potential of smartwatches as an effective attack vector for ultrasonic covert channels in air-gapped systems, despite their physical isolation from external networks.", "method": "Propose SmartAttack, leveraging smartwatch microphones to capture ultrasonic signals (18-22 kHz) in real time. Evaluate feasibility through experiments varying environmental conditions, distances, orientations, and noise levels. Analyze smartwatch-specific factors impacting signal propagation.", "result": "Experimental results show that ultrasonic covert communication via smartwatches is feasible under various conditions, with factors such as human body presence and microphone directionality influencing effectiveness.", "conclusion": "Smartwatches pose security risks in high-security environments due to their ability to facilitate ultrasonic covert channels; mitigation strategies are necessary to counteract this threat."}}
{"id": "2506.08401", "pdf": "https://arxiv.org/pdf/2506.08401", "abs": "https://arxiv.org/abs/2506.08401", "authors": ["Runze Li", "Di Jin", "Xiaobao Wang", "Dongxiao He", "Bingdao Feng", "Zhen Wang"], "title": "Single-Node Trigger Backdoor Attacks in Graph-Based Recommendation Systems", "categories": ["cs.AI"], "comment": null, "summary": "Graph recommendation systems have been widely studied due to their ability to\neffectively capture the complex interactions between users and items. However,\nthese systems also exhibit certain vulnerabilities when faced with attacks. The\nprevailing shilling attack methods typically manipulate recommendation results\nby injecting a large number of fake nodes and edges. However, such attack\nstrategies face two primary challenges: low stealth and high destructiveness.\nTo address these challenges, this paper proposes a novel graph backdoor attack\nmethod that aims to enhance the exposure of target items to the target user in\na covert manner, without affecting other unrelated nodes. Specifically, we\ndesign a single-node trigger generator, which can effectively expose multiple\ntarget items to the target user by inserting only one fake user node.\nAdditionally, we introduce constraint conditions between the target nodes and\nirrelevant nodes to mitigate the impact of fake nodes on the recommendation\nsystem's performance. Experimental results show that the exposure of the target\nitems reaches no less than 50% in 99% of the target users, while the impact on\nthe recommendation system's performance is controlled within approximately 5%.", "AI": {"tldr": "This paper proposes a novel covert graph backdoor attack method for recommendation systems that enhances target item exposure to target users with minimal impact on system performance.", "motivation": "Graph recommendation systems are vulnerable to attacks, especially shilling attacks which inject fake nodes and edges. However, existing methods suffer from low stealth and high destructiveness.", "method": "The paper designs a single-node trigger generator to expose multiple target items to the target user by inserting one fake user node. Constraint conditions are introduced between target and irrelevant nodes to reduce impact on the recommendation system's overall performance.", "result": "In 99% of target users, the exposure of target items reached at least 50%, while the impact on the recommendation system's performance was controlled within approximately 5%.", "conclusion": "The proposed graph backdoor attack method effectively increases target item exposure in a covert manner with limited influence on unrelated nodes and overall system performance."}}
{"id": "2506.08070", "pdf": "https://arxiv.org/pdf/2506.08070", "abs": "https://arxiv.org/abs/2506.08070", "authors": ["Ziheng Qin", "Hailun Xu", "Wei Chee Yew", "Qi Jia", "Yang Luo", "Kanchan Sarkar", "Danhui Guan", "Kai Wang", "Yang You"], "title": "Info-Coevolution: An Efficient Framework for Data Model Coevolution", "categories": ["cs.LG", "cs.AI"], "comment": "V1", "summary": "Machine learning relies heavily on data, yet the continuous growth of\nreal-world data poses challenges for efficient dataset construction and\ntraining. A fundamental yet unsolved question is: given our current model and\ndata, does a new data (sample/batch) need annotation/learning? Conventional\napproaches retain all available data, leading to non-optimal data and training\nefficiency. Active learning aims to reduce data redundancy by selecting a\nsubset of samples to annotate, while it increases pipeline complexity and\nintroduces bias. In this work, we propose Info-Coevolution, a novel framework\nthat efficiently enables models and data to coevolve through online selective\nannotation with no bias. Leveraging task-specific models (and open-source\nmodels), it selectively annotates and integrates online and web data to improve\ndatasets efficiently. For real-world datasets like ImageNet-1K,\nInfo-Coevolution reduces annotation and training costs by 32\\% without\nperformance loss. It is able to automatically give the saving ratio without\ntuning the ratio. It can further reduce the annotation ratio to 50\\% with\nsemi-supervised learning. We also explore retrieval-based dataset enhancement\nusing unlabeled open-source data. Code is available at\nhttps://github.com/NUS-HPC-AI-Lab/Info-Coevolution/.", "AI": {"tldr": "The paper introduces Info-Coevolution, a framework that allows models and data to coevolve efficiently by selectively annotating data without introducing bias. It reduces annotation and training costs by 32% on ImageNet-1K without performance loss.", "motivation": "The continuous growth of real-world data challenges efficient dataset construction and training in machine learning. The question arises whether all new data needs annotation or learning, as conventional approaches retaining all data lead to inefficiencies. Active learning, while reducing redundancy, increases complexity and introduces bias.", "method": "Info-Coevolution leverages task-specific and open-source models to enable online selective annotation of data, allowing models and datasets to coevolve efficiently without bias. It integrates online and web data to enhance datasets and can automatically determine the saving ratio without manual tuning.", "result": "On ImageNet-1K, Info-Coevolution reduces annotation and training costs by 32% without any performance loss. With semi-supervised learning, it can further reduce the annotation ratio to 50%. Additionally, retrieval-based dataset enhancement using unlabeled open-source data is explored.", "conclusion": "Info-Coevolution presents an effective solution for efficient dataset construction and training by enabling unbiased selective annotation and coevolution of models and data."}}
{"id": "2506.08918", "pdf": "https://arxiv.org/pdf/2506.08918", "abs": "https://arxiv.org/abs/2506.08918", "authors": ["Vasilios Mavroudis", "Tariq Elahi"], "title": "Quantifying Mix Network Privacy Erosion with Generative Models", "categories": ["cs.CR"], "comment": null, "summary": "Modern mix networks improve over Tor and provide stronger privacy guarantees\nby robustly obfuscating metadata. As long as a message is routed through at\nleast one honest mixnode, the privacy of the users involved is safeguarded.\nHowever, the complexity of the mixing mechanisms makes it difficult to estimate\nthe cumulative privacy erosion occurring over time. This work uses a generative\nmodel trained on mixnet traffic to estimate the loss of privacy when users\ncommunicate persistently over a period of time. We train our large-language\nmodel from scratch on our specialized network traffic ``language'' and then use\nit to measure the sender-message unlinkability in various settings (e.g. mixing\nstrategies, security parameters, observation window). Our findings reveal\nnotable differences in privacy levels among mix strategies, even when they have\nsimilar mean latencies. In comparison, we demonstrate the limitations of\ntraditional privacy metrics, such as entropy and log-likelihood, in fully\ncapturing an adversary's potential to synthesize information from multiple\nobservations. Finally, we show that larger models exhibit greater sample\nefficiency and superior capabilities implying that further advancements in\ntransformers will consequently enhance the accuracy of model-based privacy\nestimates.", "AI": {"tldr": "Modern mix networks offer stronger privacy than Tor by obfuscating metadata. This study uses a generative model trained on mixnet traffic to estimate privacy loss over time, revealing differences in privacy levels among mix strategies and demonstrating the limitations of traditional privacy metrics.", "motivation": "Modern mix networks provide robust privacy by obfuscating metadata, but the complexity of mixing mechanisms makes it hard to estimate cumulative privacy erosion over time.", "method": "The researchers train a large-language model from scratch on specialized network traffic data to measure sender-message unlinkability in various settings, including different mixing strategies and security parameters.", "result": "Notable differences in privacy levels were found among mix strategies with similar mean latencies. Traditional privacy metrics like entropy and log-likelihood were shown to be insufficient for capturing an adversary's potential to synthesize information from multiple observations. Larger models exhibited greater sample efficiency and superior capabilities.", "conclusion": "Advancements in transformers will enhance the accuracy of model-based privacy estimates."}}
{"id": "2506.08422", "pdf": "https://arxiv.org/pdf/2506.08422", "abs": "https://arxiv.org/abs/2506.08422", "authors": ["Ikkei Itoku", "David Theil", "Evelyn Eichelsdoerfer Uehara", "Sreyoshi Bhaduri", "Junnosuke Kuroda", "Toshi Yumoto", "Alex Gil", "Natalie Perez", "Rajesh Cherukuri", "Naumaan Nayyar"], "title": "Transforming Expert Knowledge into Scalable Ontology via Large Language Models", "categories": ["cs.AI"], "comment": null, "summary": "Having a unified, coherent taxonomy is essential for effective knowledge\nrepresentation in domain-specific applications as diverse terminologies need to\nbe mapped to underlying concepts. Traditional manual approaches to taxonomy\nalignment rely on expert review of concept pairs, but this becomes\nprohibitively expensive and time-consuming at scale, while subjective\ninterpretations often lead to expert disagreements. Existing automated methods\nfor taxonomy alignment have shown promise but face limitations in handling\nnuanced semantic relationships and maintaining consistency across different\ndomains. These approaches often struggle with context-dependent concept\nmappings and lack transparent reasoning processes. We propose a novel framework\nthat combines large language models (LLMs) with expert calibration and\niterative prompt optimization to automate taxonomy alignment. Our method\nintegrates expert-labeled examples, multi-stage prompt engineering, and human\nvalidation to guide LLMs in generating both taxonomy linkages and supporting\nrationales. In evaluating our framework on a domain-specific mapping task of\nconcept essentiality, we achieved an F1-score of 0.97, substantially exceeding\nthe human benchmark of 0.68. These results demonstrate the effectiveness of our\napproach in scaling taxonomy alignment while maintaining high-quality mappings\nand preserving expert oversight for ambiguous cases.", "AI": {"tldr": "The paper presents a framework combining LLMs with expert calibration and prompt optimization for automating taxonomy alignment, achieving an F1-score of 0.97.", "motivation": "To address the challenges of manual and existing automated methods in handling nuanced semantic relationships and maintaining consistency in large-scale taxonomy alignment.", "method": "The method integrates expert-labeled examples, multi-stage prompt engineering, and human validation to guide LLMs in generating both taxonomy linkages and supporting rationales.", "result": "Evaluated on a domain-specific mapping task, the framework achieved an F1-score of 0.97, surpassing the human benchmark of 0.68.", "conclusion": "The approach effectively scales taxonomy alignment while maintaining high-quality mappings and preserving expert oversight for ambiguous cases."}}
{"id": "2506.08113", "pdf": "https://arxiv.org/pdf/2506.08113", "abs": "https://arxiv.org/abs/2506.08113", "authors": ["Timoth\u00e9e Hornek Amir Sartipi", "Igor Tchappi", "Gilbert Fridgen"], "title": "Benchmarking Pre-Trained Time Series Models for Electricity Price Forecasting", "categories": ["cs.LG", "cs.AI", "q-fin.ST"], "comment": null, "summary": "Accurate electricity price forecasting (EPF) is crucial for effective\ndecision-making in power trading on the spot market. While recent advances in\ngenerative artificial intelligence (GenAI) and pre-trained large language\nmodels (LLMs) have inspired the development of numerous time series foundation\nmodels (TSFMs) for time series forecasting, their effectiveness in EPF remains\nuncertain. To address this gap, we benchmark several state-of-the-art\npretrained models--Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and\nTimeGPT--against established statistical and machine learning (ML) methods for\nEPF. Using 2024 day-ahead auction (DAA) electricity prices from Germany,\nFrance, the Netherlands, Austria, and Belgium, we generate daily forecasts with\na one-day horizon. Chronos-Bolt and Time-MoE emerge as the strongest among the\nTSFMs, performing on par with traditional models. However, the biseasonal MSTL\nmodel, which captures daily and weekly seasonality, stands out for its\nconsistent performance across countries and evaluation metrics, with no TSFM\nstatistically outperforming it.", "AI": {"tldr": "Electricity price forecasting is vital in power trading. This study benchmarks several advanced models like Chronos-Bolt, Time-MoE, and biseasonal MSTL against traditional methods using day-ahead auction data from five European countries. Results indicate that while some TSFMs perform well, the biseasonal MSTL model consistently outperforms.", "motivation": "Accurate electricity price forecasting (EPF) plays a critical role in effective decision-making in power trading on the spot market. The rise of generative artificial intelligence (GenAI) and pre-trained large language models (LLMs) has led to the development of time series foundation models (TSFMs). However, their effectiveness in EPF remains unclear, prompting the need for a benchmarking study.", "method": "The research evaluates several state-of-the-art pretrained models including Chronos-Bolt, Chronos-T5, TimesFM, Moirai, Time-MoE, and TimeGPT against established statistical and machine learning (ML) methods for EPF. The evaluation uses 2024 day-ahead auction (DAA) electricity prices from Germany, France, the Netherlands, Austria, and Belgium, generating daily forecasts with a one-day horizon.", "result": "Chronos-Bolt and Time-MoE emerge as the strongest among the TSFMs, performing similarly to traditional models. However, the biseasonal MSTL model stands out due to its consistent performance across different countries and evaluation metrics, with no TSFM statistically surpassing it.", "conclusion": "While some TSFMs show promise in electricity price forecasting, the biseasonal MSTL model demonstrates superior and consistent performance compared to these advanced models."}}
{"id": "2506.08922", "pdf": "https://arxiv.org/pdf/2506.08922", "abs": "https://arxiv.org/abs/2506.08922", "authors": ["Cl\u00e9ment Parssegny", "Johan Mazel", "Olivier Levillain", "Pierre Chifflier"], "title": "Striking Back At Cobalt: Using Network Traffic Metadata To Detect Cobalt Strike Masquerading Command and Control Channels", "categories": ["cs.CR"], "comment": null, "summary": "Off-the-shelf software for Command and Control is often used by attackers and\nlegitimate pentesters looking for discretion. Among other functionalities,\nthese tools facilitate the customization of their network traffic so it can\nmimic popular websites, thereby increasing their secrecy. Cobalt Strike is one\nof the most famous solutions in this category, used by known advanced attacker\ngroups such as \"Mustang Panda\" or \"Nobelium\". In response to these threats,\nSecurity Operation Centers and other defense actors struggle to detect Command\nand Control traffic, which often use encryption protocols such as TLS. Network\ntraffic metadata-based machine learning approaches have been proposed to detect\nencrypted malware communications or fingerprint websites over Tor network. This\npaper presents a machine learning-based method to detect Cobalt Strike Command\nand Control activity based only on widely used network traffic metadata. The\nproposed method is, to the best of our knowledge, the first of its kind that is\nable to adapt the model it uses to the observed traffic to optimize its\nperformance. This specificity permits our method to performs equally or better\nthan the state of the art while using standard features. Our method is thus\neasier to use in a production environment and more explainable.", "AI": {"tldr": "A machine learning method is presented to detect Cobalt Strike Command and Control activity based on network traffic metadata. The method adapts its model to observed traffic for optimized performance, performing equal to or better than current standards while being more production-friendly and explainable.", "motivation": "Cobalt Strike is a popular tool used by attackers which can mimic popular websites' network traffic, making it difficult for Security Operation Centers and defense actors to detect malicious Command and Control traffic, especially when encryption protocols like TLS are used.", "method": "The paper proposes a machine learning-based method that uses widely adopted network traffic metadata to detect Cobalt Strike Command and Control activities. It introduces a model that adapts to the observed traffic to enhance detection performance.", "result": "The proposed method performs equally or better than existing state-of-the-art methods while utilizing standard features, making it easier to implement in a production environment and more understandable.", "conclusion": "This is reportedly the first method of its kind that can adapt its model to observed traffic for improved performance in detecting Cobalt Strike Command and Control activity using network traffic metadata."}}
{"id": "2506.08424", "pdf": "https://arxiv.org/pdf/2506.08424", "abs": "https://arxiv.org/abs/2506.08424", "authors": ["Yong Liang Goh", "Zhiguang Cao", "Yining Ma", "Jianan Zhou", "Mohammad Haroon Dupty", "Wee Sun Lee"], "title": "SHIELD: Multi-task Multi-distribution Vehicle Routing Solver with Sparsity and Hierarchy", "categories": ["cs.AI"], "comment": "Accepted in the 42nd International Conference of Machine Learning\n  (ICML)", "summary": "Recent advances toward foundation models for routing problems have shown\ngreat potential of a unified deep model for various VRP variants. However, they\noverlook the complex real-world customer distributions. In this work, we\nadvance the Multi-Task VRP (MTVRP) setting to the more realistic yet\nchallenging Multi-Task Multi-Distribution VRP (MTMDVRP) setting, and introduce\nSHIELD, a novel model that leverages both sparsity and hierarchy principles.\nBuilding on a deeper decoder architecture, we first incorporate the\nMixture-of-Depths (MoD) technique to enforce sparsity. This improves both\nefficiency and generalization by allowing the model to dynamically select nodes\nto use or skip each decoder layer, providing the needed capacity to adaptively\nallocate computation for learning the task/distribution specific and shared\nrepresentations. We also develop a context-based clustering layer that exploits\nthe presence of hierarchical structures in the problems to produce better local\nrepresentations. These two designs inductively bias the network to identify key\nfeatures that are common across tasks and distributions, leading to\nsignificantly improved generalization on unseen ones. Our empirical results\ndemonstrate the superiority of our approach over existing methods on 9\nreal-world maps with 16 VRP variants each.", "AI": {"tldr": "This paper introduces SHIELD, a novel model for Multi-Task Multi-Distribution VRP (MTMDVRP), which leverages sparsity and hierarchy principles to improve efficiency, generalization, and performance on real-world maps.", "motivation": "The motivation is to address the limitation of current foundation models for routing problems that overlook complex real-world customer distributions by advancing to a more realistic MTMDVRP setting.", "method": "The method involves incorporating Mixture-of-Depths (MoD) technique for sparsity in a deeper decoder architecture and developing a context-based clustering layer for exploiting hierarchical structures, both contributing to better local representations and generalization.", "result": "Empirical results show superiority over existing methods on 9 real-world maps with 16 VRP variants each.", "conclusion": "SHIELD significantly improves generalization on unseen tasks and distributions in VRP problems."}}
{"id": "2506.08125", "pdf": "https://arxiv.org/pdf/2506.08125", "abs": "https://arxiv.org/abs/2506.08125", "authors": ["Hanbing Liu", "Lang Cao", "Yuanyi Ren", "Mengyu Zhou", "Haoyu Dong", "Xiaojun Ma", "Shi Han", "Dongmei Zhang"], "title": "Bingo: Boosting Efficient Reasoning of LLMs via Dynamic and Significance-based Reinforcement Learning", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Large language models have demonstrated impressive reasoning capabilities,\nyet they often suffer from inefficiencies due to unnecessarily verbose or\nredundant outputs. While many works have explored reinforcement learning (RL)\nto enhance reasoning abilities, most primarily focus on improving accuracy,\nwith limited attention to reasoning efficiency. Some existing approaches\nintroduce direct length-based rewards to encourage brevity, but this often\nleads to noticeable drops in accuracy. In this paper, we propose Bingo, an RL\nframework that advances length-based reward design to boost efficient\nreasoning. Bingo incorporates two key mechanisms: a significance-aware length\nreward, which gradually guides the model to reduce only insignificant tokens,\nand a dynamic length reward, which initially encourages elaborate reasoning for\nhard questions but decays over time to improve overall efficiency. Experiments\nacross multiple reasoning benchmarks show that Bingo improves both accuracy and\nefficiency. It outperforms the vanilla reward and several other length-based\nreward baselines in RL, achieving a favorable trade-off between accuracy and\nefficiency. These results underscore the potential of training LLMs explicitly\nfor efficient reasoning.", "AI": {"tldr": "Large language models (LLMs) often produce verbose outputs. This paper introduces Bingo, an RL framework that enhances reasoning efficiency in LLMs without sacrificing accuracy. It uses significance-aware and dynamic length rewards to achieve a balance between concise and accurate outputs.", "motivation": "To address the inefficiencies in LLMs caused by verbose or redundant outputs while maintaining or improving accuracy.", "method": "Proposes Bingo, an RL framework with two key mechanisms: significance-aware length reward and dynamic length reward. The former reduces insignificant tokens gradually, and the latter adjusts reasoning elaboration based on question difficulty over time.", "result": "Bingo improves both accuracy and efficiency across multiple reasoning benchmarks, outperforming vanilla rewards and other length-based reward baselines in RL.", "conclusion": "The results highlight the potential of training LLMs explicitly for efficient reasoning."}}
{"id": "2506.08996", "pdf": "https://arxiv.org/pdf/2506.08996", "abs": "https://arxiv.org/abs/2506.08996", "authors": ["Brian Tang", "Duc Bui", "Kang G. Shin"], "title": "Navigating Cookie Consent Violations Across the Globe", "categories": ["cs.CR"], "comment": "Published at 34th USENIX Security Symposium (2025)", "summary": "Online services provide users with cookie banners to accept/reject the\ncookies placed on their web browsers. Despite the increased adoption of cookie\nbanners, little has been done to ensure that cookie consent is compliant with\nprivacy laws around the globe. Prior studies have found that cookies are often\nplaced on browsers even after their explicit rejection by users. These\ninconsistencies in cookie banner behavior circumvent users' consent preferences\nand are known as cookie consent violations. To address this important problem,\nwe propose an end-to-end system, called ConsentChk, that detects and analyzes\ncookie banner behavior. ConsentChk uses a formal model to systematically detect\nand categorize cookie consent violations. We investigate eight English-speaking\nregions across the world, and analyze cookie banner behavior across 1,793\nglobally-popular websites. Cookie behavior, cookie consent violation rates, and\ncookie banner implementations are found to be highly dependent on region. Our\nevaluation reveals that consent management platforms (CMPs) and website\ndevelopers likely tailor cookie banner configurations based on their (often\nincorrect) interpretations of regional privacy laws. We discuss various root\ncauses behind these cookie consent violations. The resulting implementations\nproduce misleading cookie banners, indicating the prevalence of inconsistently\nimplemented and enforced cookie consent between various regions.", "AI": {"tldr": "An end-to-end system called ConsentChk is proposed to detect and analyze cookie banner behavior, revealing that cookie consent violation rates are highly dependent on region and often due to incorrect interpretations of regional privacy laws.", "motivation": "To ensure that cookie consent is compliant with privacy laws around the globe and address the problem of cookie consent violations where cookies are placed on browsers even after their explicit rejection by users.", "method": "Propose an end-to-end system named ConsentChk which uses a formal model to systematically detect and categorize cookie consent violations, investigating eight English-speaking regions across the world and analyzing cookie banner behavior across 1,793 globally-popular websites.", "result": "Cookie behavior, consent violation rates, and banner implementations are found to be highly dependent on region. CMPs and developers likely tailor cookie banner configurations based on their (often incorrect) interpretations of regional privacy laws.", "conclusion": "The implementations produce misleading cookie banners, indicating inconsistently implemented and enforced cookie consent between various regions."}}
{"id": "2506.08446", "pdf": "https://arxiv.org/pdf/2506.08446", "abs": "https://arxiv.org/abs/2506.08446", "authors": ["Peng-Yuan Wang", "Tian-Shuo Liu", "Chenyang Wang", "Yi-Di Wang", "Shu Yan", "Cheng-Xing Jia", "Xu-Hui Liu", "Xin-Wei Chen", "Jia-Cheng Xu", "Ziniu Li", "Yang Yu"], "title": "A Survey on Large Language Models for Mathematical Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Mathematical reasoning has long represented one of the most fundamental and\nchallenging frontiers in artificial intelligence research. In recent years,\nlarge language models (LLMs) have achieved significant advances in this area.\nThis survey examines the development of mathematical reasoning abilities in\nLLMs through two high-level cognitive phases: comprehension, where models gain\nmathematical understanding via diverse pretraining strategies, and answer\ngeneration, which has progressed from direct prediction to step-by-step\nChain-of-Thought (CoT) reasoning. We review methods for enhancing mathematical\nreasoning, ranging from training-free prompting to fine-tuning approaches such\nas supervised fine-tuning and reinforcement learning, and discuss recent work\non extended CoT and \"test-time scaling\". Despite notable progress, fundamental\nchallenges remain in terms of capacity, efficiency, and generalization. To\naddress these issues, we highlight promising research directions, including\nadvanced pretraining and knowledge augmentation techniques, formal reasoning\nframeworks, and meta-generalization through principled learning paradigms. This\nsurvey tries to provide some insights for researchers interested in enhancing\nreasoning capabilities of LLMs and for those seeking to apply these techniques\nto other domains.", "AI": {"tldr": "\u6570\u5b66\u63a8\u7406\u662fAI\u7814\u7a76\u7684\u91cd\u8981\u9886\u57df\uff0c\u8fd1\u5e74\u6765\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8be5\u9886\u57df\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002\u672c\u6587\u56de\u987e\u4e86LLM\u5728\u6570\u5b66\u63a8\u7406\u80fd\u529b\u65b9\u9762\u7684\u8fdb\u5c55\uff0c\u5305\u62ec\u7406\u89e3\u4e0e\u7b54\u6848\u751f\u6210\u4e24\u4e2a\u9636\u6bb5\uff0c\u5e76\u8ba8\u8bba\u4e86\u589e\u5f3a\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u4ee5\u53ca\u9762\u4e34\u7684\u6311\u6218\u548c\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u63d0\u5347\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6570\u5b66\u63a8\u7406\u80fd\u529b\u5bf9\u4e8e\u63a8\u52a8\u4eba\u5de5\u667a\u80fd\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u540c\u65f6\u8fd9\u4e00\u9886\u57df\u7684\u7814\u7a76\u4e5f\u9762\u4e34\u8bf8\u591a\u6311\u6218\u3002", "method": "\u901a\u8fc7\u56de\u987e\u4e24\u79cd\u9ad8\u7ea7\u8ba4\u77e5\u9636\u6bb5\uff08\u7406\u89e3\u4e0e\u7b54\u6848\u751f\u6210\uff09\u7684\u53d1\u5c55\uff0c\u4ee5\u53ca\u4ece\u65e0\u8bad\u7ec3\u63d0\u793a\u5230\u5fae\u8c03\u65b9\u6cd5\uff08\u5982\u76d1\u7763\u5fae\u8c03\u548c\u5f3a\u5316\u5b66\u4e60\uff09\u7b49\u589e\u5f3a\u6570\u5b66\u63a8\u7406\u80fd\u529b\u7684\u65b9\u6cd5\u3002", "result": "\u5c3d\u7ba1\u53d6\u5f97\u4e86\u4e00\u5b9a\u7684\u8fdb\u5c55\uff0c\u4f46\u5728\u5bb9\u91cf\u3001\u6548\u7387\u548c\u6cdb\u5316\u65b9\u9762\u4ecd\u5b58\u5728\u6839\u672c\u6027\u6311\u6218\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6709\u524d\u666f\u7684\u7814\u7a76\u65b9\u5411\uff0c\u5982\u5148\u8fdb\u7684\u9884\u8bad\u7ec3\u548c\u77e5\u8bc6\u589e\u5f3a\u6280\u672f\u3001\u5f62\u5f0f\u63a8\u7406\u6846\u67b6\u53ca\u901a\u8fc7\u539f\u5219\u6027\u5b66\u4e60\u8303\u5f0f\u5b9e\u73b0\u7684\u5143\u6cdb\u5316\uff0c\u4e3a\u6709\u5174\u8da3\u63d0\u9ad8LLM\u63a8\u7406\u80fd\u529b\u7684\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002"}}
{"id": "2506.08139", "pdf": "https://arxiv.org/pdf/2506.08139", "abs": "https://arxiv.org/abs/2506.08139", "authors": ["Aviad Susman", "Mayte Su\u00e1rez-Fari\u00f1as", "Joseph T Colonel"], "title": "Nearness of Neighbors Attention for Regression in Supervised Finetuning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "It is common in supervised machine learning to combine the feature extraction\ncapabilities of neural networks with the predictive power of traditional\nalgorithms, such as k-nearest neighbors (k-NN) or support vector machines. This\nprocedure involves performing supervised fine-tuning (SFT) on a\ndomain-appropriate feature extractor, followed by training a traditional\npredictor on the resulting SFT embeddings. When used in this manner,\ntraditional predictors often deliver increased performance over the SFT model\nitself, despite the fine-tuned feature extractor yielding embeddings\nspecifically optimized for prediction by the neural network's final dense\nlayer. This suggests that directly incorporating traditional algorithms into\nSFT as prediction layers may further improve performance. However, many\ntraditional algorithms have not been implemented as neural network layers due\nto their non-differentiable nature and their unique optimization requirements.\nAs a step towards solving this problem, we introduce the Nearness of Neighbors\nAttention (NONA) regression layer. NONA uses the mechanics of neural network\nattention and a novel learned attention-masking scheme to yield a\ndifferentiable proxy of the k-NN regression algorithm. Results on multiple\nunstructured datasets show improved performance over both dense layer\nprediction and k-NN on SFT embeddings for regression.", "AI": {"tldr": "The paper introduces Nearness of Neighbors Attention (NONA) regression layer, a differentiable proxy for k-NN regression algorithm, using neural network attention and a novel learned attention-masking scheme. Results show improved performance over dense layer prediction and k-NN on SFT embeddings in regression tasks.", "motivation": "Traditional predictors often deliver increased performance over the SFT model itself when combined with neural networks in supervised machine learning. This suggests that directly incorporating traditional algorithms into SFT as prediction layers may further improve performance.", "method": "The authors introduce NONA, which uses the mechanics of neural network attention and a novel learned attention-masking scheme to yield a differentiable proxy of the k-NN regression algorithm.", "result": "Results on multiple unstructured datasets show improved performance over both dense layer prediction and k-NN on SFT embeddings for regression.", "conclusion": "The Nearness of Neighbors Attention (NONA) regression layer offers a way to incorporate traditional algorithms like k-NN into neural networks, improving performance in regression tasks."}}
{"id": "2506.08055", "pdf": "https://arxiv.org/pdf/2506.08055", "abs": "https://arxiv.org/abs/2506.08055", "authors": ["Sabbir M. Saleh", "Nazim Madhavji", "John Steinbacher"], "title": "A Systematic Literature Review on Continuous Integration and Deployment (CI/CD) for Secure Cloud Computing", "categories": ["cs.SE", "cs.CR", "D.2.11"], "comment": "11 pages, 3 figures", "summary": "As cloud environments become widespread, cybersecurity has emerged as a top\npriority across areas such as networks, communication, data privacy, response\ntimes, and availability. Various sectors, including industries, healthcare, and\ngovernment, have recently faced cyberattacks targeting their computing systems.\nEnsuring secure app deployment in cloud environments requires substantial\neffort. With the growing interest in cloud security, conducting a systematic\nliterature review (SLR) is critical to identifying research gaps. Continuous\nSoftware Engineering, which includes continuous integration (CI), delivery\n(CDE), and deployment (CD), is essential for software development and\ndeployment. In our SLR, we reviewed 66 papers, summarising tools, approaches,\nand challenges related to the security of CI/CD in the cloud. We addressed key\naspects of cloud security and CI/CD and reported on tools such as Harbor,\nSonarQube, and GitHub Actions. Challenges such as image manipulation,\nunauthorised access, and weak authentication were highlighted. The review also\nuncovered research gaps in how tools and practices address these security\nissues in CI/CD pipelines, revealing a need for further study to improve\ncloud-based security solutions.", "AI": {"tldr": "In this paper, the authors conduct a systematic literature review of 66 papers focused on cloud security in continuous software engineering, specifically CI/CD pipelines. They identify key tools (Harbor, SonarQube, GitHub Actions), challenges (image manipulation, unauthorized access, weak authentication), and research gaps in improving cloud-based security solutions.", "motivation": "The motivation for this paper is the increasing importance of cybersecurity in cloud environments due to the rise in cyberattacks across various sectors. Ensuring secure app deployment in the cloud has become a significant challenge that requires substantial effort.", "method": "The authors performed a systematic literature review (SLR) of 66 papers. They examined tools, approaches, and challenges related to securing CI/CD processes in cloud environments.", "result": "The SLR identified several key tools used in cloud security such as Harbor, SonarQube, and GitHub Actions. It also highlighted challenges like image manipulation, unauthorized access, and weak authentication within CI/CD pipelines. Research gaps were uncovered regarding how current tools and practices address these security issues.", "conclusion": "There is a need for further research to enhance cloud-based security solutions, particularly within CI/CD pipelines, to effectively counteract the identified security challenges."}}
{"id": "2506.08462", "pdf": "https://arxiv.org/pdf/2506.08462", "abs": "https://arxiv.org/abs/2506.08462", "authors": ["Christos Margadji", "Sebastian W. Pattinson"], "title": "Hybrid Reasoning for Perception, Explanation, and Autonomous Action in Manufacturing", "categories": ["cs.AI", "cs.HC", "cs.RO", "cs.SY", "eess.SY"], "comment": null, "summary": "Industrial processes must be robust and adaptable, as environments and tasks\nare often unpredictable, while operational errors remain costly and difficult\nto detect. AI-based control systems offer a path forward, yet typically depend\non supervised learning with extensive labelled datasets, which limits their\nability to generalize across variable and data-scarce industrial settings.\nFoundation models could enable broader reasoning and knowledge integration, but\nrarely deliver the quantitative precision demanded by engineering applications.\nHere, we introduceControl and Interpretation of Production via Hybrid Expertise\nand Reasoning (CIPHER): a vision-language-action (VLA) model framework aiming\nto replicate human-like reasoning for industrial control, instantiated in a\ncommercial-grade 3D printer. It integrates a process expert, a regression model\nenabling quantitative characterization of system states required for\nengineering tasks. CIPHER also incorporates retrieval-augmented generation to\naccess external expert knowledge and support physics-informed, chain-of-thought\nreasoning. This hybrid architecture exhibits strong generalization to\nout-of-distribution tasks. It interprets visual or textual inputs from process\nmonitoring, explains its decisions, and autonomously generates precise machine\ninstructions, without requiring explicit annotations. CIPHER thus lays the\nfoundations for autonomous systems that act with precision, reason with\ncontext, and communicate decisions transparently, supporting safe and trusted\ndeployment in industrial settings.", "AI": {"tldr": "CIPHER is a VLA model framework that integrates process expert and regression model to enable autonomous systems with strong generalization for industrial control.", "motivation": "Industrial processes need robustness and adaptability, but AI-based control systems are limited by the need for extensive labelled datasets and foundation models lack the quantitative precision for engineering applications.", "method": "Integrates a process expert and a regression model within a vision-language-action (VLA) model framework, uses retrieval-augmented generation to access external expert knowledge and supports physics-informed reasoning.", "result": "Exhibits strong generalization to out-of-distribution tasks, interprets visual or textual inputs, explains decisions, and autonomously generates precise machine instructions without explicit annotations.", "conclusion": "Lays the foundations for autonomous systems that act with precision, reason with context, and communicate decisions transparently, supporting safe deployment in industrial settings."}}
{"id": "2506.08140", "pdf": "https://arxiv.org/pdf/2506.08140", "abs": "https://arxiv.org/abs/2506.08140", "authors": ["Yifei Li", "Hanane Nour Moussa", "Ziru Chen", "Shijie Chen", "Botao Yu", "Mingyi Xue", "Benjamin Burns", "Tzu-Yao Chiu", "Vishal Dey", "Zitong Lu", "Chen Wei", "Qianheng Zhang", "Tianyu Zhang", "Song Gao", "Xuhui Huang", "Xia Ning", "Nesreen K. Ahmed", "Ali Payani", "Huan Sun"], "title": "AutoSDT: Scaling Data-Driven Discovery Tasks Toward Open Co-Scientists", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Despite long-standing efforts in accelerating scientific discovery with AI,\nbuilding AI co-scientists remains challenging due to limited high-quality data\nfor training and evaluation. To tackle this data scarcity issue, we present\nAutoSDT, an automatic pipeline that collects high-quality coding tasks in\nreal-world data-driven discovery workflows. AutoSDT leverages the coding\ncapabilities and parametric knowledge of LLMs to search for diverse sources,\nselect ecologically valid tasks, and synthesize accurate task instructions and\ncode solutions. Using our pipeline, we construct AutoSDT-5K, a dataset of 5,404\ncoding tasks for data-driven discovery that covers four scientific disciplines\nand 756 unique Python packages. To the best of our knowledge, AutoSDT-5K is the\nonly automatically collected and the largest open dataset for data-driven\nscientific discovery. Expert feedback on a subset of 256 tasks shows the\neffectiveness of AutoSDT: 93% of the collected tasks are ecologically valid,\nand 92.2% of the synthesized programs are functionally correct. Trained on\nAutoSDT-5K, the Qwen2.5-Coder-Instruct LLM series, dubbed AutoSDT-Coder, show\nsubstantial improvement on two challenging data-driven discovery benchmarks,\nScienceAgentBench and DiscoveryBench. Most notably, AutoSDT-Coder-32B reaches\nthe same level of performance as GPT-4o on ScienceAgentBench with a success\nrate of 7.8%, doubling the performance of its base model. On DiscoveryBench, it\nlifts the hypothesis matching score to 8.1, bringing a 17.4% relative\nimprovement and closing the gap between open-weight models and GPT-4o.", "AI": {"tldr": "The paper introduces AutoSDT, an automatic pipeline to collect high-quality coding tasks for data-driven scientific discovery workflows. It creates the AutoSDT-5K dataset, which is used to train the Qwen2.5-Coder-Instruct LLM series (AutoSDT-Coder). This leads to significant improvements on benchmarks like ScienceAgentBench and DiscoveryBench.", "motivation": "There is a lack of high-quality data for training and evaluating AI models in the field of scientific discovery. The authors aim to address this issue by creating a system that automatically gathers relevant coding tasks.", "method": "The AutoSDT pipeline leverages the capabilities of LLMs to search for diverse sources, select valid tasks, and synthesize accurate task instructions and code solutions. Using this pipeline, they construct the AutoSDT-5K dataset consisting of 5,404 coding tasks covering four scientific disciplines and 756 unique Python packages.", "result": "Expert feedback indicates that 93% of the collected tasks are ecologically valid and 92.2% of the synthesized programs are functionally correct. Training on AutoSDT-5K significantly improves performance on challenging benchmarks, with AutoSDT-Coder-32B doubling the performance of its base model on ScienceAgentBench and achieving a 17.4% relative improvement on DiscoveryBench.", "conclusion": "AutoSDT addresses the data scarcity issue in AI for scientific discovery by providing a large, high-quality dataset. The resulting AutoSDT-Coder LLM series demonstrates substantial improvements in performance on data-driven discovery benchmarks."}}
{"id": "2506.08312", "pdf": "https://arxiv.org/pdf/2506.08312", "abs": "https://arxiv.org/abs/2506.08312", "authors": ["Tom\u00e1s Gonz\u00e1lez", "Giulia Fanti", "Aaditya Ramdas"], "title": "Private Evolution Converges", "categories": ["cs.LG", "cs.CR", "cs.DS", "math.PR", "math.ST", "stat.TH", "68P27 (Primary) 68Q32, 68Q87, 60B10 (Secondary)"], "comment": null, "summary": "Private Evolution (PE) is a promising training-free method for differentially\nprivate (DP) synthetic data generation. While it achieves strong performance in\nsome domains (e.g., images and text), its behavior in others (e.g., tabular\ndata) is less consistent. To date, the only theoretical analysis of the\nconvergence of PE depends on unrealistic assumptions about both the algorithm's\nbehavior and the structure of the sensitive dataset. In this work, we develop a\nnew theoretical framework to explain PE's practical behavior and identify\nsufficient conditions for its convergence. For $d$-dimensional sensitive\ndatasets with $n$ data points from a bounded domain, we prove that PE produces\nan $(\\epsilon, \\delta)$-DP synthetic dataset with expected 1-Wasserstein\ndistance of order $\\tilde{O}(d(n\\epsilon)^{-1/d})$ from the original,\nestablishing worst-case convergence of the algorithm as $n \\to \\infty$. Our\nanalysis extends to general Banach spaces as well. We also connect PE to the\nPrivate Signed Measure Mechanism, a method for DP synthetic data generation\nthat has thus far not seen much practical adoption. We demonstrate the\npractical relevance of our theoretical findings in simulations.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08486", "pdf": "https://arxiv.org/pdf/2506.08486", "abs": "https://arxiv.org/abs/2506.08486", "authors": ["Rahatara Ferdousi", "M Anwar Hossain"], "title": "RHealthTwin: Towards Responsible and Multimodal Digital Twins for Personalized Well-being", "categories": ["cs.AI", "68T50, 92C50, 68T01 68T50, 92C50, 68T01 68T50, 92C50, 68T01", "I.2.7; J.3; I.5.1"], "comment": "18 pages, 12 figures, IEEE EMBS JBHI", "summary": "The rise of large language models (LLMs) has created new possibilities for\ndigital twins in healthcare. However, the deployment of such systems in\nconsumer health contexts raises significant concerns related to hallucination,\nbias, lack of transparency, and ethical misuse. In response to recommendations\nfrom health authorities such as the World Health Organization (WHO), we propose\nResponsible Health Twin (RHealthTwin), a principled framework for building and\ngoverning AI-powered digital twins for well-being assistance. RHealthTwin\nprocesses multimodal inputs that guide a health-focused LLM to produce safe,\nrelevant, and explainable responses. At the core of RHealthTwin is the\nResponsible Prompt Engine (RPE), which addresses the limitations of traditional\nLLM configuration. Conventionally, users input unstructured prompt and the\nsystem instruction to configure the LLM, which increases the risk of\nhallucination. In contrast, RPE extracts predefined slots dynamically to\nstructure both inputs. This guides the language model to generate responses\nthat are context aware, personalized, fair, reliable, and explainable for\nwell-being assistance. The framework further adapts over time through a\nfeedback loop that updates the prompt structure based on user satisfaction. We\nevaluate RHealthTwin across four consumer health domains including mental\nsupport, symptom triage, nutrition planning, and activity coaching. RPE\nachieves state-of-the-art results with BLEU = 0.41, ROUGE-L = 0.63, and\nBERTScore = 0.89 on benchmark datasets. Also, we achieve over 90% in ethical\ncompliance and instruction-following metrics using LLM-as-judge evaluation,\noutperforming baseline strategies. We envision RHealthTwin as a forward-looking\nfoundation for responsible LLM-based applications in health and well-being.", "AI": {"tldr": "The paper introduces RHealthTwin, a framework using LLMs for healthcare digital twins addressing issues like hallucination and bias through the Responsible Prompt Engine (RPE). It shows state-of-the-art results in health domains while maintaining high ethical compliance.", "motivation": "To create a responsible AI-powered digital twin system for healthcare that addresses concerns such as hallucination, bias, lack of transparency, and ethical misuse in consumer health contexts.", "method": "Proposes RHealthTwin with a core component called Responsible Prompt Engine (RPE) that processes multimodal inputs to produce safe, relevant, and explainable responses by structuring both user inputs and system instructions dynamically. Also includes a feedback loop for adaptation over time.", "result": "RPE achieves state-of-the-art results with BLEU = 0.41, ROUGE-L = 0.63, BERTScore = 0.89 on benchmark datasets across four consumer health domains. Over 90% in ethical compliance and instruction-following metrics using LLM-as-judge evaluation.", "conclusion": "RHealthTwin serves as a forward-looking foundation for responsible LLM-based applications in health and well-being assistance."}}
{"id": "2506.08143", "pdf": "https://arxiv.org/pdf/2506.08143", "abs": "https://arxiv.org/abs/2506.08143", "authors": ["Francesco Tonin", "Alex Lambert", "Johan A. K. Suykens", "Volkan Cevher"], "title": "Accelerating Spectral Clustering under Fairness Constraints", "categories": ["cs.LG"], "comment": "ICML 2025", "summary": "Fairness of decision-making algorithms is an increasingly important issue. In\nthis paper, we focus on spectral clustering with group fairness constraints,\nwhere every demographic group is represented in each cluster proportionally as\nin the general population. We present a new efficient method for fair spectral\nclustering (Fair SC) by casting the Fair SC problem within the difference of\nconvex functions (DC) framework. To this end, we introduce a novel variable\naugmentation strategy and employ an alternating direction method of multipliers\ntype of algorithm adapted to DC problems. We show that each associated\nsubproblem can be solved efficiently, resulting in higher computational\nefficiency compared to prior work, which required a computationally expensive\neigendecomposition. Numerical experiments demonstrate the effectiveness of our\napproach on both synthetic and real-world benchmarks, showing significant\nspeedups in computation time over prior art, especially as the problem size\ngrows. This work thus represents a considerable step forward towards the\nadoption of fair clustering in real-world applications.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6709\u6548\u65b9\u6cd5\u6765\u8fdb\u884c\u516c\u5e73\u8c31\u805a\u7c7b\uff08Fair SC\uff09\uff0c\u901a\u8fc7\u5f15\u5165\u65b0\u9896\u7684\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u548c\u9002\u5e94\u4e8eDC\u95ee\u9898\u7684\u4e58\u5b50\u4ea4\u66ff\u65b9\u5411\u6cd5\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u5de5\u4f5c\u4e2d\u8ba1\u7b97\u6602\u8d35\u7684\u7279\u5f81\u5206\u89e3\u95ee\u9898\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u4e0a\u5747\u5177\u6709\u663e\u8457\u7684\u8ba1\u7b97\u52a0\u901f\u6548\u679c\u3002", "motivation": "\u51b3\u7b56\u7b97\u6cd5\u7684\u516c\u5e73\u6027\u65e5\u76ca\u91cd\u8981\uff0c\u7279\u522b\u662f\u5728\u8c31\u805a\u7c7b\u4e2d\u5b9e\u73b0\u7fa4\u4f53\u516c\u5e73\u7ea6\u675f\u7684\u95ee\u9898\uff0c\u5373\u6bcf\u4e2a\u65cf\u7fa4\u5728\u6bcf\u4e2a\u7c07\u4e2d\u7684\u4ee3\u8868\u6027\u5e94\u4e0e\u603b\u4f53\u4eba\u53e3\u6210\u6bd4\u4f8b\u3002", "method": "\u4f5c\u8005\u5c06\u516c\u5e73\u8c31\u805a\u7c7b\u95ee\u9898\u7f6e\u4e8e\u51f8\u51fd\u6570\u5dee\uff08DC\uff09\u6846\u67b6\u5185\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u53d8\u91cf\u589e\u5f3a\u7b56\u7565\u4ee5\u53ca\u9002\u5e94\u4e8eDC\u95ee\u9898\u7684\u4e58\u5b50\u4ea4\u66ff\u65b9\u5411\u6cd5\u7b97\u6cd5\u3002\u8fd9\u79cd\u65b9\u6cd5\u907f\u514d\u4e86\u5148\u524d\u5de5\u4f5c\u4e2d\u9700\u8981\u7684\u6602\u8d35\u7684\u7279\u5f81\u5206\u89e3\u8ba1\u7b97\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5408\u6210\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u5747\u8868\u73b0\u51fa\u663e\u8457\u7684\u8ba1\u7b97\u52a0\u901f\u6548\u679c\uff0c\u5c24\u5176\u662f\u5728\u95ee\u9898\u89c4\u6a21\u589e\u5927\u65f6\u66f4\u4e3a\u660e\u663e\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u516c\u5e73\u805a\u7c7b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u91cd\u8981\u7684\u8fdb\u5c55\u3002"}}
{"id": "2506.08347", "pdf": "https://arxiv.org/pdf/2506.08347", "abs": "https://arxiv.org/abs/2506.08347", "authors": ["Yinan Huang", "Haoteng Ying", "Eli Chien", "Rongzhe Wei", "Pan Li"], "title": "Differentially Private Relational Learning with Entity-level Privacy Guarantees", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "Learning with relational and network-structured data is increasingly vital in\nsensitive domains where protecting the privacy of individual entities is\nparamount. Differential Privacy (DP) offers a principled approach for\nquantifying privacy risks, with DP-SGD emerging as a standard mechanism for\nprivate model training. However, directly applying DP-SGD to relational\nlearning is challenging due to two key factors: (i) entities often participate\nin multiple relations, resulting in high and difficult-to-control sensitivity;\nand (ii) relational learning typically involves multi-stage, potentially\ncoupled (interdependent) sampling procedures that make standard privacy\namplification analyses inapplicable. This work presents a principled framework\nfor relational learning with formal entity-level DP guarantees. We provide a\nrigorous sensitivity analysis and introduce an adaptive gradient clipping\nscheme that modulates clipping thresholds based on entity occurrence frequency.\nWe also extend the privacy amplification results to a tractable subclass of\ncoupled sampling, where the dependence arises only through sample sizes. These\ncontributions lead to a tailored DP-SGD variant for relational data with\nprovable privacy guarantees. Experiments on fine-tuning text encoders over\ntext-attributed network-structured relational data demonstrate the strong\nutility-privacy trade-offs of our approach. Our code is available at\nhttps://github.com/Graph-COM/Node_DP.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5173\u7cfb\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u6846\u67b6\uff0c\u89e3\u51b3\u4e86DP-SGD\u5728\u5173\u7cfb\u5b66\u4e60\u4e2d\u7684\u5e94\u7528\u96be\u9898\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u9690\u79c1\u4fdd\u62a4\u4e0e\u6a21\u578b\u6548\u7528\u4e4b\u95f4\u7684\u826f\u597d\u6743\u8861\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u5904\u7406\u5173\u7cfb\u548c\u7f51\u7edc\u7ed3\u6784\u5316\u6570\u636e\u65f6\uff0c\u9700\u8981\u4fdd\u62a4\u4e2a\u4f53\u5b9e\u4f53\u7684\u9690\u79c1\u3002\u7136\u800c\uff0c\u76f4\u63a5\u5c06DP-SGD\u5e94\u7528\u4e8e\u5173\u7cfb\u5b66\u4e60\u5b58\u5728\u9ad8\u654f\u611f\u6027\u548c\u590d\u6742\u7684\u91c7\u6837\u8fc7\u7a0b\u7b49\u95ee\u9898\uff0c\u4e9f\u9700\u4e00\u79cd\u4e13\u95e8\u9488\u5bf9\u5173\u7cfb\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u5173\u7cfb\u5b66\u4e60\u7684\u5f62\u5f0f\u5316\u5b9e\u4f53\u7ea7\u5dee\u5206\u9690\u79c1\u6846\u67b6\u3002\n2. \u8fdb\u884c\u4e25\u683c\u7684\u654f\u611f\u6027\u5206\u6790\u5e76\u5f15\u5165\u81ea\u9002\u5e94\u68af\u5ea6\u88c1\u526a\u65b9\u6848\uff0c\u4f9d\u636e\u5b9e\u4f53\u51fa\u73b0\u9891\u7387\u8c03\u6574\u88c1\u526a\u9608\u503c\u3002\n3. \u6269\u5c55\u9690\u79c1\u653e\u5927\u7ed3\u679c\u81f3\u4e00\u7c7b\u4f9d\u8d56\u6837\u672c\u5927\u5c0f\u7684\u8026\u5408\u91c7\u6837\u5b50\u96c6\u3002\n4. \u8bbe\u8ba1\u4e86\u4e00\u79cd\u9002\u7528\u4e8e\u5173\u7cfb\u6570\u636e\u7684\u6539\u8fdb\u7248DP-SGD\u7b97\u6cd5\uff0c\u63d0\u4f9b\u53ef\u8bc1\u660e\u7684\u9690\u79c1\u4fdd\u969c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u7ec6\u8c03\u6587\u672c\u7f16\u7801\u5668\u65f6\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5173\u7cfb\u6570\u636e\u4e0a\u5b9e\u73b0\u5f3a\u5927\u7684\u6548\u7528-\u9690\u79c1\u6743\u8861\u3002\u4ee3\u7801\u5df2\u516c\u5f00\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u5173\u7cfb\u6570\u636e\u7684\u5dee\u5206\u9690\u79c1\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4fdd\u62a4\u9690\u79c1\u7684\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u6a21\u578b\u6548\u7528\u3002"}}
{"id": "2506.08518", "pdf": "https://arxiv.org/pdf/2506.08518", "abs": "https://arxiv.org/abs/2506.08518", "authors": ["Sunny Gupta", "Nikita Jangid", "Shounak Das", "Amit Sethi"], "title": "FEDTAIL: Federated Long-Tailed Domain Generalization with Sharpness-Guided Gradient Matching", "categories": ["cs.AI", "cs.CV", "cs.LG", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": "Accepted at ICML 2025 Workshop on Collaborative and Federated Agentic\n  Workflows CFAgentic @ ICML'25", "summary": "Domain Generalization (DG) seeks to train models that perform reliably on\nunseen target domains without access to target data during training. While\nrecent progress in smoothing the loss landscape has improved generalization,\nexisting methods often falter under long-tailed class distributions and\nconflicting optimization objectives. We introduce FedTAIL, a federated domain\ngeneralization framework that explicitly addresses these challenges through\nsharpness-guided, gradient-aligned optimization. Our method incorporates a\ngradient coherence regularizer to mitigate conflicts between classification and\nadversarial objectives, leading to more stable convergence. To combat class\nimbalance, we perform class-wise sharpness minimization and propose a\ncurvature-aware dynamic weighting scheme that adaptively emphasizes\nunderrepresented tail classes. Furthermore, we enhance conditional distribution\nalignment by integrating sharpness-aware perturbations into entropy\nregularization, improving robustness under domain shift. FedTAIL unifies\noptimization harmonization, class-aware regularization, and conditional\nalignment into a scalable, federated-compatible framework. Extensive\nevaluations across standard domain generalization benchmarks demonstrate that\nFedTAIL achieves state-of-the-art performance, particularly in the presence of\ndomain shifts and label imbalance, validating its effectiveness in both\ncentralized and federated settings. Code: https://github.com/sunnyinAI/FedTail", "AI": {"tldr": "FedTAIL is a federated domain generalization framework that addresses challenges in long-tailed class distributions and conflicting optimization objectives through sharpness-guided, gradient-aligned optimization. It incorporates a gradient coherence regularizer, performs class-wise sharpness minimization, and enhances conditional distribution alignment.", "motivation": "Existing methods for Domain Generalization (DG) falter under long-tailed class distributions and conflicting optimization objectives. There is a need for a method that can handle these challenges effectively.", "method": "FedTAIL introduces sharpness-guided, gradient-aligned optimization. It includes a gradient coherence regularizer to mitigate conflicts between classification and adversarial objectives. For class imbalance, it performs class-wise sharpness minimization and proposes a curvature-aware dynamic weighting scheme. Conditional distribution alignment is enhanced by integrating sharpness-aware perturbations into entropy regularization.", "result": "FedTAIL achieves state-of-the-art performance across standard domain generalization benchmarks, particularly excelling in the presence of domain shifts and label imbalance.", "conclusion": "FedTAIL unifies optimization harmonization, class-aware regularization, and conditional alignment into a scalable, federated-compatible framework, proving effective in both centralized and federated settings."}}
{"id": "2506.08146", "pdf": "https://arxiv.org/pdf/2506.08146", "abs": "https://arxiv.org/abs/2506.08146", "authors": ["Vahidullah Ta\u00e7", "Amirhossein Amiri-Hezaveh", "Manuel K. Rausch", "Grace N. Bechtel", "Francisco Sahli Costabal", "Adrian Buganza Tepole"], "title": "Fully data-driven inverse hyperelasticity with hyper-network neural ODE fields", "categories": ["cs.LG", "physics.comp-ph"], "comment": null, "summary": "We propose a new framework for identifying mechanical properties of\nheterogeneous materials without a closed-form constitutive equation. Given a\nfull-field measurement of the displacement field, for instance as obtained from\ndigital image correlation (DIC), a continuous approximation of the strain field\nis obtained by training a neural network that incorporates Fourier features to\neffectively capture sharp gradients in the data. A physics-based data-driven\nmethod built upon ordinary neural differential equations (NODEs) is employed to\ndiscover constitutive equations. The NODE framework can represent arbitrary\nmaterials while satisfying constraints in the theory of constitutive equations\nby default. To account for heterogeneity, a hyper-network is defined, where the\ninput is the material coordinate system, and the output is the NODE-based\nconstitutive equation. The parameters of the hyper-network are optimized by\nminimizing a multi-objective loss function that includes penalty terms for\nviolations of the strong form of the equilibrium equations of elasticity and\nthe associated Neumann boundary conditions. We showcase the framework with\nseveral numerical examples, including heterogeneity arising from variations in\nmaterial parameters, spatial transitions from isotropy to anisotropy, material\nidentification in the presence of noise, and, ultimately, application to\nexperimental data. As the numerical results suggest, the proposed approach is\nrobust and general in identifying the mechanical properties of heterogeneous\nmaterials with very few assumptions, making it a suitable alternative to\nclassical inverse methods.", "AI": {"tldr": "A new framework using neural networks with Fourier features and NODEs to identify mechanical properties of heterogeneous materials from displacement field data, showcasing robustness and generality in several numerical examples.", "motivation": "To address the challenge of identifying mechanical properties of heterogeneous materials without a closed-form constitutive equation, leveraging full-field measurements like those from digital image correlation (DIC).", "method": "Propose a framework that uses a neural network incorporating Fourier features for strain field approximation and NODEs for discovering constitutive equations. A hyper-network accounts for heterogeneity by taking material coordinate system as input and outputting NODE-based constitutive equations. Parameters are optimized through a multi-objective loss function including penalties for equilibrium and boundary condition violations.", "result": "The framework successfully identifies mechanical properties in various scenarios, including material parameter variations, transitions from isotropy to anisotropy, noise presence, and experimental data application, demonstrating robustness and generality.", "conclusion": "This approach offers a suitable alternative to classical inverse methods, requiring very few assumptions to effectively identify the mechanical properties of heterogeneous materials."}}
{"id": "2506.08383", "pdf": "https://arxiv.org/pdf/2506.08383", "abs": "https://arxiv.org/abs/2506.08383", "authors": ["Jiaqi Chen", "Rongbin Ye"], "title": "Network Threat Detection: Addressing Class Imbalanced Data with Deep Forest", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "With the rapid expansion of Internet of Things (IoT) networks, detecting\nmalicious traffic in real-time has become a critical cybersecurity challenge.\nThis research addresses the detection challenges by presenting a comprehensive\nempirical analysis of machine learning techniques for malware detection using\nthe IoT-23 dataset provided by the Stratosphere Laboratory. We address the\nsignificant class imbalance within the dataset through three resampling\nstrategies. We implement and compare a few machine learning techniques. Our\nfindings demonstrate that the combination of appropriate imbalance treatment\ntechniques with ensemble methods, particularly gcForest, achieves better\ndetection performance compared to traditional approaches. This work contributes\nsignificantly to the development of more intelligent and efficient automated\nthreat detection systems for IoT environments, helping to secure critical\ninfrastructure against sophisticated cyber attacks while optimizing\ncomputational resource usage.", "AI": {"tldr": "The paper conducts an empirical analysis of machine learning techniques for detecting malicious IoT traffic using the IoT-23 dataset, showing gcForest with imbalance treatment achieves superior performance.", "motivation": "To address the challenge of detecting malicious traffic in real-time within expanding IoT networks, which is crucial for cybersecurity.", "method": "Empirical analysis of machine learning techniques on the IoT-23 dataset with three resampling strategies to handle class imbalance and comparison of various methods including ensemble approaches like gcForest.", "result": "gcForest combined with appropriate imbalance treatment techniques outperforms traditional methods in detection performance.", "conclusion": "This research advances the creation of intelligent and efficient automated threat detection systems for securing IoT environments."}}
{"id": "2506.08532", "pdf": "https://arxiv.org/pdf/2506.08532", "abs": "https://arxiv.org/abs/2506.08532", "authors": ["Yanwei Gong", "Xiaolin Chang"], "title": "Safe and Economical UAV Trajectory Planning in Low-Altitude Airspace: A Hybrid DRL-LLM Approach with Compliance Awareness", "categories": ["cs.AI"], "comment": null, "summary": "The rapid growth of the low-altitude economy has driven the widespread\nadoption of unmanned aerial vehicles (UAVs). This growing deployment presents\nnew challenges for UAV trajectory planning in complex urban environments.\nHowever, existing studies often overlook key factors, such as urban airspace\nconstraints and economic efficiency, which are essential in low-altitude\neconomy contexts. Deep reinforcement learning (DRL) is regarded as a promising\nsolution to these issues, while its practical adoption remains limited by low\nlearning efficiency. To overcome this limitation, we propose a novel UAV\ntrajectory planning framework that combines DRL with large language model (LLM)\nreasoning to enable safe, compliant, and economically viable path planning.\nExperimental results demonstrate that our method significantly outperforms\nexisting baselines across multiple metrics, including data collection rate,\ncollision avoidance, successful landing, regulatory compliance, and energy\nefficiency. These results validate the effectiveness of our approach in\naddressing UAV trajectory planning key challenges under constraints of the\nlow-altitude economy networking.", "AI": {"tldr": "The paper proposes a new UAV trajectory planning framework combining DRL with LLM reasoning, addressing urban airspace constraints and economic efficiency while showing superior performance in various metrics.", "motivation": "The motivation of this paper is to address the challenges of UAV trajectory planning in complex urban environments within the context of the growing low-altitude economy, particularly focusing on urban airspace constraints and economic efficiency which are often neglected in existing studies.", "method": "The method involves proposing a novel UAV trajectory planning framework that integrates deep reinforcement learning (DRL) with large language model (LLM) reasoning. This combination aims to improve learning efficiency and enable safe, compliant, and economically viable path planning for UAVs.", "result": "The experimental results indicate that the proposed method surpasses existing baselines in multiple aspects such as data collection rate, collision avoidance, successful landing, regulatory compliance, and energy efficiency.", "conclusion": "The conclusion drawn from this study is that the integration of DRL with LLM reasoning provides an effective solution to the key challenges of UAV trajectory planning under the constraints of the low-altitude economy networking."}}
{"id": "2506.08164", "pdf": "https://arxiv.org/pdf/2506.08164", "abs": "https://arxiv.org/abs/2506.08164", "authors": ["Hadi Reisizadeh", "Jinghan Jia", "Zhiqi Bu", "Bhanukiran Vinzamuri", "Anil Ramakrishna", "Kai-Wei Chang", "Volkan Cevher", "Sijia Liu", "Mingyi Hong"], "title": "BLUR: A Bi-Level Optimization Approach for LLM Unlearning", "categories": ["cs.LG"], "comment": null, "summary": "Enabling large language models (LLMs) to unlearn knowledge and capabilities\nacquired during training has proven vital for ensuring compliance with data\nregulations and promoting ethical practices in generative AI. Although there\nare growing interests in developing various unlearning algorithms, it remains\nunclear how to best formulate the unlearning problem. The most popular\nformulation uses a weighted sum of forget and retain loss, but it often leads\nto performance degradation due to the inherent trade-off between forget and\nretain losses. In this work, we argue that it is important to model the\nhierarchical structure of the unlearning problem, where the forget problem\n(which \\textit{unlearns} certain knowledge and/or capabilities) takes priority\nover the retain problem (which preserves model utility). This hierarchical\nstructure naturally leads to a bi-level optimization formulation where the\nlower-level objective focuses on minimizing the forget loss, while the\nupper-level objective aims to maintain the model's utility. Based on this new\nformulation, we propose a novel algorithm, termed Bi-Level UnleaRning\n(\\texttt{BLUR}), which not only possesses strong theoretical guarantees but\nmore importantly, delivers superior performance. In particular, our extensive\nexperiments demonstrate that \\texttt{BLUR} consistently outperforms all the\nstate-of-the-art algorithms across various unlearning tasks, models, and\nmetrics. Codes are available at\nhttps://github.com/OptimAI-Lab/BLURLLMUnlearning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u5c42\u4f18\u5316\u516c\u5f0f\u5316\u9057\u5fd8\u95ee\u9898\u7684\u65b9\u6cd5\uff0c\u5e76\u57fa\u4e8e\u6b64\u63d0\u51fa\u4e86\u540d\u4e3aBLUR\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u5404\u79cd\u9057\u5fd8\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u76ee\u524d\u6700\u6d41\u884c\u7684\u9057\u5fd8\u95ee\u9898\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f1a\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\uff0c\u56e0\u4e3a\u5b83\u4eec\u672a\u80fd\u5f88\u597d\u5730\u5904\u7406\u9057\u5fd8\u548c\u4fdd\u7559\u635f\u5931\u4e4b\u95f4\u7684\u56fa\u6709\u6298\u8877\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u66f4\u597d\u5730\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u5c06\u9057\u5fd8\u95ee\u9898\u5efa\u6a21\u4e3a\u5177\u6709\u5c42\u7ea7\u7ed3\u6784\u7684\u53cc\u5c42\u4f18\u5316\u95ee\u9898\uff0c\u5176\u4e2d\u4e0b\u5c42\u76ee\u6807\u4e13\u6ce8\u4e8e\u6700\u5c0f\u5316\u9057\u5fd8\u635f\u5931\uff0c\u800c\u4e0a\u5c42\u76ee\u6807\u5219\u65e8\u5728\u4fdd\u6301\u6a21\u578b\u7684\u5b9e\u7528\u6027\u3002\u57fa\u4e8e\u8fd9\u79cd\u65b0\u516c\u5f0f\u5316\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86\u540d\u4e3aBLUR\u7684\u65b0\u7b97\u6cd5\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0cBLUR\u7b97\u6cd5\u5728\u5404\u79cd\u9057\u5fd8\u4efb\u52a1\u3001\u6a21\u578b\u548c\u5ea6\u91cf\u6807\u51c6\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u6240\u6709\u6700\u5148\u8fdb\u7684\u7b97\u6cd5\u3002", "conclusion": "BLUR\u4e0d\u4ec5\u5177\u5907\u5f3a\u5927\u7684\u7406\u8bba\u4fdd\u8bc1\uff0c\u800c\u4e14\u5728\u5b9e\u8df5\u4e2d\u4e5f\u8868\u73b0\u51fa\u4e86\u4f18\u8d8a\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08435", "pdf": "https://arxiv.org/pdf/2506.08435", "abs": "https://arxiv.org/abs/2506.08435", "authors": ["Mingyuan Fan", "Fuyi Wang", "Cen Chen", "Jianying Zhou"], "title": "Boosting Gradient Leakage Attacks: Data Reconstruction in Realistic FL Settings", "categories": ["cs.LG", "cs.CR", "cs.CV"], "comment": "Accepted to Usenix Security 2025", "summary": "Federated learning (FL) enables collaborative model training among multiple\nclients without the need to expose raw data. Its ability to safeguard privacy,\nat the heart of FL, has recently been a hot-button debate topic. To elaborate,\nseveral studies have introduced a type of attacks known as gradient leakage\nattacks (GLAs), which exploit the gradients shared during training to\nreconstruct clients' raw data. On the flip side, some literature, however,\ncontends no substantial privacy risk in practical FL environments due to the\neffectiveness of such GLAs being limited to overly relaxed conditions, such as\nsmall batch sizes and knowledge of clients' data distributions.\n  This paper bridges this critical gap by empirically demonstrating that\nclients' data can still be effectively reconstructed, even within realistic FL\nenvironments. Upon revisiting GLAs, we recognize that their performance\nfailures stem from their inability to handle the gradient matching problem. To\nalleviate the performance bottlenecks identified above, we develop FedLeak,\nwhich introduces two novel techniques, partial gradient matching and gradient\nregularization. Moreover, to evaluate the performance of FedLeak in real-world\nFL environments, we formulate a practical evaluation protocol grounded in a\nthorough review of extensive FL literature and industry practices. Under this\nprotocol, FedLeak can still achieve high-fidelity data reconstruction, thereby\nunderscoring the significant vulnerability in FL systems and the urgent need\nfor more effective defense methods.", "AI": {"tldr": "Federated learning (FL) allows multiple clients to collaboratively train models without exposing raw data, and its privacy protection ability has been debated. Some studies introduce gradient leakage attacks (GLAs) that can reconstruct client data through shared gradients, but others argue that GLAs are not effective in practical FL environments. This paper demonstrates that client data can still be effectively reconstructed within realistic FL environments by revisiting GLAs and developing FedLeak, which introduces partial gradient matching and gradient regularization techniques. FedLeak achieves high-fidelity data reconstruction under a practical evaluation protocol, highlighting the vulnerability in FL systems.", "motivation": "To bridge the gap in the debate about whether federated learning (FL) poses significant privacy risks in practical environments, as previous studies have shown both the potential for gradient leakage attacks (GLAs) and their ineffectiveness under certain conditions.", "method": "The authors revisit gradient leakage attacks (GLAs) and identify performance failures due to the inability to handle the gradient matching problem. They then develop FedLeak, incorporating two novel techniques: partial gradient matching and gradient regularization. Additionally, they create a practical evaluation protocol based on a thorough review of FL literature and industry practices to assess FedLeak's performance in real-world FL environments.", "result": "FedLeak is able to achieve high-fidelity data reconstruction under the practical evaluation protocol formulated by the authors, demonstrating that client data can be effectively reconstructed even in realistic FL environments.", "conclusion": "This study underscores the significant vulnerability present in current FL systems and emphasizes the urgent need for more effective defense methods against data reconstruction attacks."}}
{"id": "2506.08580", "pdf": "https://arxiv.org/pdf/2506.08580", "abs": "https://arxiv.org/abs/2506.08580", "authors": ["Yang Lv", "Jinlong Lei", "Peng Yi"], "title": "HGFormer: A Hierarchical Graph Transformer Framework for Two-Stage Colonel Blotto Games via Reinforcement Learning", "categories": ["cs.AI"], "comment": null, "summary": "Two-stage Colonel Blotto game represents a typical adversarial resource\nallocation problem, in which two opposing agents sequentially allocate\nresources in a network topology across two phases: an initial resource\ndeployment followed by multiple rounds of dynamic reallocation adjustments. The\nsequential dependency between game stages and the complex constraints imposed\nby the graph topology make it difficult for traditional approaches to attain a\nglobally optimal strategy. To address these challenges, we propose a\nhierarchical graph Transformer framework called HGformer. By incorporating an\nenhanced graph Transformer encoder with structural biases and a two-agent\nhierarchical decision model, our approach enables efficient policy generation\nin large-scale adversarial environments. Moreover, we design a layer-by-layer\nfeedback reinforcement learning algorithm that feeds the long-term returns from\nlower-level decisions back into the optimization of the higher-level strategy,\nthus bridging the coordination gap between the two decision-making stages.\nExperimental results demonstrate that, compared to existing hierarchical\ndecision-making or graph neural network methods, HGformer significantly\nimproves resource allocation efficiency and adversarial payoff, achieving\nsuperior overall performance in complex dynamic game scenarios.", "AI": {"tldr": "In a two-stage Colonel Blotto game, traditional methods struggle to find globally optimal strategies due to sequential dependencies and complex constraints. The paper proposes HGformer, a hierarchical graph Transformer framework with an enhanced encoder and two-agent decision model for efficient policy generation. A feedback reinforcement learning algorithm bridges the coordination gap between decision stages. Experiments show HGformer improves resource allocation efficiency and adversarial payoff.", "motivation": "The motivation is to overcome the challenges posed by sequential dependencies and complex constraints in a two-stage Colonel Blotto game, where traditional approaches fail to achieve globally optimal strategies.", "method": "The method involves proposing a hierarchical graph Transformer framework named HGformer. It incorporates an enhanced graph Transformer encoder with structural biases and a two-agent hierarchical decision model for policy generation. Additionally, a layer-by-layer feedback reinforcement learning algorithm is designed to optimize higher-level strategy using long-term returns from lower-level decisions.", "result": "HGformer significantly enhances resource allocation efficiency and adversarial payoff compared to existing hierarchical decision-making or graph neural network methods. It demonstrates superior overall performance in complex dynamic game scenarios.", "conclusion": "HGformer successfully addresses the challenges of the two-stage Colonel Blotto game by efficiently generating policies and bridging the coordination gap between decision stages through its innovative architecture and reinforcement learning approach."}}
{"id": "2506.08167", "pdf": "https://arxiv.org/pdf/2506.08167", "abs": "https://arxiv.org/abs/2506.08167", "authors": ["Sunny Gupta", "Nikita Jangid", "Amit Sethi"], "title": "UniVarFL: Uniformity and Variance Regularized Federated Learning for Heterogeneous Data", "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.DC", "I.2.6; C.1.4; D.1.3; I.5.1; H.3.4; I.2.10; I.4.0; I.4.1; I.4.2;\n  I.4.6; I.4.7; I.4.8; I.4.9; I.4.10; I.5.1; I.5.2; I.5.4; J.2; I.2.11; I.2.10"], "comment": null, "summary": "Federated Learning (FL) often suffers from severe performance degradation\nwhen faced with non-IID data, largely due to local classifier bias. Traditional\nremedies such as global model regularization or layer freezing either incur\nhigh computational costs or struggle to adapt to feature shifts. In this work,\nwe propose UniVarFL, a novel FL framework that emulates IID-like training\ndynamics directly at the client level, eliminating the need for global model\ndependency. UniVarFL leverages two complementary regularization strategies\nduring local training: Classifier Variance Regularization, which aligns\nclass-wise probability distributions with those expected under IID conditions,\neffectively mitigating local classifier bias; and Hyperspherical Uniformity\nRegularization, which encourages a uniform distribution of feature\nrepresentations across the hypersphere, thereby enhancing the model's ability\nto generalize under diverse data distributions. Extensive experiments on\nmultiple benchmark datasets demonstrate that UniVarFL outperforms existing\nmethods in accuracy, highlighting its potential as a highly scalable and\nefficient solution for real-world FL deployments, especially in\nresource-constrained settings. Code: https://github.com/sunnyinAI/UniVarFL", "AI": {"tldr": "UniVarFL is a new Federated Learning framework that addresses non-IID data challenges through two regularization strategies, improving accuracy and scalability.", "motivation": "Federated Learning experiences performance issues with non-IID data due to local classifier bias. Current solutions either have high computational costs or adapt poorly to feature shifts.", "method": "Proposes UniVarFL with Classifier Variance Regularization to align class-wise probability distributions for mitigating bias, and Hyperspherical Uniformity Regularization to encourage uniform feature representation distribution enhancing generalization.", "result": "Experiments on benchmark datasets show UniVarFL outperforms existing methods in accuracy, making it scalable and efficient for real-world applications, especially in resource-constrained settings.", "conclusion": "UniVarFL presents an effective solution to the non-IID data problem in Federated Learning, offering improved accuracy and scalability."}}
{"id": "2506.08461", "pdf": "https://arxiv.org/pdf/2506.08461", "abs": "https://arxiv.org/abs/2506.08461", "authors": ["Sungwoong Yune", "Hyojeong Lee", "Adiwena Putra", "Hyunjun Cho", "Cuong Duong Manh", "Jaeho Jeon", "Joo-Young Kim"], "title": "ABC-FHE : A Resource-Efficient Accelerator Enabling Bootstrappable Parameters for Client-Side Fully Homomorphic Encryption", "categories": ["cs.AR", "cs.CR", "cs.ET"], "comment": "7 pages, 6 figures, DAC 2025: 62st IEEE/ACM Design Automation\n  Conference. (DAC'25)", "summary": "As the demand for privacy-preserving computation continues to grow, fully\nhomomorphic encryption (FHE)-which enables continuous computation on encrypted\ndata-has become a critical solution. However, its adoption is hindered by\nsignificant computational overhead, requiring 10000-fold more computation\ncompared to plaintext processing. Recent advancements in FHE accelerators have\nsuccessfully improved server-side performance, but client-side computations\nremain a bottleneck, particularly under bootstrappable parameter\nconfigurations, which involve combinations of encoding, encrypt, decoding, and\ndecrypt for large-sized parameters. To address this challenge, we propose\nABC-FHE, an area- and power-efficient FHE accelerator that supports\nbootstrappable parameters on the client side. ABC-FHE employs a streaming\narchitecture to maximize performance density, minimize area usage, and reduce\noff-chip memory access. Key innovations include a reconfigurable Fourier engine\ncapable of switching between NTT and FFT modes. Additionally, an on-chip\npseudo-random number generator and a unified on-the-fly twiddle factor\ngenerator significantly reduce memory demands, while optimized task scheduling\nenhances the CKKS client-side processing, achieving reduced latency. Overall,\nABC-FHE occupies a die area of 28.638 mm2 and consumes 5.654 W of power in 28\nnm technology. It delivers significant performance improvements, achieving a\n1112x speed-up in encoding and encryption execution time compared to a CPU, and\n214x over the state-of-the-art client-side accelerator. For decoding and\ndecryption, it achieves a 963x speed-up over the CPU and 82x over the\nstate-of-the-art accelerator.", "AI": {"tldr": "To overcome the computational challenges of Fully Homomorphic Encryption (FHE) on client-side, this paper proposes ABC-FHE, an advanced FHE accelerator with a streaming architecture and key innovations such as reconfigurable Fourier engine, on-chip PRNG, and optimized task scheduling. It achieves significant performance improvements over CPUs and existing accelerators.", "motivation": "The demand for privacy-preserving computation is growing, but the adoption of Fully Homomorphic Encryption (FHE) is hindered by substantial computational overhead, especially on the client side under bootstrappable parameter configurations.", "method": "ABC-FHE employs a streaming architecture to maximize performance density, minimize area usage, and reduce off-chip memory access. Innovations include a reconfigurable Fourier engine that can switch between NTT and FFT modes, an on-chip pseudo-random number generator, and a unified on-the-fly twiddle factor generator. Optimized task scheduling enhances CKKS client-side processing.", "result": "ABC-FHE occupies a die area of 28.638 mm\u00b2 and consumes 5.654 W in 28 nm technology. It achieves a 1112x speed-up in encoding and encryption execution time compared to a CPU, and 214x over the state-of-the-art client-side accelerator. For decoding and decryption, it achieves a 963x speed-up over the CPU and 82x over the state-of-the-art accelerator.", "conclusion": "ABC-FHE is an efficient FHE accelerator designed for client-side operations, providing significant improvements in performance, power efficiency, and area usage compared to existing solutions."}}
{"id": "2506.08627", "pdf": "https://arxiv.org/pdf/2506.08627", "abs": "https://arxiv.org/abs/2506.08627", "authors": ["Douwe Geurtjens", "Xixi Lu"], "title": "FoldA: Computing Partial-Order Alignments Using Directed Net Unfoldings", "categories": ["cs.AI"], "comment": "Conditionally accepted at BPM 2025", "summary": "Conformance checking is a fundamental task of process mining, which\nquantifies the extent to which the observed process executions match a\nnormative process model. The state-of-the-art approaches compute alignments by\nexploring the state space formed by the synchronous product of the process\nmodel and the trace. This often leads to state space explosion, particularly\nwhen the model exhibits a high degree of choice and concurrency. Moreover, as\nalignments inherently impose a sequential structure, they fail to fully\nrepresent the concurrent behavior present in many real-world processes. To\naddress these limitations, this paper proposes a new technique for computing\npartial-order alignments {on the fly using directed Petri net unfoldings, named\nFoldA. We evaluate our technique on 485 synthetic model-log pairs and compare\nit against Astar- and Dijkstra-alignments on 13 real-life model-log pairs and 6\nbenchmark pairs. The results show that our unfolding alignment, although it\nrequires more computation time, generally reduces the number of queued states\nand provides a more accurate representation of concurrency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6280\u672fFoldA\uff0c\u7528\u4e8e\u4f7f\u7528\u6709\u5411Petri\u7f51\u5c55\u5f00\u8ba1\u7b97\u90e8\u5206\u987a\u5e8f\u5bf9\u9f50\u3002\u5c3d\u7ba1\u8ba1\u7b97\u65f6\u95f4\u66f4\u957f\uff0c\u4f46\u901a\u5e38\u51cf\u5c11\u4e86\u6392\u961f\u72b6\u6001\u7684\u6570\u91cf\uff0c\u5e76\u63d0\u4f9b\u4e86\u5bf9\u5e76\u53d1\u6027\u7684\u66f4\u51c6\u786e\u8868\u793a\u3002", "motivation": "\u4e00\u81f4\u6027\u68c0\u67e5\u662f\u8fc7\u7a0b\u6316\u6398\u7684\u57fa\u672c\u4efb\u52a1\uff0c\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u8ba1\u7b97\u5bf9\u9f50\u65f6\u5bb9\u6613\u5bfc\u81f4\u72b6\u6001\u7a7a\u95f4\u7206\u70b8\uff0c\u5e76\u4e14\u65e0\u6cd5\u5145\u5206\u8868\u793a\u73b0\u5b9e\u4e16\u754c\u8fc7\u7a0b\u4e2d\u7684\u5e76\u53d1\u884c\u4e3a\u3002", "method": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u6709\u5411Petri\u7f51\u5c55\u5f00\u7684\u90e8\u5206\u987a\u5e8f\u5bf9\u9f50\uff08FoldA\uff09\u6280\u672f\uff0c\u8be5\u6280\u672f\u53ef\u4ee5\u5728\u8fd0\u884c\u65f6\u52a8\u6001\u8ba1\u7b97\u5bf9\u9f50\u3002", "result": "\u5728485\u4e2a\u5408\u6210\u6a21\u578b\u65e5\u5fd7\u5bf9\u548c19\u4e2a\u73b0\u5b9e\u751f\u6d3b\u53ca\u57fa\u51c6\u6a21\u578b\u65e5\u5fd7\u5bf9\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u5c3d\u7ba1\u8ba1\u7b97\u65f6\u95f4\u8f83\u957f\uff0c\u4f46\u51cf\u5c11\u4e86\u6392\u961f\u72b6\u6001\u6570\u91cf\u5e76\u66f4\u51c6\u786e\u5730\u8868\u793a\u4e86\u5e76\u53d1\u6027\u3002", "conclusion": "FoldA\u6280\u672f\u4e3a\u89e3\u51b3\u9ad8\u9009\u62e9\u6027\u548c\u5e76\u53d1\u6027\u6a21\u578b\u7684\u4e00\u81f4\u6027\u68c0\u67e5\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002"}}
{"id": "2506.08169", "pdf": "https://arxiv.org/pdf/2506.08169", "abs": "https://arxiv.org/abs/2506.08169", "authors": ["Jingqiao Tang", "Ryan Bausback", "Feng Bao", "Richard Archibald"], "title": "Federated Learning on Stochastic Neural Networks", "categories": ["cs.LG", "cs.DC"], "comment": "25 pages, 19 figures, Submitted to Journal of Machine Learning for\n  Modeling and Computing", "summary": "Federated learning is a machine learning paradigm that leverages edge\ncomputing on client devices to optimize models while maintaining user privacy\nby ensuring that local data remains on the device. However, since all data is\ncollected by clients, federated learning is susceptible to latent noise in\nlocal datasets. Factors such as limited measurement capabilities or human\nerrors may introduce inaccuracies in client data. To address this challenge, we\npropose the use of a stochastic neural network as the local model within the\nfederated learning framework. Stochastic neural networks not only facilitate\nthe estimation of the true underlying states of the data but also enable the\nquantification of latent noise. We refer to our federated learning approach,\nwhich incorporates stochastic neural networks as local models, as Federated\nstochastic neural networks. We will present numerical experiments demonstrating\nthe performance and effectiveness of our method, particularly in handling\nnon-independent and identically distributed data.", "AI": {"tldr": "In this paper, the authors tackle the issue of latent noise in federated learning by proposing Federated stochastic neural networks, which incorporate stochastic neural networks as local models. They demonstrate its performance through numerical experiments.", "motivation": "Federated learning is vulnerable to latent noise due to inaccuracies in client data from factors like limited measurement capabilities or human errors.", "method": "The use of a stochastic neural network as the local model within the federated learning framework to estimate true underlying states of data and quantify latent noise.", "result": "Numerical experiments show the effectiveness of the proposed method in handling non-independent and identically distributed data.", "conclusion": "Federated stochastic neural networks provide an effective approach to dealing with latent noise in federated learning."}}
{"id": "2506.08991", "pdf": "https://arxiv.org/pdf/2506.08991", "abs": "https://arxiv.org/abs/2506.08991", "authors": ["Anudeep Das", "Gurjot Singh", "Prach Chantasantitam", "N. Asokan"], "title": "Do Concept Replacement Techniques Really Erase Unacceptable Concepts?", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "Generative models, particularly diffusion-based text-to-image (T2I) models,\nhave demonstrated astounding success. However, aligning them to avoid\ngenerating content with unacceptable concepts (e.g., offensive or copyrighted\ncontent, or celebrity likenesses) remains a significant challenge. Concept\nreplacement techniques (CRTs) aim to address this challenge, often by trying to\n\"erase\" unacceptable concepts from models. Recently, model providers have\nstarted offering image editing services which accept an image and a text prompt\nas input, to produce an image altered as specified by the prompt. These are\nknown as image-to-image (I2I) models. In this paper, we first use an I2I model\nto empirically demonstrate that today's state-of-the-art CRTs do not in fact\nerase unacceptable concepts. Existing CRTs are thus likely to be ineffective in\nemerging I2I scenarios, despite their proven ability to remove unwanted\nconcepts in T2I pipelines, highlighting the need to understand this discrepancy\nbetween T2I and I2I settings. Next, we argue that a good CRT, while replacing\nunacceptable concepts, should preserve other concepts specified in the inputs\nto generative models. We call this fidelity. Prior work on CRTs have neglected\nfidelity in the case of unacceptable concepts. Finally, we propose the use of\ntargeted image-editing techniques to achieve both effectiveness and fidelity.\nWe present such a technique, AntiMirror, and demonstrate its viability.", "AI": {"tldr": "This paper explores the ineffectiveness of current Concept Replacement Techniques (CRTs) in image-to-image (I2I) models compared to text-to-image (T2I) models when handling unacceptable content. It emphasizes the need for fidelity\u2014preserving other concepts while replacing unwanted ones\u2014and introduces AntiMirror, a targeted image-editing technique designed to achieve both effectiveness and fidelity.", "motivation": "The motivation behind this paper is the challenge faced by generative models, specifically I2I models, in effectively erasing unacceptable content using existing CRTs. While CRTs have shown success in T2I pipelines, they fail to do so in I2I settings, necessitating further investigation into this discrepancy.", "method": "The authors first use an I2I model to empirically show that state-of-the-art CRTs do not erase unacceptable concepts. They then introduce the concept of fidelity, which refers to preserving other input-specified concepts while replacing unacceptable ones. Lastly, they propose and demonstrate the viability of AntiMirror, a targeted image-editing technique aimed at achieving both effectiveness and fidelity.", "result": "The study reveals that existing CRTs are ineffective in I2I scenarios. The proposed technique, AntiMirror, demonstrates potential in achieving both effectiveness in removing unacceptable content and fidelity in preserving other specified concepts.", "conclusion": "Current CRTs are insufficient for I2I models due to their inability to erase unacceptable content while preserving fidelity. AntiMirror shows promise as a solution, combining effectiveness and fidelity in concept replacement."}}
{"id": "2506.08630", "pdf": "https://arxiv.org/pdf/2506.08630", "abs": "https://arxiv.org/abs/2506.08630", "authors": ["Laurens Engwegen", "Daan Brinks", "Wendelin B\u00f6hmer"], "title": "Modular Recurrence in Contextual MDPs for Universal Morphology Control", "categories": ["cs.AI", "cs.RO"], "comment": null, "summary": "A universal controller for any robot morphology would greatly improve\ncomputational and data efficiency. By utilizing contextual information about\nthe properties of individual robots and exploiting their modular structure in\nthe architecture of deep reinforcement learning agents, steps have been made\ntowards multi-robot control. Generalization to new, unseen robots, however,\nremains a challenge. In this paper we hypothesize that the relevant contextual\ninformation is partially observable, but that it can be inferred through\ninteractions for better generalization to contexts that are not seen during\ntraining. To this extent, we implement a modular recurrent architecture and\nevaluate its generalization performance on a large set of MuJoCo robots. The\nresults show a substantial improved performance on robots with unseen dynamics,\nkinematics, and topologies, in four different environments.", "AI": {"tldr": "This paper explores the use of a modular recurrent architecture in deep reinforcement learning to improve generalization for controlling robots with unseen dynamics, kinematics, and topologies.", "motivation": "The motivation is to create a universal controller that can generalize well to new, unseen robot morphologies, thus improving computational and data efficiency.", "method": "The method involves implementing a modular recurrent architecture that uses contextual information inferred through interactions, to enhance generalization performance.", "result": "The results indicate a significant improvement in performance on robots with unseen dynamics, kinematics, and topologies across four different environments.", "conclusion": "A modular recurrent architecture can effectively improve the generalization of robot control to previously unseen robot morphologies."}}
{"id": "2506.08176", "pdf": "https://arxiv.org/pdf/2506.08176", "abs": "https://arxiv.org/abs/2506.08176", "authors": ["Anh V Nguyen", "Diego Klabjan"], "title": "FedGA-Tree: Federated Decision Tree using Genetic Algorithm", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "In recent years, with rising concerns for data privacy, Federated Learning\nhas gained prominence, as it enables collaborative training without the\naggregation of raw data from participating clients. However, much of the\ncurrent focus has been on parametric gradient-based models, while nonparametric\ncounterparts such as decision tree are relatively understudied. Existing\nmethods for adapting decision trees to Federated Learning generally combine a\ngreedy tree-building algorithm with differential privacy to produce a global\nmodel for all clients. These methods are limited to classification trees and\ncategorical data due to the constraints of differential privacy. In this paper,\nwe explore an alternative approach that utilizes Genetic Algorithm to\nfacilitate the construction of personalized decision trees and accommodate\ncategorical and numerical data, thus allowing for both classification and\nregression trees. Comprehensive experiments demonstrate that our method\nsurpasses decision trees trained solely on local data and a benchmark\nalgorithm.", "AI": {"tldr": "The paper explores an alternative approach using Genetic Algorithm to build personalized decision trees in Federated Learning, which accommodates categorical and numerical data for both classification and regression. Experiments show it outperforms local-only training and a benchmark algorithm.", "motivation": "Federated Learning has become prominent due to data privacy concerns, but nonparametric models like decision trees are relatively understudied compared to parametric gradient-based models. Existing methods for adapting decision trees to Federated Learning have limitations with differential privacy.", "method": "The paper proposes utilizing Genetic Algorithm to facilitate the construction of personalized decision trees that can accommodate both categorical and numerical data, allowing for both classification and regression trees.", "result": "Comprehensive experiments demonstrate that the proposed method surpasses decision trees trained solely on local data and also outperforms a benchmark algorithm.", "conclusion": "The use of Genetic Algorithm for constructing personalized decision trees in Federated Learning is effective for both classification and regression tasks, and performs better than existing methods."}}
{"id": "2506.08745", "pdf": "https://arxiv.org/pdf/2506.08745", "abs": "https://arxiv.org/abs/2506.08745", "authors": ["Kongcheng Zhang", "Qi Yao", "Shunyu Liu", "Yingjie Wang", "Baisheng Lai", "Jieping Ye", "Mingli Song", "Dacheng Tao"], "title": "Consistent Paths Lead to Truth: Self-Rewarding Reinforcement Learning for LLM Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Recent advances of Reinforcement Learning (RL) have highlighted its potential\nin complex reasoning tasks, yet effective training often relies on external\nsupervision, which limits the broader applicability. In this work, we propose a\nnovel self-rewarding reinforcement learning framework to enhance Large Language\nModel (LLM) reasoning by leveraging the consistency of intermediate reasoning\nstates across different reasoning trajectories. Our key insight is that correct\nresponses often exhibit consistent trajectory patterns in terms of model\nlikelihood: their intermediate reasoning states tend to converge toward their\nown final answers (high consistency) with minimal deviation toward other\ncandidates (low volatility). Inspired by this observation, we introduce CoVo,\nan intrinsic reward mechanism that integrates Consistency and Volatility via a\nrobust vector-space aggregation strategy, complemented by a curiosity bonus to\npromote diverse exploration. CoVo enables LLMs to perform RL in a\nself-rewarding manner, offering a scalable pathway for learning to reason\nwithout external supervision. Extensive experiments on diverse reasoning\nbenchmarks show that CoVo achieves performance comparable to or even surpassing\nsupervised RL. Our code is available at https://github.com/sastpg/CoVo.", "AI": {"tldr": "CoVo is a new self-rewarding reinforcement learning framework for Large Language Models (LLMs) that uses consistency and volatility of reasoning trajectories to improve performance without external supervision.", "motivation": "To address the limitation of relying on external supervision in reinforcement learning, which hinders broader applicability, this work aims to enhance LLM reasoning through a novel self-rewarding RL framework.", "method": "The proposed method, CoVo, leverages the consistency of intermediate reasoning states across different reasoning trajectories. It introduces an intrinsic reward mechanism integrating Consistency and Volatility using a robust vector-space aggregation strategy, along with a curiosity bonus to promote exploration.", "result": "Experiments on diverse reasoning benchmarks demonstrate that CoVo achieves performance comparable to or even surpassing supervised RL.", "conclusion": "CoVo provides a scalable way for LLMs to learn reasoning without external supervision, showcasing its potential in enhancing LLMs' reasoning capabilities."}}
{"id": "2506.08201", "pdf": "https://arxiv.org/pdf/2506.08201", "abs": "https://arxiv.org/abs/2506.08201", "authors": ["Krishna Pillutla", "Jalaj Upadhyay", "Christopher A. Choquette-Choo", "Krishnamurthy Dvijotham", "Arun Ganesh", "Monika Henzinger", "Jonathan Katz", "Ryan McKenna", "H. Brendan McMahan", "Keith Rush", "Thomas Steinke", "Abhradeep Thakurta"], "title": "Correlated Noise Mechanisms for Differentially Private Learning", "categories": ["cs.LG", "cs.CR"], "comment": "212 pages", "summary": "This monograph explores the design and analysis of correlated noise\nmechanisms for differential privacy (DP), focusing on their application to\nprivate training of AI and machine learning models via the core primitive of\nestimation of weighted prefix sums. While typical DP mechanisms inject\nindependent noise into each step of a stochastic gradient (SGD) learning\nalgorithm in order to protect the privacy of the training data, a growing body\nof recent research demonstrates that introducing (anti-)correlations in the\nnoise can significantly improve privacy-utility trade-offs by carefully\ncanceling out some of the noise added on earlier steps in subsequent steps.\nSuch correlated noise mechanisms, known variously as matrix mechanisms,\nfactorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) when\napplied to learning algorithms, have also been influential in practice, with\nindustrial deployment at a global scale.", "AI": {"tldr": "This monograph explores the design and analysis of correlated noise mechanisms for differential privacy (DP) in private training of AI models.", "motivation": "To improve privacy-utility trade-offs by introducing (anti-)correlations in the noise injected into each step of a stochastic gradient learning algorithm.", "method": "Correlated noise mechanisms such as matrix mechanisms, factorization mechanisms, and DP-Follow-the-Regularized-Leader (DP-FTRL) are applied to cancel out some of the noise added on earlier steps in subsequent steps.", "result": "These mechanisms have been influential in practice, with industrial deployment at a global scale.", "conclusion": "The exploration focuses on their application to private training of AI and machine learning models via the core primitive of estimation of weighted prefix sums."}}
{"id": "2506.08747", "pdf": "https://arxiv.org/pdf/2506.08747", "abs": "https://arxiv.org/abs/2506.08747", "authors": ["Boyang Sun", "Yu Yao", "Xinshuai Dong", "Zongfang Liu", "Tongliang Liu", "Yumou Qiu", "Kun Zhang"], "title": "A Sample Efficient Conditional Independence Test in the Presence of Discretization", "categories": ["cs.AI", "stat.ML"], "comment": null, "summary": "In many real-world scenarios, interested variables are often represented as\ndiscretized values due to measurement limitations. Applying Conditional\nIndependence (CI) tests directly to such discretized data, however, can lead to\nincorrect conclusions. To address this, recent advancements have sought to\ninfer the correct CI relationship between the latent variables through\nbinarizing observed data. However, this process inevitably results in a loss of\ninformation, which degrades the test's performance. Motivated by this, this\npaper introduces a sample-efficient CI test that does not rely on the\nbinarization process. We find that the independence relationships of latent\ncontinuous variables can be established by addressing an over-identifying\nrestriction problem with Generalized Method of Moments (GMM). Based on this\ninsight, we derive an appropriate test statistic and establish its asymptotic\ndistribution correctly reflecting CI by leveraging nodewise regression.\nTheoretical findings and Empirical results across various datasets demonstrate\nthat the superiority and effectiveness of our proposed test. Our code\nimplementation is provided in https://github.com/boyangaaaaa/DCT", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684\u6761\u4ef6\u72ec\u7acb\u6027\uff08CI\uff09\u68c0\u9a8c\u65b9\u6cd5\uff0c\u65e0\u9700\u5bf9\u6570\u636e\u8fdb\u884c\u4e8c\u503c\u5316\u5904\u7406\uff0c\u901a\u8fc7\u5e7f\u4e49\u77e9\u4f30\u8ba1\uff08GMM\uff09\u548c\u8282\u70b9\u56de\u5f52\u63a8\u5bfc\u51fa\u9002\u5f53\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u7406\u8bba\u548c\u5b9e\u8bc1\u7ed3\u679c\u5747\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u548c\u6709\u6548\u6027\u3002", "motivation": "\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u7531\u4e8e\u6d4b\u91cf\u9650\u5236\uff0c\u611f\u5174\u8da3\u7684\u53d8\u91cf\u901a\u5e38\u4ee5\u79bb\u6563\u503c\u8868\u793a\u3002\u76f4\u63a5\u5c06\u6761\u4ef6\u72ec\u7acb\u6027\uff08CI\uff09\u68c0\u9a8c\u5e94\u7528\u4e8e\u8fd9\u79cd\u79bb\u6563\u5316\u6570\u636e\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7ed3\u8bba\u3002\u73b0\u6709\u7684\u901a\u8fc7\u4e8c\u503c\u5316\u89c2\u6d4b\u6570\u636e\u6765\u63a8\u65ad\u6f5c\u5728\u53d8\u91cf\u7684CI\u5173\u7cfb\u7684\u65b9\u6cd5\u4f1a\u5bfc\u81f4\u4fe1\u606f\u4e22\u5931\uff0c\u4ece\u800c\u964d\u4f4e\u68c0\u9a8c\u6027\u80fd\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u4e8e\u4e8c\u503c\u5316\u8fc7\u7a0b\u7684CI\u68c0\u9a8c\u65b9\u6cd5\u3002", "method": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6837\u672c\u9ad8\u6548\u7684CI\u68c0\u9a8c\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u5e7f\u4e49\u77e9\u4f30\u8ba1\uff08GMM\uff09\u89e3\u51b3\u8fc7\u5ea6\u8bc6\u522b\u7ea6\u675f\u95ee\u9898\uff0c\u5efa\u7acb\u6f5c\u5728\u8fde\u7eed\u53d8\u91cf\u7684\u72ec\u7acb\u6027\u5173\u7cfb\u3002\u57fa\u4e8e\u6b64\u89c1\u89e3\uff0c\u5229\u7528\u8282\u70b9\u56de\u5f52\u63a8\u5bfc\u51fa\u9002\u5f53\u7684\u68c0\u9a8c\u7edf\u8ba1\u91cf\uff0c\u5e76\u5efa\u7acb\u4e86\u5176\u6e10\u8fd1\u5206\u5e03\uff0c\u6b63\u786e\u53cd\u6620\u6761\u4ef6\u72ec\u7acb\u6027\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684CI\u68c0\u9a8c\u65b9\u6cd5\u5177\u6709\u4f18\u8d8a\u6027\u548c\u6709\u6548\u6027\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684CI\u68c0\u9a8c\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u65e0\u9700\u4e8c\u503c\u5316\u8fc7\u7a0b\uff0c\u80fd\u591f\u66f4\u6709\u6548\u5730\u63a8\u65ad\u6f5c\u5728\u8fde\u7eed\u53d8\u91cf\u7684\u72ec\u7acb\u6027\u5173\u7cfb\uff0c\u4e14\u7406\u8bba\u548c\u5b9e\u8bc1\u7814\u7a76\u5747\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2506.08205", "pdf": "https://arxiv.org/pdf/2506.08205", "abs": "https://arxiv.org/abs/2506.08205", "authors": ["Shadab Anwar Shaikh", "Kranthi Balusu", "Ayoub Soulami"], "title": "A Machine Learning Approach to Generate Residual Stress Distributions using Sparse Characterization Data in Friction-Stir Processed Parts", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Residual stresses, which remain within a component after processing, can\ndeteriorate performance. Accurately determining their full-field distributions\nis essential for optimizing the structural integrity and longevity. However,\nthe experimental effort required for full-field characterization is\nimpractical. Given these challenges, this work proposes a machine learning (ML)\nbased Residual Stress Generator (RSG) to infer full-field stresses from limited\nmeasurements. An extensive dataset was initially constructed by performing\nnumerous process simulations with a diverse parameter set. A ML model based on\nU-Net architecture was then trained to learn the underlying structure through\nsystematic hyperparameter tuning. Then, the model's ability to generate\nsimulated stresses was evaluated, and it was ultimately tested on actual\ncharacterization data to validate its effectiveness. The model's prediction of\nsimulated stresses shows that it achieved excellent predictive accuracy and\nexhibited a significant degree of generalization, indicating that it\nsuccessfully learnt the latent structure of residual stress distribution. The\nRSG's performance in predicting experimentally characterized data highlights\nthe feasibility of the proposed approach in providing a comprehensive\nunderstanding of residual stress distributions from limited measurements,\nthereby significantly reducing experimental efforts.", "AI": {"tldr": "The paper proposes a machine learning-based Residual Stress Generator (RSG) using U-Net architecture to predict full-field residual stress distributions from limited measurements, significantly reducing experimental efforts.", "motivation": "Residual stresses within components can negatively impact performance, and accurately determining their distribution is crucial for structural integrity and longevity. However, full-field characterization through experiments is impractical.", "method": "An extensive dataset was created via process simulations with diverse parameters. A U-Net based ML model was trained with hyperparameter tuning to learn the latent structure of residual stress distribution. The model was evaluated on simulated data and validated on experimental data.", "result": "The model achieved excellent predictive accuracy on simulated stress prediction and showed significant generalization ability, indicating successful learning of the latent structure. It also performed well on experimentally characterized data.", "conclusion": "The proposed RSG approach is feasible for predicting full-field residual stress distributions from limited measurements, greatly reducing the need for extensive experimental efforts."}}
{"id": "2506.08771", "pdf": "https://arxiv.org/pdf/2506.08771", "abs": "https://arxiv.org/abs/2506.08771", "authors": ["Yuni Susanti", "Michael F\u00e4rber"], "title": "Paths to Causality: Finding Informative Subgraphs Within Knowledge Graphs for Knowledge-Based Causal Discovery", "categories": ["cs.AI", "cs.CL", "cs.IR", "cs.LG"], "comment": "Accepted at KDD 2025 (full research paper)", "summary": "Inferring causal relationships between variable pairs is crucial for\nunderstanding multivariate interactions in complex systems. Knowledge-based\ncausal discovery -- which involves inferring causal relationships by reasoning\nover the metadata of variables (e.g., names or textual context) -- offers a\ncompelling alternative to traditional methods that rely on observational data.\nHowever, existing methods using Large Language Models (LLMs) often produce\nunstable and inconsistent results, compromising their reliability for causal\ninference. To address this, we introduce a novel approach that integrates\nKnowledge Graphs (KGs) with LLMs to enhance knowledge-based causal discovery.\nOur approach identifies informative metapath-based subgraphs within KGs and\nfurther refines the selection of these subgraphs using Learning-to-Rank-based\nmodels. The top-ranked subgraphs are then incorporated into zero-shot prompts,\nimproving the effectiveness of LLMs in inferring the causal relationship.\nExtensive experiments on biomedical and open-domain datasets demonstrate that\nour method outperforms most baselines by up to 44.4 points in F1 scores,\nevaluated across diverse LLMs and KGs. Our code and datasets are available on\nGitHub: https://github.com/susantiyuni/path-to-causality", "AI": {"tldr": "The paper proposes a new method integrating Knowledge Graphs (KGs) with Large Language Models (LLMs) for knowledge-based causal discovery. This approach uses metapath-based subgraphs refined by Learning-to-Rank models, incorporated into zero-shot prompts to enhance LLMs' causal inference ability. Experiments show significant improvement over baselines.", "motivation": "Existing methods using LLMs for causal discovery often produce unstable and inconsistent results, which affects their reliability.", "method": "The method integrates KGs with LLMs by identifying informative metapath-based subgraphs within KGs, refining the selection of these subgraphs using Learning-to-Rank-based models, and incorporating the top-ranked subgraphs into zero-shot prompts.", "result": "Extensive experiments on biomedical and open-domain datasets demonstrate that the proposed method outperforms most baselines by up to 44.4 points in F1 scores, evaluated across diverse LLMs and KGs.", "conclusion": "This novel approach significantly enhances the effectiveness of LLMs in inferring causal relationships and provides a reliable alternative for knowledge-based causal discovery."}}
{"id": "2506.08216", "pdf": "https://arxiv.org/pdf/2506.08216", "abs": "https://arxiv.org/abs/2506.08216", "authors": ["Shahaf Bassan", "Guy Amir", "Meirav Zehavi", "Guy Katz"], "title": "What makes an Ensemble (Un) Interpretable?", "categories": ["cs.LG", "cs.CC", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Ensemble models are widely recognized in the ML community for their limited\ninterpretability. For instance, while a single decision tree is considered\ninterpretable, ensembles of trees (e.g., boosted trees) are often treated as\nblack-boxes. Despite this folklore recognition, there remains a lack of\nrigorous mathematical understanding of what particularly makes an ensemble\n(un)-interpretable, including how fundamental factors like the (1) *number*,\n(2) *size*, and (3) *type* of base models influence its interpretability. In\nthis work, we seek to bridge this gap by applying concepts from computational\ncomplexity theory to study the challenges of generating explanations for\nvarious ensemble configurations. Our analysis uncovers nuanced complexity\npatterns influenced by various factors. For example, we demonstrate that under\nstandard complexity assumptions like P$\\neq$NP, interpreting ensembles remains\nintractable even when base models are of constant size. Surprisingly, the\ncomplexity changes drastically with the number of base models: small ensembles\nof decision trees are efficiently interpretable, whereas interpreting ensembles\nwith even a constant number of linear models remains intractable. We believe\nthat our findings provide a more robust foundation for understanding the\ninterpretability of ensembles, emphasizing the benefits of examining it through\na computational complexity lens.", "AI": {"tldr": "The paper explores why ensemble models are hard to interpret by using computational complexity theory, revealing that factors like the number and type of base models significantly affect interpretability.", "motivation": "Ensemble models, despite being powerful, are often treated as black-boxes due to limited interpretability. There is a lack of rigorous understanding of what makes ensembles (un)-interpretable based on fundamental factors such as the number, size, and type of base models.", "method": "The authors apply concepts from computational complexity theory to analyze the challenges of generating explanations for different ensemble configurations, considering various factors including the number, size, and type of base models.", "result": "The analysis reveals nuanced complexity patterns showing that interpreting ensembles remains intractable even when base models are of constant size under standard complexity assumptions like P\u2260NP. However, small ensembles of decision trees are efficiently interpretable while ensembles with even a few linear models remain intractable.", "conclusion": "The findings provide a more robust foundation for understanding ensemble interpretability, highlighting the importance of examining it through the lens of computational complexity."}}
{"id": "2506.08800", "pdf": "https://arxiv.org/pdf/2506.08800", "abs": "https://arxiv.org/abs/2506.08800", "authors": ["Irene Testini", "Jos\u00e9 Hern\u00e1ndez-Orallo", "Lorenzo Pacchiardi"], "title": "Measuring Data Science Automation: A Survey of Evaluation Tools for AI Assistants and Agents", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Data science aims to extract insights from data to support decision-making\nprocesses. Recently, Large Language Models (LLMs) are increasingly used as\nassistants for data science, by suggesting ideas, techniques and small code\nsnippets, or for the interpretation of results and reporting. Proper automation\nof some data-science activities is now promised by the rise of LLM agents,\ni.e., AI systems powered by an LLM equipped with additional affordances--such\nas code execution and knowledge bases--that can perform self-directed actions\nand interact with digital environments. In this paper, we survey the evaluation\nof LLM assistants and agents for data science. We find (1) a dominant focus on\na small subset of goal-oriented activities, largely ignoring data management\nand exploratory activities; (2) a concentration on pure assistance or fully\nautonomous agents, without considering intermediate levels of human-AI\ncollaboration; and (3) an emphasis on human substitution, therefore neglecting\nthe possibility of higher levels of automation thanks to task transformation.", "AI": {"tldr": "The paper surveys the evaluation of LLM assistants and agents for data science, finding a focus on goal-oriented activities, pure assistance or fully autonomous agents, and human substitution while neglecting other important aspects.", "motivation": "To assess how LLM assistants and agents are currently evaluated in data science and identify gaps or imbalances in their application and evaluation.", "method": "Surveying the evaluations of LLM assistants and agents in data science to analyze their focus areas, levels of human-AI collaboration, and automation possibilities.", "result": "(1) Most evaluations concentrate on goal-oriented activities, with less attention to data management and exploratory tasks; (2) There is an emphasis on either pure assistance or fully autonomous agents, ignoring intermediate levels of human-AI collaboration; (3) Evaluations primarily focus on human substitution rather than exploring higher levels of automation through task transformation.", "conclusion": "There is a need to broaden the scope of evaluating LLM assistants and agents in data science to include data management, exploratory activities, intermediate levels of human-AI collaboration, and the potential for task transformation leading to higher levels of automation."}}
{"id": "2506.08226", "pdf": "https://arxiv.org/pdf/2506.08226", "abs": "https://arxiv.org/abs/2506.08226", "authors": ["Arthur Feeney", "Kuei-Hsiang Huang", "Aparna Chandramowlishwaran"], "title": "Mondrian: Transformer Operators via Domain Decomposition", "categories": ["cs.LG"], "comment": "26 pages, 7 figures", "summary": "Operator learning enables data-driven modeling of partial differential\nequations (PDEs) by learning mappings between function spaces. However, scaling\ntransformer-based operator models to high-resolution, multiscale domains\nremains a challenge due to the quadratic cost of attention and its coupling to\ndiscretization. We introduce \\textbf{Mondrian}, transformer operators that\ndecompose a domain into non-overlapping subdomains and apply attention over\nsequences of subdomain-restricted functions. Leveraging principles from domain\ndecomposition, Mondrian decouples attention from discretization. Within each\nsubdomain, it replaces standard layers with expressive neural operators, and\nattention across subdomains is computed via softmax-based inner products over\nfunctions. The formulation naturally extends to hierarchical windowed and\nneighborhood attention, supporting both local and global interactions. Mondrian\nachieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating\nresolution scaling without retraining. These results highlight the promise of\ndomain-decomposed attention for scalable and general-purpose neural operators.", "AI": {"tldr": "Mondrian is a transformer-based operator model that decomposes domains into subdomains for efficient attention computation, using neural operators within each subdomain and softmax-based inner products across subdomains. It shows strong performance on PDEs like Allen-Cahn and Navier-Stokes without retraining when resolution scales.", "motivation": "To address the challenge of scaling transformer-based operator models to high-resolution, multiscale domains due to the quadratic cost of attention and its coupling to discretization.", "method": "The method involves decomposing a domain into non-overlapping subdomains and applying attention over sequences of subdomain-restricted functions. Within each subdomain, standard layers are replaced with expressive neural operators, and attention across subdomains is computed via softmax-based inner products over functions.", "result": "Mondrian achieves strong performance on Allen-Cahn and Navier-Stokes PDEs, demonstrating resolution scaling without retraining.", "conclusion": "These results highlight the promise of domain-decomposed attention for scalable and general-purpose neural operators."}}
{"id": "2506.08872", "pdf": "https://arxiv.org/pdf/2506.08872", "abs": "https://arxiv.org/abs/2506.08872", "authors": ["Nataliya Kosmyna", "Eugene Hauptmann", "Ye Tong Yuan", "Jessica Situ", "Xian-Hao Liao", "Ashly Vivian Beresnitzky", "Iris Braunstein", "Pattie Maes"], "title": "Your Brain on ChatGPT: Accumulation of Cognitive Debt when Using an AI Assistant for Essay Writing Task", "categories": ["cs.AI"], "comment": "206 pages, 92 figures, 4 tables and appendix", "summary": "This study explores the neural and behavioral consequences of LLM-assisted\nessay writing. Participants were divided into three groups: LLM, Search Engine,\nand Brain-only (no tools). Each completed three sessions under the same\ncondition. In a fourth session, LLM users were reassigned to Brain-only group\n(LLM-to-Brain), and Brain-only users were reassigned to LLM condition\n(Brain-to-LLM). A total of 54 participants took part in Sessions 1-3, with 18\ncompleting session 4. We used electroencephalography (EEG) to assess cognitive\nload during essay writing, and analyzed essays using NLP, as well as scoring\nessays with the help from human teachers and an AI judge. Across groups, NERs,\nn-gram patterns, and topic ontology showed within-group homogeneity. EEG\nrevealed significant differences in brain connectivity: Brain-only participants\nexhibited the strongest, most distributed networks; Search Engine users showed\nmoderate engagement; and LLM users displayed the weakest connectivity.\nCognitive activity scaled down in relation to external tool use. In session 4,\nLLM-to-Brain participants showed reduced alpha and beta connectivity,\nindicating under-engagement. Brain-to-LLM users exhibited higher memory recall\nand activation of occipito-parietal and prefrontal areas, similar to Search\nEngine users. Self-reported ownership of essays was the lowest in the LLM group\nand the highest in the Brain-only group. LLM users also struggled to accurately\nquote their own work. While LLMs offer immediate convenience, our findings\nhighlight potential cognitive costs. Over four months, LLM users consistently\nunderperformed at neural, linguistic, and behavioral levels. These results\nraise concerns about the long-term educational implications of LLM reliance and\nunderscore the need for deeper inquiry into AI's role in learning.", "AI": {"tldr": "This study explores the neural and behavioral consequences of LLM-assisted essay writing, finding that while LLMs offer convenience, there are potential cognitive costs and long-term educational implications.", "motivation": "To understand the impact of LLMs on cognitive load, linguistic patterns, and self-reported ownership in essay writing.", "method": "Participants were divided into three groups and completed essay writing sessions under different conditions. EEG was used to assess cognitive load, NLP was used to analyze essays, and essays were scored by human teachers and an AI judge.", "result": "LLM users showed weaker brain connectivity and underperformed at neural, linguistic, and behavioral levels. Self-reported ownership was lowest in the LLM group. Cognitive activity scaled down with external tool use.", "conclusion": "The findings highlight potential cognitive costs of LLM use and raise concerns about the long-term educational implications of relying on LLMs."}}
{"id": "2506.08228", "pdf": "https://arxiv.org/pdf/2506.08228", "abs": "https://arxiv.org/abs/2506.08228", "authors": ["Mustafa Baniodeh", "Kratarth Goel", "Scott Ettinger", "Carlos Fuertes", "Ari Seff", "Tim Shen", "Cole Gulino", "Chenjie Yang", "Ghassen Jerfel", "Dokook Choe", "Rui Wang", "Vinutha Kallem", "Sergio Casas", "Rami Al-Rfou", "Benjamin Sapp", "Dragomir Anguelov"], "title": "Scaling Laws of Motion Forecasting and Planning -- A Technical Report", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the empirical scaling laws of a family of encoder-decoder\nautoregressive transformer models on the task of joint motion forecasting and\nplanning in the autonomous driving domain. Using a 500 thousand hours driving\ndataset, we demonstrate that, similar to language modeling, model performance\nimproves as a power-law function of the total compute budget, and we observe a\nstrong correlation between model training loss and model evaluation metrics.\nMost interestingly, closed-loop metrics also improve with scaling, which has\nimportant implications for the suitability of open-loop metrics for model\ndevelopment and hill climbing. We also study the optimal scaling of the number\nof transformer parameters and the training data size for a training\ncompute-optimal model. We find that as the training compute budget grows,\noptimal scaling requires increasing the model size 1.5x as fast as the dataset\nsize. We also study inference-time compute scaling, where we observe that\nsampling and clustering the output of smaller models makes them competitive\nwith larger models, up to a crossover point beyond which a larger models\nbecomes more inference-compute efficient. Overall, our experimental results\ndemonstrate that optimizing the training and inference-time scaling properties\nof motion forecasting and planning models is a key lever for improving their\nperformance to address a wide variety of driving scenarios. Finally, we briefly\nstudy the utility of training on general logged driving data of other agents to\nimprove the performance of the ego-agent, an important research area to address\nthe scarcity of robotics data for large capacity models training.", "AI": {"tldr": "\u7814\u7a76\u4e86\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u4e2d\u7f16\u7801\u5668-\u89e3\u7801\u5668\u81ea\u56de\u5f52Transformer\u6a21\u578b\u7684\u7ecf\u9a8c\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u6027\u80fd\u4e0e\u8ba1\u7b97\u9884\u7b97\u7684\u5e42\u5f8b\u5173\u7cfb\uff0c\u5e76\u63a2\u8ba8\u4e86\u6a21\u578b\u53c2\u6570\u3001\u8bad\u7ec3\u6570\u636e\u548c\u63a8\u7406\u65f6\u95f4\u8ba1\u7b97\u7684\u6700\u4f73\u7f29\u653e\u7b56\u7565\u3002", "motivation": "\u63a2\u7d22\u5728\u81ea\u52a8\u9a7e\u9a76\u4efb\u52a1\u4e2d\uff0c\u6a21\u578b\u6027\u80fd\u5982\u4f55\u968f\u8ba1\u7b97\u9884\u7b97\u3001\u53c2\u6570\u6570\u91cf\u548c\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u7684\u53d8\u5316\u800c\u53d8\u5316\uff0c\u4ee5\u53ca\u8fd9\u4e9b\u53d8\u5316\u5bf9\u5f00\u73af\u548c\u95ed\u73af\u5ea6\u91cf\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u752850\u4e07\u5c0f\u65f6\u9a7e\u9a76\u6570\u636e\u96c6\u5206\u6790Transformer\u6a21\u578b\u7684\u7f29\u653e\u89c4\u5f8b\uff0c\u7814\u7a76\u6a21\u578b\u53c2\u6570\u3001\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u548c\u63a8\u7406\u8ba1\u7b97\u7684\u6700\u4f73\u7f29\u653e\u7b56\u7565\uff0c\u5e76\u6bd4\u8f83\u5c0f\u6a21\u578b\u91c7\u6837\u4e0e\u5927\u6a21\u578b\u7684\u6548\u679c\u3002", "result": "\u6a21\u578b\u6027\u80fd\u968f\u8ba1\u7b97\u9884\u7b97\u5448\u5e42\u5f8b\u589e\u957f\uff0c\u8bad\u7ec3\u635f\u5931\u4e0e\u8bc4\u4f30\u6307\u6807\u9ad8\u5ea6\u76f8\u5173\uff1b\u95ed\u73af\u6307\u6807\u4e5f\u968f\u7f29\u653e\u6539\u5584\uff1b\u6a21\u578b\u5927\u5c0f\u5e94\u4ee51.5\u500d\u4e8e\u6570\u636e\u96c6\u5927\u5c0f\u7684\u901f\u5ea6\u589e\u957f\uff1b\u5c0f\u6a21\u578b\u901a\u8fc7\u91c7\u6837\u548c\u805a\u7c7b\u53ef\u4e0e\u5927\u6a21\u578b\u7ade\u4e89\u81f3\u4ea4\u53c9\u70b9\u3002", "conclusion": "\u4f18\u5316\u6a21\u578b\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u7684\u7f29\u653e\u7279\u6027\u662f\u63d0\u5347\u81ea\u52a8\u9a7e\u9a76\u6a21\u578b\u6027\u80fd\u7684\u5173\u952e\uff0c\u540c\u65f6\u5229\u7528\u5176\u4ed6\u4ee3\u7406\u4eba\u7684\u9a7e\u9a76\u6570\u636e\u6709\u52a9\u4e8e\u7f13\u89e3\u673a\u5668\u4eba\u6570\u636e\u7a00\u7f3a\u95ee\u9898\u3002"}}
{"id": "2506.08898", "pdf": "https://arxiv.org/pdf/2506.08898", "abs": "https://arxiv.org/abs/2506.08898", "authors": ["Mingfeng Fan", "Jianan Zhou", "Yifeng Zhang", "Yaoxin Wu", "Jinbiao Chen", "Guillaume Adrien Sartoretti"], "title": "Preference-Driven Multi-Objective Combinatorial Optimization with Conditional Computation", "categories": ["cs.AI"], "comment": "22 pages, 6 figures, under review", "summary": "Recent deep reinforcement learning methods have achieved remarkable success\nin solving multi-objective combinatorial optimization problems (MOCOPs) by\ndecomposing them into multiple subproblems, each associated with a specific\nweight vector. However, these methods typically treat all subproblems equally\nand solve them using a single model, hindering the effective exploration of the\nsolution space and thus leading to suboptimal performance. To overcome the\nlimitation, we propose POCCO, a novel plug-and-play framework that enables\nadaptive selection of model structures for subproblems, which are subsequently\noptimized based on preference signals rather than explicit reward values.\nSpecifically, we design a conditional computation block that routes subproblems\nto specialized neural architectures. Moreover, we propose a preference-driven\noptimization algorithm that learns pairwise preferences between winning and\nlosing solutions. We evaluate the efficacy and versatility of POCCO by applying\nit to two state-of-the-art neural methods for MOCOPs. Experimental results\nacross four classic MOCOP benchmarks demonstrate its significant superiority\nand strong generalization.", "AI": {"tldr": "Recent deep reinforcement learning methods for multi-objective combinatorial optimization problems (MOCOPs) have limitations in exploration and performance. This paper proposes POCCO, a framework that enables adaptive model structure selection for subproblems and preference-driven optimization. Experimental results show its superiority and generalization.", "motivation": "Current deep reinforcement learning methods for MOCOPs treat all subproblems equally and use a single model, which limits effective exploration of the solution space and leads to suboptimal performance.", "method": "The paper proposes POCCO, a plug-and-play framework that allows adaptive selection of model structures for subproblems. It includes a conditional computation block that routes subproblems to specialized neural architectures and a preference-driven optimization algorithm that learns pairwise preferences between solutions.", "result": "POCCO was applied to two state-of-the-art neural methods for MOCOPs and tested across four classic MOCOP benchmarks. The results demonstrate its significant superiority and strong generalization.", "conclusion": "POCCO is an effective framework for solving MOCOPs by enabling adaptive model structure selection and preference-driven optimization, leading to superior performance and strong generalization."}}
{"id": "2506.08231", "pdf": "https://arxiv.org/pdf/2506.08231", "abs": "https://arxiv.org/abs/2506.08231", "authors": ["Melissa Estevez", "Nisha Singh", "Lauren Dyson", "Blythe Adamson", "Qianyu Yuan", "Megan W. Hildner", "Erin Fidyk", "Olive Mbah", "Farhad Khan", "Kathi Seidl-Rathkopf", "Aaron B. Cohen"], "title": "Ensuring Reliability of Curated EHR-Derived Data: The Validation of Accuracy for LLM/ML-Extracted Information and Data (VALID) Framework", "categories": ["cs.LG", "cs.AI", "cs.PF"], "comment": "18 pages, 3 tables, 1 figure", "summary": "Large language models (LLMs) are increasingly used to extract clinical data\nfrom electronic health records (EHRs), offering significant improvements in\nscalability and efficiency for real-world data (RWD) curation in oncology.\nHowever, the adoption of LLMs introduces new challenges in ensuring the\nreliability, accuracy, and fairness of extracted data, which are essential for\nresearch, regulatory, and clinical applications. Existing quality assurance\nframeworks for RWD and artificial intelligence do not fully address the unique\nerror modes and complexities associated with LLM-extracted data. In this paper,\nwe propose a comprehensive framework for evaluating the quality of clinical\ndata extracted by LLMs. The framework integrates variable-level performance\nbenchmarking against expert human abstraction, automated verification checks\nfor internal consistency and plausibility, and replication analyses comparing\nLLM-extracted data to human-abstracted datasets or external standards. This\nmultidimensional approach enables the identification of variables most in need\nof improvement, systematic detection of latent errors, and confirmation of\ndataset fitness-for-purpose in real-world research. Additionally, the framework\nsupports bias assessment by stratifying metrics across demographic subgroups.\nBy providing a rigorous and transparent method for assessing LLM-extracted RWD,\nthis framework advances industry standards and supports the trustworthy use of\nAI-powered evidence generation in oncology research and practice.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ece\u7535\u5b50\u5065\u5eb7\u8bb0\u5f55\u4e2d\u63d0\u53d6\u4e34\u5e8a\u6570\u636e\u8d28\u91cf\u7684\u5168\u9762\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u591a\u7ef4\u5ea6\u65b9\u6cd5\u786e\u4fdd\u6570\u636e\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\uff0c\u652f\u6301\u5728\u80bf\u7624\u5b66\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u53ef\u4fe1\u8d56\u5730\u4f7f\u7528AI\u751f\u6210\u7684\u8bc1\u636e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u9ad8\u4e86\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff08RWD\uff09\u5728\u80bf\u7624\u5b66\u4e2d\u7684\u6574\u7406\u6548\u7387\uff0c\u4f46\u5176\u5f15\u5165\u7684\u6570\u636e\u53ef\u9760\u6027\u3001\u51c6\u786e\u6027\u548c\u516c\u5e73\u6027\u95ee\u9898\u5c1a\u672a\u88ab\u73b0\u6709\u8d28\u91cf\u4fdd\u8bc1\u6846\u67b6\u5145\u5206\u89e3\u51b3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7efc\u5408\u6846\u67b6\uff0c\u5305\u62ec\uff1a\u53d8\u91cf\u7ea7\u522b\u7684\u6027\u80fd\u57fa\u51c6\u6d4b\u8bd5\uff08\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u5bf9\u6bd4\uff09\u3001\u81ea\u52a8\u5316\u9a8c\u8bc1\u68c0\u67e5\uff08\u5185\u90e8\u4e00\u81f4\u6027\u548c\u5408\u7406\u6027\uff09\u3001\u590d\u5236\u5206\u6790\uff08\u4e0e\u4eba\u7c7b\u62bd\u8c61\u6570\u636e\u96c6\u6216\u5916\u90e8\u6807\u51c6\u6bd4\u8f83\uff09\uff0c\u4ee5\u53ca\u504f\u5dee\u8bc4\u4f30\uff08\u8de8\u4eba\u53e3\u7edf\u8ba1\u5b50\u7fa4\uff09\u3002", "result": "\u80fd\u591f\u8bc6\u522b\u6700\u9700\u6539\u8fdb\u7684\u53d8\u91cf\u3001\u7cfb\u7edf\u68c0\u6d4b\u6f5c\u5728\u9519\u8bef\uff0c\u5e76\u786e\u8ba4\u6570\u636e\u96c6\u5728\u5b9e\u9645\u7814\u7a76\u4e2d\u7684\u9002\u7528\u6027\uff0c\u540c\u65f6\u652f\u6301\u504f\u5dee\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u4e25\u683c\u4e14\u900f\u660e\u7684\u65b9\u6cd5\u6765\u8bc4\u4f30LLM\u63d0\u53d6\u7684\u771f\u5b9e\u4e16\u754c\u6570\u636e\uff0c\u63a8\u52a8\u884c\u4e1a\u6807\u51c6\u53d1\u5c55\u5e76\u4fc3\u8fdbAI\u5728\u80bf\u7624\u5b66\u7814\u7a76\u548c\u5b9e\u8df5\u4e2d\u7684\u53ef\u4fe1\u5e94\u7528\u3002"}}
{"id": "2506.08957", "pdf": "https://arxiv.org/pdf/2506.08957", "abs": "https://arxiv.org/abs/2506.08957", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "IntTrajSim: Trajectory Prediction for Simulating Multi-Vehicle driving at Signalized Intersections", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Traffic simulators are widely used to study the operational efficiency of\nroad infrastructure, but their rule-based approach limits their ability to\nmimic real-world driving behavior. Traffic intersections are critical\ncomponents of the road infrastructure, both in terms of safety risk (nearly 28%\nof fatal crashes and 58% of nonfatal crashes happen at intersections) as well\nas the operational efficiency of a road corridor. This raises an important\nquestion: can we create a data-driven simulator that can mimic the macro- and\nmicro-statistics of the driving behavior at a traffic intersection? Deep\nGenerative Modeling-based trajectory prediction models provide a good starting\npoint to model the complex dynamics of vehicles at an intersection. But they\nare not tested in a \"live\" micro-simulation scenario and are not evaluated on\ntraffic engineering-related metrics. In this study, we propose traffic\nengineering-related metrics to evaluate generative trajectory prediction models\nand provide a simulation-in-the-loop pipeline to do so. We also provide a\nmulti-headed self-attention-based trajectory prediction model that incorporates\nthe signal information, which outperforms our previous models on the evaluation\nmetrics.", "AI": {"tldr": "The study proposes a data-driven simulator and multi-headed self-attention-based trajectory prediction model for mimicking driving behavior at traffic intersections, incorporating signal information to improve performance on traffic engineering-related metrics.", "motivation": "Traffic simulators with rule-based approach have limitations in mimicking real-world driving behavior, especially at intersections which are crucial for safety and road efficiency.", "method": "Proposing traffic engineering-related metrics to evaluate generative trajectory prediction models and providing a simulation-in-the-loop pipeline. Developing a multi-headed self-attention-based trajectory prediction model that includes signal information.", "result": "The new model outperforms previous models on the proposed evaluation metrics.", "conclusion": "A data-driven simulator and improved trajectory prediction model can better mimic driving behavior at intersections."}}
{"id": "2506.08240", "pdf": "https://arxiv.org/pdf/2506.08240", "abs": "https://arxiv.org/abs/2506.08240", "authors": ["Dongkyu Cho", "Rumi Chunara"], "title": "Dealing with the Evil Twins: Improving Random Augmentation by Addressing Catastrophic Forgetting of Diverse Augmentations", "categories": ["cs.LG"], "comment": "12 pages, 6 figures", "summary": "Data augmentation is a promising tool for enhancing out-of-distribution\ngeneralization, where the key is to produce diverse, challenging variations of\nthe source domain via costly targeted augmentations that maximize its\ngeneralization effect. Conversely, random augmentation is inexpensive but is\ndeemed suboptimal due to its limited effect. In this paper, we revisit random\naugmentation and explore methods to address its shortcomings. We show that the\nstochastic nature of random augmentation can produce a set of colliding\naugmentations that distorts the learned features, similar to catastrophic\nforgetting. We propose a simple solution that improves the generalization\neffect of random augmentation by addressing forgetting, which displays strong\ngeneralization performance across various single source domain generalization\n(sDG) benchmarks.", "AI": {"tldr": "\u901a\u8fc7\u6539\u8fdb\u968f\u673a\u589e\u5f3a\u65b9\u6cd5\u4ee5\u51cf\u5c11\u7279\u5f81\u626d\u66f2\u548c\u9057\u5fd8\u95ee\u9898\uff0c\u4ece\u800c\u63d0\u9ad8\u6cdb\u5316\u6027\u80fd\u3002", "motivation": "\u968f\u673a\u6570\u636e\u589e\u5f3a\u867d\u7136\u6210\u672c\u4f4e\u4f46\u6548\u679c\u6709\u9650\uff0c\u7136\u800c\u5176\u6f5c\u5728\u7684\u6539\u8fdb\u7a7a\u95f4\u5c1a\u672a\u88ab\u5145\u5206\u6316\u6398\u3002", "method": "\u91cd\u65b0\u5ba1\u89c6\u968f\u673a\u589e\u5f3a\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e00\u79cd\u7b80\u5355\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u89e3\u51b3\u968f\u673a\u589e\u5f3a\u4e2d\u56e0\u7279\u5f81\u78b0\u649e\u5bfc\u81f4\u7684\u9057\u5fd8\u95ee\u9898\u6765\u63d0\u5347\u6cdb\u5316\u6548\u679c\u3002", "result": "\u6240\u63d0\u65b9\u6cd5\u5728\u591a\u4e2a\u5355\u6e90\u57df\u6cdb\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684\u968f\u673a\u589e\u5f3a\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u63d0\u5347\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u4e14\u5728\u4e0d\u540c\u5355\u6e90\u57df\u6cdb\u5316\u4efb\u52a1\u4e2d\u6548\u679c\u663e\u8457\u3002"}}
{"id": "2506.08963", "pdf": "https://arxiv.org/pdf/2506.08963", "abs": "https://arxiv.org/abs/2506.08963", "authors": ["Yash Ranjan", "Rahul Sengupta", "Anand Rangarajan", "Sanjay Ranka"], "title": "Evaluating Generative Vehicle Trajectory Models for Traffic Intersection Dynamics", "categories": ["cs.AI"], "comment": null, "summary": "Traffic Intersections are vital to urban road networks as they regulate the\nmovement of people and goods. However, they are regions of conflicting\ntrajectories and are prone to accidents. Deep Generative models of traffic\ndynamics at signalized intersections can greatly help traffic authorities\nbetter understand the efficiency and safety aspects. At present, models are\nevaluated on computational metrics that primarily look at trajectory\nreconstruction errors. They are not evaluated online in a `live'\nmicrosimulation scenario. Further, these metrics do not adequately consider\ntraffic engineering-specific concerns such as red-light violations, unallowed\nstoppage, etc. In this work, we provide a comprehensive analytics tool to\ntrain, run, and evaluate models with metrics that give better insights into\nmodel performance from a traffic engineering point of view. We train a\nstate-of-the-art multi-vehicle trajectory forecasting model on a large dataset\ncollected by running a calibrated scenario of a real-world urban intersection.\nWe then evaluate the performance of the prediction models, online in a\nmicrosimulator, under unseen traffic conditions. We show that despite using\nideally-behaved trajectories as input, and achieving low trajectory\nreconstruction errors, the generated trajectories show behaviors that break\ntraffic rules. We introduce new metrics to evaluate such undesired behaviors\nand present our results.", "AI": {"tldr": "\u5c3d\u7ba1\u4f7f\u7528\u7406\u60f3\u8f68\u8ff9\u4f5c\u4e3a\u8f93\u5165\u5e76\u83b7\u5f97\u8f83\u4f4e\u7684\u8f68\u8ff9\u91cd\u5efa\u8bef\u5dee\uff0c\u751f\u6210\u7684\u8f68\u8ff9\u4ecd\u8868\u73b0\u51fa\u8fdd\u53cd\u4ea4\u901a\u89c4\u5219\u7684\u884c\u4e3a\u3002\u6211\u4eec\u5f15\u5165\u65b0\u6307\u6807\u6765\u8bc4\u4f30\u8fd9\u4e9b\u4e0d\u826f\u884c\u4e3a\u5e76\u5c55\u793a\u7ed3\u679c\u3002", "motivation": "\u4ea4\u53c9\u8def\u53e3\u662f\u57ce\u5e02\u8def\u7f51\u7684\u5173\u952e\u90e8\u5206\uff0c\u4f46\u5bb9\u6613\u53d1\u751f\u4e8b\u6545\u3002\u5f53\u524d\u5bf9\u4fe1\u53f7\u4ea4\u53c9\u53e3\u7684\u4ea4\u901a\u52a8\u6001\u751f\u6210\u6a21\u578b\u4e3b\u8981\u4f9d\u8d56\u4e8e\u8ba1\u7b97\u8f68\u8ff9\u91cd\u5efa\u8bef\u5dee\u7684\u6307\u6807\uff0c\u672a\u5145\u5206\u8003\u8651\u5982\u95ef\u7ea2\u706f\u7b49\u4ea4\u901a\u5de5\u7a0b\u7279\u5b9a\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u5206\u6790\u5de5\u5177\uff0c\u7528\u4e8e\u8bad\u7ec3\u3001\u8fd0\u884c\u548c\u8bc4\u4f30\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u4f7f\u7528\u66f4\u7b26\u5408\u4ea4\u901a\u5de5\u7a0b\u89c2\u70b9\u7684\u6307\u6807\u3002\u6211\u4eec\u5728\u5927\u578b\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u6700\u5148\u8fdb\u7684\u591a\u8f66\u8f86\u8f68\u8ff9\u9884\u6d4b\u6a21\u578b\uff0c\u5e76\u5728\u5fae\u4eff\u771f\u5668\u4e2d\u8bc4\u4f30\u5176\u5728\u672a\u77e5\u4ea4\u901a\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u5373\u4f7f\u8f93\u5165\u7406\u60f3\u8f68\u8ff9\u4e14\u91cd\u5efa\u8bef\u5dee\u4f4e\uff0c\u751f\u6210\u7684\u8f68\u8ff9\u4ecd\u5b58\u5728\u8fdd\u53cd\u4ea4\u901a\u89c4\u5219\u7684\u884c\u4e3a\u3002\u6211\u4eec\u5f15\u5165\u4e86\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u6765\u8861\u91cf\u8fd9\u4e9b\u4e0d\u826f\u884c\u4e3a\u3002", "conclusion": "\u9700\u8981\u66f4\u597d\u7684\u6307\u6807\u6765\u8bc4\u4f30\u4ea4\u901a\u6a21\u578b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4ea4\u901a\u5de5\u7a0b\u65b9\u9762\u7684\u95ee\u9898\u3002"}}
{"id": "2506.08243", "pdf": "https://arxiv.org/pdf/2506.08243", "abs": "https://arxiv.org/abs/2506.08243", "authors": ["Zhenjiang Mao", "Artem Bisliouk", "Rohith Reddy Nama", "Ivan Ruchkin"], "title": "Temporalizing Confidence: Evaluation of Chain-of-Thought Reasoning with Signal Temporal Logic", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown impressive performance in\nmathematical reasoning tasks when guided by Chain-of-Thought (CoT) prompting.\nHowever, they tend to produce highly confident yet incorrect outputs, which\nposes significant risks in domains like education, where users may lack the\nexpertise to assess reasoning steps. To address this, we propose a structured\nframework that models stepwise confidence as a temporal signal and evaluates it\nusing Signal Temporal Logic (STL). In particular, we define formal STL-based\nconstraints to capture desirable temporal properties and compute robustness\nscores that serve as structured, interpretable confidence estimates. Our\napproach also introduces a set of uncertainty reshaping strategies to enforce\nsmoothness, monotonicity, and causal consistency across the reasoning\ntrajectory. Experiments show that our approach consistently improves\ncalibration metrics and provides more reliable uncertainty estimates than\nconventional confidence aggregation and post-hoc calibration.", "AI": {"tldr": "\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\uff0c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u867d\u7136\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u6709\u65f6\u4f1a\u4ea7\u751f\u9ad8\u5ea6\u81ea\u4fe1\u5374\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u8fd9\u5728\u6559\u80b2\u7b49\u9886\u57df\u5b58\u5728\u98ce\u9669\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5bf9\u9010\u6b65\u7f6e\u4fe1\u5ea6\u8fdb\u884c\u5efa\u6a21\u548c\u8bc4\u4f30\uff0c\u540c\u65f6\u5f15\u5165\u4e0d\u786e\u5b9a\u6027\u91cd\u5851\u7b56\u7565\u4ee5\u786e\u4fdd\u63a8\u7406\u8fc7\u7a0b\u7684\u4e00\u81f4\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6821\u51c6\u6307\u6807\u5e76\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "motivation": "\u5c3d\u7ba1\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u4f7f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u53ef\u80fd\u751f\u6210\u9ad8\u5ea6\u81ea\u4fe1\u4e14\u9519\u8bef\u7684\u8f93\u51fa\uff0c\u8fd9\u5728\u7528\u6237\u7f3a\u4e4f\u4e13\u4e1a\u77e5\u8bc6\u6765\u8bc4\u4f30\u63a8\u7406\u6b65\u9aa4\u7684\u9886\u57df\uff08\u5982\u6559\u80b2\uff09\u4e2d\u5e26\u6765\u4e86\u663e\u8457\u98ce\u9669\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u6784\u5316\u6846\u67b6\uff0c\u5c06\u9010\u6b65\u7f6e\u4fe1\u5ea6\u4f5c\u4e3a\u65f6\u95f4\u4fe1\u53f7\u8fdb\u884c\u5efa\u6a21\uff0c\u5e76\u4f7f\u7528\u4fe1\u53f7\u65f6\u5e8f\u903b\u8f91\uff08STL\uff09\u5bf9\u5176\u8fdb\u884c\u8bc4\u4f30\u3002\u5b9a\u4e49\u4e86\u57fa\u4e8eSTL\u7684\u5f62\u5f0f\u7ea6\u675f\u4ee5\u6355\u83b7\u7406\u60f3\u7684\u65f6\u5e8f\u5c5e\u6027\uff0c\u5e76\u8ba1\u7b97\u7a33\u5065\u6027\u5f97\u5206\u4f5c\u4e3a\u7ed3\u6784\u5316\u3001\u53ef\u89e3\u91ca\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002\u8fd8\u5f15\u5165\u4e86\u4e00\u7cfb\u5217\u4e0d\u786e\u5b9a\u6027\u91cd\u5851\u7b56\u7565\uff0c\u4ee5\u5728\u6574\u4e2a\u63a8\u7406\u8f68\u8ff9\u4e2d\u5f3a\u5236\u6267\u884c\u5e73\u6ed1\u6027\u3001\u5355\u8c03\u6027\u548c\u56e0\u679c\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u4e00\u81f4\u5730\u63d0\u9ad8\u4e86\u6821\u51c6\u6307\u6807\uff0c\u5e76\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edf\u7f6e\u4fe1\u5ea6\u805a\u5408\u548c\u4e8b\u540e\u6821\u51c6\u66f4\u4e3a\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u6846\u67b6\u80fd\u591f\u6709\u6548\u6539\u8fdbLLMs\u5728\u6570\u5b66\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u63d0\u4f9b\u66f4\u53ef\u9760\u3001\u66f4\u53ef\u89e3\u91ca\u7684\u4e0d\u786e\u5b9a\u6027\u8bc4\u4f30\uff0c\u4ece\u800c\u964d\u4f4e\u6f5c\u5728\u98ce\u9669\u3002"}}
{"id": "2506.08970", "pdf": "https://arxiv.org/pdf/2506.08970", "abs": "https://arxiv.org/abs/2506.08970", "authors": ["Jiyao Wei", "Saiping Guan", "Da Li", "Xiaolong Jin", "Jiafeng Guo", "Xueqi Cheng"], "title": "A Survey of Link Prediction in N-ary Knowledge Graphs", "categories": ["cs.AI"], "comment": null, "summary": "N-ary Knowledge Graphs (NKGs) are a specialized type of knowledge graph\ndesigned to efficiently represent complex real-world facts. Unlike traditional\nknowledge graphs, where a fact typically involves two entities, NKGs can\ncapture n-ary facts containing more than two entities. Link prediction in NKGs\naims to predict missing elements within these n-ary facts, which is essential\nfor completing NKGs and improving the performance of downstream applications.\nThis task has recently gained significant attention. In this paper, we present\nthe first comprehensive survey of link prediction in NKGs, providing an\noverview of the field, systematically categorizing existing methods, and\nanalyzing their performance and application scenarios. We also outline\npromising directions for future research.", "AI": {"tldr": "N-ary Knowledge Graphs (NKGs) are designed for complex facts representation. Link prediction in NKGs predicts missing elements within these facts. This paper surveys link prediction methods in NKGs, categorizes them, and suggests future research directions.", "motivation": "To provide a comprehensive understanding of the link prediction task in N-ary Knowledge Graphs and guide future research.", "method": "Systematic categorization and analysis of existing link prediction methods in NKGs.", "result": "Overview of the field, classification of methods, performance and application analysis, and identification of promising research directions.", "conclusion": "The first comprehensive survey on link prediction in NKGs has been presented, offering insights into current methods and suggesting future research opportunities."}}
{"id": "2506.08244", "pdf": "https://arxiv.org/pdf/2506.08244", "abs": "https://arxiv.org/abs/2506.08244", "authors": ["Riccardo Ali", "Pietro Li\u00f2", "Jamie Vicary"], "title": "Parameter-free approximate equivariance for tasks with finite group symmetry", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Equivariant neural networks incorporate symmetries through group actions,\nembedding them as an inductive bias to improve performance on a wide variety of\ntasks. However, existing equivariant methods can be computationally intensive,\nwith high parameter counts, and are often tied to a specific architecture. We\npropose a simple zero-parameter approach that imposes approximate equivariance\nfor a finite group in the latent representation, as an additional term in the\nloss function. We conduct experiments which allow the network to learn a group\nrepresentation on the latent space, and show in every case it prefers to learn\nthe regular representation. Fixing this action on the latent space, this yields\na simple method to impose approximate equivariance as an additional loss\npenalty. We benchmark our approach on three datasets and compare it against\nseveral existing equivariant methods, showing that in many cases it achieves\nsimilar or better performance for a fraction of the parameters.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u9879\u6765\u5728\u6f5c\u5728\u8868\u793a\u4e2d\u65bd\u52a0\u6709\u9650\u7fa4\u7684\u8fd1\u4f3c\u7b49\u53d8\u6027\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u7f51\u7edc\u503e\u5411\u4e8e\u5b66\u4e60\u89c4\u5219\u8868\u793a\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u6bd4\uff0c\u5728\u4f7f\u7528\u8f83\u5c11\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u7b49\u53d8\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u3001\u53c2\u6570\u591a\u4e14\u901a\u5e38\u4e0e\u7279\u5b9a\u67b6\u6784\u7ed1\u5b9a\u3002\u4e3a\u4e86\u7b80\u5316\u7b49\u53d8\u795e\u7ecf\u7f51\u7edc\u7684\u8bbe\u8ba1\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u5b9e\u73b0\u8fd1\u4f3c\u7b49\u53d8\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u96f6\u53c2\u6570\u7684\u65b9\u6cd5\uff0c\u5728\u6f5c\u5728\u8868\u793a\u4e2d\u901a\u8fc7\u5728\u635f\u5931\u51fd\u6570\u4e2d\u6dfb\u52a0\u989d\u5916\u9879\u6765\u65bd\u52a0\u6709\u9650\u7fa4\u7684\u8fd1\u4f3c\u7b49\u53d8\u6027\u3002\u5141\u8bb8\u7f51\u7edc\u5b66\u4e60\u6f5c\u5728\u7a7a\u95f4\u4e0a\u7684\u7fa4\u8868\u793a\uff0c\u5e76\u89c2\u5bdf\u5176\u662f\u5426\u503e\u5411\u4e8e\u5b66\u4e60\u89c4\u5219\u8868\u793a\u3002", "result": "\u5728\u4e09\u4e2a\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bb8\u591a\u60c5\u51b5\u4e0b\u4ee5\u66f4\u5c11\u7684\u53c2\u6570\u5b9e\u73b0\u4e86\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u4f3c\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u624b\u6bb5\uff0c\u53ef\u4ee5\u901a\u8fc7\u635f\u5931\u51fd\u6570\u4e2d\u7684\u60e9\u7f5a\u9879\u6765\u65bd\u52a0\u8fd1\u4f3c\u7b49\u53d8\u6027\uff0c\u4ece\u800c\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u5e76\u63d0\u9ad8\u6027\u80fd\u3002"}}
{"id": "2506.09038", "pdf": "https://arxiv.org/pdf/2506.09038", "abs": "https://arxiv.org/abs/2506.09038", "authors": ["Polina Kirichenko", "Mark Ibrahim", "Kamalika Chaudhuri", "Samuel J. Bell"], "title": "AbstentionBench: Reasoning LLMs Fail on Unanswerable Questions", "categories": ["cs.AI"], "comment": null, "summary": "For Large Language Models (LLMs) to be reliably deployed in both everyday and\nhigh-stakes domains, knowing when not to answer is equally critical as\nanswering correctly. Real-world user queries, which can be underspecified,\nill-posed, or fundamentally unanswerable, require LLMs to reason about\nuncertainty and selectively abstain -- i.e., refuse to answer definitively.\nHowever, abstention remains understudied, without a systematic evaluation\nframework for modern LLMs. In this work, we introduce AbstentionBench, a\nlarge-scale benchmark for holistically evaluating abstention across 20 diverse\ndatasets, including questions with unknown answers, underspecification, false\npremises, subjective interpretations, and outdated information. Evaluating 20\nfrontier LLMs reveals abstention is an unsolved problem, and one where scaling\nmodels is of little use. While recent reasoning LLMs have shown impressive\nresults in complex problem solving, surprisingly, we find that reasoning\nfine-tuning degrades abstention (by $24\\%$ on average), even for math and\nscience domains on which reasoning models are explicitly trained. We find that\nwhile a carefully crafted system prompt can boost abstention in practice, it\ndoes not resolve models' fundamental inability to reason about uncertainty. We\nrelease AbstentionBench to foster research into advancing LLM reliability.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9700\u8981\u77e5\u9053\u4f55\u65f6\u4e0d\u7ed9\u51fa\u7b54\u6848\uff0c\u8fd9\u4e0e\u6b63\u786e\u56de\u7b54\u95ee\u9898\u540c\u6837\u91cd\u8981\u3002\u7136\u800c\uff0c\u62d2\u7edd\u56de\u7b54\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\uff0c\u7f3a\u4e4f\u9488\u5bf9\u73b0\u4ee3LLM\u7684\u7cfb\u7edf\u8bc4\u4f30\u6846\u67b6\u3002\u672c\u6587\u4ecb\u7ecd\u4e86AbstentionBench\uff0c\u8fd9\u662f\u4e00\u4e2a\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5168\u9762\u8bc4\u4f3020\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u62d2\u7edd\u56de\u7b54\u80fd\u529b\uff0c\u6db5\u76d6\u672a\u77e5\u7b54\u6848\u3001\u672a\u660e\u786e\u6307\u5b9a\u3001\u9519\u8bef\u524d\u63d0\u7b49\u95ee\u9898\u3002\u5bf920\u4e2a\u524d\u6cbfLLM\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u589e\u5927\u6a21\u578b\u89c4\u6a21\u5bf9\u63d0\u5347\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u5e2e\u52a9\u4e0d\u5927\uff0c\u4e14\u6700\u8fd1\u7684\u63a8\u7406\u5fae\u8c03\u53cd\u800c\u964d\u4f4e\u4e86\u8be5\u80fd\u529b\uff08\u5e73\u5747\u964d\u4f4e24%\uff09\u3002\u867d\u7136\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7cfb\u7edf\u63d0\u793a\u53ef\u4ee5\u5b9e\u9645\u63d0\u9ad8\u62d2\u7edd\u56de\u7b54\u80fd\u529b\uff0c\u4f46\u5e76\u4e0d\u80fd\u89e3\u51b3\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u65b9\u9762\u7684\u6839\u672c\u7f3a\u9677\u3002\u6211\u4eec\u53d1\u5e03\u4e86AbstentionBench\u4ee5\u63a8\u52a8LLM\u53ef\u9760\u6027\u7684\u7814\u7a76\u3002", "motivation": "\u76ee\u524d\u5bf9\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f55\u65f6\u4e0d\u5e94\u63d0\u4f9b\u7b54\u6848\u8fd9\u4e00\u65b9\u9762\u7f3a\u4e4f\u6df1\u5165\u7814\u7a76\u548c\u7cfb\u7edf\u6027\u8bc4\u4f30\u6846\u67b6\u3002\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u7528\u6237\u67e5\u8be2\u53ef\u80fd\u672a\u660e\u786e\u6307\u5b9a\u3001\u8868\u8ff0\u4e0d\u5f53\u6216\u6839\u672c\u65e0\u6cd5\u56de\u7b54\uff0c\u56e0\u6b64\u9700\u8981LLMs\u5177\u5907\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u80fd\u529b\u548c\u9009\u62e9\u6027\u62d2\u7edd\u56de\u7b54\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aAbstentionBench\u7684\u5927\u89c4\u6a21\u57fa\u51c6\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4e8620\u4e2a\u4e0d\u540c\u7684\u6570\u636e\u96c6\uff0c\u5305\u62ec\u672a\u77e5\u7b54\u6848\u7684\u95ee\u9898\u3001\u672a\u660e\u786e\u6307\u5b9a\u7684\u95ee\u9898\u3001\u9519\u8bef\u524d\u63d0\u7684\u95ee\u9898\u7b49\u3002\u901a\u8fc7\u8fd9\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f5c\u8005\u8bc4\u4f30\u4e8620\u4e2a\u524d\u6cbfLLM\u7684\u62d2\u7edd\u56de\u7b54\u80fd\u529b\uff0c\u5e76\u5206\u6790\u4e86\u6a21\u578b\u89c4\u6a21\u3001\u63a8\u7406\u5fae\u8c03\u548c\u7cfb\u7edf\u63d0\u793a\u7b49\u56e0\u7d20\u5bf9\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u7684\u5f71\u54cd\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u663e\u793a\uff0c\u589e\u5927\u6a21\u578b\u89c4\u6a21\u5bf9\u63d0\u5347\u62d2\u7edd\u56de\u7b54\u80fd\u529b\u5e2e\u52a9\u4e0d\u5927\uff0c\u4e14\u6700\u8fd1\u7684\u63a8\u7406\u5fae\u8c03\u53cd\u800c\u964d\u4f4e\u4e86\u8be5\u80fd\u529b\uff08\u5e73\u5747\u964d\u4f4e24%\uff09\u3002\u867d\u7136\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u7cfb\u7edf\u63d0\u793a\u53ef\u4ee5\u5b9e\u9645\u63d0\u9ad8\u62d2\u7edd\u56de\u7b54\u80fd\u529b\uff0c\u4f46\u5e76\u4e0d\u80fd\u89e3\u51b3\u6a21\u578b\u5728\u4e0d\u786e\u5b9a\u6027\u63a8\u7406\u65b9\u9762\u7684\u6839\u672c\u7f3a\u9677\u3002", "conclusion": "\u4f5c\u8005\u8ba4\u4e3a\u62d2\u7edd\u56de\u7b54\u662f\u4e00\u4e2a\u5c1a\u672a\u89e3\u51b3\u7684\u95ee\u9898\uff0c\u5e76\u53d1\u5e03\u4e86AbstentionBench\u4ee5\u63a8\u52a8LLM\u53ef\u9760\u6027\u7684\u7814\u7a76\u3002"}}
{"id": "2506.08255", "pdf": "https://arxiv.org/pdf/2506.08255", "abs": "https://arxiv.org/abs/2506.08255", "authors": ["Patryk Krukowski", "\u0141ukasz Gorczyca", "Piotr Helm", "Kamil Ksi\u0105\u017cek", "Przemys\u0142aw Spurek"], "title": "SHIELD: Secure Hypernetworks for Incremental Expansion Learning Defense", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Traditional deep neural networks suffer from several limitations, including\ncatastrophic forgetting. When models are adapted to new datasets, they tend to\nquickly forget previously learned knowledge. Another significant issue is the\nlack of robustness to even small perturbations in the input data. In practice,\nwe can often easily perform adversarial attacks and change the network's\npredictions, adding minimal noise to the input. Dedicated architectures and\ntraining procedures can solve each of the above problems separately.\nUnfortunately, currently, no model can simultaneously address both catastrophic\nforgetting and vulnerability to adversarial attacks. We introduce SHIELD\n(Secure Hypernetworks for Incremental Expansion and Learning Defense), a novel\napproach that integrates a hypernetwork-based continual learning approach with\ninterval arithmetic. SHIELD use the hypernetwork to transfer trainable task\nembedding vectors into the weights of a target model dedicated to specific\ndata. This paradigm allows for the dynamic generation of separate networks for\neach subtask, while the hypernetwork aggregates and analyzes information across\nall tasks. The target model takes in the input a data sample with a defined\ninterval range, and by creating a hypercube, produces a prediction for the\ngiven range. Therefore, such target models provide strict guarantees against\nall possible attacks for data samples within the interval range. Our approach\nenhances security without sacrificing network adaptability, addressing the\noverlooked challenge of safety in continual learning.", "AI": {"tldr": "The paper proposes SHIELD, a method that combines hypernetwork-based continual learning with interval arithmetic to address catastrophic forgetting and vulnerability to adversarial attacks simultaneously.", "motivation": "Traditional deep neural networks face issues like catastrophic forgetting when adapting to new datasets and vulnerability to adversarial attacks. No existing model can solve both problems at the same time.", "method": "SHIELD integrates a hypernetwork-based continual learning approach with interval arithmetic. It uses hypernetworks to transfer task embedding vectors into target model weights for specific data, enabling dynamic generation of separate networks per subtask. The target model processes data samples in an interval range, creating a hypercube to provide guarantees against attacks within this range.", "result": "This approach enhances security while maintaining network adaptability, successfully addressing safety in continual learning.", "conclusion": "SHIELD presents a novel solution for overcoming catastrophic forgetting and adversarial attack vulnerabilities concurrently without compromising on adaptability."}}
{"id": "2506.09049", "pdf": "https://arxiv.org/pdf/2506.09049", "abs": "https://arxiv.org/abs/2506.09049", "authors": ["Li Kang", "Xiufeng Song", "Heng Zhou", "Yiran Qin", "Jie Yang", "Xiaohong Liu", "Philip Torr", "Lei Bai", "Zhenfei Yin"], "title": "VIKI-R: Coordinating Embodied Multi-Agent Cooperation via Reinforcement Learning", "categories": ["cs.AI", "cs.CV", "cs.RO"], "comment": "Project page: https://faceong.github.io/VIKI-R/", "summary": "Coordinating multiple embodied agents in dynamic environments remains a core\nchallenge in artificial intelligence, requiring both perception-driven\nreasoning and scalable cooperation strategies. While recent works have\nleveraged large language models (LLMs) for multi-agent planning, a few have\nbegun to explore vision-language models (VLMs) for visual reasoning. However,\nthese VLM-based approaches remain limited in their support for diverse\nembodiment types. In this work, we introduce VIKI-Bench, the first hierarchical\nbenchmark tailored for embodied multi-agent cooperation, featuring three\nstructured levels: agent activation, task planning, and trajectory perception.\nVIKI-Bench includes diverse robot embodiments, multi-view visual observations,\nand structured supervision signals to evaluate reasoning grounded in visual\ninputs. To demonstrate the utility of VIKI-Bench, we propose VIKI-R, a\ntwo-stage framework that fine-tunes a pretrained vision-language model (VLM)\nusing Chain-of-Thought annotated demonstrations, followed by reinforcement\nlearning under multi-level reward signals. Our extensive experiments show that\nVIKI-R significantly outperforms baselines method across all task levels.\nFurthermore, we show that reinforcement learning enables the emergence of\ncompositional cooperation patterns among heterogeneous agents. Together,\nVIKI-Bench and VIKI-R offer a unified testbed and method for advancing\nmulti-agent, visual-driven cooperation in embodied AI systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86VIKI-Bench\uff0c\u4e00\u4e2a\u4e13\u4e3a\u591a\u667a\u80fd\u4f53\u534f\u4f5c\u8bbe\u8ba1\u7684\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5e76\u63d0\u51fa\u4e86VIKI-R\u6846\u67b6\uff0c\u901a\u8fc7\u5fae\u8c03\u9884\u8bad\u7ec3\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u548c\u5f3a\u5316\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u591a\u4efb\u52a1\u7ea7\u522b\u7684\u8868\u73b0\u3002", "motivation": "\u76ee\u524d\u5728\u52a8\u6001\u73af\u5883\u4e2d\u534f\u8c03\u591a\u4e2a\u5177\u8eab\u667a\u80fd\u4f53\u4ecd\u662f\u4e00\u4e2a\u6838\u5fc3\u6311\u6218\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u65b9\u6cd5\u5728\u652f\u6301\u591a\u6837\u5316\u7684\u5177\u8eab\u7c7b\u578b\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u5f15\u5165\u4e86VIKI-Bench\uff0c\u4e00\u4e2a\u5305\u542b\u4e09\u4e2a\u7ed3\u6784\u5316\u5c42\u6b21\uff08\u667a\u80fd\u4f53\u6fc0\u6d3b\u3001\u4efb\u52a1\u89c4\u5212\u548c\u8f68\u8ff9\u611f\u77e5\uff09\u7684\u5206\u5c42\u57fa\u51c6\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4ee5\u53caVIKI-R\uff0c\u4e00\u4e2a\u4e24\u9636\u6bb5\u6846\u67b6\uff0c\u5229\u7528\u601d\u7ef4\u94fe\u6807\u6ce8\u6f14\u793a\u5fae\u8c03\u9884\u8bad\u7ec3\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff0c\u7136\u540e\u8fdb\u884c\u591a\u5c42\u6b21\u5956\u52b1\u4fe1\u53f7\u4e0b\u7684\u5f3a\u5316\u5b66\u4e60\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVIKI-R\u5728\u6240\u6709\u4efb\u52a1\u7ea7\u522b\u4e0a\u5747\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u4e14\u5f3a\u5316\u5b66\u4e60\u80fd\u591f\u4fc3\u4f7f\u5f02\u6784\u667a\u80fd\u4f53\u4e4b\u95f4\u51fa\u73b0\u7ec4\u5408\u534f\u4f5c\u6a21\u5f0f\u3002", "conclusion": "VIKI-Bench\u548cVIKI-R\u5171\u540c\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u7684\u6d4b\u8bd5\u5e73\u53f0\u548c\u65b9\u6cd5\uff0c\u4ee5\u63a8\u52a8\u5177\u8eabAI\u7cfb\u7edf\u4e2d\u591a\u667a\u80fd\u4f53\u3001\u89c6\u89c9\u9a71\u52a8\u534f\u4f5c\u7684\u53d1\u5c55\u3002"}}
{"id": "2506.08266", "pdf": "https://arxiv.org/pdf/2506.08266", "abs": "https://arxiv.org/abs/2506.08266", "authors": ["Yaswanth Chittepu", "Blossom Metevier", "Will Schwarzer", "Austin Hoag", "Scott Niekum", "Philip S. Thomas"], "title": "Reinforcement Learning from Human Feedback with High-Confidence Safety Constraints", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.AP"], "comment": "20 pages, 6 figures, 4 tables, Second Reinforcement Learning\n  Conference (RLC 2025)", "summary": "Existing approaches to language model alignment often treat safety as a\ntradeoff against helpfulness, which can lead to unacceptable responses in\nsensitive domains. To ensure reliable performance in such settings, we propose\nHigh-Confidence Safe Reinforcement Learning from Human Feedback (HC-RLHF), a\nmethod that provides high-confidence safety guarantees while maximizing\nhelpfulness. Similar to previous methods, HC-RLHF explicitly decouples human\npreferences into helpfulness and harmlessness (safety), which are learned by\ntraining a reward model and a cost model, respectively. It then employs a\ntwo-step process to find safe solutions. In the first step, it optimizes the\nreward function under an intentionally pessimistic version of the cost\nconstraint. In the second step, the trained model undergoes a safety test to\nverify whether its performance stays within an upper-confidence bound of the\nactual cost constraint. We provide a theoretical analysis of HC-RLHF, including\nproof that it will not return an unsafe solution with a probability greater\nthan a user-specified threshold. For our empirical analysis, we apply HC-RLHF\nto align three different language models (Qwen2-1.5B, Qwen2.5-3B, and\nLLaMa3.2-3B) with human preferences. Our results demonstrate that HC-RLHF\nproduces safe models with high probability and can improve harmlessness and\nhelpfulness compared to previous methods.", "AI": {"tldr": "The paper introduces HC-RLHF, a method ensuring safe and helpful language model alignment through high-confidence safety guarantees. It separates human preferences into helpfulness and harmlessness, optimizes under pessimistic cost constraints, verifies safety with upper-confidence bounds, and demonstrates effectiveness on three models.", "motivation": "Current methods for aligning language models often compromise between safety and helpfulness, potentially leading to unacceptable responses in sensitive areas. There is a need for a method that can ensure safety while maintaining helpfulness.", "method": "HC-RLHF decouples human preferences into helpfulness (reward model) and harmlessness (cost model). It optimizes the reward function under a pessimistic cost constraint and then tests the model's safety within an upper-confidence bound of the actual cost constraint.", "result": "HC-RLHF successfully produces safe models with high probability when applied to Qwen2-1.5B, Qwen2.5-3B, and LLaMa3.2-3B. It improves both harmlessness and helpfulness compared to previous methods.", "conclusion": "HC-RLHF provides a reliable approach to align language models with human preferences, ensuring safety without significantly sacrificing helpfulness."}}
{"id": "2506.09050", "pdf": "https://arxiv.org/pdf/2506.09050", "abs": "https://arxiv.org/abs/2506.09050", "authors": ["Yuki Imajuku", "Kohki Horie", "Yoichi Iwata", "Kensho Aoki", "Naohiro Takahashi", "Takuya Akiba"], "title": "ALE-Bench: A Benchmark for Long-Horizon Objective-Driven Algorithm Engineering", "categories": ["cs.AI"], "comment": "36 pages", "summary": "How well do AI systems perform in algorithm engineering for hard optimization\nproblems in domains such as package-delivery routing, crew scheduling, factory\nproduction planning, and power-grid balancing? We introduce ALE-Bench, a new\nbenchmark for evaluating AI systems on score-based algorithmic programming\ncontests. Drawing on real tasks from the AtCoder Heuristic Contests, ALE-Bench\npresents optimization problems that are computationally hard and admit no known\nexact solution. Unlike short-duration, pass/fail coding benchmarks, ALE-Bench\nencourages iterative solution refinement over long time horizons. Our software\nframework supports interactive agent architectures that leverage test-run\nfeedback and visualizations. Our evaluation of frontier LLMs revealed that\nwhile they demonstrate high performance on specific problems, a notable gap\nremains compared to humans in terms of consistency across problems and\nlong-horizon problem-solving capabilities. This highlights the need for this\nbenchmark to foster future AI advancements.", "AI": {"tldr": "The paper introduces ALE-Bench, a benchmark for evaluating AI systems in solving hard optimization problems. Unlike traditional benchmarks, ALE-Bench encourages iterative solution refinement over long time horizons and supports interactive agent architectures. The evaluation of frontier LLMs showed high performance on specific problems but inconsistency across problems and lacking long-horizon problem-solving capabilities compared to humans.", "motivation": "To evaluate how well AI systems perform in algorithm engineering for hard optimization problems in various domains, and to address the limitations of existing short-duration, pass/fail coding benchmarks.", "method": "Introduced ALE-Bench, a new benchmark drawing on real tasks from AtCoder Heuristic Contests, presenting computationally hard optimization problems without known exact solutions. The software framework supports interactive agent architectures leveraging test-run feedback and visualizations.", "result": "Frontier LLMs demonstrated high performance on specific problems but showed inconsistency across problems and lacked long-horizon problem-solving capabilities compared to humans.", "conclusion": "There is a notable gap between AI systems and humans in terms of consistency and long-horizon problem-solving capabilities, highlighting the need for ALE-Bench to foster future AI advancements."}}
{"id": "2506.08267", "pdf": "https://arxiv.org/pdf/2506.08267", "abs": "https://arxiv.org/abs/2506.08267", "authors": ["Mansooreh Montazerin", "Majd Al Aawar", "Antonio Ortega", "Ajitesh Srivastava"], "title": "Sparse Interpretable Deep Learning with LIES Networks for Symbolic Regression", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Symbolic regression (SR) aims to discover closed-form mathematical\nexpressions that accurately describe data, offering interpretability and\nanalytical insight beyond standard black-box models. Existing SR methods often\nrely on population-based search or autoregressive modeling, which struggle with\nscalability and symbolic consistency. We introduce LIES (Logarithm, Identity,\nExponential, Sine), a fixed neural network architecture with interpretable\nprimitive activations that are optimized to model symbolic expressions. We\ndevelop a framework to extract compact formulae from LIES networks by training\nwith an appropriate oversampling strategy and a tailored loss function to\npromote sparsity and to prevent gradient instability. After training, it\napplies additional pruning strategies to further simplify the learned\nexpressions into compact formulae. Our experiments on SR benchmarks show that\nthe LIES framework consistently produces sparse and accurate symbolic formulae\noutperforming all baselines. We also demonstrate the importance of each design\ncomponent through ablation studies.", "AI": {"tldr": "The paper introduces LIES, a new neural network architecture for symbolic regression that generates interpretable and compact mathematical expressions. It consistently outperforms baselines in producing sparse and accurate symbolic formulae.", "motivation": "Symbolic regression (SR) seeks to discover closed-form mathematical expressions describing data with interpretability. Current SR methods face challenges in scalability and symbolic consistency.", "method": "LIES is a fixed neural network architecture with interpretable primitive activations optimized for modeling symbolic expressions. A framework is developed to extract compact formulae from LIES networks using an oversampling strategy and tailored loss function. Additional pruning strategies simplify learned expressions into compact formulae.", "result": "Experiments on SR benchmarks show that the LIES framework consistently produces sparse and accurate symbolic formulae surpassing all baselines. Ablation studies demonstrate the importance of each design component.", "conclusion": "LIES offers a scalable and effective approach for symbolic regression, generating interpretable and compact mathematical expressions."}}
{"id": "2506.00160", "pdf": "https://arxiv.org/pdf/2506.00160", "abs": "https://arxiv.org/abs/2506.00160", "authors": ["Qihui Fan", "Enfu Nan", "Wenbo Li", "Lei Lu", "Pu Zhao", "Yanzhi Wang"], "title": "Werewolf: A Straightforward Game Framework with TTS for Improved User Engagement", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The growing popularity of social deduction game systems for both business\napplications and AI research has greatly benefited from the rapid advancements\nin Large Language Models (LLMs), which now demonstrate stronger reasoning and\npersuasion capabilities. Especially with the raise of DeepSeek R1 and V3\nmodels, LLMs should enable a more engaging experience for human players in\nLLM-agent-based social deduction games like Werewolf. Previous works either\nfine-tuning, advanced prompting engineering, or additional experience pool to\nachieve engaging text-format Werewolf game experience. We propose a novel yet\nstraightforward LLM-based Werewolf game system with tuned Text-to-Speech(TTS)\nmodels designed for enhanced compatibility with various LLM models, and\nimproved user engagement. We argue with ever enhancing LLM reasoning, extra\ncomponents will be unnecessary in the case of Werewolf.", "AI": {"tldr": "The paper presents a new LLM-based Werewolf game system with tuned TTS models for better user engagement, arguing that with improving LLM reasoning, extra components may be unnecessary.", "motivation": "To create a more engaging experience for human players in LLM-agent-based social deduction games like Werewolf by leveraging advancements in LLMs.", "method": "Proposing a novel LLM-based Werewolf game system with tuned Text-to-Speech (TTS) models to improve compatibility with various LLM models and enhance user engagement.", "result": "Argues that as LLM reasoning improves, additional components such as fine-tuning or advanced prompting engineering may become unnecessary for creating an engaging Werewolf game experience.", "conclusion": "A straightforward LLM-based Werewolf game system with tuned TTS models can provide an enhanced and engaging experience without the need for extra components."}}
{"id": "2506.08270", "pdf": "https://arxiv.org/pdf/2506.08270", "abs": "https://arxiv.org/abs/2506.08270", "authors": ["Zitong Huang", "Mansooreh Montazerin", "Ajitesh Srivastava"], "title": "SWAT-NN: Simultaneous Weights and Architecture Training for Neural Networks in a Latent Space", "categories": ["cs.LG"], "comment": null, "summary": "Designing neural networks typically relies on manual trial and error or a\nneural architecture search (NAS) followed by weight training. The former is\ntime-consuming and labor-intensive, while the latter often discretizes\narchitecture search and weight optimization. In this paper, we propose a\nfundamentally different approach that simultaneously optimizes both the\narchitecture and the weights of a neural network. Our framework first trains a\nuniversal multi-scale autoencoder that embeds both architectural and parametric\ninformation into a continuous latent space, where functionally similar neural\nnetworks are mapped closer together. Given a dataset, we then randomly\ninitialize a point in the embedding space and update it via gradient descent to\nobtain the optimal neural network, jointly optimizing its structure and\nweights. The optimization process incorporates sparsity and compactness\npenalties to promote efficient models. Experiments on synthetic regression\ntasks demonstrate that our method effectively discovers sparse and compact\nneural networks with strong performance.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540c\u65f6\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u548c\u6743\u91cd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\u5d4c\u5165\u67b6\u6784\u4e0e\u53c2\u6570\u4fe1\u606f\u81f3\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\uff0c\u5e76\u5229\u7528\u7a00\u758f\u6027\u548c\u7d27\u51d1\u6027\u60e9\u7f5a\u6765\u4fc3\u8fdb\u9ad8\u6548\u6a21\u578b\u3002\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u53d1\u73b0\u5177\u6709\u5f3a\u5927\u6027\u80fd\u7684\u7a00\u758f\u7d27\u51d1\u578b\u795e\u7ecf\u7f51\u7edc\u3002", "motivation": "\u76ee\u524d\u8bbe\u8ba1\u795e\u7ecf\u7f51\u7edc\u4f9d\u8d56\u4e8e\u624b\u52a8\u8bd5\u9519\u6216\u795e\u7ecf\u67b6\u6784\u641c\u7d22\uff08NAS\uff09\u52a0\u4e0a\u6743\u91cd\u8bad\u7ec3\uff0c\u524d\u8005\u8017\u65f6\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u540e\u8005\u5e38\u5c06\u67b6\u6784\u641c\u7d22\u4e0e\u6743\u91cd\u4f18\u5316\u5206\u79bb\u3002", "method": "\u9996\u5148\u8bad\u7ec3\u4e00\u4e2a\u901a\u7528\u7684\u591a\u5c3a\u5ea6\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5c06\u67b6\u6784\u548c\u53c2\u6570\u4fe1\u606f\u5d4c\u5165\u5230\u8fde\u7eed\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u529f\u80fd\u76f8\u4f3c\u7684\u795e\u7ecf\u7f51\u7edc\u5728\u8be5\u7a7a\u95f4\u4e2d\u6620\u5c04\u5f97\u66f4\u63a5\u8fd1\u3002\u7136\u540e\u5728\u7ed9\u5b9a\u6570\u636e\u96c6\u4e0a\uff0c\u968f\u673a\u521d\u59cb\u5316\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u70b9\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u8be5\u70b9\u4ee5\u83b7\u5f97\u6700\u4f18\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6\u4f18\u5316\u5176\u7ed3\u6784\u548c\u6743\u91cd\u3002\u4f18\u5316\u8fc7\u7a0b\u4e2d\u52a0\u5165\u7a00\u758f\u6027\u548c\u7d27\u51d1\u6027\u60e9\u7f5a\u4ee5\u4fc3\u8fdb\u9ad8\u6548\u6a21\u578b\u3002", "result": "\u5728\u5408\u6210\u56de\u5f52\u4efb\u52a1\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u53d1\u73b0\u7a00\u758f\u548c\u7d27\u51d1\u7684\u795e\u7ecf\u7f51\u7edc\uff0c\u8fd9\u4e9b\u7f51\u7edc\u5177\u6709\u5f3a\u5927\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u53ef\u4ee5\u540c\u65f6\u4f18\u5316\u795e\u7ecf\u7f51\u7edc\u7684\u7ed3\u6784\u548c\u6743\u91cd\uff0c\u751f\u6210\u9ad8\u6548\u7684\u7a00\u758f\u548c\u7d27\u51d1\u578b\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u5408\u6210\u56de\u5f52\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.04760", "pdf": "https://arxiv.org/pdf/2506.04760", "abs": "https://arxiv.org/abs/2506.04760", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Exp4Fuse: A Rank Fusion Framework for Enhanced Sparse Retrieval using Large Language Model-based Query Expansion", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) have shown potential in generating hypothetical\ndocuments for query expansion, thereby enhancing information retrieval\nperformance. However, the efficacy of this method is highly dependent on the\nquality of the generated documents, which often requires complex prompt\nstrategies and the integration of advanced dense retrieval techniques. This can\nbe both costly and computationally intensive. To mitigate these limitations, we\nexplore the use of zero-shot LLM-based query expansion to improve sparse\nretrieval, particularly for learned sparse retrievers. We introduce a novel\nfusion ranking framework, Exp4Fuse, which enhances the performance of sparse\nretrievers through an indirect application of zero-shot LLM-based query\nexpansion. Exp4Fuse operates by simultaneously considering two retrieval\nroutes-one based on the original query and the other on the LLM-augmented\nquery. It then generates two ranked lists using a sparse retriever and fuses\nthem using a modified reciprocal rank fusion method. We conduct extensive\nevaluations of Exp4Fuse against leading LLM-based query expansion methods and\nadvanced retrieval techniques on three MS MARCO-related datasets and seven\nlow-resource datasets. Experimental results reveal that Exp4Fuse not only\nsurpasses existing LLM-based query expansion methods in enhancing sparse\nretrievers but also, when combined with advanced sparse retrievers, achieves\nSOTA results on several benchmarks. This highlights the superior performance\nand effectiveness of Exp4Fuse in improving query expansion for sparse\nretrieval.", "AI": {"tldr": "Exp4Fuse\u662f\u4e00\u79cd\u65b0\u7684\u878d\u5408\u6392\u540d\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u6837\u672cLLM\u67e5\u8be2\u6269\u5c55\u63d0\u5347\u7a00\u758f\u68c0\u7d22\u6027\u80fd\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u7528\u4e8e\u67e5\u8be2\u6269\u5c55\u7684\u5047\u8bbe\u6587\u6863\u65b9\u9762\u663e\u793a\u51fa\u6f5c\u529b\uff0c\u4f46\u5176\u6548\u679c\u9ad8\u5ea6\u4f9d\u8d56\u4e8e\u751f\u6210\u6587\u6863\u7684\u8d28\u91cf\uff0c\u5e76\u4e14\u9700\u8981\u590d\u6742\u7684\u63d0\u793a\u7b56\u7565\u548c\u9ad8\u7ea7\u5bc6\u96c6\u68c0\u7d22\u6280\u672f\uff0c\u8fd9\u65e2\u6602\u8d35\u53c8\u8ba1\u7b97\u5bc6\u96c6\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u63a2\u7d22\u4e86\u96f6\u6837\u672cLLM\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\u4ee5\u6539\u5584\u7a00\u758f\u68c0\u7d22\uff0c\u7279\u522b\u662f\u5bf9\u4e8e\u5b66\u4e60\u578b\u7a00\u758f\u68c0\u7d22\u5668\u3002", "method": "\u5f15\u5165\u4e86\u540d\u4e3aExp4Fuse\u7684\u65b0\u9896\u878d\u5408\u6392\u540d\u6846\u67b6\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u95f4\u63a5\u5e94\u7528\u96f6\u6837\u672cLLM\u67e5\u8be2\u6269\u5c55\u6765\u589e\u5f3a\u7a00\u758f\u68c0\u7d22\u5668\u7684\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0cExp4Fuse\u540c\u65f6\u8003\u8651\u4e24\u4e2a\u68c0\u7d22\u8def\u5f84\uff1a\u4e00\u4e2a\u57fa\u4e8e\u539f\u59cb\u67e5\u8be2\uff0c\u53e6\u4e00\u4e2a\u57fa\u4e8eLLM\u589e\u5f3a\u67e5\u8be2\u3002\u7136\u540e\u4f7f\u7528\u7a00\u758f\u68c0\u7d22\u5668\u751f\u6210\u4e24\u4e2a\u6392\u5e8f\u5217\u8868\uff0c\u5e76\u4f7f\u7528\u4fee\u6539\u540e\u7684\u4e92\u60e0\u7b49\u7ea7\u878d\u5408\u65b9\u6cd5\u5c06\u5b83\u4eec\u878d\u5408\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cExp4Fuse\u4e0d\u4ec5\u8d85\u8d8a\u4e86\u73b0\u6709\u7684\u57fa\u4e8eLLM\u7684\u67e5\u8be2\u6269\u5c55\u65b9\u6cd5\u4ee5\u589e\u5f3a\u7a00\u758f\u68c0\u7d22\u5668\uff0c\u800c\u4e14\u5f53\u4e0e\u5148\u8fdb\u7684\u7a00\u758f\u68c0\u7d22\u5668\u7ed3\u5408\u65f6\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\uff08SOTA\uff09\u7684\u7ed3\u679c\u3002", "conclusion": "Exp4Fuse\u5c55\u793a\u4e86\u5353\u8d8a\u7684\u6027\u80fd\u548c\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u6539\u5584\u7a00\u758f\u68c0\u7d22\u4e2d\u7684\u67e5\u8be2\u6269\u5c55\u3002"}}
{"id": "2506.08272", "pdf": "https://arxiv.org/pdf/2506.08272", "abs": "https://arxiv.org/abs/2506.08272", "authors": ["Tarushri N. S."], "title": "Universal Differential Equations for Scientific Machine Learning of Node-Wise Battery Dynamics in Smart Grids", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Universal Differential Equations (UDEs), which blend neural networks with\nphysical differential equations, have emerged as a powerful framework for\nscientific machine learning (SciML), enabling data-efficient, interpretable,\nand physically consistent modeling. In the context of smart grid systems,\nmodeling node-wise battery dynamics remains a challenge due to the\nstochasticity of solar input and variability in household load profiles.\nTraditional approaches often struggle with generalization and fail to capture\nunmodeled residual dynamics. This work proposes a UDE-based approach to learn\nnode-specific battery evolution by embedding a neural residual into a\nphysically inspired battery ODE. Synthetic yet realistic solar generation and\nload demand data are used to simulate battery dynamics over time. The neural\ncomponent learns to model unobserved or stochastic corrections arising from\nheterogeneity in node demand and environmental conditions. Comprehensive\nexperiments reveal that the trained UDE aligns closely with ground truth\nbattery trajectories, exhibits smooth convergence behavior, and maintains\nstability in long-term forecasts. These findings affirm the viability of\nUDE-based SciML approaches for battery modeling in decentralized energy\nnetworks and suggest broader implications for real-time control and\noptimization in renewable-integrated smart grids.", "AI": {"tldr": "This paper proposes a UDE-based approach to learn node-specific battery evolution by embedding a neural residual into a physically inspired battery ODE in smart grid systems.", "motivation": "Modeling node-wise battery dynamics remains a challenge due to the stochasticity of solar input and variability in household load profiles. Traditional approaches often struggle with generalization and fail to capture unmodeled residual dynamics.", "method": "The work proposes a Universal Differential Equations (UDEs) based approach which blends neural networks with physical differential equations for scientific machine learning (SciML). A neural residual is embedded into a physically inspired battery ODE to model unobserved or stochastic corrections arising from heterogeneity in node demand and environmental conditions.", "result": "Comprehensive experiments reveal that the trained UDE aligns closely with ground truth battery trajectories, exhibits smooth convergence behavior, and maintains stability in long-term forecasts.", "conclusion": "The findings affirm the viability of UDE-based SciML approaches for battery modeling in decentralized energy networks and suggest broader implications for real-time control and optimization in renewable-integrated smart grids."}}
{"id": "2506.05695", "pdf": "https://arxiv.org/pdf/2506.05695", "abs": "https://arxiv.org/abs/2506.05695", "authors": ["Lingyuan Liu", "Mengxiang Zhang"], "title": "Being Strong Progressively! Enhancing Knowledge Distillation of Large Language Models through a Curriculum Learning Framework", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Knowledge Distillation (KD) compresses large language models (LLMs) by\ntransferring the teacher model's capabilities to a smaller student model,\nreducing inference cost and memory usage while maintaining performance.\nHowever, existing KD methods for LLMs often fail to prevent significant shifts\nin the student model's distribution during training, leading to issues such as\ncatastrophic forgetting, mode collapse, and training-inference mismatch. To\naddress these challenges, we propose a novel, plug-in curriculum learning\nframework inspired by the strength training principle of \"progressive overload\"\n(POCL), which can be seamlessly integrated into existing white-box KD\napproaches with minimal computational overhead. The framework comprises two\ncore components: (1) a difficulty measurer that ranks and partitions training\nsamples from easy to hard, and (2) a training scheduler that incrementally\nintroduces these subsets into the distillation process at fixed intervals while\napplying loss functions with progressively rising temperatures. By starting\nwith the easiest samples and progressively increasing the difficulty, the\napproach enhances both the stability and efficiency of learning. Extensive\nexperiments in instruction-following settings demonstrate that POCL\nconsistently improves the performance of distilled student models across\nvarious white-box KD methods and model families. Our findings highlight the\neffectiveness of sorted training samples in KD for LLMs. More generally, our\nwork demonstrates how to structure training data within the KD process to\nenhance the stability and performance of distilled LLMs.", "AI": {"tldr": "The paper proposes a novel curriculum learning framework called POCL for Knowledge Distillation of large language models, which enhances stability and efficiency in training student models.", "motivation": "Existing KD methods for LLMs often fail to prevent significant shifts in the student model's distribution during training, leading to catastrophic forgetting, mode collapse, and training-inference mismatch.", "method": "The framework comprises two core components: (1) a difficulty measurer that ranks and partitions training samples from easy to hard, and (2) a training scheduler that incrementally introduces these subsets into the distillation process at fixed intervals while applying loss functions with progressively rising temperatures.", "result": "Extensive experiments in instruction-following settings demonstrate that POCL consistently improves the performance of distilled student models across various white-box KD methods and model families.", "conclusion": "The findings highlight the effectiveness of sorted training samples in KD for LLMs and demonstrate how to structure training data within the KD process to enhance the stability and performance of distilled LLMs."}}
{"id": "2506.08274", "pdf": "https://arxiv.org/pdf/2506.08274", "abs": "https://arxiv.org/abs/2506.08274", "authors": ["Jo\u00e3o Manoel Herrera Pinheiro", "Suzana Vilas Boas de Oliveira", "Thiago Henrique Segreto Silva", "Pedro Antonio Rabelo Saraiva", "Enzo Ferreira de Souza", "Leonardo Andr\u00e9 Ambrosio", "Marcelo Becker"], "title": "The Impact of Feature Scaling In Machine Learning: Effects on Regression and Classification Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "27 pages", "summary": "This research addresses the critical lack of comprehensive studies on feature\nscaling by systematically evaluating 12 scaling techniques - including several\nless common transformations - across 14 different Machine Learning algorithms\nand 16 datasets for classification and regression tasks. We meticulously\nanalyzed impacts on predictive performance (using metrics such as accuracy,\nMAE, MSE, and $R^2$) and computational costs (training time, inference time,\nand memory usage). Key findings reveal that while ensemble methods (such as\nRandom Forest and gradient boosting models like XGBoost, CatBoost and LightGBM)\ndemonstrate robust performance largely independent of scaling, other widely\nused models such as Logistic Regression, SVMs, TabNet, and MLPs show\nsignificant performance variations highly dependent on the chosen scaler. This\nextensive empirical analysis, with all source code, experimental results, and\nmodel parameters made publicly available to ensure complete transparency and\nreproducibility, offers model-specific crucial guidance to practitioners on the\nneed for an optimal selection of feature scaling techniques.", "AI": {"tldr": "This research systematically evaluates 12 feature scaling techniques across 14 ML algorithms and 16 datasets, providing model-specific guidance on optimal scaling methods.", "motivation": "To address the lack of comprehensive studies on feature scaling in machine learning models and provide practitioners with crucial guidance for optimal selection of scaling techniques.", "method": "Systematically evaluate 12 scaling techniques across 14 different ML algorithms and 16 datasets for classification and regression tasks. Analyze impacts on predictive performance (accuracy, MAE, MSE, $R^2$) and computational costs (training time, inference time, memory usage).", "result": "Ensemble methods like Random Forest and gradient boosting models show robust performance largely independent of scaling. Other models such as Logistic Regression, SVMs, TabNet, and MLPs demonstrate significant performance variations highly dependent on the chosen scaler.", "conclusion": "The study offers model-specific guidance to practitioners regarding the necessity of selecting optimal feature scaling techniques."}}
{"id": "2506.06363", "pdf": "https://arxiv.org/pdf/2506.06363", "abs": "https://arxiv.org/abs/2506.06363", "authors": ["Thang D. Pham", "Aditya Tanikanti", "Murat Ke\u00e7eli"], "title": "ChemGraph: An Agentic Framework for Computational Chemistry Workflows", "categories": ["physics.chem-ph", "cond-mat.mtrl-sci", "cs.AI", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "Atomistic simulations are essential tools in chemistry and materials science,\naccelerating the discovery of novel catalysts, energy storage materials, and\npharmaceuticals. However, running these simulations remains challenging due to\nthe wide range of computational methods, diverse software ecosystems, and the\nneed for expert knowledge and manual effort for the setup, execution, and\nvalidation stages. In this work, we present ChemGraph, an agentic framework\npowered by artificial intelligence and state-of-the-art simulation tools to\nstreamline and automate computational chemistry and materials science\nworkflows. ChemGraph leverages graph neural network-based foundation models for\naccurate yet computationally efficient calculations and large language models\n(LLMs) for natural language understanding, task planning, and scientific\nreasoning to provide an intuitive and interactive interface. Users can perform\ntasks such as molecular structure generation, single-point energy, geometry\noptimization, vibrational analysis, and thermochemistry calculations with\nmethods ranging from tight-binding and machine learning interatomic potentials\nto density functional theory or wave function theory-based methods. We evaluate\nChemGraph across 13 benchmark tasks and demonstrate that smaller LLMs\n(GPT-4o-mini, Claude-3.5-haiku, Qwen2.5-14B) perform well on simple workflows,\nwhile more complex tasks benefit from using larger models like GPT-4o.\nImportantly, we show that decomposing complex tasks into smaller subtasks\nthrough a multi-agent framework enables smaller LLM models to match or exceed\nGPT-4o's performance in specific scenarios.", "AI": {"tldr": "ChemGraph is an AI-powered framework that automates computational chemistry workflows using graph neural networks and language models, showing strong performance across 13 benchmark tasks with different model sizes.", "motivation": "To address the challenges in running atomistic simulations due to diverse methods, software ecosystems, and the need for expert knowledge, streamlining and automating computational chemistry workflows is necessary.", "method": "ChemGraph uses graph neural network-based foundation models for efficient calculations and large language models for natural language understanding, task planning, and scientific reasoning. It supports various simulation methods and can handle tasks like molecular structure generation, energy calculation, geometry optimization, etc.", "result": "ChemGraph performs well on 13 benchmark tasks. Smaller LLMs are sufficient for simple workflows, while complex tasks benefit from larger models. Decomposing complex tasks into subtasks via a multi-agent framework allows smaller LLMs to match or exceed GPT-4o's performance in certain scenarios.", "conclusion": "ChemGraph successfully automates computational chemistry workflows, demonstrating the effectiveness of combining AI and state-of-the-art simulation tools."}}
{"id": "2506.08292", "pdf": "https://arxiv.org/pdf/2506.08292", "abs": "https://arxiv.org/abs/2506.08292", "authors": ["Xie Yi", "Zhanke Zhou", "Chentao Cao", "Qiyu Niu", "Tongliang Liu", "Bo Han"], "title": "From Debate to Equilibrium: Belief-Driven Multi-Agent LLM Reasoning via Bayesian Nash Equilibrium", "categories": ["cs.LG", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "Multi-agent frameworks can substantially boost the reasoning power of large\nlanguage models (LLMs), but they typically incur heavy computational costs and\nlack convergence guarantees. To overcome these challenges, we recast multi-LLM\ncoordination as an incomplete-information game and seek a Bayesian Nash\nequilibrium (BNE), in which each agent optimally responds to its probabilistic\nbeliefs about the strategies of others. We introduce Efficient Coordination via\nNash Equilibrium (ECON), a hierarchical reinforcement-learning paradigm that\nmarries distributed reasoning with centralized final output. Under ECON, each\nLLM independently selects responses that maximize its expected reward,\nconditioned on its beliefs about co-agents, without requiring costly\ninter-agent exchanges. We mathematically prove that ECON attains a markedly\ntighter regret bound than non-equilibrium multi-agent schemes. Empirically,\nECON outperforms existing multi-LLM approaches by 11.2% on average across six\nbenchmarks spanning complex reasoning and planning tasks. Further experiments\ndemonstrate ECON's ability to flexibly incorporate additional models,\nconfirming its scalability and paving the way toward larger, more powerful\nmulti-LLM ensembles. The code is publicly available at:\nhttps://github.com/tmlr-group/ECON.", "AI": {"tldr": "The paper introduces ECON, a hierarchical reinforcement-learning paradigm that treats multi-LLM coordination as an incomplete-information game to find a Bayesian Nash equilibrium. It reduces computational costs and improves performance compared to other methods.", "motivation": "Multi-agent frameworks for large language models have significant reasoning power but suffer from high computational costs and lack convergence guarantees.", "method": "ECON recasts multi-LLM coordination as an incomplete-information game seeking a Bayesian Nash equilibrium. Each LLM independently selects responses maximizing its expected reward based on beliefs about co-agents without needing costly inter-agent exchanges.", "result": "ECON outperforms existing multi-LLM approaches by 11.2% on average across six benchmarks and demonstrates scalability by incorporating additional models.", "conclusion": "ECON is a promising approach for enhancing multi-LLM coordination with reduced computational costs and improved performance."}}
{"id": "2506.07675", "pdf": "https://arxiv.org/pdf/2506.07675", "abs": "https://arxiv.org/abs/2506.07675", "authors": ["Yuyang Song", "Hanxu Yan", "Jiale Lao", "Yibo Wang", "Yufei Li", "Yuanchun Zhou", "Jianguo Wang", "Mingjie Tang"], "title": "QUITE: A Query Rewrite System Beyond Rules with LLM Agents", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Query rewrite transforms SQL queries into semantically equivalent forms that\nrun more efficiently. Existing approaches mainly rely on predefined rewrite\nrules, but they handle a limited subset of queries and can cause performance\nregressions. This limitation stems from three challenges of rule-based query\nrewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite\nrules do not generalize to new query patterns, and (3) some rewrite techniques\ncannot be expressed as fixed rules. Motivated by the fact that human experts\nexhibit significantly better rewrite ability but suffer from scalability, and\nLarge Language Models (LLMs) have demonstrated nearly human-level semantic and\nreasoning abilities, we propose a new approach of using LLMs to rewrite SQL\nqueries beyond rules. Due to the hallucination problems in LLMs, directly\napplying LLMs often leads to nonequivalent and suboptimal queries. To address\nthis issue, we propose QUITE (query rewrite), a training-free and\nfeedback-aware system based on LLM agents that rewrites SQL queries into\nsemantically equivalent forms with significantly better performance, covering a\nbroader range of query patterns and rewrite strategies compared to rule-based\nmethods. Firstly, we design a multi-agent framework controlled by a finite\nstate machine (FSM) to equip LLMs with the ability to use external tools and\nenhance the rewrite process with real-time database feedback. Secondly, we\ndevelop a rewrite middleware to enhance the ability of LLMs to generate\noptimized query equivalents. Finally, we employ a novel hint injection\ntechnique to improve execution plans for rewritten queries. Extensive\nexperiments show that QUITE reduces query execution time by up to 35.8% over\nstate-of-the-art approaches and produces 24.1% more rewrites than prior\nmethods, covering query cases that earlier systems did not handle.", "AI": {"tldr": "QUITE is a system leveraging LLMs to rewrite SQL queries into semantically equivalent forms with better performance, overcoming the limitations of rule-based methods.", "motivation": "Existing query rewrite methods relying on predefined rules are limited in discovering new rules, generalizing to new patterns, and expressing certain techniques. Human experts perform better but lack scalability, prompting the exploration of LLMs for this task.", "method": "A training-free, feedback-aware system called QUITE based on LLM agents is proposed. It includes a multi-agent framework controlled by a FSM for real-time database feedback, a rewrite middleware to generate optimized queries, and a hint injection technique to improve execution plans.", "result": "Experiments indicate that QUITE reduces query execution time by up to 35.8% compared to state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering previously unhandled query cases.", "conclusion": "QUITE successfully overcomes the limitations of rule-based query rewriting by utilizing LLMs, enhancing query performance across a broader range of patterns and strategies."}}
{"id": "2506.08295", "pdf": "https://arxiv.org/pdf/2506.08295", "abs": "https://arxiv.org/abs/2506.08295", "authors": ["Zhanke Zhou", "Xiao Feng", "Zhaocheng Zhu", "Jiangchao Yao", "Sanmi Koyejo", "Bo Han"], "title": "From Passive to Active Reasoning: Can Large Language Models Ask the Right Questions under Incomplete Information?", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by ICML 2025", "summary": "While existing benchmarks probe the reasoning abilities of large language\nmodels (LLMs) across diverse domains, they predominantly assess passive\nreasoning, providing models with all the information needed to reach a\nsolution. By contrast, active reasoning-where an LLM must interact with\nexternal systems to acquire missing evidence or data-has received little\nsystematic attention. To address this shortfall, we present AR-Bench, a novel\nbenchmark designed explicitly to evaluate an LLM's active reasoning skills.\nAR-Bench comprises three task families-detective cases, situation puzzles, and\nguessing numbers-that together simulate real-world, agentic scenarios and\nmeasure performance across commonsense, logical, and symbolic reasoning\nchallenges. Empirical evaluation on AR-Bench demonstrates that contemporary\nLLMs exhibit pronounced difficulties with active reasoning: they frequently\nfail to acquire or leverage the information needed to solve tasks. This gap\nhighlights a stark divergence between their passive and active reasoning\nabilities. Moreover, ablation studies indicate that even advanced strategies,\nsuch as tree-based searching or post-training approaches, yield only modest\ngains and fall short of the levels required for real-world deployment.\nCollectively, these findings highlight the critical need to advance methodology\nfor active reasoning, e.g., incorporating interactive learning, real-time\nfeedback loops, and environment-aware objectives for training. The benchmark is\npublicly available at: https://github.com/tmlr-group/AR-Bench.", "AI": {"tldr": "\u73b0\u6709\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u88ab\u52a8\u63a8\u7406\u80fd\u529b\uff0c\u800c\u4e3b\u52a8\u63a8\u7406\uff08\u9700\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u4ee5\u83b7\u53d6\u7f3a\u5931\u8bc1\u636e\u6216\u6570\u636e\uff09\u5374\u7f3a\u4e4f\u7cfb\u7edf\u5173\u6ce8\u3002\u4e3a\u5f25\u8865\u8fd9\u4e00\u4e0d\u8db3\uff0c\u672c\u6587\u63d0\u51fa\u4e86AR-Bench\uff0c\u4e00\u4e2a\u4e13\u95e8\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u52a8\u63a8\u7406\u6280\u80fd\u7684\u65b0\u57fa\u51c6\u3002\u5b83\u5305\u62ec\u4fa6\u63a2\u6848\u4f8b\u3001\u60c5\u5883\u8c1c\u9898\u548c\u731c\u6570\u5b57\u4e09\u4e2a\u4efb\u52a1\u5bb6\u65cf\uff0c\u6db5\u76d6\u5e38\u8bc6\u3001\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u6311\u6218\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u52a8\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u56f0\u96be\uff0c\u5373\u4f7f\u91c7\u7528\u5148\u8fdb\u7684\u7b56\u7565\u4e5f\u53ea\u80fd\u83b7\u5f97 modest \u6539\u5584\u3002\u7814\u7a76\u5f3a\u8c03\u4e86\u63a8\u8fdb\u4e3b\u52a8\u63a8\u7406\u65b9\u6cd5\u8bba\u7684\u91cd\u8981\u6027\uff0c\u4f8b\u5982\u7ed3\u5408\u4e92\u52a8\u5b66\u4e60\u3001\u5b9e\u65f6\u53cd\u9988\u56de\u8def\u548c\u73af\u5883\u611f\u77e5\u76ee\u6807\u8fdb\u884c\u8bad\u7ec3\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u6db5\u76d6\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u9886\u57df\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u5b83\u4eec\u4e3b\u8981\u96c6\u4e2d\u5728\u88ab\u52a8\u63a8\u7406\u4e0a\uff0c\u5373\u63d0\u4f9b\u6240\u6709\u89e3\u51b3\u95ee\u9898\u6240\u9700\u7684\u4fe1\u606f\u3002\u7136\u800c\uff0c\u4e3b\u52a8\u63a8\u7406\u2014\u2014\u9700\u8981\u5927\u8bed\u8a00\u6a21\u578b\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u4ee5\u83b7\u53d6\u7f3a\u5931\u8bc1\u636e\u6216\u6570\u636e\u2014\u2014\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u6027\u7814\u7a76\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u4e13\u95e8\u8bc4\u4f30\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u6765\u63ed\u793a\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u5e76\u63a8\u52a8\u76f8\u5173\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa AR-Bench\uff0c\u4e00\u4e2a\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4e3b\u52a8\u63a8\u7406\u6280\u80fd\u7684\u57fa\u51c6\u3002\u8be5\u57fa\u51c6\u5305\u542b\u4e09\u4e2a\u4efb\u52a1\u5bb6\u65cf\uff1a\u4fa6\u63a2\u6848\u4f8b\u3001\u60c5\u5883\u8c1c\u9898\u548c\u731c\u6570\u5b57\uff0c\u8fd9\u4e9b\u4efb\u52a1\u6a21\u62df\u73b0\u5b9e\u4e16\u754c\u573a\u666f\uff0c\u5e76\u8861\u91cf\u6a21\u578b\u5728\u5e38\u8bc6\u3001\u903b\u8f91\u548c\u7b26\u53f7\u63a8\u7406\u65b9\u9762\u7684\u8868\u73b0\u3002\u901a\u8fc7\u8ba9\u6a21\u578b\u4e0e\u5916\u90e8\u7cfb\u7edf\u4ea4\u4e92\u4ee5\u83b7\u53d6\u5fc5\u8981\u4fe1\u606f\uff0c\u8bc4\u4f30\u5176\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8fd8\u8fdb\u884c\u4e86\u6d88\u878d\u7814\u7a76\uff0c\u63a2\u8ba8\u6811\u641c\u7d22\u548c\u540e\u8bad\u7ec3\u7b49\u7b56\u7565\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5f53\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u52a8\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u5e38\u5e38\u65e0\u6cd5\u83b7\u53d6\u6216\u5229\u7528\u89e3\u51b3\u4efb\u52a1\u6240\u9700\u7684\u5fc5\u8981\u4fe1\u606f\u3002\u5373\u4f7f\u91c7\u7528\u9ad8\u7ea7\u7b56\u7565\uff08\u5982\u57fa\u4e8e\u6811\u7684\u641c\u7d22\u6216\u540e\u8bad\u7ec3\u65b9\u6cd5\uff09\uff0c\u4e5f\u4ec5\u80fd\u5e26\u6765\u6709\u9650\u7684\u6539\u8fdb\uff0c\u4ecd\u8fdc\u672a\u8fbe\u5230\u5b9e\u9645\u5e94\u7528\u7684\u8981\u6c42\u3002\u8fd9\u8868\u660e\u6a21\u578b\u5728\u4e3b\u52a8\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\u3002", "conclusion": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4e3b\u52a8\u63a8\u7406\u65b9\u9762\u7684\u80fd\u529b\u660e\u663e\u4e0d\u8db3\uff0c\u4e0e\u88ab\u52a8\u63a8\u7406\u80fd\u529b\u5f62\u6210\u9c9c\u660e\u5bf9\u6bd4\u3002\u4e3a\u4e86\u63d0\u5347\u4e3b\u52a8\u63a8\u7406\u80fd\u529b\uff0c\u672a\u6765\u7684\u7814\u7a76\u5e94\u7740\u91cd\u4e8e\u6539\u8fdb\u65b9\u6cd5\u8bba\uff0c\u4f8b\u5982\u5f15\u5165\u4e92\u52a8\u5b66\u4e60\u3001\u5b9e\u65f6\u53cd\u9988\u673a\u5236\u548c\u73af\u5883\u611f\u77e5\u76ee\u6807\u3002AR-Bench \u7684\u53d1\u5e03\u4e3a\u8fd9\u4e00\u9886\u57df\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u8bc4\u4f30\u5de5\u5177\uff0c\u516c\u5f00\u5730\u5740\u4e3a https://github.com/tmlr-group/AR-Bench\u3002"}}
{"id": "2506.08298", "pdf": "https://arxiv.org/pdf/2506.08298", "abs": "https://arxiv.org/abs/2506.08298", "authors": ["Trung-Kien Nguyen", "Heng Ping", "Shixuan Li", "Peiyu Zhang", "Nikos Kanakaris", "Nicholas Kotov", "Paul Bogdan"], "title": "H$^2$GFM: Towards unifying Homogeneity and Heterogeneity on Text-Attributed Graphs", "categories": ["cs.LG", "cs.SI"], "comment": null, "summary": "The growing interests and applications of graph learning in diverse domains\nhave propelled the development of a unified model generalizing well across\ndifferent graphs and tasks, known as the Graph Foundation Model (GFM). Existing\nresearch has leveraged text-attributed graphs (TAGs) to tackle the\nheterogeneity in node features among graphs. However, they primarily focus on\nhomogeneous TAGs (HoTAGs), leaving heterogeneous TAGs (HeTAGs), where multiple\ntypes of nodes/edges reside, underexplored. To enhance the capabilities and\napplications of GFM, we introduce H$^2$GFM, a novel framework designed to\ngeneralize across both HoTAGs and HeTAGs. Our model projects diverse\nmeta-relations among graphs under a unified textual space, and employs a\ncontext encoding to capture spatial and higher-order semantic relationships. To\nachieve robust node representations, we propose a novel context-adaptive graph\ntransformer (CGT), effectively capturing information from both context\nneighbors and their relationships. Furthermore, we employ a mixture of CGT\nexperts to capture the heterogeneity in structural patterns among graph types.\nComprehensive experiments on a wide range of HoTAGs and HeTAGs as well as\nlearning scenarios demonstrate the effectiveness of our model.", "AI": {"tldr": "H$^2$GFM is a novel framework that generalizes across both homogeneous and heterogeneous text-attributed graphs by employing context encoding, context-adaptive graph transformer (CGT), and a mixture of CGT experts.", "motivation": "Existing research on graph foundation model (GFM) mainly focuses on homogeneous text-attributed graphs (HoTAGs), while the potential of handling heterogeneous TAGs (HeTAGs) remains underexplored.", "method": "The H$^2$GFM framework projects diverse meta-relations among graphs into a unified textual space and uses context encoding to capture spatial and higher-order semantic relationships. A context-adaptive graph transformer (CGT) is proposed to capture robust node representations from context neighbors and their relationships. Additionally, a mixture of CGT experts is employed to capture structural pattern heterogeneity among graph types.", "result": "Comprehensive experiments on various HoTAGs and HeTAGs as well as learning scenarios show the effectiveness of the H$^2$GFM model.", "conclusion": "H$^2$GFM successfully generalizes across both homogeneous and heterogeneous text-attributed graphs, providing enhanced capabilities and applications for graph foundation models."}}
{"id": "2506.08309", "pdf": "https://arxiv.org/pdf/2506.08309", "abs": "https://arxiv.org/abs/2506.08309", "authors": ["Katherine Tieu", "Dongqi Fu", "Zihao Li", "Ross Maciejewski", "Jingrui He"], "title": "Learnable Spatial-Temporal Positional Encoding for Link Prediction", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by ICML 2025. 28 pages, 1 figures, 22 tables", "summary": "Accurate predictions rely on the expressiveness power of graph deep learning\nframeworks like graph neural networks and graph transformers, where a\npositional encoding mechanism has become much more indispensable in recent\nstate-of-the-art works to record the canonical position information. However,\nthe current positional encoding is limited in three aspects: (1) most\npositional encoding methods use pre-defined, and fixed functions, which are\ninadequate to adapt to the complex attributed graphs; (2) a few pioneering\nworks proposed the learnable positional encoding but are still limited to the\nstructural information, not considering the real-world time-evolving\ntopological and feature information; (3) most positional encoding methods are\nequipped with transformers' attention mechanism to fully leverage their\ncapabilities, where the dense or relational attention is often unaffordable on\nlarge-scale structured data. Hence, we aim to develop Learnable\nSpatial-Temporal Positional Encoding in an effective and efficient manner and\npropose a simple temporal link prediction model named L-STEP. Briefly, for\nL-STEP, we (1) prove the proposed positional learning scheme can preserve the\ngraph property from the spatial-temporal spectral viewpoint, (2) verify that\nMLPs can fully exploit the expressiveness and reach transformers' performance\non that encoding, (3) change different initial positional encoding inputs to\nshow robustness, (4) analyze the theoretical complexity and obtain less\nempirical running time than SOTA, and (5) demonstrate its temporal link\nprediction out-performance on 13 classic datasets and with 10 algorithms in\nboth transductive and inductive settings using 3 different sampling strategies.\nAlso, \\name\\ obtains the leading performance in the newest large-scale TGB\nbenchmark. Our code is available at https://github.com/kthrn22/L-STEP.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u5b66\u4e60\u7684\u7a7a\u95f4-\u65f6\u95f4\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\uff08L-STEP\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4f4d\u7f6e\u7f16\u7801\u5728\u590d\u6742\u56fe\u6570\u636e\u4e0a\u7684\u4e0d\u8db3\uff0c\u540c\u65f6\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\u3002", "motivation": "\u5f53\u524d\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u5b58\u5728\u4e09\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a(1) \u5927\u591a\u6570\u65b9\u6cd5\u4f7f\u7528\u9884\u5b9a\u4e49\u548c\u56fa\u5b9a\u7684\u51fd\u6570\uff0c\u96be\u4ee5\u9002\u5e94\u590d\u6742\u7684\u5c5e\u6027\u56fe\uff1b(2) \u5c11\u6570\u53ef\u5b66\u4e60\u7684\u4f4d\u7f6e\u7f16\u7801\u4ec5\u9650\u4e8e\u7ed3\u6784\u4fe1\u606f\uff0c\u672a\u8003\u8651\u65f6\u53d8\u7684\u62d3\u6251\u548c\u7279\u5f81\u4fe1\u606f\uff1b(3) \u5728\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u4e0a\uff0c\u5bc6\u96c6\u6216\u5173\u7cfb\u6ce8\u610f\u529b\u673a\u5236\u901a\u5e38\u4e0d\u53ef\u884c\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u4e14\u9ad8\u6548\u7684\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u5f00\u53d1\u4e86Learnable Spatial-Temporal Positional Encoding (L-STEP)\uff0c\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u5b9e\u73b0\uff1a(1) \u4ece\u7a7a\u95f4-\u65f6\u95f4\u8c31\u89d2\u5ea6\u8bc1\u660e\u6240\u63d0\u51fa\u7684\u7f16\u7801\u65b9\u6848\u53ef\u4ee5\u4fdd\u7559\u56fe\u7684\u6027\u8d28\uff1b(2) \u9a8c\u8bc1MLP\u80fd\u591f\u5145\u5206\u5229\u7528\u8868\u8fbe\u80fd\u529b\uff0c\u5e76\u8fbe\u5230\u4e0eTransformer\u76f8\u5f53\u7684\u6027\u80fd\uff1b(3) \u6d4b\u8bd5\u4e0d\u540c\u521d\u59cb\u4f4d\u7f6e\u7f16\u7801\u8f93\u5165\u4ee5\u5c55\u793a\u9c81\u68d2\u6027\uff1b(4) \u5206\u6790\u7406\u8bba\u590d\u6742\u5ea6\u5e76\u83b7\u5f97\u6bd4SOTA\u66f4\u5c11\u7684\u7ecf\u9a8c\u8fd0\u884c\u65f6\u95f4\uff1b(5) \u572813\u4e2a\u7ecf\u5178\u6570\u636e\u96c6\u300110\u79cd\u7b97\u6cd5\u4ee5\u53ca\u4e0d\u540c\u7684\u91c7\u6837\u7b56\u7565\u4e0b\u9a8c\u8bc1\u5176\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\u3002", "result": "L-STEP\u572813\u4e2a\u7ecf\u5178\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u4f18\u4e8e10\u79cd\u7b97\u6cd5\u7684\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\u6027\u80fd\uff0c\u5728\u8f6c\u5bfc\u548c\u5f52\u7eb3\u8bbe\u7f6e\u4e2d\u5747\u8868\u73b0\u826f\u597d\u3002\u6b64\u5916\uff0c\u5728\u6700\u65b0\u7684\u5927\u89c4\u6a21TGB\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cL-STEP\u4e5f\u53d6\u5f97\u4e86\u9886\u5148\u6027\u80fd\u3002", "conclusion": "L-STEP\u662f\u4e00\u79cd\u7b80\u5355\u800c\u6709\u6548\u7684\u6a21\u578b\uff0c\u80fd\u591f\u5728\u5927\u89c4\u6a21\u7ed3\u6784\u5316\u6570\u636e\u4e0a\u8fdb\u884c\u9ad8\u6548\u7684\u65f6\u5e8f\u94fe\u63a5\u9884\u6d4b\uff0c\u540c\u65f6\u4fdd\u7559\u56fe\u7684\u6027\u8d28\u5e76\u5177\u6709\u8f83\u4f4e\u7684\u8fd0\u884c\u65f6\u95f4\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.08023", "pdf": "https://arxiv.org/pdf/2506.08023", "abs": "https://arxiv.org/abs/2506.08023", "authors": ["Qifeng Wu", "Zhengzhe Liu", "Han Zhu", "Yizhou Zhao", "Daisuke Kihara", "Min Xu"], "title": "Aligning Proteins and Language: A Foundation Model for Protein Retrieval", "categories": ["q-bio.BM", "cs.AI", "cs.CE", "cs.CV", "cs.LG"], "comment": "4 pages for body, 3 pages for appendix, 11 figures. Accepted to CVPR\n  2025 Workshop on Multimodal Foundation Models for Biomedicine: Challenges and\n  Opportunities(MMFM-BIOMED)", "summary": "This paper aims to retrieve proteins with similar structures and semantics\nfrom large-scale protein dataset, facilitating the functional interpretation of\nprotein structures derived by structural determination methods like\ncryo-Electron Microscopy (cryo-EM). Motivated by the recent progress of\nvision-language models (VLMs), we propose a CLIP-style framework for aligning\n3D protein structures with functional annotations using contrastive learning.\nFor model training, we propose a large-scale dataset of approximately 200,000\nprotein-caption pairs with rich functional descriptors. We evaluate our model\nin both in-domain and more challenging cross-database retrieval on Protein Data\nBank (PDB) and Electron Microscopy Data Bank (EMDB) dataset, respectively. In\nboth cases, our approach demonstrates promising zero-shot retrieval\nperformance, highlighting the potential of multimodal foundation models for\nstructure-function understanding in protein biology.", "AI": {"tldr": "This paper aims to retrieve proteins with similar structures and semantics from large-scale protein dataset using a CLIP-style framework, demonstrating promising zero-shot retrieval performance.", "motivation": "Motivated by the recent progress of vision-language models (VLMs).", "method": "Propose a CLIP-style framework for aligning 3D protein structures with functional annotations using contrastive learning, and a large-scale dataset of approximately 200,000 protein-caption pairs for model training.", "result": "Demonstrates promising zero-shot retrieval performance in both in-domain and cross-database retrieval on Protein Data Bank (PDB) and Electron Microscopy Data Bank (EMDB) dataset.", "conclusion": "Highlights the potential of multimodal foundation models for structure-function understanding in protein biology."}}
{"id": "2506.08316", "pdf": "https://arxiv.org/pdf/2506.08316", "abs": "https://arxiv.org/abs/2506.08316", "authors": ["Alan N. Amin", "Nate Gruver", "Andrew Gordon Wilson"], "title": "Why Masking Diffusion Works: Condition on the Jump Schedule for Improved Discrete Diffusion", "categories": ["cs.LG", "stat.ML"], "comment": "Code available at: https://github.com/AlanNawzadAmin/SCUD", "summary": "Discrete diffusion models, like continuous diffusion models, generate\nhigh-quality samples by gradually undoing noise applied to datapoints with a\nMarkov process. Gradual generation in theory comes with many conceptual\nbenefits; for example, inductive biases can be incorporated into the noising\nMarkov process, and access to improved sampling algorithms. In practice,\nhowever, the consistently best performing discrete diffusion model is,\nsurprisingly, masking diffusion, which does not denoise gradually. Here we\nexplain the superior performance of masking diffusion by noting that it makes\nuse of a fundamental difference between continuous and discrete Markov\nprocesses: discrete Markov processes evolve by discontinuous jumps at a fixed\nrate and, unlike other discrete diffusion models, masking diffusion builds in\nthe known distribution of jump times and only learns where to jump to. We show\nthat we can similarly bake in the known distribution of jump times into any\ndiscrete diffusion model. The resulting models - schedule-conditioned discrete\ndiffusion (SCUD) - generalize classical discrete diffusion and masking\ndiffusion. By applying SCUD to models with noising processes that incorporate\ninductive biases on images, text, and protein data, we build models that\noutperform masking.", "AI": {"tldr": "\u5728\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\uff0cmasking diffusion\u8868\u73b0\u4f18\u5f02\u7684\u539f\u56e0\u5728\u4e8e\u5b83\u5229\u7528\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u672c\u8d28\u7279\u6027\u3002\u57fa\u4e8e\u6b64\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u901a\u7528\u7684SCUD\u6a21\u578b\uff0c\u8d85\u8d8a\u4e86\u4f20\u7edf\u7684masking diffusion\uff0c\u5728\u56fe\u50cf\u3001\u6587\u672c\u548c\u86cb\u767d\u8d28\u6570\u636e\u4e0a\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u9010\u6b65\u751f\u6210\u7406\u8bba\u4e0a\u5177\u6709\u8bb8\u591a\u6982\u5ff5\u4f18\u52bf\uff0c\u4f46\u5728\u79bb\u6563\u6269\u6563\u6a21\u578b\u4e2d\uff0c\u8868\u73b0\u6700\u4f73\u7684\u662f\u5e76\u4e0d\u9010\u6b65\u53bb\u566a\u7684masking diffusion\u3002\u9700\u8981\u89e3\u91ca\u5176\u4f18\u8d8a\u6027\u80fd\u5e76\u63a2\u7d22\u6539\u8fdb\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u5206\u6790masking diffusion\u5229\u7528\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u95f4\u65ad\u8df3\u8dc3\u7279\u6027\uff0c\u63d0\u51fa\u5c06\u5df2\u77e5\u8df3\u8dc3\u65f6\u95f4\u5206\u5e03\u878d\u5165\u4efb\u610f\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u65b9\u6cd5\uff0c\u5f62\u6210\u901a\u7528\u7684SCUD\u6a21\u578b\u3002", "result": "SCUD\u6a21\u578b\u4e0d\u4ec5\u6982\u62ec\u4e86\u7ecf\u5178\u7684\u79bb\u6563\u6269\u6563\u548cmasking diffusion\uff0c\u8fd8\u5728\u7ed3\u5408\u56fe\u50cf\u3001\u6587\u672c\u548c\u86cb\u767d\u8d28\u6570\u636e\u7684\u5f52\u7eb3\u504f\u5dee\u7684\u53bb\u566a\u8fc7\u7a0b\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8emasking diffusion\u7684\u6027\u80fd\u3002", "conclusion": "SCUD\u6a21\u578b\u5145\u5206\u5229\u7528\u4e86\u79bb\u6563\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\u7684\u7279\u6027\uff0c\u5e76\u5728\u591a\u79cd\u6570\u636e\u7c7b\u578b\u4e0a\u5c55\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u4e3a\u79bb\u6563\u6269\u6563\u6a21\u578b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2506.08326", "pdf": "https://arxiv.org/pdf/2506.08326", "abs": "https://arxiv.org/abs/2506.08326", "authors": ["Xingbo Fu", "Zehong Wang", "Zihan Chen", "Jiazheng Li", "Yaochen Zhu", "Zhenyu Lei", "Cong Shen", "Yanfang Ye", "Chuxu Zhang", "Jundong Li"], "title": "Graph Prompting for Graph Learning Models: Recent Advances and Future Directions", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by KDD 2025 Tutorial/Survey Track", "summary": "Graph learning models have demonstrated great prowess in learning expressive\nrepresentations from large-scale graph data in a wide variety of real-world\nscenarios. As a prevalent strategy for training powerful graph learning models,\nthe \"pre-training, adaptation\" scheme first pre-trains graph learning models on\nunlabeled graph data in a self-supervised manner and then adapts them to\nspecific downstream tasks. During the adaptation phase, graph prompting emerges\nas a promising approach that learns trainable prompts while keeping the\npre-trained graph learning models unchanged. In this paper, we present a\nsystematic review of recent advancements in graph prompting. First, we\nintroduce representative graph pre-training methods that serve as the\nfoundation step of graph prompting. Next, we review mainstream techniques in\ngraph prompting and elaborate on how they design learnable prompts for graph\nprompting. Furthermore, we summarize the real-world applications of graph\nprompting from different domains. Finally, we discuss several open challenges\nin existing studies with promising future directions in this field.", "AI": {"tldr": "This paper systematically reviews recent advancements in graph prompting, introduces representative graph pre-training methods, reviews mainstream techniques in graph prompting, summarizes real-world applications from different domains, and discusses open challenges and future directions.", "motivation": "Graph prompting has emerged as a promising approach for adapting pre-trained graph learning models to specific downstream tasks without changing the original model.", "method": "The paper first introduces representative graph pre-training methods. Then it reviews mainstream techniques in graph prompting and how they design learnable prompts. It also summarizes real-world applications of graph prompting from different domains.", "result": "A systematic review of graph prompting is provided, including its foundation, techniques, applications, and challenges.", "conclusion": "The authors discuss several open challenges in existing studies and provide promising future directions in the field of graph prompting."}}
{"id": "2506.08029", "pdf": "https://arxiv.org/pdf/2506.08029", "abs": "https://arxiv.org/abs/2506.08029", "authors": ["Jiayu Li", "Masood Mortazavi", "Ning Yan", "Yihong Ma", "Reza Zafarani"], "title": "Inverse Design in Distributed Circuits Using Single-Step Reinforcement Learning", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "comment": "A briefer version of this paper was accepted as a Work-in-Progress\n  (WIP) at the Design Automation Conference (DAC) 2024", "summary": "The goal of inverse design in distributed circuits is to generate\nnear-optimal designs that meet a desirable transfer function specification.\nExisting design exploration methods use some combination of strategies\ninvolving artificial grids, differentiable evaluation procedures, and specific\ntemplate topologies. However, real-world design practices often require\nnon-differentiable evaluation procedures, varying topologies, and\nnear-continuous placement spaces. In this paper, we propose DCIDA, a design\nexploration framework that learns a near-optimal design sampling policy for a\ntarget transfer function. DCIDA decides all design factors in a compound\nsingle-step action by sampling from a set of jointly-trained conditional\ndistributions generated by the policy. Utilizing an injective interdependent\n``map\", DCIDA transforms raw sampled design ``actions\" into uniquely equivalent\nphysical representations, enabling the framework to learn the conditional\ndependencies among joint ``raw'' design decisions. Our experiments demonstrate\nDCIDA's Transformer-based policy network achieves significant reductions in\ndesign error compared to state-of-the-art approaches, with significantly better\nfit in cases involving more complex transfer functions.", "AI": {"tldr": "The paper proposes DCIDA, a design exploration framework that learns to generate near-optimal distributed circuit designs for target transfer functions, showing significant improvements over existing methods especially for complex functions.", "motivation": "Inverse design in distributed circuits aims to create designs matching desirable transfer function specifications. Current methods have limitations when faced with real-world requirements such as non-differentiable evaluations, varying topologies, and near-continuous placement spaces.", "method": "DCIDA employs a Transformer-based policy network to sample near-optimal design actions in a single step from jointly-trained conditional distributions. It uses an injective interdependent mapping to transform raw sampled actions into physical representations, capturing conditional dependencies among design decisions.", "result": "Experiments indicate that DCIDA significantly reduces design error compared to state-of-the-art methods, particularly excelling in fitting complex transfer functions.", "conclusion": "DCIDA offers a robust framework for inverse design in distributed circuits by effectively handling non-differentiable procedures, varying topologies, and continuous placement spaces, providing superior performance for complex transfer functions."}}
{"id": "2506.08337", "pdf": "https://arxiv.org/pdf/2506.08337", "abs": "https://arxiv.org/abs/2506.08337", "authors": ["Juhyeok Choi", "Chenglin Fan"], "title": "A Simple Analysis of Discretization Error in Diffusion Models", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Diffusion models, formulated as discretizations of stochastic differential\nequations (SDEs), achieve state-of-the-art generative performance. However,\nexisting analyses of their discretization error often rely on complex\nprobabilistic tools. In this work, we present a simplified theoretical\nframework for analyzing the Euler--Maruyama discretization of\nvariance-preserving SDEs (VP-SDEs) in Denoising Diffusion Probabilistic Models\n(DDPMs), where $ T $ denotes the number of denoising steps in the diffusion\nprocess. Our approach leverages Gr\\\"onwall's inequality to derive a convergence\nrate of $ \\mathcal{O}(1/T^{1/2}) $ under Lipschitz assumptions, significantly\nstreamlining prior proofs. Furthermore, we demonstrate that the Gaussian noise\nin the discretization can be replaced by a discrete random variable (e.g.,\nRademacher or uniform noise) without sacrificing convergence guarantees-an\ninsight with practical implications for efficient sampling. Experiments\nvalidate our theory, showing that (1) the error scales as predicted, (2)\ndiscrete noise achieves comparable sample quality to Gaussian noise, and (3)\nincorrect noise scaling degrades performance. By unifying simplified analysis\nand discrete noise substitution, our work bridges theoretical rigor with\npractical efficiency in diffusion-based generative modeling.", "AI": {"tldr": "Diffusion models based on stochastic differential equations (SDEs) are powerful in generative tasks, but their error analyses can be complex. This paper simplifies the analysis of discretization errors for variance-preserving SDEs in DDPMs, achieving a convergence rate of O(1/T^1/2). It also shows that Gaussian noise can be replaced with discrete random variables without affecting performance, thus enhancing sampling efficiency.", "motivation": "The motivation behind this work is to simplify the theoretical framework for analyzing the Euler--Maruyama discretization error in variance-preserving SDEs used in DDPMs, making it more accessible and less reliant on advanced probabilistic tools. Additionally, exploring the potential substitution of Gaussian noise with discrete random variables could lead to more efficient sampling methods.", "method": "The authors employ Gr\u00f6nwall's inequality under Lipschitz assumptions to derive the convergence rate of O(1/T^1/2) for the Euler--Maruyama discretization of VP-SDEs in DDPMs. They also investigate the effects of replacing Gaussian noise with discrete random variables such as Rademacher or uniform noise, validating their findings through experiments.", "result": "The results confirm the predicted scaling of the error with respect to the number of denoising steps T. Moreover, the use of discrete noise achieves similar sample quality compared to Gaussian noise, while incorrect noise scaling leads to performance degradation. These findings support both the theoretical analysis and practical implications of the study.", "conclusion": "This research provides a simplified theoretical analysis for the discretization of VP-SDEs in diffusion models, contributing to a better understanding of their convergence properties. The ability to substitute Gaussian noise with discrete noise opens up possibilities for enhancing the efficiency of sampling processes in generative modeling."}}
{"id": "2506.08041", "pdf": "https://arxiv.org/pdf/2506.08041", "abs": "https://arxiv.org/abs/2506.08041", "authors": ["Siddharth Siddharth", "Brainerd Prince", "Amol Harsh", "Shreyas Ramachandran"], "title": "The World of AI: A Novel Approach to AI Literacy for First-year Engineering Students", "categories": ["cs.CY", "cs.AI"], "comment": "Accepted for publication at AIED 2025 in the late-breaking work track", "summary": "This work presents a novel course titled The World of AI designed for\nfirst-year undergraduate engineering students with little to no prior exposure\nto AI. The central problem addressed by this course is that engineering\nstudents often lack foundational knowledge of AI and its broader societal\nimplications at the outset of their academic journeys. We believe the way to\naddress this gap is to design and deliver an interdisciplinary course that can\na) be accessed by first-year undergraduate engineering students across any\ndomain, b) enable them to understand the basic workings of AI systems sans\nmathematics, and c) make them appreciate AI's far-reaching implications on our\nlives. The course was divided into three modules co-delivered by faculty from\nboth engineering and humanities. The planetary module explored AI's dual role\nas both a catalyst for sustainability and a contributor to environmental\nchallenges. The societal impact module focused on AI biases and concerns around\nprivacy and fairness. Lastly, the workplace module highlighted AI-driven job\ndisplacement, emphasizing the importance of adaptation. The novelty of this\ncourse lies in its interdisciplinary curriculum design and pedagogical\napproach, which combines technical instruction with societal discourse. Results\nrevealed that students' comprehension of AI challenges improved across diverse\nmetrics like (a) increased awareness of AI's environmental impact, and (b)\nefficient corrective solutions for AI fairness. Furthermore, it also indicated\nthe evolution in students' perception of AI's transformative impact on our\nlives.", "AI": {"tldr": "A new interdisciplinary course 'The World of AI' for first-year engineering students improved their understanding of AI challenges and its societal implications.", "motivation": "Engineering students often lack foundational knowledge of AI and its societal implications at the outset of their academic journeys.", "method": "Design and deliver an interdisciplinary course with three modules (planetary, societal impact, workplace) co-taught by faculty from engineering and humanities, focusing on understanding AI without mathematics and appreciating its implications.", "result": "Students showed improved comprehension of AI challenges across diverse metrics, increased awareness of environmental impact, and efficient solutions for AI fairness. Their perception of AI's transformative impact also evolved.", "conclusion": "The interdisciplinary curriculum design combining technical instruction with societal discourse is effective in enhancing first-year engineering students' understanding of AI."}}
{"id": "2506.08340", "pdf": "https://arxiv.org/pdf/2506.08340", "abs": "https://arxiv.org/abs/2506.08340", "authors": ["Emo Todorov"], "title": "Dynamical System Optimization", "categories": ["cs.LG"], "comment": null, "summary": "We develop an optimization framework centered around a core idea: once a\n(parametric) policy is specified, control authority is transferred to the\npolicy, resulting in an autonomous dynamical system. Thus we should be able to\noptimize policy parameters without further reference to controls or actions,\nand without directly using the machinery of approximate Dynamic Programming and\nReinforcement Learning. Here we derive simpler algorithms at the autonomous\nsystem level, and show that they compute the same quantities as policy\ngradients and Hessians, natural gradients, proximal methods. Analogs to\napproximate policy iteration and off-policy learning are also available. Since\npolicy parameters and other system parameters are treated uniformly, the same\nalgorithms apply to behavioral cloning, mechanism design, system\nidentification, learning of state estimators. Tuning of generative AI models is\nnot only possible, but is conceptually closer to the present framework than to\nReinforcement Learning.", "AI": {"tldr": "An optimization framework is developed to optimize policy parameters as an autonomous dynamical system, simplifying algorithms and unifying various tasks like behavioral cloning and generative AI model tuning.", "motivation": "To create a simpler optimization framework for policy parameters without relying on traditional methods of Dynamic Programming and Reinforcement Learning.", "method": "Developing an optimization framework centered around the concept of transferring control authority to a specified (parametric) policy, resulting in an autonomous dynamical system.", "result": "The derived algorithms compute the same quantities as policy gradients and other related methods while providing analogs to approximate policy iteration and off-policy learning.", "conclusion": "This new framework not only simplifies algorithms but also unifies various tasks such as behavioral cloning, mechanism design, system identification, and tuning of generative AI models."}}
{"id": "2506.08045", "pdf": "https://arxiv.org/pdf/2506.08045", "abs": "https://arxiv.org/abs/2506.08045", "authors": ["Ranjan Sapkota", "Konstantinos I. Roumeliotis", "Manoj Karkee"], "title": "UAVs Meet Agentic AI: A Multidomain Survey of Autonomous Aerial Intelligence and Agentic UAVs", "categories": ["cs.RO", "cs.AI"], "comment": "40 pages, 6 Figures", "summary": "Agentic UAVs represent a new frontier in autonomous aerial intelligence,\nintegrating perception, decision-making, memory, and collaborative planning to\noperate adaptively in complex, real-world environments. Driven by recent\nadvances in Agentic AI, these systems surpass traditional UAVs by exhibiting\ngoal-driven behavior, contextual reasoning, and interactive autonomy. We\nprovide a comprehensive foundation for understanding the architectural\ncomponents and enabling technologies that distinguish Agentic UAVs from\ntraditional autonomous UAVs. Furthermore, a detailed comparative analysis\nhighlights advancements in autonomy with AI agents, learning, and mission\nflexibility. This study explores seven high-impact application domains\nprecision agriculture, construction & mining, disaster response, environmental\nmonitoring, infrastructure inspection, logistics, security, and wildlife\nconservation, illustrating the broad societal value of agentic aerial\nintelligence. Furthermore, we identify key challenges in technical constraints,\nregulatory limitations, and data-model reliability, and we present emerging\nsolutions across hardware innovation, learning architectures, and human-AI\ninteraction. Finally, a future roadmap is proposed, outlining pathways toward\nself-evolving aerial ecosystems, system-level collaboration, and sustainable,\nequitable deployments. This survey establishes a foundational framework for the\nfuture development, deployment, and governance of agentic aerial systems\n(Agentic UAVs) across diverse societal and industrial domains.", "AI": {"tldr": "Agentic UAVs are advanced autonomous aerial systems that integrate perception, decision-making, memory and collaborative planning. They go beyond traditional UAVs by incorporating AI-driven goal-oriented behavior, contextual reasoning, and interactive autonomy.", "motivation": "To provide a comprehensive understanding of the architectural components and enabling technologies that distinguish Agentic UAVs from traditional UAVs, highlighting advancements in autonomy with AI agents, learning, and mission flexibility.", "method": "The study explores seven high-impact application domains for Agentic UAVs, identifies key challenges in technical constraints, regulatory limitations, and data-model reliability, and presents emerging solutions across hardware innovation, learning architectures, and human-AI interaction.", "result": "Illustrates the broad societal value of agentic aerial intelligence in diverse fields such as precision agriculture, disaster response, environmental monitoring, among others, while addressing current challenges and proposing future pathways.", "conclusion": "A foundational framework is established for the future development, deployment, and governance of Agentic UAVs across various societal and industrial domains."}}
{"id": "2506.08047", "pdf": "https://arxiv.org/pdf/2506.08047", "abs": "https://arxiv.org/abs/2506.08047", "authors": ["A. G. R. Sandeepa", "Sanka Mohottala"], "title": "Evaluation of Machine Learning Models in Student Academic Performance Prediction", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": "Paper Accepted for IEEE ICARC Conference (2025). 6 pages, 5 figures", "summary": "This research investigates the use of machine learning methods to forecast\nstudents' academic performance in a school setting. Students' data with\nbehavioral, academic, and demographic details were used in implementations with\nstandard classical machine learning models including multi-layer perceptron\nclassifier (MLPC). MLPC obtained 86.46% maximum accuracy for test set across\nall implementations. Under 10-fold cross validation, MLPC obtained 79.58%\naverage accuracy for test set while for train set, it was 99.65%. MLP's better\nperformance over other machine learning models strongly suggest the potential\nuse of neural networks as data-efficient models. Feature selection approach\nplayed a crucial role in improving the performance and multiple evaluation\napproaches were used in order to compare with existing literature. Explainable\nmachine learning methods were utilized to demystify the black box models and to\nvalidate the feature selection approach.", "AI": {"tldr": "This paper explores using machine learning, particularly multi-layer perceptron classifier (MLPC), to predict students' academic performance, achieving 86.46% accuracy with feature selection enhancing results.", "motivation": "To identify an effective method for forecasting students' academic performance using available data with behavioral, academic, and demographic details.", "method": "Implementing standard classical machine learning models including MLPC on student data, utilizing feature selection, multiple evaluation approaches, and explainable machine learning methods.", "result": "MLPC achieved 86.46% maximum accuracy on the test set, with an average of 79.58% under 10-fold cross validation, showing neural networks' potential as data-efficient models.", "conclusion": "Neural networks like MLP are promising for predicting student performance with enhanced data efficiency through feature selection."}}
{"id": "2506.08353", "pdf": "https://arxiv.org/pdf/2506.08353", "abs": "https://arxiv.org/abs/2506.08353", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "An Adaptive Method Stabilizing Activations for Enhanced Generalization", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "We introduce AdaAct, a novel optimization algorithm that adjusts learning\nrates according to activation variance. Our method enhances the stability of\nneuron outputs by incorporating neuron-wise adaptivity during the training\nprocess, which subsequently leads to better generalization -- a complementary\napproach to conventional activation regularization methods. Experimental\nresults demonstrate AdaAct's competitive performance across standard image\nclassification benchmarks. We evaluate AdaAct on CIFAR and ImageNet, comparing\nit with other state-of-the-art methods. Importantly, AdaAct effectively bridges\nthe gap between the convergence speed of Adam and the strong generalization\ncapabilities of SGD, all while maintaining competitive execution times. Code is\navailable at https://github.com/hseung88/adaact.", "AI": {"tldr": "AdaAct is an optimization algorithm that adjusts learning rates based on activation variance, enhancing neuron output stability and generalization. It performs competitively on image classification benchmarks like CIFAR and ImageNet, bridging the gap between Adam's convergence speed and SGD's generalization while maintaining efficient execution times.", "motivation": "To improve the stability of neuron outputs during training and achieve better generalization by introducing a method that adjusts learning rates according to activation variance, thus complementing conventional activation regularization techniques.", "method": "AdaAct incorporates neuron-wise adaptivity by adjusting learning rates based on activation variance, which enhances the stability of neuron outputs during the training process.", "result": "AdaAct demonstrates competitive performance in standard image classification benchmarks such as CIFAR and ImageNet. It bridges the gap between Adam's fast convergence and SGD's strong generalization capabilities while keeping competitive execution times.", "conclusion": "AdaAct presents a promising approach for improving generalization and stability in neural network training, offering a balance between convergence speed and generalization capabilities."}}
{"id": "2506.08048", "pdf": "https://arxiv.org/pdf/2506.08048", "abs": "https://arxiv.org/abs/2506.08048", "authors": ["Zheng Han", "Jun Zhou", "Jialun Pei", "Jing Qin", "Yingfang Fan", "Qi Dou"], "title": "Towards Reliable AR-Guided Surgical Navigation: Interactive Deformation Modeling with Data-Driven Biomechanics and Prompts", "categories": ["cs.CV", "cs.AI", "cs.RO"], "comment": null, "summary": "In augmented reality (AR)-guided surgical navigation, preoperative organ\nmodels are superimposed onto the patient's intraoperative anatomy to visualize\ncritical structures such as vessels and tumors. Accurate deformation modeling\nis essential to maintain the reliability of AR overlays by ensuring alignment\nbetween preoperative models and the dynamically changing anatomy. Although the\nfinite element method (FEM) offers physically plausible modeling, its high\ncomputational cost limits intraoperative applicability. Moreover, existing\nalgorithms often fail to handle large anatomical changes, such as those induced\nby pneumoperitoneum or ligament dissection, leading to inaccurate anatomical\ncorrespondences and compromised AR guidance. To address these challenges, we\npropose a data-driven biomechanics algorithm that preserves FEM-level accuracy\nwhile improving computational efficiency. In addition, we introduce a novel\nhuman-in-the-loop mechanism into the deformation modeling process. This enables\nsurgeons to interactively provide prompts to correct anatomical misalignments,\nthereby incorporating clinical expertise and allowing the model to adapt\ndynamically to complex surgical scenarios. Experiments on a publicly available\ndataset demonstrate that our algorithm achieves a mean target registration\nerror of 3.42 mm. Incorporating surgeon prompts through the interactive\nframework further reduces the error to 2.78 mm, surpassing state-of-the-art\nmethods in volumetric accuracy. These results highlight the ability of our\nframework to deliver efficient and accurate deformation modeling while\nenhancing surgeon-algorithm collaboration, paving the way for safer and more\nreliable computer-assisted surgeries.", "AI": {"tldr": "In augmented reality (AR)-guided surgical navigation, preoperative organ models are superimposed onto the patient's intraoperative anatomy. Accurate deformation modeling is essential for maintaining alignment between these models and dynamically changing anatomy. The finite element method (FEM) offers physically plausible modeling but is computationally expensive and struggles with large anatomical changes. This paper proposes a data-driven biomechanics algorithm that preserves FEM-level accuracy while improving computational efficiency and introduces a human-in-the-loop mechanism to allow surgeons to interactively correct anatomical misalignments.", "motivation": "To address the limitations of current deformation modeling techniques in AR-guided surgical navigation, which struggle with large anatomical changes and are computationally expensive.", "method": "A data-driven biomechanics algorithm preserving FEM-level accuracy while improving computational efficiency. A human-in-the-loop mechanism enabling surgeons to interactively provide prompts to correct anatomical misalignments.", "result": "Experiments on a publicly available dataset show a mean target registration error of 3.42 mm. Incorporating surgeon prompts through the interactive framework reduces the error to 2.78 mm, surpassing state-of-the-art methods in volumetric accuracy.", "conclusion": "The proposed framework delivers efficient and accurate deformation modeling, enhances surgeon-algorithm collaboration, and paves the way for safer and more reliable computer-assisted surgeries."}}
{"id": "2506.08360", "pdf": "https://arxiv.org/pdf/2506.08360", "abs": "https://arxiv.org/abs/2506.08360", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "NysAct: A Scalable Preconditioned Gradient Descent using Nystrom Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Adaptive gradient methods are computationally efficient and converge quickly,\nbut they often suffer from poor generalization. In contrast, second-order\nmethods enhance convergence and generalization but typically incur high\ncomputational and memory costs. In this work, we introduce NysAct, a scalable\nfirst-order gradient preconditioning method that strikes a balance between\nstate-of-the-art first-order and second-order optimization methods. NysAct\nleverages an eigenvalue-shifted Nystrom method to approximate the activation\ncovariance matrix, which is used as a preconditioning matrix, significantly\nreducing time and memory complexities with minimal impact on test accuracy. Our\nexperiments show that NysAct not only achieves improved test accuracy compared\nto both first-order and second-order methods but also demands considerably less\ncomputational resources than existing second-order methods. Code is available\nat https://github.com/hseung88/nysact.", "AI": {"tldr": "The paper introduces NysAct, a scalable first-order gradient preconditioning method that balances computational efficiency and generalization. It uses an eigenvalue-shifted Nystrom method to approximate the activation covariance matrix, reducing time and memory complexities while maintaining test accuracy.", "motivation": "To address the trade-off between computational efficiency and generalization in adaptive gradient methods and second-order methods, the authors aim to develop a scalable optimization method that combines the benefits of both approaches.", "method": "NysAct leverages an eigenvalue-shifted Nystrom method to approximate the activation covariance matrix for use as a preconditioning matrix. This approach aims to reduce time and memory complexities compared to existing second-order methods.", "result": "Experiments demonstrate that NysAct achieves improved test accuracy compared to both first-order and second-order methods, while demanding significantly less computational resources than traditional second-order methods.", "conclusion": "NysAct presents a novel approach to optimization in deep learning that effectively balances computational efficiency and generalization, outperforming existing methods in terms of both accuracy and resource usage."}}
{"id": "2506.08049", "pdf": "https://arxiv.org/pdf/2506.08049", "abs": "https://arxiv.org/abs/2506.08049", "authors": ["Tengfei Lyu", "Weijia Zhang", "Hao Liu"], "title": "Physics-Informed Teleconnection-Aware Transformer for Global Subseasonal-to-Seasonal Forecasting", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Subseasonal-to-seasonal (S2S) forecasting, which predicts climate conditions\nfrom several weeks to months in advance, presents significant challenges due to\nthe chaotic dynamics of atmospheric systems and complex interactions across\nmultiple scales. Current approaches often fail to explicitly model underlying\nphysical processes and teleconnections that are crucial at S2S timescales. We\nintroduce TelePiT, a novel deep learning architecture that enhances global S2S\nforecasting through integrated multi-scale physics and teleconnection\nawareness. Our approach consists of three key components: (1) Spherical\nHarmonic Embedding, which accurately encodes global atmospheric variables onto\nspherical geometry; (2) Multi-Scale Physics-Informed Neural ODE, which\nexplicitly captures atmospheric physical processes across multiple learnable\nfrequency bands; (3) Teleconnection-Aware Transformer, which models critical\nglobal climate interactions through tactfully injecting teleconnection patterns\ninto the self-attention. Extensive experiments demonstrate that TelePiT\nsignificantly outperforms state-of-the-art data-driven baselines and\noperational numerical weather prediction systems, with remarkable improvements\nfor atmospheric variables including a 57.7% reduction in RMSE for 2-meter\ntemperature compared to previous best models.", "AI": {"tldr": "The paper introduces TelePiT, a deep learning model for S2S forecasting that integrates multi-scale physics and teleconnection awareness, outperforming existing methods.", "motivation": "S2S forecasting faces challenges due to chaotic atmospheric dynamics and complex interactions across scales. Current methods fail to explicitly model crucial physical processes and teleconnections at S2S timescales.", "method": "TelePiT consists of three components: Spherical Harmonic Embedding for encoding global atmospheric variables, Multi-Scale Physics-Informed Neural ODE for capturing atmospheric processes, and Teleconnection-Aware Transformer for modeling climate interactions.", "result": "TelePiT significantly outperforms state-of-the-art data-driven baselines and operational numerical weather prediction systems, with notable improvements such as a 57.7% reduction in RMSE for 2-meter temperature compared to previous best models.", "conclusion": "TelePiT enhances global S2S forecasting through integrated multi-scale physics and teleconnection awareness."}}
{"id": "2506.08365", "pdf": "https://arxiv.org/pdf/2506.08365", "abs": "https://arxiv.org/abs/2506.08365", "authors": ["Cheng Tan", "Zhenxiao Cao", "Zhangyang Gao", "Siyuan Li", "Yufei Huang", "Stan Z. Li"], "title": "AlphaFold Database Debiasing for Robust Inverse Folding", "categories": ["cs.LG", "q-bio.BM"], "comment": "Under review", "summary": "The AlphaFold Protein Structure Database (AFDB) offers unparalleled\nstructural coverage at near-experimental accuracy, positioning it as a valuable\nresource for data-driven protein design. However, its direct use in training\ndeep models that are sensitive to fine-grained atomic geometry, such as inverse\nfolding, exposes a critical limitation. Comparative analysis of structural\nfeature distributions reveals that AFDB structures exhibit distinct statistical\nregularities, reflecting a systematic geometric bias that deviates from the\nconformational diversity found in experimentally determined structures from the\nProtein Data Bank (PDB). While AFDB structures are cleaner and more idealized,\nPDB structures capture the intrinsic variability and physical realism essential\nfor generalization in downstream tasks. To address this discrepancy, we\nintroduce a Debiasing Structure AutoEncoder (DeSAE) that learns to reconstruct\nnative-like conformations from intentionally corrupted backbone geometries. By\ntraining the model to recover plausible structural states, DeSAE implicitly\ncaptures a more robust and natural structural manifold. At inference, applying\nDeSAE to AFDB structures produces debiased structures that significantly\nimprove inverse folding performance across multiple benchmarks. This work\nhighlights the critical impact of subtle systematic biases in predicted\nstructures and presents a principled framework for debiasing, significantly\nboosting the performance of structure-based learning tasks like inverse\nfolding.", "AI": {"tldr": "DeSAE is introduced to debias AFDB structures for better inverse folding performance by reconstructing native-like conformations from corrupted geometries.", "motivation": "The motivation is the critical limitation of using AFDB directly in training deep models due to its systematic geometric bias that deviates from the conformational diversity in PDB structures.", "method": "Debiasing Structure AutoEncoder (DeSAE) learns to reconstruct native-like conformations from intentionally corrupted backbone geometries, capturing a more robust and natural structural manifold.", "result": "Applying DeSAE to AFDB structures significantly improves inverse folding performance across multiple benchmarks.", "conclusion": "This work highlights the impact of systematic biases in predicted structures and presents a framework for debiasing to boost structure-based learning tasks."}}
{"id": "2506.08379", "pdf": "https://arxiv.org/pdf/2506.08379", "abs": "https://arxiv.org/abs/2506.08379", "authors": ["Yurun Yuan", "Tengyang Xie"], "title": "Reinforce LLM Reasoning through Multi-Agent Reflection", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "International Conference on Machine Learning (ICML), 2025", "summary": "Leveraging more test-time computation has proven to be an effective way to\nboost the reasoning capabilities of large language models (LLMs). Among various\nmethods, the verify-and-improve paradigm stands out for enabling dynamic\nsolution exploration and feedback incorporation. However, existing approaches\noften suffer from restricted feedback spaces and lack of coordinated training\nof different parties, leading to suboptimal performance. To address this, we\nmodel this multi-turn refinement process as a Markov Decision Process and\nintroduce DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement\nlearning algorithm that trains an actor-critic LLM system to iteratively refine\nanswers via direct preference learning on self-generated data. Theoretically,\nDPSDP can match the performance of any policy within the training distribution.\nEmpirically, we instantiate DPSDP with various base models and show\nimprovements on both in- and out-of-distribution benchmarks. For example, on\nbenchmark MATH 500, majority voting over five refinement steps increases\nfirst-turn accuracy from 58.2% to 63.2% with Ministral-based models. An\nablation study further confirms the benefits of multi-agent collaboration and\nout-of-distribution generalization.", "AI": {"tldr": "This paper proposes DPSDP, a reinforcement learning algorithm that leverages the verify-and-improve paradigm for large language models (LLMs) by modeling a multi-turn refinement process as a Markov Decision Process. It trains an actor-critic LLM system via direct preference learning on self-generated data and demonstrates improvements in both in-distribution and out-of-distribution benchmarks.", "motivation": "The motivation of this paper is to address the limitations of existing approaches which suffer from restricted feedback spaces and lack of coordinated training of different parties when leveraging more test-time computation to boost reasoning capabilities of LLMs.", "method": "The method involves modeling the multi-turn refinement process as a Markov Decision Process and introducing DPSDP (Direct Policy Search by Dynamic Programming), a reinforcement learning algorithm that trains an actor-critic LLM system to iteratively refine answers through direct preference learning on self-generated data.", "result": "Empirical results show improvements on both in- and out-of-distribution benchmarks. For instance, majority voting over five refinement steps increases first-turn accuracy from 58.2% to 63.2% on the MATH 500 benchmark using Ministral-based models. An ablation study confirms the benefits of multi-agent collaboration and out-of-distribution generalization.", "conclusion": "DPSDP can match the performance of any policy within the training distribution and shows significant improvements on various benchmarks, demonstrating its effectiveness in enhancing the reasoning capabilities of LLMs."}}
{"id": "2506.08059", "pdf": "https://arxiv.org/pdf/2506.08059", "abs": "https://arxiv.org/abs/2506.08059", "authors": ["Huong Van Le", "Weibin Ren", "Junhong Kim", "Yukyung Yun", "Young Bin Park", "Young Jun Kim", "Bok Kyung Han", "Inho Choi", "Jong IL Park", "Hwi-Yeol Yun", "Jae-Mun Choi"], "title": "CaliciBoost: Performance-Driven Evaluation of Molecular Representations for Caco-2 Permeability Prediction", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "49 pages, 11 figures", "summary": "Caco-2 permeability serves as a critical in vitro indicator for predicting\nthe oral absorption of drug candidates during early-stage drug discovery. To\nenhance the accuracy and efficiency of computational predictions, we\nsystematically investigated the impact of eight molecular feature\nrepresentation types including 2D/3D descriptors, structural fingerprints, and\ndeep learning-based embeddings combined with automated machine learning\ntechniques to predict Caco-2 permeability. Using two datasets of differing\nscale and diversity (TDC benchmark and curated OCHEM data), we assessed model\nperformance across representations and identified PaDEL, Mordred, and RDKit\ndescriptors as particularly effective for Caco-2 prediction. Notably, the\nAutoML-based model CaliciBoost achieved the best MAE performance. Furthermore,\nfor both PaDEL and Mordred representations, the incorporation of 3D descriptors\nresulted in a 15.73% reduction in MAE compared to using 2D features alone, as\nconfirmed by feature importance analysis. These findings highlight the\neffectiveness of AutoML approaches in ADMET modeling and offer practical\nguidance for feature selection in data-limited prediction tasks.", "AI": {"tldr": "This paper explores the impact of various molecular feature representation types combined with AutoML techniques to predict Caco-2 permeability, finding that PaDEL, Mordred, and RDKit descriptors are particularly effective, and CaliciBoost achieved the best MAE performance. Incorporating 3D descriptors led to a significant reduction in MAE.", "motivation": "To enhance the accuracy and efficiency of computational predictions for Caco-2 permeability, which is a critical indicator for predicting oral drug absorption in early-stage drug discovery.", "method": "Systematically investigated eight molecular feature representation types including 2D/3D descriptors, structural fingerprints, and deep learning-based embeddings combined with automated machine learning techniques. Used two datasets (TDC benchmark and curated OCHEM data) to assess model performance across representations.", "result": "Identified PaDEL, Mordred, and RDKit descriptors as particularly effective for Caco-2 prediction. The AutoML-based model CaliciBoost achieved the best MAE performance. Incorporation of 3D descriptors resulted in a 15.73% reduction in MAE compared to using 2D features alone.", "conclusion": "AutoML approaches are effective in ADMET modeling and offer practical guidance for feature selection in data-limited prediction tasks."}}
{"id": "2506.08388", "pdf": "https://arxiv.org/pdf/2506.08388", "abs": "https://arxiv.org/abs/2506.08388", "authors": ["Edoardo Cetin", "Tianyu Zhao", "Yujin Tang"], "title": "Reinforcement Learning Teachers of Test Time Scaling", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Preprint", "summary": "Training reasoning language models (LMs) with reinforcement learning (RL) for\none-hot correctness inherently relies on the LM being able to explore and solve\nits task with some chance at initialization. Furthermore, a key use case of\nreasoning LMs is to act as teachers for distilling new students and\ncold-starting future RL iterations rather than being deployed themselves. From\nthese considerations, we introduce a new framework that avoids RL's exploration\nchallenge by training a new class of Reinforcement-Learned Teachers (RLTs)\nfocused on yielding the most effective downstream distillation. RLTs are\nprompted with both the question and solution to each problem, and tasked to\nsimply \"connect-the-dots\" with detailed explanations tailored for their\nstudents. We train RLTs with dense rewards obtained by feeding each explanation\nto the student and testing its understanding of the problem's solution. In\npractice, the raw outputs of a 7B RLT provide higher final performance on\ncompetition and graduate-level tasks than existing distillation and\ncold-starting pipelines that collect and postprocess the reasoning traces of\norders of magnitude larger LMs. Furthermore, RLTs maintain their effectiveness\nwhen training larger students and when applied zero-shot to out-of-distribution\ntasks, unlocking new levels of efficiency and re-usability for the RL reasoning\nframework.", "AI": {"tldr": "This paper introduces a new framework that trains Reinforcement-Learned Teachers (RLTs) to provide detailed explanations for students, avoiding RL's exploration challenge and improving distillation performance.", "motivation": "The motivation is to overcome the limitations of training reasoning language models with reinforcement learning, particularly the reliance on initial exploration ability and the need for effective distillation for future use.", "method": "RLTs are trained using dense rewards obtained by feeding each explanation to the student and testing its understanding. They are prompted with both the question and solution to connect the dots with tailored explanations.", "result": "The 7B RLTs outperform existing pipelines in final performance on competition and graduate-level tasks. They remain effective when training larger students and when applied zero-shot to out-of-distribution tasks.", "conclusion": "This new framework unlocks higher efficiency and re-usability for the RL reasoning framework by focusing on effective downstream distillation."}}
{"id": "2506.08397", "pdf": "https://arxiv.org/pdf/2506.08397", "abs": "https://arxiv.org/abs/2506.08397", "authors": ["Vamshika Sutar", "Amandeep Singh", "Rohitash Chandra"], "title": "Spatiotemporal deep learning models for detection of rapid intensification in cyclones", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Cyclone rapid intensification is the rapid increase in cyclone wind\nintensity, exceeding a threshold of 30 knots, within 24 hours. Rapid\nintensification is considered an extreme event during a cyclone, and its\noccurrence is relatively rare, contributing to a class imbalance in the\ndataset. A diverse array of factors influences the likelihood of a cyclone\nundergoing rapid intensification, further complicating the task for\nconventional machine learning models. In this paper, we evaluate deep learning,\nensemble learning and data augmentation frameworks to detect cyclone rapid\nintensification based on wind intensity and spatial coordinates. We note that\nconventional data augmentation methods cannot be utilised for generating\nspatiotemporal patterns replicating cyclones that undergo rapid\nintensification. Therefore, our framework employs deep learning models to\ngenerate spatial coordinates and wind intensity that replicate cyclones to\naddress the class imbalance problem of rapid intensification. We also use a\ndeep learning model for the classification module within the data augmentation\nframework to differentiate between rapid and non-rapid intensification events\nduring a cyclone. Our results show that data augmentation improves the results\nfor rapid intensification detection in cyclones, and spatial coordinates play a\ncritical role as input features to the given models. This paves the way for\nresearch in synthetic data generation for spatiotemporal data with extreme\nevents.", "AI": {"tldr": "Cyclone rapid intensification is an extreme event that is relatively rare. This paper evaluates deep learning, ensemble learning and data augmentation frameworks to detect cyclone rapid intensification based on wind intensity and spatial coordinates.", "motivation": "Cyclone rapid intensification is an extreme event that is relatively rare and influenced by a diverse array of factors, making it challenging for conventional machine learning models.", "method": "The paper uses deep learning, ensemble learning and data augmentation frameworks to detect cyclone rapid intensification. It employs deep learning models to generate spatial coordinates and wind intensity that replicate cyclones to address the class imbalance problem and also use a deep learning model for the classification module within the data augmentation framework.", "result": "Data augmentation improves the results for rapid intensification detection in cyclones, and spatial coordinates play a critical role as input features to the given models.", "conclusion": "This research paves the way for research in synthetic data generation for spatiotemporal data with extreme events."}}
{"id": "2506.08066", "pdf": "https://arxiv.org/pdf/2506.08066", "abs": "https://arxiv.org/abs/2506.08066", "authors": ["Alexander Stepikin", "Evgenia Romanenkova", "Alexey Zaytsev"], "title": "WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point Detection", "categories": ["stat.ML", "cs.AI", "cs.LG"], "comment": null, "summary": "Change Point Detection (CPD) aims to identify moments of abrupt distribution\nshifts in data streams. Real-world high-dimensional CPD remains challenging due\nto data pattern complexity and violation of common assumptions. Resorting to\nstandalone deep neural networks, the current state-of-the-art detectors have\nyet to achieve perfect quality. Concurrently, ensembling provides more robust\nsolutions, boosting the performance. In this paper, we investigate ensembles of\ndeep change point detectors and realize that standard prediction aggregation\ntechniques, e.g., averaging, are suboptimal and fail to account for problem\npeculiarities. Alternatively, we introduce WWAggr -- a novel task-specific\nmethod of ensemble aggregation based on the Wasserstein distance. Our procedure\nis versatile, working effectively with various ensembles of deep CPD models.\nMoreover, unlike existing solutions, we practically lift a long-standing\nproblem of the decision threshold selection for CPD.", "AI": {"tldr": "The paper explores ensembles of deep change point detectors and proposes WWAggr, a new ensemble aggregation method based on the Wasserstein distance, which is more effective than standard techniques and addresses the issue of decision threshold selection.", "motivation": "Current deep neural network-based CPD methods have not reached perfect quality due to data pattern complexity and violation of common assumptions. Ensembling provides more robust solutions but standard prediction aggregation techniques like averaging are suboptimal.", "method": "The authors introduce WWAggr, a novel task-specific ensemble aggregation method based on the Wasserstein distance, designed for ensembles of deep CPD models. This method aims to account for problem peculiarities and improve performance.", "result": "WWAggr is versatile and works effectively with various ensembles of deep CPD models. It also addresses the long-standing problem of decision threshold selection for CPD.", "conclusion": "Ensembles of deep change point detectors with the proposed WWAggr method offer improved performance in high-dimensional CPD tasks."}}
{"id": "2506.08409", "pdf": "https://arxiv.org/pdf/2506.08409", "abs": "https://arxiv.org/abs/2506.08409", "authors": ["Fred Xu", "Song Jiang", "Zijie Huang", "Xiao Luo", "Shichang Zhang", "Adrian Chen", "Yizhou Sun"], "title": "FUSE: Measure-Theoretic Compact Fuzzy Set Representation for Taxonomy Expansion", "categories": ["cs.LG", "cs.NE"], "comment": null, "summary": "Taxonomy Expansion, which models complex concepts and their relations, can be\nformulated as a set representation learning task. The generalization of set,\nfuzzy set, incorporates uncertainty and measures the information within a\nsemantic concept, making it suitable for concept modeling. Existing works\nusually model sets as vectors or geometric objects such as boxes, which are not\nclosed under set operations. In this work, we propose a sound and efficient\nformulation of set representation learning based on its volume approximation as\na fuzzy set. The resulting embedding framework, Fuzzy Set Embedding (FUSE),\nsatisfies all set operations and compactly approximates the underlying fuzzy\nset, hence preserving information while being efficient to learn, relying on\nminimum neural architecture. We empirically demonstrate the power of FUSE on\nthe task of taxonomy expansion, where FUSE achieves remarkable improvements up\nto 23% compared with existing baselines. Our work marks the first attempt to\nunderstand and efficiently compute the embeddings of fuzzy sets.", "AI": {"tldr": "This paper proposes Fuzzy Set Embedding (FUSE), a new method for taxonomy expansion based on fuzzy set representation learning, achieving significant improvements in performance.", "motivation": "Existing methods for modeling sets do not fully support set operations and lack the ability to incorporate uncertainty within semantic concepts.", "method": "The paper introduces FUSE, which uses volume approximation of fuzzy sets as embeddings. This framework satisfies all set operations, preserves information, and is efficient to learn with minimal neural architecture.", "result": "FUSE shows substantial improvements in taxonomy expansion tasks, reaching up to 23% better performance compared to existing baselines.", "conclusion": "FUSE represents an effective approach for set representation learning and marks the first effort in understanding and computing fuzzy set embeddings."}}
{"id": "2506.08412", "pdf": "https://arxiv.org/pdf/2506.08412", "abs": "https://arxiv.org/abs/2506.08412", "authors": ["Saraa Ali", "Aleksandr Khizhik", "Stepan Svirin", "Artem Ryzhikov", "Denis Derkach"], "title": "Learning to Hear Broken Motors: Signature-Guided Data Augmentation for Induction-Motor Diagnostics", "categories": ["cs.LG"], "comment": null, "summary": "The application of machine learning (ML) algorithms in the intelligent\ndiagnosis of three-phase engines has the potential to significantly enhance\ndiagnostic performance and accuracy. Traditional methods largely rely on\nsignature analysis, which, despite being a standard practice, can benefit from\nthe integration of advanced ML techniques. In our study, we innovate by\ncombining ML algorithms with a novel unsupervised anomaly generation\nmethodology that takes into account the engine physics model. We propose\nSignature-Guided Data Augmentation (SGDA), an unsupervised framework that\nsynthesizes physically plausible faults directly in the frequency domain of\nhealthy current signals. Guided by Motor Current Signature Analysis, SGDA\ncreates diverse and realistic anomalies without resorting to computationally\nintensive simulations. This hybrid approach leverages the strengths of both\nsupervised ML and unsupervised signature analysis, achieving superior\ndiagnostic accuracy and reliability along with wide industrial application. The\nfindings highlight the potential of our approach to contribute significantly to\nthe field of engine diagnostics, offering a robust and efficient solution for\nreal-world applications.", "AI": {"tldr": "The paper proposes Signature-Guided Data Augmentation (SGDA), an unsupervised framework that synthesizes faults in the frequency domain of healthy current signals to enhance diagnostic accuracy and reliability in three-phase engine diagnostics.", "motivation": "Traditional methods for diagnosing three-phase engines largely depend on signature analysis, which is effective but can be improved by incorporating advanced machine learning techniques.", "method": "The authors developed SGDA, a novel unsupervised data augmentation methodology that uses the engine physics model to generate physically plausible faults directly in the frequency domain of healthy current signals. This approach is guided by Motor Current Signature Analysis.", "result": "The hybrid approach combining supervised ML and unsupervised signature analysis achieved superior diagnostic accuracy and reliability, showing potential for wide industrial application.", "conclusion": "The study concludes that the proposed SGDA method offers a robust and efficient solution for real-world applications in engine diagnostics, significantly contributing to the field."}}
{"id": "2506.08073", "pdf": "https://arxiv.org/pdf/2506.08073", "abs": "https://arxiv.org/abs/2506.08073", "authors": ["Yu Liu", "Utkarsh Pratiush", "Kamyar Barakati", "Hiroshi Funakubo", "Ching-Che Lin", "Jaegyu Kim", "Lane W. Martin", "Sergei V. Kalinin"], "title": "Domain Switching on the Pareto Front: Multi-Objective Deep Kernel Learning in Automated Piezoresponse Force Microscopy", "categories": ["cond-mat.mtrl-sci", "cond-mat.mes-hall", "cs.AI", "cs.LG"], "comment": null, "summary": "Ferroelectric polarization switching underpins the functional performance of\na wide range of materials and devices, yet its dependence on complex local\nmicrostructural features renders systematic exploration by manual or grid-based\nspectroscopic measurements impractical. Here, we introduce a multi-objective\nkernel-learning workflow that infers the microstructural rules governing\nswitching behavior directly from high-resolution imaging data. Applied to\nautomated piezoresponse force microscopy (PFM) experiments, our framework\nefficiently identifies the key relationships between domain-wall configurations\nand local switching kinetics, revealing how specific wall geometries and defect\ndistributions modulate polarization reversal. Post-experiment analysis projects\nabstract reward functions, such as switching ease and domain symmetry, onto\nphysically interpretable descriptors including domain configuration and\nproximity to boundaries. This enables not only high-throughput active learning,\nbut also mechanistic insight into the microstructural control of switching\nphenomena. While demonstrated for ferroelectric domain switching, our approach\nprovides a powerful, generalizable tool for navigating complex,\nnon-differentiable design spaces, from structure-property correlations in\nmolecular discovery to combinatorial optimization across diverse imaging\nmodalities.", "AI": {"tldr": "A multi-objective kernel-learning workflow infers microstructural rules governing ferroelectric polarization switching from high-resolution imaging data, enabling high-throughput active learning and mechanistic insights.", "motivation": "Ferroelectric polarization switching is crucial for material performance, but its dependence on complex microstructural features makes manual exploration impractical.", "method": "Introduced a multi-objective kernel-learning workflow applied to automated piezoresponse force microscopy (PFM) experiments. This framework identifies relationships between domain-wall configurations and local switching kinetics.", "result": "The workflow revealed how specific wall geometries and defect distributions modulate polarization reversal, and projected abstract reward functions onto physically interpretable descriptors.", "conclusion": "This approach not only provides high-throughput active learning for ferroelectric domain switching but also serves as a generalizable tool for navigating complex design spaces in various fields."}}
{"id": "2506.08415", "pdf": "https://arxiv.org/pdf/2506.08415", "abs": "https://arxiv.org/abs/2506.08415", "authors": ["Licong Lin", "Jingfeng Wu", "Peter L. Bartlett"], "title": "Improved Scaling Laws in Linear Regression via Data Reuse", "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"], "comment": null, "summary": "Neural scaling laws suggest that the test error of large language models\ntrained online decreases polynomially as the model size and data size increase.\nHowever, such scaling can be unsustainable when running out of new data. In\nthis work, we show that data reuse can improve existing scaling laws in linear\nregression. Specifically, we derive sharp test error bounds on $M$-dimensional\nlinear models trained by multi-pass stochastic gradient descent (multi-pass\nSGD) on $N$ data with sketched features. Assuming that the data covariance has\na power-law spectrum of degree $a$, and that the true parameter follows a prior\nwith an aligned power-law spectrum of degree $b-a$ (with $a > b > 1$), we show\nthat multi-pass SGD achieves a test error of $\\Theta(M^{1-b} + L^{(1-b)/a})$,\nwhere $L \\lesssim N^{a/b}$ is the number of iterations. In the same setting,\none-pass SGD only attains a test error of $\\Theta(M^{1-b} + N^{(1-b)/a})$ (see\ne.g., Lin et al., 2024). This suggests an improved scaling law via data reuse\n(i.e., choosing $L>N$) in data-constrained regimes. Numerical simulations are\nalso provided to verify our theoretical findings.", "AI": {"tldr": "\u901a\u8fc7\u6570\u636e\u91cd\u7528\uff0c\u591a\u904d\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08multi-pass SGD\uff09\u53ef\u4ee5\u6539\u5584\u7ebf\u6027\u56de\u5f52\u4e2d\u7684\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u3002\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\uff0c\u76f8\u6bd4\u5355\u904dSGD\uff0c\u591a\u904dSGD\u80fd\u5b9e\u73b0\u66f4\u4f18\u7684\u6d4b\u8bd5\u8bef\u5dee\u3002", "motivation": "\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\u8868\u660e\uff0c\u5f53\u6a21\u578b\u548c\u6570\u636e\u89c4\u6a21\u589e\u5927\u65f6\uff0c\u5728\u7ebf\u8bad\u7ec3\u7684\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u8bef\u5dee\u4f1a\u591a\u9879\u5f0f\u4e0b\u964d\u3002\u7136\u800c\uff0c\u5f53\u65b0\u6570\u636e\u8017\u5c3d\u65f6\uff0c\u8fd9\u79cd\u7f29\u653e\u53ef\u80fd\u4e0d\u53ef\u6301\u7eed\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u63a2\u7d22\u4e86\u6570\u636e\u91cd\u7528\u5bf9\u7f29\u653e\u5b9a\u5f8b\u7684\u5f71\u54cd\u3002", "method": "\u7814\u7a76\u63a8\u5bfc\u4e86\u5728N\u4e2a\u6570\u636e\u4e0a\u4f7f\u7528\u591a\u904d\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08multi-pass SGD\uff09\u8bad\u7ec3M\u7ef4\u7ebf\u6027\u6a21\u578b\u7684\u7cbe\u786e\u6d4b\u8bd5\u8bef\u5dee\u754c\u9650\u3002\u5047\u8bbe\u6570\u636e\u534f\u65b9\u5dee\u5177\u6709a\u9636\u5e42\u5f8b\u8c31\uff0c\u771f\u5b9e\u53c2\u6570\u9075\u5faab-a\u9636\u5bf9\u9f50\u5e42\u5f8b\u8c31\uff08\u5176\u4e2da>b>1\uff09\uff0c\u5219\u591a\u904dSGD\u7684\u6d4b\u8bd5\u8bef\u5dee\u4e3a\u0398(M^(1-b) + L^((1-b)/a))\uff0c\u5176\u4e2dL\u4e0eN^(a/b)\u6210\u6bd4\u4f8b\uff0c\u662f\u8fed\u4ee3\u6b21\u6570\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0c\u5355\u904dSGD\u53ea\u80fd\u8fbe\u5230\u0398(M^(1-b) + N^((1-b)/a))\u7684\u6d4b\u8bd5\u8bef\u5dee\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u9009\u62e9L>N\uff08\u5373\u8fdb\u884c\u6570\u636e\u91cd\u7528\uff09\uff0c\u5728\u6570\u636e\u53d7\u9650\u60c5\u51b5\u4e0b\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6539\u8fdb\u7684\u7f29\u653e\u5b9a\u5f8b\u3002\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u4e86\u7406\u8bba\u53d1\u73b0\u3002", "conclusion": "\u6570\u636e\u91cd\u7528\u80fd\u591f\u6709\u6548\u6539\u5584\u7ebf\u6027\u56de\u5f52\u4e2d\u73b0\u6709\u7684\u795e\u7ecf\u7f29\u653e\u5b9a\u5f8b\uff0c\u5c24\u5176\u662f\u5728\u6570\u636e\u53d7\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u8fd9\u4e3a\u4f18\u5316\u6a21\u578b\u8bad\u7ec3\u7b56\u7565\u63d0\u4f9b\u4e86\u65b0\u7684\u601d\u8def\u3002"}}
{"id": "2506.08074", "pdf": "https://arxiv.org/pdf/2506.08074", "abs": "https://arxiv.org/abs/2506.08074", "authors": ["Abdellah Ghassel", "Ian Robinson", "Gabriel Tanase", "Hal Cooper", "Bryan Thompson", "Zhen Han", "Vassilis N. Ioannidis", "Soji Adeshina", "Huzefa Rangwala"], "title": "Hierarchical Lexical Graph for Enhanced Multi-Hop Retrieval", "categories": ["cs.IR", "cs.AI", "cs.CL"], "comment": "KDD '25", "summary": "Retrieval-Augmented Generation (RAG) grounds large language models in\nexternal evidence, yet it still falters when answers must be pieced together\nacross semantically distant documents. We close this gap with the Hierarchical\nLexical Graph (HLG), a three-tier index that (i) traces every atomic\nproposition to its source, (ii) clusters propositions into latent topics, and\n(iii) links entities and relations to expose cross-document paths. On top of\nHLG we build two complementary, plug-and-play retrievers: StatementGraphRAG,\nwhich performs fine-grained entity-aware beam search over propositions for\nhigh-precision factoid questions, and TopicGraphRAG, which selects coarse\ntopics before expanding along entity links to supply broad yet relevant context\nfor exploratory queries. Additionally, existing benchmarks lack the complexity\nrequired to rigorously evaluate multi-hop summarization systems, often focusing\non single-document queries or limited datasets. To address this, we introduce a\nsynthetic dataset generation pipeline that curates realistic, multi-document\nquestion-answer pairs, enabling robust evaluation of multi-hop retrieval\nsystems. Extensive experiments across five datasets demonstrate that our\nmethods outperform naive chunk-based RAG achieving an average relative\nimprovement of 23.1% in retrieval recall and correctness. Open-source Python\nlibrary is available at https://github.com/awslabs/graphrag-toolkit.", "AI": {"tldr": "The paper introduces Hierarchical Lexical Graph (HLG) and two retrievers, StatementGraphRAG and TopicGraphRAG, to enhance Retrieval-Augmented Generation (RAG) systems. It also presents a synthetic dataset generation pipeline for evaluating multi-hop summarization systems.", "motivation": "Current RAG models struggle with answers that require information from semantically distant documents. To address this, the authors propose HLG as a three-tier index system.", "method": "1. Developed HLG which traces propositions to sources, clusters them into topics, and links entities.\n2. Built two retrievers: StatementGraphRAG for high-precision questions and TopicGraphRAG for exploratory queries.\n3. Created a synthetic dataset generation pipeline for robust evaluation of multi-hop retrieval systems.", "result": "Extensive experiments show an average relative improvement of 23.1% in retrieval recall and correctness across five datasets compared to naive chunk-based RAG.", "conclusion": "The proposed methods outperform existing RAG approaches, and an open-source library is available."}}
{"id": "2506.08417", "pdf": "https://arxiv.org/pdf/2506.08417", "abs": "https://arxiv.org/abs/2506.08417", "authors": ["Qingmao Yao", "Zhichao Lei", "Tianyuan Chen", "Ziyue Yuan", "Xuefan Chen", "Jianxiang Liu", "Faguo Wu", "Xiao Zhang"], "title": "Offline RL with Smooth OOD Generalization in Convex Hull and its Neighborhood", "categories": ["cs.LG", "cs.AI"], "comment": "ICLR 2025", "summary": "Offline Reinforcement Learning (RL) struggles with distributional shifts,\nleading to the $Q$-value overestimation for out-of-distribution (OOD) actions.\nExisting methods address this issue by imposing constraints; however, they\noften become overly conservative when evaluating OOD regions, which constrains\nthe $Q$-function generalization. This over-constraint issue results in poor\n$Q$-value estimation and hinders policy improvement. In this paper, we\nintroduce a novel approach to achieve better $Q$-value estimation by enhancing\n$Q$-function generalization in OOD regions within Convex Hull and its\nNeighborhood (CHN). Under the safety generalization guarantees of the CHN, we\npropose the Smooth Bellman Operator (SBO), which updates OOD $Q$-values by\nsmoothing them with neighboring in-sample $Q$-values. We theoretically show\nthat SBO approximates true $Q$-values for both in-sample and OOD actions within\nthe CHN. Our practical algorithm, Smooth Q-function OOD Generalization (SQOG),\nempirically alleviates the over-constraint issue, achieving near-accurate\n$Q$-value estimation. On the D4RL benchmarks, SQOG outperforms existing\nstate-of-the-art methods in both performance and computational efficiency.", "AI": {"tldr": "This paper proposes Smooth Bellman Operator (SBO) and Smooth Q-function OOD Generalization (SQOG) to enhance Q-function generalization in offline Reinforcement Learning, leading to better Q-value estimation and policy improvement.", "motivation": "Offline RL faces challenges with distributional shifts causing Q-value overestimation for out-of-distribution actions. Current methods addressing this issue become overly conservative when evaluating OOD regions, which restricts the Q-function generalization.", "method": "The authors introduce SBO which updates OOD Q-values by smoothing them with neighboring in-sample Q-values under Convex Hull and its Neighborhood guarantees. They also present SQOG as a practical algorithm that alleviates the over-constraint issue.", "result": "SQOG achieves near-accurate Q-value estimation and outperforms existing state-of-the-art methods on D4RL benchmarks in both performance and computational efficiency.", "conclusion": "The proposed SBO and SQOG improve Q-function generalization in OOD regions, resulting in better Q-value estimation and policy enhancement."}}
{"id": "2506.08419", "pdf": "https://arxiv.org/pdf/2506.08419", "abs": "https://arxiv.org/abs/2506.08419", "authors": ["Ruichen Jiang", "Ali Kavis", "Aryan Mokhtari"], "title": "Online Learning-guided Learning Rate Adaptation via Gradient Alignment", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "24 pages, 5 figures", "summary": "The performance of an optimizer on large-scale deep learning models depends\ncritically on fine-tuning the learning rate, often requiring an extensive grid\nsearch over base learning rates, schedules, and other hyperparameters. In this\npaper, we propose a principled framework called GALA (Gradient Alignment-based\nLearning rate Adaptation), which dynamically adjusts the learning rate by\ntracking the alignment between consecutive gradients and using a local\ncurvature estimate. Guided by the convergence analysis, we formulate the\nproblem of selecting the learning rate as a one-dimensional online learning\nproblem. When paired with an online learning algorithm such as\nFollow-the-Regularized-Leader, our method produces a flexible, adaptive\nlearning rate schedule that tends to increase when consecutive gradients are\naligned and decrease otherwise. We establish a data-adaptive convergence rate\nfor normalized SGD equipped with GALA in the smooth, nonconvex setting.\nEmpirically, common optimizers such as SGD and Adam, when augmented with GALA,\ndemonstrate robust performance across a wide range of initial learning rates\nand perform competitively without the need for tuning.", "AI": {"tldr": "This paper introduces GALA, a framework that dynamically adjusts learning rates for optimizers in deep learning models by tracking gradient alignment and local curvature. It formulates learning rate selection as an online learning problem and demonstrates robust performance with SGD and Adam optimizers across various initial learning rates without tuning.", "motivation": "The motivation of this paper is to address the challenge of fine-tuning learning rates for optimizers in large-scale deep learning models, which often requires extensive grid search over multiple hyperparameters.", "method": "The method proposed is called GALA (Gradient Alignment-based Learning rate Adaptation), which dynamically adjusts the learning rate by tracking the alignment between consecutive gradients and using a local curvature estimate. It formulates the problem of selecting the learning rate as a one-dimensional online learning problem paired with algorithms such as Follow-the-Regularized-Leader.", "result": "GALA establishes a data-adaptive convergence rate for normalized SGD in smooth, nonconvex settings. Empirical results show that optimizers like SGD and Adam augmented with GALA demonstrate robust performance across a wide range of initial learning rates without the need for tuning.", "conclusion": "GALA provides a principled framework to adaptively adjust learning rates, reducing the need for extensive hyperparameter tuning and demonstrating competitive performance with common optimizers."}}
{"id": "2506.08137", "pdf": "https://arxiv.org/pdf/2506.08137", "abs": "https://arxiv.org/abs/2506.08137", "authors": ["Oishee Bintey Hoque", "Abhijin Adiga", "Aniruddha Adiga", "Siddharth Chaudhary", "Madhav V. Marathe", "S. S. Ravi", "Kirti Rajagopalan", "Amanda Wilson", "Samarth Swarup"], "title": "IGraSS: Learning to Identify Infrastructure Networks from Satellite Imagery by Iterative Graph-constrained Semantic Segmentation", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Accurate canal network mapping is essential for water management, including\nirrigation planning and infrastructure maintenance. State-of-the-art semantic\nsegmentation models for infrastructure mapping, such as roads, rely on large,\nwell-annotated remote sensing datasets. However, incomplete or inadequate\nground truth can hinder these learning approaches. Many infrastructure networks\nhave graph-level properties such as reachability to a source (like canals) or\nconnectivity (roads) that can be leveraged to improve these existing ground\ntruth. This paper develops a novel iterative framework IGraSS, combining a\nsemantic segmentation module-incorporating RGB and additional modalities (NDWI,\nDEM)-with a graph-based ground-truth refinement module. The segmentation module\nprocesses satellite imagery patches, while the refinement module operates on\nthe entire data viewing the infrastructure network as a graph. Experiments show\nthat IGraSS reduces unreachable canal segments from around 18% to 3%, and\ntraining with refined ground truth significantly improves canal identification.\nIGraSS serves as a robust framework for both refining noisy ground truth and\nmapping canal networks from remote sensing imagery. We also demonstrate the\neffectiveness and generalizability of IGraSS using road networks as an example,\napplying a different graph-theoretic constraint to complete road networks.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u7ed3\u5408\u8bed\u4e49\u5206\u5272\u548c\u56fe\u4f18\u5316\u7684\u8fed\u4ee3\u6846\u67b6IGraSS\uff0c\u7528\u4e8e\u6539\u8fdb\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\uff08\u5982\u8fd0\u6cb3\u548c\u9053\u8def\uff09\u7684\u5730\u56fe\u7ed8\u5236\u548c\u5730\u9762\u771f\u503c\u7cbe\u5316\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u6cb3\u548c\u9053\u8def\u7f51\u7edc\u7684\u6620\u5c04\u51c6\u786e\u6027\u3002", "motivation": "\u51c6\u786e\u7684\u8fd0\u6cb3\u7f51\u7edc\u5730\u56fe\u5bf9\u4e8e\u6c34\u8d44\u6e90\u7ba1\u7406\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u57fa\u4e8e\u5927\u89c4\u6a21\u6ce8\u91ca\u6570\u636e\u96c6\u7684\u8bed\u4e49\u5206\u5272\u6a21\u578b\u53d7\u9650\u4e8e\u4e0d\u5b8c\u6574\u6216\u4e0d\u8db3\u7684\u5730\u9762\u771f\u503c\u3002\u5229\u7528\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u7684\u56fe\u7ea7\u5c5e\u6027\uff08\u5982\u53ef\u8fbe\u6027\u548c\u8fde\u901a\u6027\uff09\u53ef\u4ee5\u6539\u5584\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u8fed\u4ee3\u6846\u67b6IGraSS\uff0c\u5c06\u8bed\u4e49\u5206\u5272\u6a21\u5757\uff08\u7ed3\u5408RGB\u3001NDWI\u548cDEM\u6a21\u6001\uff09\u4e0e\u57fa\u4e8e\u56fe\u7684\u5730\u9762\u771f\u503c\u7cbe\u5316\u6a21\u5757\u76f8\u7ed3\u5408\u3002\u8bed\u4e49\u5206\u5272\u6a21\u5757\u5904\u7406\u536b\u661f\u56fe\u50cf\u5757\uff0c\u800c\u7cbe\u5316\u6a21\u5757\u5c06\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\u89c6\u4e3a\u56fe\u8fdb\u884c\u64cd\u4f5c\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cIGraSS\u5c06\u4e0d\u53ef\u8fbe\u8fd0\u6cb3\u6bb5\u7684\u6bd4\u4f8b\u4ece18%\u964d\u4f4e\u52303%\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u8fd0\u6cb3\u8bc6\u522b\u80fd\u529b\u3002\u6b64\u5916\uff0c\u8be5\u6846\u67b6\u5728\u9053\u8def\u7f51\u7edc\u4e2d\u4e5f\u8868\u73b0\u51fa\u6709\u6548\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "IGraSS\u662f\u4e00\u4e2a\u5f3a\u5927\u7684\u6846\u67b6\uff0c\u53ef\u7528\u4e8e\u7cbe\u5316\u566a\u58f0\u5730\u9762\u771f\u503c\u5e76\u4ece\u9065\u611f\u5f71\u50cf\u4e2d\u7ed8\u5236\u8fd0\u6cb3\u7f51\u7edc\uff0c\u540c\u65f6\u5177\u6709\u826f\u597d\u7684\u901a\u7528\u6027\uff0c\u9002\u7528\u4e8e\u5176\u4ed6\u57fa\u7840\u8bbe\u65bd\u7f51\u7edc\uff08\u5982\u9053\u8def\uff09\u3002"}}
{"id": "2506.08426", "pdf": "https://arxiv.org/pdf/2506.08426", "abs": "https://arxiv.org/abs/2506.08426", "authors": ["Zheng Lin", "Zhe Chen", "Xianhao Chen", "Wei Ni", "Yue Gao"], "title": "HASFL: Heterogeneity-aware Split Federated Learning over Edge Computing Systems", "categories": ["cs.LG", "cs.AI", "cs.DC"], "comment": "16 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:2403.13101", "summary": "Split federated learning (SFL) has emerged as a promising paradigm to\ndemocratize machine learning (ML) on edge devices by enabling layer-wise model\npartitioning. However, existing SFL approaches suffer significantly from the\nstraggler effect due to the heterogeneous capabilities of edge devices. To\naddress the fundamental challenge, we propose adaptively controlling batch\nsizes (BSs) and model splitting (MS) for edge devices to overcome resource\nheterogeneity. We first derive a tight convergence bound of SFL that quantifies\nthe impact of varied BSs and MS on learning performance. Based on the\nconvergence bound, we propose HASFL, a heterogeneity-aware SFL framework\ncapable of adaptively controlling BS and MS to balance communication-computing\nlatency and training convergence in heterogeneous edge networks. Extensive\nexperiments with various datasets validate the effectiveness of HASFL and\ndemonstrate its superiority over state-of-the-art benchmarks.", "AI": {"tldr": "HASFL is a heterogeneity-aware split federated learning framework that adaptively controls batch sizes and model splitting to balance communication-computing latency and training convergence in heterogeneous edge networks.", "motivation": "Existing split federated learning approaches suffer from the straggler effect due to the heterogeneous capabilities of edge devices.", "method": "Propose HASFL which derives a tight convergence bound of SFL and then uses this bound to adaptively control batch sizes and model splitting for edge devices.", "result": "Extensive experiments with various datasets validate the effectiveness of HASFL and demonstrate its superiority over state-of-the-art benchmarks.", "conclusion": "HASFL can effectively address the resource heterogeneity challenge in split federated learning on edge devices."}}
{"id": "2506.08147", "pdf": "https://arxiv.org/pdf/2506.08147", "abs": "https://arxiv.org/abs/2506.08147", "authors": ["Muhammad Usman", "Muhammad Ahmad", "M. Shahiki Tash", "Irina Gelbukh", "Rolando Quintero Tellez", "Grigori Sidorov"], "title": "Multilingual Hate Speech Detection in Social Media Using Translation-Based Approaches with Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Social media platforms are critical spaces for public discourse, shaping\nopinions and community dynamics, yet their widespread use has amplified harmful\ncontent, particularly hate speech, threatening online safety and inclusivity.\nWhile hate speech detection has been extensively studied in languages like\nEnglish and Spanish, Urdu remains underexplored, especially using\ntranslation-based approaches. To address this gap, we introduce a trilingual\ndataset of 10,193 tweets in English (3,834 samples), Urdu (3,197 samples), and\nSpanish (3,162 samples), collected via keyword filtering, with a balanced\ndistribution of 4,849 Hateful and 5,344 Not-Hateful labels. Our methodology\nleverages attention layers as a precursor to transformer-based models and large\nlanguage models (LLMs), enhancing feature extraction for multilingual hate\nspeech detection. For non-transformer models, we use TF-IDF for feature\nextraction. The dataset is benchmarked using state-of-the-art models, including\nGPT-3.5 Turbo and Qwen 2.5 72B, alongside traditional machine learning models\nlike SVM and other transformers (e.g., BERT, RoBERTa). Three annotators,\nfollowing rigorous guidelines, ensured high dataset quality, achieving a\nFleiss' Kappa of 0.821. Our approach, integrating attention layers with GPT-3.5\nTurbo and Qwen 2.5 72B, achieves strong performance, with macro F1 scores of\n0.87 for English (GPT-3.5 Turbo), 0.85 for Spanish (GPT-3.5 Turbo), 0.81 for\nUrdu (Qwen 2.5 72B), and 0.88 for the joint multilingual model (Qwen 2.5 72B).\nThese results reflect improvements of 8.75% in English (over SVM baseline\n0.80), 8.97% in Spanish (over SVM baseline 0.78), 5.19% in Urdu (over SVM\nbaseline 0.77), and 7.32% in the joint multilingual model (over SVM baseline\n0.82). Our framework offers a robust solution for multilingual hate speech\ndetection, fostering safer digital communities worldwide.", "AI": {"tldr": "The paper presents a trilingual dataset for hate speech detection in English, Urdu, and Spanish, using advanced models like GPT-3.5 Turbo and Qwen 2.5 72B. It achieves significant performance improvements over traditional methods.", "motivation": "To address the lack of research on hate speech detection in Urdu and improve multilingual hate speech detection overall, especially using translation-based approaches.", "method": "Created a trilingual dataset with balanced labels, used attention layers before transformer/LLM models, applied TF-IDF for non-transformer models, and benchmarked with state-of-the-art models including GPT-3.5 Turbo and Qwen 2.5 72B.", "result": "Achieved macro F1 scores of 0.87 for English, 0.85 for Spanish, 0.81 for Urdu, and 0.88 for the joint multilingual model, showing substantial improvements over baselines.", "conclusion": "The proposed framework provides an effective solution for multilingual hate speech detection, promoting safer online environments."}}
{"id": "2506.08438", "pdf": "https://arxiv.org/pdf/2506.08438", "abs": "https://arxiv.org/abs/2506.08438", "authors": ["Yuchen Wu", "Xinyi Zhong", "Zhuoran Yang"], "title": "Learning to Lead: Incentivizing Strategic Agents in the Dark", "categories": ["cs.LG", "cs.GT", "stat.ML"], "comment": "81 pages, 7 figures", "summary": "We study an online learning version of the generalized principal-agent model,\nwhere a principal interacts repeatedly with a strategic agent possessing\nprivate types, private rewards, and taking unobservable actions. The agent is\nnon-myopic, optimizing a discounted sum of future rewards and may strategically\nmisreport types to manipulate the principal's learning. The principal,\nobserving only her own realized rewards and the agent's reported types, aims to\nlearn an optimal coordination mechanism that minimizes strategic regret. We\ndevelop the first provably sample-efficient algorithm for this challenging\nsetting. Our approach features a novel pipeline that combines (i) a delaying\nmechanism to incentivize approximately myopic agent behavior, (ii) an\ninnovative reward angle estimation framework that uses sector tests and a\nmatching procedure to recover type-dependent reward functions, and (iii) a\npessimistic-optimistic LinUCB algorithm that enables the principal to explore\nefficiently while respecting the agent's incentive constraints. We establish a\nnear optimal $\\tilde{O}(\\sqrt{T}) $ regret bound for learning the principal's\noptimal policy, where $\\tilde{O}(\\cdot) $ omits logarithmic factors. Our\nresults open up new avenues for designing robust online learning algorithms for\na wide range of game-theoretic settings involving private types and strategic\nagents.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e00\u4e2a\u5728\u7ebf\u5b66\u4e60\u7248\u672c\u7684\u5e7f\u4e49\u59d4\u6258\u4ee3\u7406\u6a21\u578b\uff0c\u63d0\u51fa\u4e86\u9996\u4e2a\u53ef\u8bc1\u660e\u6837\u672c\u9ad8\u6548\u7684\u7b97\u6cd5\uff0c\u5efa\u7acb\u4e86\u63a5\u8fd1\u6700\u4f18\u7684$\\tilde{O}(\\sqrt{T}) $\u9057\u61be\u754c\u9650\uff0c\u4e3a\u6d89\u53ca\u79c1\u4eba\u7c7b\u578b\u548c\u6218\u7565\u6027\u4ee3\u7406\u4eba\u7684\u535a\u5f08\u8bba\u8bbe\u7f6e\u8bbe\u8ba1\u7a33\u5065\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002", "motivation": "\u5728\u5e7f\u4e49\u59d4\u6258\u4ee3\u7406\u6a21\u578b\u4e2d\uff0c\u59d4\u6258\u4eba\u4e0e\u5177\u6709\u79c1\u4eba\u7c7b\u578b\u3001\u79c1\u4eba\u5956\u52b1\u548c\u91c7\u53d6\u4e0d\u53ef\u89c2\u5bdf\u884c\u52a8\u7684\u6218\u7565\u6027\u4ee3\u7406\u4eba\u53cd\u590d\u4e92\u52a8\u3002\u4ee3\u7406\u4eba\u4f1a\u6218\u7565\u6027\u5730\u9519\u8bef\u62a5\u544a\u7c7b\u578b\u4ee5\u64cd\u7eb5\u59d4\u6258\u4eba\u7684\u5b66\u4e60\uff0c\u800c\u59d4\u6258\u4eba\u53ea\u80fd\u89c2\u5bdf\u5230\u5979\u81ea\u5df1\u7684\u5b9e\u73b0\u5956\u52b1\u548c\u4ee3\u7406\u4eba\u7684\u62a5\u544a\u7c7b\u578b\uff0c\u76ee\u6807\u662f\u5b66\u4e60\u4e00\u4e2a\u6700\u4f73\u534f\u8c03\u673a\u5236\u4ee5\u6700\u5c0f\u5316\u6218\u7565\u9057\u61be\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a(i) \u5ef6\u8fdf\u673a\u5236\u4ee5\u6fc0\u52b1\u8fd1\u4f3c\u77ed\u89c6\u7684\u4ee3\u7406\u884c\u4e3a\uff1b(ii) \u521b\u65b0\u7684\u5956\u52b1\u89d2\u5ea6\u4f30\u8ba1\u6846\u67b6\uff0c\u4f7f\u7528\u6247\u533a\u6d4b\u8bd5\u548c\u5339\u914d\u7a0b\u5e8f\u6765\u6062\u590d\u7c7b\u578b\u4f9d\u8d56\u7684\u5956\u52b1\u51fd\u6570\uff1b(iii) \u60b2\u89c2\u4e50\u89c2\u7684LinUCB\u7b97\u6cd5\uff0c\u4f7f\u59d4\u6258\u4eba\u80fd\u591f\u6709\u6548\u63a2\u7d22\u540c\u65f6\u5c0a\u91cd\u4ee3\u7406\u4eba\u7684\u6fc0\u52b1\u7ea6\u675f\u3002", "result": "\u5efa\u7acb\u4e86\u63a5\u8fd1\u6700\u4f18\u7684$\\tilde{O}(\\sqrt{T}) $\u9057\u61be\u754c\u9650\uff0c\u4e3a\u5b66\u4e60\u59d4\u6258\u4eba\u7684\u6700\u4f73\u7b56\u7565\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002", "conclusion": "\u8be5\u7ed3\u679c\u4e3a\u8bbe\u8ba1\u7a33\u5065\u7684\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\uff0c\u5e94\u7528\u4e8e\u6d89\u53ca\u79c1\u4eba\u7c7b\u578b\u548c\u6218\u7565\u6027\u4ee3\u7406\u4eba\u7684\u5e7f\u6cdb\u535a\u5f08\u8bba\u8bbe\u7f6e\u5f00\u8f9f\u4e86\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2506.08149", "pdf": "https://arxiv.org/pdf/2506.08149", "abs": "https://arxiv.org/abs/2506.08149", "authors": ["Hang Wang", "Dechen Gao", "Junshan Zhang"], "title": "Ego-centric Learning of Communicative World Models for Autonomous Driving", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "We study multi-agent reinforcement learning (MARL) for tasks in complex\nhigh-dimensional environments, such as autonomous driving. MARL is known to\nsuffer from the \\textit{partial observability} and \\textit{non-stationarity}\nissues. To tackle these challenges, information sharing is often employed,\nwhich however faces major hurdles in practice, including overwhelming\ncommunication overhead and scalability concerns. By making use of generative AI\nembodied in world model together with its latent representation, we develop\n{\\it CALL}, \\underline{C}ommunic\\underline{a}tive Wor\\underline{l}d\nMode\\underline{l}, for MARL, where 1) each agent first learns its world model\nthat encodes its state and intention into low-dimensional latent representation\nwith smaller memory footprint, which can be shared with other agents of\ninterest via lightweight communication; and 2) each agent carries out\nego-centric learning while exploiting lightweight information sharing to enrich\nher world model, and then exploits its generalization capacity to improve\nprediction for better planning. We characterize the gain on the prediction\naccuracy from the information sharing and its impact on performance gap.\nExtensive experiments are carried out on the challenging local trajectory\nplanning tasks in the CARLA platform to demonstrate the performance gains of\nusing \\textit{CALL}.", "AI": {"tldr": "The paper introduces CALL, a new method for multi-agent reinforcement learning (MARL) that uses world models and latent representations to enable efficient information sharing among agents, improving performance in complex tasks like autonomous driving.", "motivation": "MARL faces challenges such as partial observability and non-stationarity in high-dimensional environments. Current information-sharing methods have issues with communication overhead and scalability.", "method": "CALL allows each agent to learn a world model that encodes its state and intention into a low-dimensional latent representation. This can be shared with other agents through lightweight communication. Agents perform ego-centric learning while using this shared information to enhance their world models and improve prediction accuracy.", "result": "Experiments on the CARLA platform show that CALL improves prediction accuracy and reduces the performance gap in local trajectory planning tasks.", "conclusion": "CALL addresses the challenges of MARL by enabling efficient information sharing through world models and latent representations, leading to improved performance in complex tasks."}}
{"id": "2506.08441", "pdf": "https://arxiv.org/pdf/2506.08441", "abs": "https://arxiv.org/abs/2506.08441", "authors": ["Anh N. Nhu", "Sanghyun Son", "Ming Lin"], "title": "Time-Aware World Model for Adaptive Prediction and Control", "categories": ["cs.LG", "cs.AI", "cs.SY", "eess.SY"], "comment": "Paper accepted to ICML 2025", "summary": "In this work, we introduce the Time-Aware World Model (TAWM), a model-based\napproach that explicitly incorporates temporal dynamics. By conditioning on the\ntime-step size, {\\Delta}t, and training over a diverse range of {\\Delta}t\nvalues -- rather than sampling at a fixed time-step -- TAWM learns both high-\nand low-frequency task dynamics across diverse control problems. Grounded in\nthe information-theoretic insight that the optimal sampling rate depends on a\nsystem's underlying dynamics, this time-aware formulation improves both\nperformance and data efficiency. Empirical evaluations show that TAWM\nconsistently outperforms conventional models across varying observation rates\nin a variety of control tasks, using the same number of training samples and\niterations. Our code can be found online at:\ngithub.com/anh-nn01/Time-Aware-World-Model.", "AI": {"tldr": "This paper introduces Time-Aware World Model (TAWM), which incorporates temporal dynamics by conditioning on time-step size and training across diverse \u0394t values. It enhances performance and data efficiency in control problems, outperforming conventional models under varying observation rates.", "motivation": "The motivation of this work is to improve the performance and data efficiency in learning control tasks by explicitly incorporating temporal dynamics into world models. This addresses limitations of conventional models that often use a fixed time-step, ignoring the varying optimal sampling rates for different system dynamics.", "method": "The method involves developing TAWM, a model-based approach that conditions on the time-step size (\u0394t) and trains over a diverse range of \u0394t values instead of using a fixed time-step. This allows the model to learn both high- and low-frequency task dynamics, leveraging an information-theoretic insight about the relationship between optimal sampling rate and system's underlying dynamics.", "result": "Empirical evaluations demonstrate that TAWM consistently outperforms conventional models across different observation rates in various control tasks, while using the same number of training samples and iterations.", "conclusion": "TAWM improves both performance and data efficiency in learning control tasks by incorporating temporal dynamics through conditioning on time-step size. The model outperforms traditional approaches across varying observation rates."}}
{"id": "2506.08153", "pdf": "https://arxiv.org/pdf/2506.08153", "abs": "https://arxiv.org/abs/2506.08153", "authors": ["Renato Cordeiro Ferreira"], "title": "A Metrics-Oriented Architectural Model to Characterize Complexity on Machine Learning-Enabled Systems", "categories": ["cs.SE", "cs.AI", "cs.LG", "D.2.11; D.2.8; I.2.0"], "comment": "4 pages, 3 figures (2 diagrams, 1 table), to be published in CAIN\n  2025", "summary": "How can the complexity of ML-enabled systems be managed effectively? The goal\nof this research is to investigate how complexity affects ML-Enabled Systems\n(MLES). To address this question, this research aims to introduce a\nmetrics-based architectural model to characterize the complexity of MLES. The\ngoal is to support architectural decisions, providing a guideline for the\ninception and growth of these systems. This paper showcases the first step for\ncreating the metrics-based architectural model: an extension of a reference\narchitecture that can describe MLES to collect their metrics.", "AI": {"tldr": "The paper explores how to manage the complexity of ML-enabled systems by introducing a metrics-based architectural model, starting with an extension of a reference architecture for collecting metrics.", "motivation": "To investigate how complexity affects ML-Enabled Systems and manage their complexity effectively.", "method": "Introducing a metrics-based architectural model to characterize the complexity of ML-Enabled Systems, beginning with extending a reference architecture to collect metrics.", "result": "Showcased the first step in creating the metrics-based architectural model, which is the extension of a reference architecture for collecting metrics on ML-Enabled Systems.", "conclusion": "This research aims to support architectural decisions and provide guidelines for the development and growth of ML-Enabled Systems through a metrics-based architectural model."}}
{"id": "2506.08460", "pdf": "https://arxiv.org/pdf/2506.08460", "abs": "https://arxiv.org/abs/2506.08460", "authors": ["Yihong Guo", "Yu Yang", "Pan Xu", "Anqi Liu"], "title": "MOBODY: Model Based Off-Dynamics Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": null, "summary": "We study the off-dynamics offline reinforcement learning problem, where the\ngoal is to learn a policy from offline datasets collected from source and\ntarget domains with mismatched transition. Existing off-dynamics offline RL\nmethods typically either filter source transitions that resemble those of the\ntarget domain or apply reward augmentation to source data, both constrained by\nthe limited transitions available from the target domain. As a result, the\nlearned policy is unable to explore target domain beyond the offline datasets.\nWe propose MOBODY, a Model-Based Off-Dynamics offline RL algorithm that\naddresses this limitation by enabling exploration of the target domain via\nlearned dynamics. MOBODY generates new synthetic transitions in the target\ndomain through model rollouts, which are used as data augmentation during\noffline policy learning. Unlike existing model-based methods that learn\ndynamics from a single domain, MOBODY tackles the challenge of mismatched\ndynamics by leveraging both source and target datasets. Directly merging these\ndatasets can bias the learned model toward source dynamics. Instead, MOBODY\nlearns target dynamics by discovering a shared latent representation of states\nand transitions across domains through representation learning. To stabilize\ntraining, MOBODY incorporates a behavior cloning loss that regularizes the\npolicy. Specifically, we introduce a Q-weighted behavior cloning loss that\nregularizes the policy toward actions with high target-domain Q-values, rather\nthan uniformly imitating all actions in the dataset. These Q-values are learned\nfrom an enhanced target dataset composed of offline target data, augmented\nsource data, and rollout data from the learned target dynamics. We evaluate\nMOBODY on MuJoCo benchmarks and show that it significantly outperforms\nstate-of-the-art baselines, with especially pronounced improvements in\nchallenging scenarios.", "AI": {"tldr": "MOBODY is a Model-Based Off-Dynamics offline RL algorithm that enables exploration of the target domain beyond offline datasets by generating new synthetic transitions through model rollouts. It learns target dynamics by discovering a shared latent representation and incorporates a Q-weighted behavior cloning loss to stabilize training.", "motivation": "Existing off-dynamics offline RL methods are limited in their ability to explore the target domain beyond the available offline datasets due to constraints such as filtering source transitions or applying reward augmentation based on limited target domain transitions.", "method": "MOBODY generates new synthetic transitions in the target domain via model rollouts for data augmentation during offline policy learning. It avoids bias towards source dynamics by discovering a shared latent representation of states and transitions across domains through representation learning, rather than directly merging datasets. Additionally, it incorporates a Q-weighted behavior cloning loss to regularize the policy towards actions with high target-domain Q-values.", "result": "MOBODY significantly outperforms state-of-the-art baselines on MuJoCo benchmarks, particularly showing pronounced improvements in challenging scenarios.", "conclusion": "MOBODY addresses the limitation of existing methods by enabling exploration beyond offline datasets and effectively handling mismatched dynamics through its unique approach of shared latent representation learning and Q-weighted behavior cloning."}}
{"id": "2506.08463", "pdf": "https://arxiv.org/pdf/2506.08463", "abs": "https://arxiv.org/abs/2506.08463", "authors": ["Zhishuai Liu", "Yu Yang", "Ruhan Wang", "Pan Xu", "Dongruo Zhou"], "title": "How to Provably Improve Return Conditioned Supervised Learning?", "categories": ["cs.LG", "cs.AI", "cs.RO"], "comment": "25 pages, 4 figures, 12 tables", "summary": "In sequential decision-making problems, Return-Conditioned Supervised\nLearning (RCSL) has gained increasing recognition for its simplicity and\nstability in modern decision-making tasks. Unlike traditional offline\nreinforcement learning (RL) algorithms, RCSL frames policy learning as a\nsupervised learning problem by taking both the state and return as input. This\napproach eliminates the instability often associated with temporal difference\n(TD) learning in offline RL. However, RCSL has been criticized for lacking the\nstitching property, meaning its performance is inherently limited by the\nquality of the policy used to generate the offline dataset. To address this\nlimitation, we propose a principled and simple framework called Reinforced\nRCSL. The key innovation of our framework is the introduction of a concept we\ncall the in-distribution optimal return-to-go. This mechanism leverages our\npolicy to identify the best achievable in-dataset future return based on the\ncurrent state, avoiding the need for complex return augmentation techniques.\nOur theoretical analysis demonstrates that Reinforced RCSL can consistently\noutperform the standard RCSL approach. Empirical results further validate our\nclaims, showing significant performance improvements across a range of\nbenchmarks.", "AI": {"tldr": "In sequential decision-making, RCSL is a stable method but limited by dataset quality. Reinforced RCSL introduces in-distribution optimal return-to-go to overcome this, outperforming standard RCSL theoretically and empirically.", "motivation": "RCSL is recognized for its simplicity and stability in decision-making tasks, but it lacks the stitching property, limiting its performance by the quality of the policy used to generate the offline dataset.", "method": "Propose Reinforced RCSL with the introduction of in-distribution optimal return-to-go, which leverages the policy to identify the best achievable in-dataset future return based on the current state.", "result": "Theoretical analysis shows Reinforced RCSL consistently outperforms standard RCSL. Empirical results validate significant performance improvements across benchmarks.", "conclusion": "Reinforced RCSL addresses the limitation of RCSL by introducing in-distribution optimal return-to-go, leading to better performance."}}
{"id": "2506.08171", "pdf": "https://arxiv.org/pdf/2506.08171", "abs": "https://arxiv.org/abs/2506.08171", "authors": ["Daniel Koh", "Yannic Noller", "Corina S. Pasareanu", "Adrians Skapars", "Youcheng Sun"], "title": "Worst-Case Symbolic Constraints Analysis and Generalisation with Large Language Models", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have been successfully applied to a variety of\ncoding tasks, including code generation, completion, and repair. However, more\ncomplex symbolic reasoning tasks remain largely unexplored by LLMs. This paper\ninvestigates the capacity of LLMs to reason about worst-case executions in\nprograms through symbolic constraints analysis, aiming to connect LLMs and\nsymbolic reasoning approaches. Specifically, we define and address the problem\nof worst-case symbolic constraints analysis as a measure to assess the\ncomprehension of LLMs. We evaluate the performance of existing LLMs on this\nnovel task and further improve their capabilities through symbolic\nreasoning-guided fine-tuning, grounded in SMT (Satisfiability Modulo Theories)\nconstraint solving and supported by a specially designed dataset of symbolic\nconstraints. Experimental results show that our solver-aligned model,\nWARP-1.0-3B, consistently surpasses size-matched and even much larger\nbaselines, demonstrating that a 3B LLM can recover the very constraints that\npin down an algorithm's worst-case behaviour through reinforcement learning\nmethods. These findings suggest that LLMs are capable of engaging in deeper\nsymbolic reasoning, supporting a closer integration between neural\nnetwork-based learning and formal methods for rigorous program analysis.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u4ee3\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u590d\u6742\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u5f00\u53d1\u3002\u672c\u6587\u7814\u7a76\u4e86LLMs\u901a\u8fc7\u7b26\u53f7\u7ea6\u675f\u5206\u6790\u5bf9\u7a0b\u5e8f\u6700\u574f\u60c5\u51b5\u6267\u884c\u8fdb\u884c\u63a8\u7406\u7684\u80fd\u529b\uff0c\u5e76\u901a\u8fc7SMT\u7ea6\u675f\u6c42\u89e3\u548c\u7279\u5b9a\u8bbe\u8ba1\u7684\u6570\u636e\u96c6\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6539\u8fdb\u540e\u7684\u6a21\u578bWARP-1.0-3B\u5728\u8be5\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\uff0c\u8bc1\u660e\u4e86LLMs\u53ef\u4ee5\u6df1\u5165\u53c2\u4e0e\u7b26\u53f7\u63a8\u7406\uff0c\u4e3a\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\u4e0e\u5f62\u5f0f\u5316\u65b9\u6cd5\u7684\u7ed3\u5408\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u591a\u79cd\u7f16\u7801\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5728\u66f4\u590d\u6742\u7684\u7b26\u53f7\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u4ecd\u8f83\u5c11\u63a2\u7d22\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u8bc4\u4f30LLMs\u662f\u5426\u80fd\u591f\u5904\u7406\u6d89\u53ca\u7a0b\u5e8f\u6700\u574f\u60c5\u51b5\u6267\u884c\u7684\u7b26\u53f7\u7ea6\u675f\u5206\u6790\u4efb\u52a1\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u6a21\u578b\u589e\u5f3a\u5176\u7b26\u53f7\u63a8\u7406\u80fd\u529b\u3002", "method": "\u5b9a\u4e49\u4e86\u4e00\u4e2a\u65b0\u7684\u4efb\u52a1\u2014\u2014\u6700\u574f\u60c5\u51b5\u7b26\u53f7\u7ea6\u675f\u5206\u6790\uff0c\u7528\u4e8e\u8bc4\u4f30LLMs\u7684\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff1b\u4f7f\u7528SMT\u7ea6\u675f\u6c42\u89e3\u6280\u672f\uff0c\u5e76\u57fa\u4e8e\u4e13\u95e8\u8bbe\u8ba1\u7684\u7b26\u53f7\u7ea6\u675f\u6570\u636e\u96c6\uff0c\u5bf9LLMs\u8fdb\u884c\u4e86\u7b26\u53f7\u63a8\u7406\u5f15\u5bfc\u7684\u5fae\u8c03\uff1b\u5f00\u53d1\u4e86\u540d\u4e3aWARP-1.0-3B\u7684\u65b0\u6a21\u578b\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u4f7f\u5176\u80fd\u591f\u6062\u590d\u7b97\u6cd5\u7684\u6700\u574f\u60c5\u51b5\u884c\u4e3a\u5bf9\u5e94\u7684\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u7ecf\u8fc7\u5fae\u8c03\u7684WARP-1.0-3B\u6a21\u578b\u5728\u6700\u574f\u60c5\u51b5\u7b26\u53f7\u7ea6\u675f\u5206\u6790\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8d85\u8d8a\u4e86\u89c4\u6a21\u76f8\u5f53\u751a\u81f3\u66f4\u5927\u7684\u57fa\u7ebf\u6a21\u578b\uff0c\u6210\u529f\u6062\u590d\u4e86\u4e0e\u7b97\u6cd5\u6700\u574f\u60c5\u51b5\u884c\u4e3a\u76f8\u5173\u7684\u7ea6\u675f\u6761\u4ef6\u3002\u8fd9\u8868\u660eLLMs\u53ef\u4ee5\u901a\u8fc7\u9002\u5f53\u7684\u8bad\u7ec3\u548c\u4f18\u5316\u5b9e\u73b0\u66f4\u6df1\u5c42\u6b21\u7684\u7b26\u53f7\u63a8\u7406\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0cLLMs\u5177\u5907\u8f83\u5f3a\u7684\u7b26\u53f7\u63a8\u7406\u80fd\u529b\uff0c\u53ef\u4ee5\u5728\u7a0b\u5e8f\u5206\u6790\u4e2d\u7ed3\u5408\u5f62\u5f0f\u5316\u65b9\u6cd5\u548c\u795e\u7ecf\u7f51\u7edc\u5b66\u4e60\uff0c\u4e3a\u4e25\u8c28\u7684\u7a0b\u5e8f\u5206\u6790\u63d0\u4f9b\u652f\u6301\u3002\u8fd9\u4e00\u53d1\u73b0\u4e3a\u672a\u6765\u5c06\u6df1\u5ea6\u5b66\u4e60\u4e0e\u5f62\u5f0f\u5316\u9a8c\u8bc1\u6280\u672f\u76f8\u7ed3\u5408\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2506.08464", "pdf": "https://arxiv.org/pdf/2506.08464", "abs": "https://arxiv.org/abs/2506.08464", "authors": ["Hyunseok Seung", "Jaewoo Lee", "Hyunsuk Ko"], "title": "MAC: An Efficient Gradient Preconditioning using Mean Activation Approximated Curvature", "categories": ["cs.LG"], "comment": null, "summary": "Second-order optimization methods for training neural networks, such as KFAC,\nexhibit superior convergence by utilizing curvature information of loss\nlandscape. However, it comes at the expense of high computational burden. In\nthis work, we analyze the two components that constitute the layer-wise Fisher\ninformation matrix (FIM) used in KFAC: the Kronecker factors related to\nactivations and pre-activation gradients. Based on empirical observations on\ntheir eigenspectra, we propose efficient approximations for them, resulting in\na computationally efficient optimization method called MAC. To the best of our\nknowledge, MAC is the first algorithm to apply the Kronecker factorization to\nthe FIM of attention layers used in transformers and explicitly integrate\nattention scores into the preconditioning. We also study the convergence\nproperty of MAC on nonlinear neural networks and provide two conditions under\nwhich it converges to global minima. Our extensive evaluations on various\nnetwork architectures and datasets show that the proposed method outperforms\nKFAC and other state-of-the-art methods in terms of accuracy, end-to-end\ntraining time, and memory usage. Code is available at\nhttps://github.com/hseung88/mac.", "AI": {"tldr": "This paper proposes MAC, an efficient optimization method that applies Kronecker factorization to the Fisher information matrix (FIM) of attention layers in transformers, and integrates attention scores into preconditioning. It outperforms KFAC and other methods in accuracy, training time, and memory usage.", "motivation": "Second-order optimization methods like KFAC offer superior convergence for neural network training but come with high computational costs. The authors aim to develop a more computationally efficient method.", "method": "The authors analyze the two components of the layer-wise Fisher information matrix (FIM) used in KFAC: Kronecker factors related to activations and pre-activation gradients. They propose efficient approximations based on empirical observations of their eigenspectra, leading to the development of MAC. MAC explicitly integrates attention scores into the preconditioning and applies Kronecker factorization to the FIM of attention layers in transformers.", "result": "MAC outperforms KFAC and other state-of-the-art methods in terms of accuracy, end-to-end training time, and memory usage across various network architectures and datasets.", "conclusion": "MAC is presented as a computationally efficient second-order optimization method for training neural networks, particularly effective for transformer architectures."}}
{"id": "2506.08173", "pdf": "https://arxiv.org/pdf/2506.08173", "abs": "https://arxiv.org/abs/2506.08173", "authors": ["Nguyen Phu Vinh", "Anh Chung Hoang", "Chris Ngo", "Truong-Son Hy"], "title": "Repeton: Structured Bug Repair with ReAct-Guided Patch-and-Test Cycles", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have shown strong capabilities in code\ngeneration and comprehension, yet their application to complex software\nengineering tasks often suffers from low precision and limited\ninterpretability. We present Repeton, a fully open-source framework that\nleverages LLMs for precise and automated code manipulation in real-world Git\nrepositories. Rather than generating holistic fixes, Repeton operates through a\nstructured patch-and-test pipeline: it iteratively diagnoses issues, proposes\ncode changes, and validates each patch through automated testing. This stepwise\nprocess is guided by lightweight heuristics and development tools, avoiding\nreliance on embedding-based retrieval systems. Evaluated on the SWE-bench Lite\nbenchmark, our method shows good performance compared to RAG-based methods in\nboth patch validity and interpretability. By decomposing software engineering\ntasks into modular, verifiable stages, Repeton provides a practical path toward\nscalable and transparent autonomous debugging.", "AI": {"tldr": "Repeton is an open-source framework that uses LLMs for precise and automated code manipulation in Git repositories through a structured patch-and-test pipeline, showing good performance in patch validity and interpretability.", "motivation": "To address the low precision and limited interpretability of LLMs in complex software engineering tasks.", "method": "Repeton operates via a structured patch-and-test pipeline: it iteratively diagnoses issues, proposes code changes, and validates each patch through automated testing, guided by lightweight heuristics and development tools.", "result": "Evaluated on the SWE-bench Lite benchmark, Repeton shows good performance compared to RAG-based methods in both patch validity and interpretability.", "conclusion": "Repeton provides a practical path toward scalable and transparent autonomous debugging by decomposing software engineering tasks into modular, verifiable stages."}}
{"id": "2506.08473", "pdf": "https://arxiv.org/pdf/2506.08473", "abs": "https://arxiv.org/abs/2506.08473", "authors": ["Shuo Yang", "Qihui Zhang", "Yuyang Liu", "Yue Huang", "Xiaojun Jia", "Kunpeng Ning", "Jiayu Yao", "Jigang Wang", "Hailiang Dai", "Yibing Song", "Li Yuan"], "title": "AsFT: Anchoring Safety During LLM Fine-Tuning Within Narrow Safety Basin", "categories": ["cs.LG"], "comment": null, "summary": "Large language models (LLMs) are vulnerable to safety risks during\nfine-tuning, where small amounts of malicious or harmless data can compromise\nsafeguards. In this paper, building on the concept of alignment direction --\ndefined by the weight difference between aligned and unaligned models -- we\nobserve that perturbations along this direction preserve model safety. In\ncontrast, perturbations along directions orthogonal to this alignment are\nstrongly linked to harmful direction perturbations, rapidly degrading safety\nand framing the parameter space as a narrow safety basin. Based on this\ninsight, we propose a methodology for safety fine-tuning called AsFT (Anchoring\nSafety in Fine-Tuning), which integrates a regularization term into the\ntraining objective. This term uses the alignment direction as an anchor to\nsuppress updates in harmful directions, ensuring that fine-tuning is\nconstrained within the narrow safety basin. Extensive experiments on multiple\ndatasets show that AsFT outperforms Safe LoRA, reducing harmful behavior by\n7.60 percent, improving model performance by 3.44 percent, and maintaining\nrobust performance across various experimental settings. Code is available at\nhttps://github.com/PKU-YuanGroup/AsFT", "AI": {"tldr": "Large language models (LLMs) face safety risks during fine-tuning. This paper proposes AsFT, a methodology that uses the alignment direction as an anchor to suppress harmful updates and ensure safe fine-tuning.", "motivation": "To address the vulnerability of LLMs to safety risks during fine-tuning, where even small amounts of malicious or harmless data can compromise safeguards.", "method": "The proposed method, AsFT, integrates a regularization term into the training objective that uses the alignment direction as an anchor to suppress updates in harmful directions, ensuring fine-tuning remains within a narrow safety basin.", "result": "AsFT outperforms Safe LoRA by reducing harmful behavior by 7.60 percent, improving model performance by 3.44 percent, and maintaining robust performance across various experimental settings.", "conclusion": "AsFT provides an effective way to ensure safe fine-tuning of LLMs, preserving model safety and performance."}}
{"id": "2506.08184", "pdf": "https://arxiv.org/pdf/2506.08184", "abs": "https://arxiv.org/abs/2506.08184", "authors": ["Chupei Wang", "Jiaqiu Vince Sun"], "title": "Unable to forget: Proactive lnterference Reveals Working Memory Limits in LLMs Beyond Context Length", "categories": ["cs.CL", "cs.AI", "q-bio.NC"], "comment": null, "summary": "Information retrieval in Large Language Models (LLMs) is increasingly\nrecognized as intertwined with generation capabilities rather than mere lookup.\nWhile longer contexts are often assumed to improve retrieval, the effects of\nintra-context interference remain understudied. To address this, we adapt the\nproactive interference (PI) paradigm from cognitive science, where earlier\ninformation disrupts recall of newer updates. In humans, susceptibility to such\ninterference is inversely linked to working memory capacity. We introduce\nPI-LLM, an evaluation that sequentially streams semantically related key-value\nupdates and queries only the final values. Although these final values are\nclearly positioned just before the query, LLM retrieval accuracy declines\nlog-linearly toward zero as interference accumulates; errors arise from\nretrieving previously overwritten values. Attempts to mitigate interference via\nprompt engineering (e.g., instructing models to ignore earlier input) yield\nlimited success. These findings reveal a fundamental constraint on LLMs'\nability to disentangle interference and flexibly manipulate information,\nsuggesting a working memory bottleneck beyond mere context access. This calls\nfor approaches that strengthen models' ability to suppress irrelevant content\nduring retrieval.", "AI": {"tldr": "\u4fe1\u606f\u68c0\u7d22\u5728\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4e2d\u4e0e\u751f\u6210\u80fd\u529b\u7d27\u5bc6\u76f8\u5173\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u968f\u7740\u5e72\u6270\u4fe1\u606f\u7684\u79ef\u7d2f\uff0cLLM\u7684\u4fe1\u606f\u68c0\u7d22\u51c6\u786e\u7387\u4f1a\u4e0b\u964d\u81f3\u96f6\uff0c\u63d0\u793a\u5b58\u5728\u5de5\u4f5c\u8bb0\u5fc6\u74f6\u9888\u3002\u8fd9\u9700\u8981\u6539\u8fdb\u6a21\u578b\u6291\u5236\u65e0\u5173\u5185\u5bb9\u7684\u80fd\u529b\u3002", "motivation": "\u63a2\u8ba8\u5927\u8bed\u8a00\u6a21\u578b\u5728\u4fe1\u606f\u68c0\u7d22\u4e2d\u7684\u5e72\u6270\u6548\u5e94\uff0c\u7279\u522b\u662f\u8bed\u5883\u5185\u5e72\u6270\u5bf9\u68c0\u7d22\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u4ee5\u63ed\u793a\u5176\u5de5\u4f5c\u8bb0\u5fc6\u5bb9\u91cf\u9650\u5236\u3002", "method": "\u91c7\u7528\u8ba4\u77e5\u79d1\u5b66\u4e2d\u7684 proactive interference (PI) \u8303\u5f0f\uff0c\u5f15\u5165 PI-LLM \u8bc4\u4f30\u65b9\u6cd5\uff0c\u901a\u8fc7\u8fde\u7eed\u63d0\u4f9b\u8bed\u4e49\u76f8\u5173\u7684\u952e\u503c\u66f4\u65b0\u5e76\u4ec5\u67e5\u8be2\u6700\u7ec8\u503c\u6765\u6d4b\u8bd5 LLM \u7684\u68c0\u7d22\u80fd\u529b\u3002", "result": "\u968f\u7740\u5e72\u6270\u4fe1\u606f\u7684\u589e\u52a0\uff0cLLM \u7684\u68c0\u7d22\u51c6\u786e\u7387\u4ee5\u5bf9\u6570\u7ebf\u6027\u65b9\u5f0f\u4e0b\u964d\u5230\u96f6\uff0c\u9519\u8bef\u4e3b\u8981\u6765\u6e90\u4e8e\u68c0\u7d22\u4e86\u5df2\u88ab\u8986\u76d6\u7684\u65e7\u503c\uff0c\u4e14\u901a\u8fc7\u63d0\u793a\u5de5\u7a0b\u51cf\u8f7b\u5e72\u6270\u7684\u6548\u679c\u6709\u9650\u3002", "conclusion": "\u5927\u8bed\u8a00\u6a21\u578b\u5b58\u5728\u5de5\u4f5c\u8bb0\u5fc6\u74f6\u9888\uff0c\u9700\u5f00\u53d1\u65b0\u65b9\u6cd5\u589e\u5f3a\u6a21\u578b\u5728\u68c0\u7d22\u8fc7\u7a0b\u4e2d\u6291\u5236\u65e0\u5173\u5185\u5bb9\u7684\u80fd\u529b\u3002"}}
{"id": "2506.08475", "pdf": "https://arxiv.org/pdf/2506.08475", "abs": "https://arxiv.org/abs/2506.08475", "authors": ["Xiaolong He", "Yeonjong Shin", "Anthony Gruber", "Sohyeon Jung", "Kookjin Lee", "Youngsoo Choi"], "title": "Thermodynamically Consistent Latent Dynamics Identification for Parametric Systems", "categories": ["cs.LG", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "We propose an efficient thermodynamics-informed latent space dynamics\nidentification (tLaSDI) framework for the reduced-order modeling of parametric\nnonlinear dynamical systems. This framework integrates autoencoders for\ndimensionality reduction with newly developed parametric GENERIC\nformalism-informed neural networks (pGFINNs), which enable efficient learning\nof parametric latent dynamics while preserving key thermodynamic principles\nsuch as free energy conservation and entropy generation across the parameter\nspace. To further enhance model performance, a physics-informed active learning\nstrategy is incorporated, leveraging a greedy, residual-based error indicator\nto adaptively sample informative training data, outperforming uniform sampling\nat equivalent computational cost. Numerical experiments on the Burgers'\nequation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed\nmethod achieves up to 3,528x speed-up with 1-3% relative errors, and\nsignificant reduction in training (50-90%) and inference (57-61%) cost.\nMoreover, the learned latent space dynamics reveal the underlying thermodynamic\nbehavior of the system, offering valuable insights into the physical-space\ndynamics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u70ed\u529b\u5b66\u4fe1\u606f\u6f5c\u5728\u7a7a\u95f4\u52a8\u529b\u5b66\u8bc6\u522b\uff08tLaSDI\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u53c2\u6570\u5316\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u7684\u964d\u9636\u5efa\u6a21\u3002\u901a\u8fc7\u7ed3\u5408\u81ea\u52a8\u7f16\u7801\u5668\u548c\u65b0\u7684\u53c2\u6570\u5316\u5e7f\u4e49\u70ed\u529b\u5b66\u5f62\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08pGFINNs\uff09\uff0c\u5b9e\u73b0\u4e86\u53c2\u6570\u5316\u6f5c\u5728\u52a8\u529b\u5b66\u7684\u6709\u6548\u5b66\u4e60\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u5173\u952e\u7684\u70ed\u529b\u5b66\u539f\u7406\u3002\u91c7\u7528\u57fa\u4e8e\u7269\u7406\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u63011-3%\u76f8\u5bf9\u8bef\u5dee\u7684\u60c5\u51b5\u4e0b\u53ef\u5b9e\u73b0\u9ad8\u8fbe3,528\u500d\u7684\u52a0\u901f\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u6210\u672c\u3002", "motivation": "\u4e3a\u4e86\u9ad8\u6548\u5730\u5bf9\u53c2\u6570\u5316\u975e\u7ebf\u6027\u52a8\u529b\u7cfb\u7edf\u8fdb\u884c\u964d\u9636\u5efa\u6a21\uff0c\u540c\u65f6\u4fdd\u7559\u70ed\u529b\u5b66\u539f\u5219\uff0c\u5982\u81ea\u7531\u80fd\u5b88\u6052\u548c\u71b5\u751f\u6210\u3002", "method": "\u5c06\u81ea\u52a8\u7f16\u7801\u5668\u4e0e\u53c2\u6570\u5316\u5e7f\u4e49\u70ed\u529b\u5b66\u5f62\u5f0f\u795e\u7ecf\u7f51\u7edc\uff08pGFINNs\uff09\u76f8\u7ed3\u5408\uff0c\u8fdb\u884c\u964d\u7ef4\u548c\u6f5c\u5728\u52a8\u529b\u5b66\u7684\u5b66\u4e60\uff1b\u5f15\u5165\u57fa\u4e8e\u7269\u7406\u7684\u4e3b\u52a8\u5b66\u4e60\u7b56\u7565\uff0c\u901a\u8fc7\u8d2a\u5a6a\u3001\u57fa\u4e8e\u6b8b\u5dee\u7684\u8bef\u5dee\u6307\u6807\u81ea\u9002\u5e94\u91c7\u6837\u8bad\u7ec3\u6570\u636e\u3002", "result": "\u5728Burgers\u65b9\u7a0b\u548c1D/1V Vlasov-Poisson\u65b9\u7a0b\u4e0a\u7684\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u8fbe3,528\u500d\u7684\u52a0\u901f\uff0c\u76f8\u5bf9\u8bef\u5dee\u4fdd\u6301\u57281-3%\uff0c\u5e76\u663e\u8457\u964d\u4f4e\u4e86\u8bad\u7ec3\uff0850-90%\uff09\u548c\u63a8\u7406\uff0857-61%\uff09\u6210\u672c\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684tLaSDI\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u5b66\u4e60\u53c2\u6570\u5316\u6f5c\u5728\u52a8\u529b\u5b66\uff0c\u540c\u65f6\u4fdd\u7559\u70ed\u529b\u5b66\u539f\u7406\uff0c\u63d0\u4f9b\u5173\u4e8e\u7269\u7406\u7a7a\u95f4\u52a8\u529b\u5b66\u7684\u6709\u4ef7\u503c\u89c1\u89e3\uff0c\u5e76\u663e\u8457\u63d0\u9ad8\u4e86\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2506.08185", "pdf": "https://arxiv.org/pdf/2506.08185", "abs": "https://arxiv.org/abs/2506.08185", "authors": ["Huixin Zhan", "Jason H. Moore"], "title": "Surgeon Style Fingerprinting and Privacy Risk Quantification via Discrete Diffusion Models in a Vision-Language-Action Framework", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Surgeons exhibit distinct operating styles due to differences in training,\nexperience, and motor behavior - yet current AI systems often ignore this\npersonalization signal. We propose a novel approach to model fine-grained,\nsurgeon-specific fingerprinting in robotic surgery using a discrete diffusion\nframework integrated with a vision-language-action (VLA) pipeline. Our method\nformulates gesture prediction as a structured sequence denoising task,\nconditioned on multimodal inputs including endoscopic video, surgical intent\nlanguage, and a privacy-aware embedding of surgeon identity and skill.\nPersonalized surgeon fingerprinting is encoded through natural language prompts\nusing third-party language models, allowing the model to retain individual\nbehavioral style without exposing explicit identity. We evaluate our method on\nthe JIGSAWS dataset and demonstrate that it accurately reconstructs gesture\nsequences while learning meaningful motion fingerprints unique to each surgeon.\nTo quantify the privacy implications of personalization, we perform membership\ninference attacks and find that more expressive embeddings improve task\nperformance but simultaneously increase susceptibility to identity leakage.\nThese findings demonstrate that while personalized embeddings improve\nperformance, they also increase vulnerability to identity leakage, revealing\nthe importance of balancing personalization with privacy risk in surgical\nmodeling. Code is available at:\nhttps://github.com/huixin-zhan-ai/Surgeon_style_fingerprinting.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u79bb\u6563\u6269\u6563\u6846\u67b6\u548c\u89c6\u89c9-\u8bed\u8a00-\u52a8\u4f5c\uff08VLA\uff09\u7ba1\u9053\u6765\u5bf9\u673a\u5668\u4eba\u624b\u672f\u4e2d\u7684\u5916\u79d1\u533b\u751f\u7279\u5b9a\u6307\u7eb9\u8fdb\u884c\u5efa\u6a21\u3002\u8be5\u65b9\u6cd5\u4f7f\u7528\u591a\u6a21\u6001\u8f93\u5165\u9884\u6d4b\u624b\u52bf\u5e8f\u5217\uff0c\u5e76\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7f16\u7801\u4e2a\u6027\u5316\u5916\u79d1\u533b\u751f\u6307\u7eb9\uff0c\u540c\u65f6\u4fdd\u62a4\u9690\u79c1\u3002\u5b9e\u9a8c\u8868\u660e\u4e2a\u6027\u5316\u5d4c\u5165\u53ef\u4ee5\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u8eab\u4efd\u6cc4\u9732\u7684\u98ce\u9669\u3002", "motivation": "\u5f53\u524d\u7684AI\u7cfb\u7edf\u5728\u5904\u7406\u5916\u79d1\u624b\u672f\u6570\u636e\u65f6\u901a\u5e38\u5ffd\u7565\u4e86\u5916\u79d1\u533b\u751f\u4e2a\u4eba\u98ce\u683c\u7684\u4fe1\u53f7\uff0c\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u4e00\u79cd\u80fd\u591f\u6355\u6349\u5916\u79d1\u533b\u751f\u72ec\u7279\u64cd\u4f5c\u98ce\u683c\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u8be5\u65b9\u6cd5\u5c06\u624b\u52bf\u9884\u6d4b\u89c6\u4e3a\u7ed3\u6784\u5316\u5e8f\u5217\u53bb\u566a\u4efb\u52a1\uff0c\u57fa\u4e8e\u5305\u62ec\u5185\u7aa5\u955c\u89c6\u9891\u3001\u624b\u672f\u610f\u56fe\u8bed\u8a00\u548c\u5916\u79d1\u533b\u751f\u8eab\u4efd\u53ca\u6280\u80fd\u7684\u9690\u79c1\u611f\u77e5\u5d4c\u5165\u7b49\u591a\u6a21\u6001\u8f93\u5165\u3002\u4f7f\u7528\u7b2c\u4e09\u65b9\u8bed\u8a00\u6a21\u578b\u901a\u8fc7\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u7f16\u7801\u4e2a\u6027\u5316\u7684\u5916\u79d1\u533b\u751f\u6307\u7eb9\uff0c\u4ee5\u4fdd\u7559\u4e2a\u4f53\u884c\u4e3a\u98ce\u683c\u800c\u4e0d\u66b4\u9732\u660e\u786e\u7684\u8eab\u4efd\u4fe1\u606f\u3002", "result": "\u5728JIGSAWS\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u51c6\u786e\u5730\u91cd\u5efa\u624b\u52bf\u5e8f\u5217\u5e76\u5b66\u4e60\u5230\u6bcf\u4e2a\u5916\u79d1\u533b\u751f\u72ec\u7279\u7684\u8fd0\u52a8\u6307\u7eb9\u3002\u7136\u800c\uff0c\u66f4\u5bcc\u6709\u8868\u73b0\u529b\u7684\u5d4c\u5165\u867d\u7136\u63d0\u9ad8\u4e86\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u540c\u65f6\u4e5f\u589e\u52a0\u4e86\u8eab\u4efd\u6cc4\u9732\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u4e2a\u6027\u5316\u5d4c\u5165\u53ef\u4ee5\u63d0\u9ad8\u4efb\u52a1\u6027\u80fd\uff0c\u4f46\u4e5f\u589e\u52a0\u4e86\u8eab\u4efd\u6cc4\u9732\u7684\u98ce\u9669\uff0c\u56e0\u6b64\u5728\u624b\u672f\u5efa\u6a21\u4e2d\u9700\u8981\u5e73\u8861\u4e2a\u6027\u5316\u4e0e\u9690\u79c1\u98ce\u9669\u3002"}}
{"id": "2506.08505", "pdf": "https://arxiv.org/pdf/2506.08505", "abs": "https://arxiv.org/abs/2506.08505", "authors": ["Shahaf Bassan", "Yizhak Yisrael Elboher", "Tobias Ladner", "Matthias Althoff", "Guy Katz"], "title": "Explaining, Fast and Slow: Abstraction and Refinement of Provable Explanations", "categories": ["cs.LG", "cs.AI", "cs.LO"], "comment": "To appear in ICML 2025", "summary": "Despite significant advancements in post-hoc explainability techniques for\nneural networks, many current methods rely on heuristics and do not provide\nformally provable guarantees over the explanations provided. Recent work has\nshown that it is possible to obtain explanations with formal guarantees by\nidentifying subsets of input features that are sufficient to determine that\npredictions remain unchanged using neural network verification techniques.\nDespite the appeal of these explanations, their computation faces significant\nscalability challenges. In this work, we address this gap by proposing a novel\nabstraction-refinement technique for efficiently computing provably sufficient\nexplanations of neural network predictions. Our method abstracts the original\nlarge neural network by constructing a substantially reduced network, where a\nsufficient explanation of the reduced network is also provably sufficient for\nthe original network, hence significantly speeding up the verification process.\nIf the explanation is in sufficient on the reduced network, we iteratively\nrefine the network size by gradually increasing it until convergence. Our\nexperiments demonstrate that our approach enhances the efficiency of obtaining\nprovably sufficient explanations for neural network predictions while\nadditionally providing a fine-grained interpretation of the network's\npredictions across different abstraction levels.", "AI": {"tldr": "An abstraction-refinement technique is proposed to efficiently compute provably sufficient explanations of neural network predictions.", "motivation": "Many current methods for explaining neural networks do not provide formally provable guarantees. Recent work shows that formal guarantees can be obtained using neural network verification techniques, but these face significant scalability challenges.", "method": "The authors propose a novel abstraction-refinement technique which constructs a reduced network from the original large neural network. A sufficient explanation of this reduced network is also sufficient for the original network, speeding up the verification process. If the explanation is insufficient on the reduced network, the network size is iteratively refined by gradually increasing it until convergence.", "result": "Experiments show that this approach improves the efficiency of obtaining provably sufficient explanations for neural network predictions and provides a fine-grained interpretation of the network's predictions across different abstraction levels.", "conclusion": "The proposed abstraction-refinement technique addresses the scalability challenge in computing provably sufficient explanations of neural network predictions, making the process more efficient."}}
{"id": "2506.08210", "pdf": "https://arxiv.org/pdf/2506.08210", "abs": "https://arxiv.org/abs/2506.08210", "authors": ["Andrew Z. Wang", "Songwei Ge", "Tero Karras", "Ming-Yu Liu", "Yogesh Balaji"], "title": "A Comprehensive Study of Decoder-Only LLMs for Text-to-Image Generation", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "CVPR 2025", "summary": "Both text-to-image generation and large language models (LLMs) have made\nsignificant advancements. However, many text-to-image models still employ the\nsomewhat outdated T5 and CLIP as their text encoders. In this work, we\ninvestigate the effectiveness of using modern decoder-only LLMs as text\nencoders for text-to-image diffusion models. We build a standardized training\nand evaluation pipeline that allows us to isolate and evaluate the effect of\ndifferent text embeddings. We train a total of 27 text-to-image models with 12\ndifferent text encoders to analyze the critical aspects of LLMs that could\nimpact text-to-image generation, including the approaches to extract\nembeddings, different LLMs variants, and model sizes. Our experiments reveal\nthat the de facto way of using last-layer embeddings as conditioning leads to\ninferior performance. Instead, we explore embeddings from various layers and\nfind that using layer-normalized averaging across all layers significantly\nimproves alignment with complex prompts. Most LLMs with this conditioning\noutperform the baseline T5 model, showing enhanced performance in advanced\nvisio-linguistic reasoning skills.", "AI": {"tldr": "This paper explores using modern decoder-only LLMs as text encoders for text-to-image models, finding that layer-normalized averaging across all layers improves performance and most LLMs outperform the baseline T5 model.", "motivation": "The motivation is to improve text-to-image generation by investigating the use of modern decoder-only LLMs as text encoders instead of outdated models like T5 and CLIP.", "method": "The method involves building a standardized training and evaluation pipeline to isolate and evaluate different text embeddings. They train 27 text-to-image models with 12 different text encoders, analyzing various aspects such as embedding extraction approaches, LLM variants, and model sizes.", "result": "The results show that using last-layer embeddings leads to inferior performance, while layer-normalized averaging across all layers significantly improves alignment with complex prompts. Most LLMs outperform the baseline T5 model in advanced visio-linguistic reasoning skills.", "conclusion": "The conclusion is that modern decoder-only LLMs can be effectively used as text encoders for text-to-image models, with specific embedding techniques enhancing performance."}}
{"id": "2506.08514", "pdf": "https://arxiv.org/pdf/2506.08514", "abs": "https://arxiv.org/abs/2506.08514", "authors": ["Jacob Piland", "Chris Sweet", "Adam Czakja"], "title": "DiffGradCAM: A Universal Class Activation Map Resistant to Adversarial Training", "categories": ["cs.LG"], "comment": null, "summary": "Class Activation Mapping (CAM) and its gradient-based variants (e.g.,\nGradCAM) have become standard tools for explaining Convolutional Neural Network\n(CNN) predictions. However, these approaches typically focus on individual\nlogits, while for neural networks using softmax, the class membership\nprobability estimates depend \\textit{only} on the \\textit{differences} between\nlogits, not on their absolute values. This disconnect leaves standard CAMs\nvulnerable to adversarial manipulation, such as passive fooling, where a model\nis trained to produce misleading CAMs without affecting decision performance.\nWe introduce \\textbf{Salience-Hoax Activation Maps (SHAMs)}, an\n\\emph{entropy-aware form of passive fooling} that serves as a benchmark for CAM\nrobustness under adversarial conditions. To address the passive fooling\nvulnerability, we then propose \\textbf{DiffGradCAM}, a novel, lightweight, and\ncontrastive approach to class activation mapping that is both non-suceptible to\npassive fooling, but also matches the output of standard CAM methods such as\nGradCAM in the non-adversarial case. Together, SHAM and DiffGradCAM establish a\nnew framework for probing and improving the robustness of saliency-based\nexplanations. We validate both contributions across multi-class tasks with few\nand many classes.", "AI": {"tldr": "The paper introduces Salience-Hoax Activation Maps (SHAMs) as a benchmark for evaluating the robustness of Class Activation Mapping (CAM) methods under adversarial conditions. It also proposes DiffGradCAM, which is resistant to passive fooling and matches standard CAM outputs in non-adversarial cases.", "motivation": "Current CAM methods focus on individual logits rather than their differences, making them vulnerable to adversarial manipulation like passive fooling where models produce misleading CAMs without impacting decision performance.", "method": "The authors introduce SHAMs, an entropy-aware form of passive fooling, to benchmark CAM robustness. They also propose DiffGradCAM, a contrastive approach that is not susceptible to passive fooling and aligns with standard CAM methods in non-adversarial scenarios.", "result": "SHAM and DiffGradCAM establish a framework for improving saliency-based explanation robustness, validated across multi-class tasks with few and many classes.", "conclusion": "DiffGradCAM offers a robust alternative to existing CAM methods by resisting adversarial manipulation while maintaining performance in standard conditions."}}
{"id": "2506.08516", "pdf": "https://arxiv.org/pdf/2506.08516", "abs": "https://arxiv.org/abs/2506.08516", "authors": ["Mouadh Yagoubi", "David Danan", "Milad Leyli-Abadi", "Ahmed Mazari", "Jean-Patrick Brunet", "Abbas Kabalan", "Fabien Casenave", "Yuxin Ma", "Giovanni Catalani", "Jean Fesquet", "Jacob Helwig", "Xuan Zhang", "Haiyang Yu", "Xavier Bertrand", "Frederic Tost", "Michael Baurheim", "Joseph Morlier", "Shuiwang Ji"], "title": "NeurIPS 2024 ML4CFD Competition: Results and Retrospective Analysis", "categories": ["cs.LG"], "comment": null, "summary": "The integration of machine learning (ML) into the physical sciences is\nreshaping computational paradigms, offering the potential to accelerate\ndemanding simulations such as computational fluid dynamics (CFD). Yet,\npersistent challenges in accuracy, generalization, and physical consistency\nhinder the practical deployment of ML models in scientific domains. To address\nthese limitations and systematically benchmark progress, we organized the\nML4CFD competition, centered on surrogate modeling for aerodynamic simulations\nover two-dimensional airfoils. The competition attracted over 240 teams, who\nwere provided with a curated dataset generated via OpenFOAM and evaluated\nthrough a multi-criteria framework encompassing predictive accuracy, physical\nfidelity, computational efficiency, and out-of-distribution generalization.\nThis retrospective analysis reviews the competition outcomes, highlighting\nseveral approaches that outperformed baselines under our global evaluation\nscore. Notably, the top entry exceeded the performance of the original OpenFOAM\nsolver on aggregate metrics, illustrating the promise of ML-based surrogates to\noutperform traditional solvers under tailored criteria. Drawing from these\nresults, we analyze the key design principles of top submissions, assess the\nrobustness of our evaluation framework, and offer guidance for future\nscientific ML challenges.", "AI": {"tldr": "The ML4CFD competition focused on using machine learning for aerodynamic simulations, attracting 240 teams. Top entries outperformed traditional solvers in accuracy, efficiency, and generalization, providing insights into future scientific ML challenges.", "motivation": "To address the limitations of ML models in scientific domains such as accuracy, generalization, and physical consistency, and to benchmark progress in this field.", "method": "Organized the ML4CFD competition centered on surrogate modeling for aerodynamic simulations over two-dimensional airfoils. Teams were provided a dataset generated via OpenFOAM and evaluated through a multi-criteria framework including predictive accuracy, physical fidelity, computational efficiency, and out-of-distribution generalization.", "result": "Several approaches outperformed baselines under the global evaluation score, with the top entry exceeding the performance of the original OpenFOAM solver on aggregate metrics.", "conclusion": "ML-based surrogates show promise in outperforming traditional solvers under tailored criteria. Key design principles of top submissions are analyzed, the robustness of the evaluation framework is assessed, and guidance for future scientific ML challenges is offered."}}
{"id": "2506.08523", "pdf": "https://arxiv.org/pdf/2506.08523", "abs": "https://arxiv.org/abs/2506.08523", "authors": ["Pedro Jim\u00e9nez-Gonz\u00e1lez", "Miguel C. Soriano", "Lucas Lacasa"], "title": "Leveraging chaos in the training of artificial neural networks", "categories": ["cs.LG", "cond-mat.dis-nn", "nlin.CD", "physics.data-an"], "comment": null, "summary": "Traditional algorithms to optimize artificial neural networks when confronted\nwith a supervised learning task are usually exploitation-type relaxational\ndynamics such as gradient descent (GD). Here, we explore the dynamics of the\nneural network trajectory along training for unconventionally large learning\nrates. We show that for a region of values of the learning rate, the GD\noptimization shifts away from purely exploitation-like algorithm into a regime\nof exploration-exploitation balance, as the neural network is still capable of\nlearning but the trajectory shows sensitive dependence on initial conditions --\nas characterized by positive network maximum Lyapunov exponent --.\nInterestingly, the characteristic training time required to reach an acceptable\naccuracy in the test set reaches a minimum precisely in such learning rate\nregion, further suggesting that one can accelerate the training of artificial\nneural networks by locating at the onset of chaos. Our results -- initially\nillustrated for the MNIST classification task -- qualitatively hold for a range\nof supervised learning tasks, learning architectures and other hyperparameters,\nand showcase the emergent, constructive role of transient chaotic dynamics in\nthe training of artificial neural networks.", "AI": {"tldr": "The paper explores how large learning rates can lead to a balance of exploration and exploitation in gradient descent optimization for neural networks, accelerating training by leveraging transient chaotic dynamics.", "motivation": "To understand the dynamics of neural network training with unusually large learning rates and determine if this approach can accelerate learning.", "method": "Investigate the behavior of gradient descent optimization under various learning rates, focusing on the transition from exploitation to an exploration-exploitation balance characterized by positive maximum Lyapunov exponents.", "result": "For certain learning rate values, gradient descent exhibits a balance between exploration and exploitation, with minimal characteristic training time at the onset of chaos.", "conclusion": "Transient chaotic dynamics during neural network training plays a constructive role in optimizing learning performance."}}
{"id": "2506.08234", "pdf": "https://arxiv.org/pdf/2506.08234", "abs": "https://arxiv.org/abs/2506.08234", "authors": ["Yu-Ang Lee", "Guan-Ting Yi", "Mei-Yi Liu", "Jui-Chao Lu", "Guan-Bo Yang", "Yun-Nung Chen"], "title": "Compound AI Systems Optimization: A Survey of Methods, Challenges, and Future Directions", "categories": ["cs.CL", "cs.AI"], "comment": "15 pages, 4 figures, 1 table", "summary": "Recent advancements in large language models (LLMs) and AI systems have led\nto a paradigm shift in the design and optimization of complex AI workflows. By\nintegrating multiple components, compound AI systems have become increasingly\nadept at performing sophisticated tasks. However, as these systems grow in\ncomplexity, new challenges arise in optimizing not only individual components\nbut also their interactions. While traditional optimization methods such as\nsupervised fine-tuning (SFT) and reinforcement learning (RL) remain\nfoundational, the rise of natural language feedback introduces promising new\napproaches, especially for optimizing non-differentiable systems. This paper\nprovides a systematic review of recent progress in optimizing compound AI\nsystems, encompassing both numerical and language-based techniques. We\nformalize the notion of compound AI system optimization, classify existing\nmethods along several key dimensions, and highlight open research challenges\nand future directions in this rapidly evolving field. A list of surveyed papers\nis publicly available at https://github.com/MiuLab/AISysOpt-Survey.", "AI": {"tldr": "Recent advancements in large language models and AI systems have caused a paradigm shift in the design and optimization of complex AI workflows. This paper reviews recent progress in optimizing compound AI systems, formalizes the concept, classifies methods, and highlights research challenges.", "motivation": "To address the challenges arising from the increasing complexity of compound AI systems and their interactions, as well as to explore new approaches such as natural language feedback for optimizing non-differentiable systems.", "method": "Provide a systematic review of recent progress in optimizing compound AI systems, encompassing both numerical and language-based techniques, formalize the notion of compound AI system optimization, classify existing methods along several key dimensions.", "result": "A comprehensive review and classification of optimization methods for compound AI systems, highlighting open research challenges and future directions in this evolving field.", "conclusion": "The field of compound AI system optimization is rapidly evolving with promising new approaches emerging, including natural language feedback."}}
{"id": "2506.08533", "pdf": "https://arxiv.org/pdf/2506.08533", "abs": "https://arxiv.org/abs/2506.08533", "authors": ["Nihal Acharya Adde", "Alexandra Gianzina", "Hanno Gottschalk", "Andreas Ebert"], "title": "Robust Evolutionary Multi-Objective Network Architecture Search for Reinforcement Learning (EMNAS-RL)", "categories": ["cs.LG", "cs.AI", "math.OC"], "comment": "Published at ESANN 2025 Conference", "summary": "This paper introduces Evolutionary Multi-Objective Network Architecture\nSearch (EMNAS) for the first time to optimize neural network architectures in\nlarge-scale Reinforcement Learning (RL) for Autonomous Driving (AD). EMNAS uses\ngenetic algorithms to automate network design, tailored to enhance rewards and\nreduce model size without compromising performance. Additionally,\nparallelization techniques are employed to accelerate the search, and\nteacher-student methodologies are implemented to ensure scalable optimization.\nThis research underscores the potential of transfer learning as a robust\nframework for optimizing performance across iterative learning processes by\neffectively leveraging knowledge from earlier generations to enhance learning\nefficiency and stability in subsequent generations. Experimental results\ndemonstrate that tailored EMNAS outperforms manually designed models, achieving\nhigher rewards with fewer parameters. The findings of these strategies\ncontribute positively to EMNAS for RL in autonomous driving, advancing the\nfield toward better-performing networks suitable for real-world scenarios.", "AI": {"tldr": "This paper introduces EMNAS, a new method using genetic algorithms to optimize neural network architectures in large-scale RL for autonomous driving. It automates network design, reduces model size, and enhances rewards. Transfer learning is used to improve efficiency and stability.", "motivation": "The motivation of this paper is to enhance the performance of neural networks in reinforcement learning for autonomous driving by reducing model size without compromising performance.", "method": "EMNAS uses genetic algorithms to automate network design and employs parallelization techniques to accelerate the search. Teacher-student methodologies are also implemented to ensure scalable optimization.", "result": "Experimental results show that EMNAS outperforms manually designed models, achieving higher rewards with fewer parameters.", "conclusion": "The findings contribute positively to EMNAS for RL in autonomous driving, advancing the field toward better-performing networks suitable for real-world scenarios."}}
{"id": "2506.08235", "pdf": "https://arxiv.org/pdf/2506.08235", "abs": "https://arxiv.org/abs/2506.08235", "authors": ["Shashidhar Reddy Javaji", "Yupeng Cao", "Haohang Li", "Yangyang Yu", "Nikhil Muralidhar", "Zining Zhu"], "title": "Can AI Validate Science? Benchmarking LLMs for Accurate Scientific Claim $\\rightarrow$ Evidence Reasoning", "categories": ["cs.CL", "cs.AI"], "comment": "21 pages, 6 figures, Under review", "summary": "Large language models (LLMs) are increasingly being used for complex research\ntasks such as literature review, idea generation, and scientific paper\nanalysis, yet their ability to truly understand and process the intricate\nrelationships within complex research papers, such as the logical links between\nclaims and supporting evidence remains largely unexplored. In this study, we\npresent CLAIM-BENCH, a comprehensive benchmark for evaluating LLMs'\ncapabilities in scientific claim-evidence extraction and validation, a task\nthat reflects deeper comprehension of scientific argumentation. We\nsystematically compare three approaches which are inspired by divide and\nconquer approaches, across six diverse LLMs, highlighting model-specific\nstrengths and weaknesses in scientific comprehension. Through evaluation\ninvolving over 300 claim-evidence pairs across multiple research domains, we\nreveal significant limitations in LLMs' ability to process complex scientific\ncontent. Our results demonstrate that closed-source models like GPT-4 and\nClaude consistently outperform open-source counterparts in precision and recall\nacross claim-evidence identification tasks. Furthermore, strategically designed\nthree-pass and one-by-one prompting approaches significantly improve LLMs'\nabilities to accurately link dispersed evidence with claims, although this\ncomes at increased computational cost. CLAIM-BENCH sets a new standard for\nevaluating scientific comprehension in LLMs, offering both a diagnostic tool\nand a path forward for building systems capable of deeper, more reliable\nreasoning across full-length papers.", "AI": {"tldr": "Large language models (LLMs) have unexplored abilities in understanding complex scientific papers. This study introduces CLAIM-BENCH, a benchmark for evaluating LLMs' capabilities in claim-evidence extraction and validation across six diverse LLMs. Closed-source models like GPT-4 outperform open-source ones. Strategic prompting approaches improve LLMs' accuracy but increase computational cost.", "motivation": "To explore and evaluate the ability of LLMs to understand and process complex relationships within research papers, specifically focusing on the logical links between claims and supporting evidence.", "method": "The study systematically compares three divide and conquer inspired approaches across six diverse LLMs using CLAIM-BENCH, a comprehensive benchmark for scientific claim-evidence extraction and validation. Evaluation involves over 300 claim-evidence pairs across multiple research domains.", "result": "Closed-source models such as GPT-4 and Claude outperform open-source counterparts in precision and recall. Strategically designed prompting approaches significantly enhance LLMs' ability to link evidence with claims, albeit with increased computational cost.", "conclusion": "CLAIM-BENCH sets a new standard for evaluating scientific comprehension in LLMs, providing a diagnostic tool and suggesting ways to build systems with deeper, more reliable reasoning."}}
{"id": "2506.08551", "pdf": "https://arxiv.org/pdf/2506.08551", "abs": "https://arxiv.org/abs/2506.08551", "authors": ["Panlong Wu", "Ting Wang", "Yifei Zhong", "Haoqi Zhang", "Zitong Wang", "Fangxin Wang"], "title": "DeepForm: Reasoning Large Language Model for Communication System Formulation", "categories": ["cs.LG"], "comment": null, "summary": "Communication system formulation is critical for advancing 6G and future\nwireless technologies, yet it remains a complex, expertise-intensive task.\nWhile Large Language Models (LLMs) offer potential, existing general-purpose\nmodels often lack the specialized domain knowledge, nuanced reasoning\ncapabilities, and access to high-quality, domain-specific training data\nrequired for adapting a general LLM into an LLM specially for communication\nsystem formulation. To bridge this gap, we introduce DeepForm, the first\nreasoning LLM specially for automated communication system formulation. We\npropose the world-first large-scale, open-source dataset meticulously curated\nfor this domain called Communication System Formulation Reasoning Corpus\n(CSFRC). Our framework employs a two-stage training strategy: first, Supervised\nFine-Tuning (SFT) with Chain-of-Thought (CoT) data to distill domain knowledge;\nsecond, a novel rule-based Reinforcement Learning (RL) algorithm, C-ReMax based\non ReMax, to cultivate advanced modeling capabilities and elicit sophisticated\nreasoning patterns like self-correction and verification. Extensive experiments\ndemonstrate that our model achieves state-of-the-art performance, significantly\noutperforming larger proprietary LLMs on diverse senerios. We will release\nrelated resources to foster further research in this area after the paper is\naccepted.", "AI": {"tldr": "The paper introduces DeepForm, the first reasoning LLM for automated communication system formulation. It uses a large-scale open-source dataset (CSFRC) and a two-stage training strategy involving Supervised Fine-Tuning and a novel Reinforcement Learning algorithm (C-ReMax). Experiments show it outperforms larger proprietary LLMs.", "motivation": "To address the complexity and expertise required in communication system formulation, and the lack of specialized domain knowledge in existing general-purpose LLMs.", "method": "Developed DeepForm using a large-scale open-source dataset (CSFRC) and a two-stage training strategy that includes Supervised Fine-Tuning with Chain-of-Thought data and a novel rule-based Reinforcement Learning algorithm (C-ReMax).", "result": "DeepForm achieves state-of-the-art performance, significantly outperforming larger proprietary LLMs in diverse scenarios.", "conclusion": "The model and related resources will be released to promote further research in communication system formulation."}}
{"id": "2506.08572", "pdf": "https://arxiv.org/pdf/2506.08572", "abs": "https://arxiv.org/abs/2506.08572", "authors": ["Waiss Azizian", "Michael Kirchhof", "Eugene Ndiaye", "Louis Bethune", "Michal Klein", "Pierre Ablin", "Marco Cuturi"], "title": "The Geometries of Truth Are Orthogonal Across Tasks", "categories": ["cs.LG", "cs.AI", "cs.CL", "stat.ML"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated impressive generalization\ncapabilities across various tasks, but their claim to practical relevance is\nstill mired by concerns on their reliability. Recent works have proposed\nexamining the activations produced by an LLM at inference time to assess\nwhether its answer to a question is correct. Some works claim that a \"geometry\nof truth\" can be learned from examples, in the sense that the activations that\ngenerate correct answers can be distinguished from those leading to mistakes\nwith a linear classifier. In this work, we underline a limitation of these\napproaches: we observe that these \"geometries of truth\" are intrinsically\ntask-dependent and fail to transfer across tasks. More precisely, we show that\nlinear classifiers trained across distinct tasks share little similarity and,\nwhen trained with sparsity-enforcing regularizers, have almost disjoint\nsupports. We show that more sophisticated approaches (e.g., using mixtures of\nprobes and tasks) fail to overcome this limitation, likely because activation\nvectors commonly used to classify answers form clearly separated clusters when\nexamined across tasks.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u53ef\u9760\u6027\u4ecd\u5b58\u5728\u7591\u8651\u3002\u5148\u524d\u7814\u7a76\u63d0\u51fa\u901a\u8fc7\u5206\u6790\u63a8\u7406\u65f6\u7684\u6fc0\u6d3b\u60c5\u51b5\u6765\u5224\u65ad\u7b54\u6848\u6b63\u786e\u6027\uff0c\u5373\u5b66\u4e60\u201c\u771f\u503c\u51e0\u4f55\u201d\u3002\u7136\u800c\uff0c\u672c\u6587\u6307\u51fa\u8fd9\u4e9b\u201c\u771f\u503c\u51e0\u4f55\u201d\u5177\u6709\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u96be\u4ee5\u8de8\u4efb\u52a1\u8fc1\u79fb\u3002\u5177\u4f53\u8868\u73b0\u4e3a\u4e0d\u540c\u4efb\u52a1\u8bad\u7ec3\u51fa\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u76f8\u4f3c\u5ea6\u4f4e\u4e14\u652f\u6301\u96c6\u51e0\u4e4e\u4e0d\u91cd\u53e0\uff0c\u5373\u4f7f\u91c7\u7528\u66f4\u590d\u6742\u7684\u65b9\u6cd5\u4e5f\u96be\u4ee5\u514b\u670d\u8fd9\u4e00\u9650\u5236\u3002", "motivation": "\u5c3d\u7ba1LLMs\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u53ef\u9760\u6027\u4ecd\u53d7\u8d28\u7591\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u80fd\u591f\u5728\u63a8\u7406\u65f6\u8bc4\u4f30LLM\u7684\u7b54\u6848\u6b63\u786e\u6027\uff0c\u800c\u76ee\u524d\u63d0\u51fa\u7684\u201c\u771f\u503c\u51e0\u4f55\u201d\u65b9\u6cd5\u662f\u5426\u6709\u6548\u503c\u5f97\u8fdb\u4e00\u6b65\u63a2\u8ba8\u3002", "method": "\u7814\u7a76\u8005\u89c2\u5bdf\u5e76\u8bc1\u660e\u4e86\u201c\u771f\u503c\u51e0\u4f55\u201d\u7684\u4efb\u52a1\u4f9d\u8d56\u6027\uff0c\u901a\u8fc7\u5b9e\u9a8c\u5c55\u793a\u4e86\u4e0d\u540c\u4efb\u52a1\u8bad\u7ec3\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u4e4b\u95f4\u76f8\u4f3c\u5ea6\u4f4e\u3001\u652f\u6301\u96c6\u51e0\u4e4e\u4e0d\u91cd\u53e0\u7684\u73b0\u8c61\uff0c\u5e76\u5c1d\u8bd5\u4f7f\u7528\u66f4\u590d\u6742\u7684\u6a21\u578b\uff08\u5982\u6df7\u5408\u63a2\u9488\u548c\u4efb\u52a1\u7684\u65b9\u6cd5\uff09\u6765\u514b\u670d\u8fd9\u4e00\u5c40\u9650\u6027\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u201c\u771f\u503c\u51e0\u4f55\u201d\u662f\u4efb\u52a1\u4f9d\u8d56\u7684\uff0c\u65e0\u6cd5\u8de8\u4efb\u52a1\u8fc1\u79fb\u3002\u4e0d\u540c\u4efb\u52a1\u7684\u7ebf\u6027\u5206\u7c7b\u5668\u51e0\u4e4e\u6ca1\u6709\u76f8\u4f3c\u6027\uff0c\u5373\u4f7f\u91c7\u7528\u66f4\u590d\u6742\u7684\u6a21\u578b\u4e5f\u65e0\u6cd5\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u53ef\u80fd\u662f\u56e0\u4e3a\u6fc0\u6d3b\u5411\u91cf\u5728\u8de8\u4efb\u52a1\u5206\u6790\u65f6\u5f62\u6210\u660e\u663e\u5206\u79bb\u7684\u7c07\u3002", "conclusion": "\u201c\u771f\u503c\u51e0\u4f55\u201d\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u533a\u5206\u6b63\u786e\u4e0e\u9519\u8bef\u7b54\u6848\uff0c\u4f46\u5176\u4efb\u52a1\u4f9d\u8d56\u6027\u548c\u8de8\u4efb\u52a1\u5931\u6548\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002\u672a\u6765\u9700\u8981\u63a2\u7d22\u5176\u4ed6\u65b9\u6cd5\u4ee5\u5b9e\u73b0\u66f4\u666e\u9002\u7684LLM\u7b54\u6848\u8bc4\u4f30\u673a\u5236\u3002"}}
{"id": "2506.08574", "pdf": "https://arxiv.org/pdf/2506.08574", "abs": "https://arxiv.org/abs/2506.08574", "authors": ["Alvise Dei Rossi", "Matteo Metaldi", "Michal Bechny", "Irina Filchenko", "Julia van der Meer", "Markus H. Schmidt", "Claudio L. A. Bassetti", "Athina Tzovara", "Francesca D. Faraci", "Luigi Fiorillo"], "title": "SLEEPYLAND: trust begins with fair evaluation of automatic sleep staging models", "categories": ["cs.LG"], "comment": "41 pages, 4 Figures, 7 Tables", "summary": "Despite advances in deep learning for automatic sleep staging, clinical\nadoption remains limited due to challenges in fair model evaluation,\ngeneralization across diverse datasets, model bias, and variability in human\nannotations. We present SLEEPYLAND, an open-source sleep staging evaluation\nframework designed to address these barriers. It includes more than 22'0000\nhours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain\n(OOD) sleep recordings, spanning a broad range of ages, sleep-wake disorders,\nand hardware setups. We release pre-trained models based on high-performing SoA\narchitectures and evaluate them under standardized conditions across single-\nand multi-channel EEG/EOG configurations. We introduce SOMNUS, an ensemble\ncombining models across architectures and channel setups via soft voting.\nSOMNUS achieves robust performance across twenty-four different datasets, with\nmacro-F1 scores between 68.7% and 87.2%, outperforming individual models in\n94.9% of cases. Notably, SOMNUS surpasses previous SoA methods, even including\ncases where compared models were trained ID while SOMNUS treated the same data\nas OOD. Using a subset of the BSWR (N=6'633), we quantify model biases linked\nto age, gender, AHI, and PLMI, showing that while ensemble improves robustness,\nno model architecture consistently minimizes bias in performance and clinical\nmarkers estimation. In evaluations on OOD multi-annotated datasets (DOD-H,\nDOD-O), SOMNUS exceeds the best human scorer, i.e., MF1 85.2% vs 80.8% on\nDOD-H, and 80.2% vs 75.9% on DOD-O, better reproducing the scorer consensus\nthan any individual expert (k = 0.89/0.85 and ACS = 0.95/0.94 for healthy/OSA\ncohorts). Finally, we introduce ensemble disagreement metrics - entropy and\ninter-model divergence based - predicting regions of scorer disagreement with\nROC AUCs up to 0.828, offering a data-driven proxy for human uncertainty.", "AI": {"tldr": "Despite advances in deep learning for automatic sleep staging, clinical adoption remains limited due to challenges in fair model evaluation, generalization across diverse datasets, model bias, and variability in human annotations. This paper presents SLEEPYLAND, an open-source sleep staging evaluation framework designed to address these barriers. It includes more than 22'0000 hours in-domain (ID) sleep recordings, and more than 84'000 hours out-of-domain (OOD) sleep recordings. SOMNUS, an ensemble combining models across architectures and channel setups via soft voting, achieves robust performance across twenty-four different datasets.", "motivation": "To overcome the challenges in fair model evaluation, generalization across diverse datasets, model bias, and variability in human annotations in the field of automatic sleep staging.", "method": "The authors developed SLEEPYLAND, an open-source sleep staging evaluation framework with extensive ID and OOD sleep recordings. They also introduced SOMNUS, an ensemble method that combines models across architectures and channel setups via soft voting.", "result": "SOMNUS achieved robust performance across twenty-four different datasets, outperforming individual models in 94.9% of cases. It surpassed previous SoA methods even when compared models were trained ID while SOMNUS treated the same data as OOD. SOMNUS exceeded the best human scorer on OOD multi-annotated datasets and better reproduced the scorer consensus than any individual expert. Ensemble disagreement metrics predicted regions of scorer disagreement with ROC AUCs up to 0.828.", "conclusion": "SLEEPYLAND and SOMNUS provide significant advancements in addressing the challenges faced in the clinical adoption of automatic sleep staging, offering improved model performance and a data-driven proxy for human uncertainty."}}
{"id": "2506.08257", "pdf": "https://arxiv.org/pdf/2506.08257", "abs": "https://arxiv.org/abs/2506.08257", "authors": ["L. Lao Beyer", "T. Li", "X. Chen", "S. Karaman", "K. He"], "title": "Highly Compressed Tokenizer Can Generate Without Training", "categories": ["cs.CV", "cs.AI"], "comment": "Main manuscript: 9 pages, 7 figures. Appendix: 8 pages, 9 figures. To\n  appear in the Proceedings of the 42nd International Conference on Machine\n  Learning", "summary": "Commonly used image tokenizers produce a 2D grid of spatially arranged\ntokens. In contrast, so-called 1D image tokenizers represent images as highly\ncompressed one-dimensional sequences of as few as 32 discrete tokens. We find\nthat the high degree of compression achieved by a 1D tokenizer with vector\nquantization enables image editing and generative capabilities through\nheuristic manipulation of tokens, demonstrating that even very crude\nmanipulations -- such as copying and replacing tokens between latent\nrepresentations of images -- enable fine-grained image editing by transferring\nappearance and semantic attributes. Motivated by the expressivity of the 1D\ntokenizer's latent space, we construct an image generation pipeline leveraging\ngradient-based test-time optimization of tokens with plug-and-play loss\nfunctions such as reconstruction or CLIP similarity. Our approach is\ndemonstrated for inpainting and text-guided image editing use cases, and can\ngenerate diverse and realistic samples without requiring training of any\ngenerative model.", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd1D\u56fe\u50cf\u6807\u8bb0\u5668\uff0c\u80fd\u591f\u901a\u8fc7\u9ad8\u5ea6\u538b\u7f29\u7684\u79bb\u6563\u6807\u8bb0\u5e8f\u5217\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u56fe\u50cf\u7f16\u8f91\u548c\u751f\u6210\u3002\u8be5\u65b9\u6cd5\u65e0\u9700\u8bad\u7ec3\u751f\u6210\u6a21\u578b\uff0c\u5229\u7528\u57fa\u4e8e\u68af\u5ea6\u7684\u6d4b\u8bd5\u65f6\u95f4\u4f18\u5316\u548c\u5373\u63d2\u5373\u7528\u635f\u5931\u51fd\u6570\u6765\u5b8c\u6210\u56fe\u50cf\u4fee\u590d\u548c\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7f16\u8f91\u4efb\u52a1\u3002", "motivation": "\u5f53\u524d\u5e38\u7528\u7684\u56fe\u50cf\u6807\u8bb0\u5668\u751f\u6210\u7684\u662f\u4e8c\u7ef4\u7f51\u683c\u6807\u8bb0\uff0c\u800c1D\u56fe\u50cf\u6807\u8bb0\u5668\u53ef\u4ee5\u5c06\u56fe\u50cf\u8868\u793a\u4e3a\u9ad8\u5ea6\u538b\u7f29\u7684\u4e00\u7ef4\u5e8f\u5217\uff0c\u8fd9\u4e3a\u901a\u8fc7\u7b80\u5355\u64cd\u4f5c\uff08\u5982\u590d\u5236\u548c\u66ff\u6362\u6807\u8bb0\uff09\u5b9e\u73b0\u590d\u6742\u7684\u56fe\u50cf\u7f16\u8f91\u63d0\u4f9b\u4e86\u53ef\u80fd\u6027\u3002", "method": "\u4f5c\u8005\u6784\u5efa\u4e86\u4e00\u4e2a\u56fe\u50cf\u751f\u6210\u7ba1\u9053\uff0c\u5229\u75281D\u6807\u8bb0\u5668\u7684\u9ad8\u5ea6\u8868\u8fbe\u80fd\u529b\uff0c\u7ed3\u5408\u57fa\u4e8e\u68af\u5ea6\u7684\u6d4b\u8bd5\u65f6\u95f4\u4f18\u5316\u6280\u672f\u548c\u5373\u63d2\u5373\u7528\u7684\u635f\u5931\u51fd\u6570\uff08\u5982\u91cd\u5efa\u6216CLIP\u76f8\u4f3c\u6027\uff09\uff0c\u5b9e\u73b0\u4e86\u56fe\u50cf\u4fee\u590d\u548c\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7f16\u8f91\u7b49\u529f\u80fd\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u8bad\u7ec3\u4efb\u4f55\u751f\u6210\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u751f\u6210\u591a\u6837\u4e14\u903c\u771f\u7684\u6837\u672c\uff0c\u5e76\u6210\u529f\u5e94\u7528\u4e8e\u56fe\u50cf\u4fee\u590d\u548c\u6587\u672c\u5f15\u5bfc\u7684\u56fe\u50cf\u7f16\u8f91\u7b49\u4f7f\u7528\u573a\u666f\u3002", "conclusion": "1D\u56fe\u50cf\u6807\u8bb0\u5668\u7684\u9ad8\u8868\u8fbe\u80fd\u529b\u548c\u57fa\u4e8e\u68af\u5ea6\u7684\u4f18\u5316\u6280\u672f\u4e3a\u56fe\u50cf\u7f16\u8f91\u548c\u751f\u6210\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6709\u6548\u9014\u5f84\uff0c\u65e0\u9700\u4f9d\u8d56\u751f\u6210\u6a21\u578b\u7684\u8bad\u7ec3\u8fc7\u7a0b\u3002"}}
{"id": "2506.08577", "pdf": "https://arxiv.org/pdf/2506.08577", "abs": "https://arxiv.org/abs/2506.08577", "authors": ["Nicholas A. Pearson", "Francesca Cairoli", "Luca Bortolussi", "Davide Russo", "Francesca Zanello"], "title": "Diffusion-based Time Series Forecasting for Sewerage Systems", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted for presentation at the 13th Urban Drainage Modelling\n  Conference, Innsbruck (Austria), September 2025", "summary": "We introduce a novel deep learning approach that harnesses the power of\ngenerative artificial intelligence to enhance the accuracy of contextual\nforecasting in sewerage systems. By developing a diffusion-based model that\nprocesses multivariate time series data, our system excels at capturing complex\ncorrelations across diverse environmental signals, enabling robust predictions\neven during extreme weather events. To strengthen the model's reliability, we\nfurther calibrate its predictions with a conformal inference technique,\ntailored for probabilistic time series data, ensuring that the resulting\nprediction intervals are statistically reliable and cover the true target\nvalues with a desired confidence level. Our empirical tests on real sewerage\nsystem data confirm the model's exceptional capability to deliver reliable\ncontextual predictions, maintaining accuracy even under severe weather\nconditions.", "AI": {"tldr": "A new deep learning method uses generative AI for better predictions in sewer systems, even during extreme weather. It combines a diffusion model with conformal inference to ensure reliable prediction intervals.", "motivation": "To improve the accuracy and reliability of contextual forecasting in sewerage systems, especially during extreme weather events.", "method": "The approach involves developing a diffusion-based model that processes multivariate time series data to capture complex correlations. Conformal inference is then used to calibrate the predictions, ensuring statistically reliable prediction intervals.", "result": "Empirical tests on real sewerage system data show that the model delivers reliable contextual predictions with maintained accuracy, even under severe weather conditions.", "conclusion": "This novel deep learning approach significantly enhances the ability to make accurate and reliable predictions in sewerage systems, which is crucial for managing infrastructure during extreme weather."}}
{"id": "2506.08260", "pdf": "https://arxiv.org/pdf/2506.08260", "abs": "https://arxiv.org/abs/2506.08260", "authors": ["Wanjing Anya Ma", "Michael Flor", "Zuowei Wang"], "title": "Automatic Generation of Inference Making Questions for Reading Comprehension Assessments", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the 20th Workshop on Innovative Use of NLP for Building\n  Educational Applications (BEA 2025), co-located with the ACL 2025", "summary": "Inference making is an essential but complex skill in reading comprehension\n(RC). Some inferences require resolving references across sentences, and some\nrely on using prior knowledge to fill in the detail that is not explicitly\nwritten in the text. Diagnostic RC questions can help educators provide more\neffective and targeted reading instruction and interventions for school-age\nstudents. We introduce a taxonomy of inference types for RC and use it to\nanalyze the distribution of items within a diagnostic RC item bank. Next, we\npresent experiments using GPT-4o to generate bridging-inference RC items for\ngiven reading passages via few-shot prompting, comparing conditions with and\nwithout chain-of-thought prompts. Generated items were evaluated on three\naspects: overall item quality, appropriate inference type, and LLM reasoning,\nachieving high inter-rater agreements above 0.90. Our results show that GPT-4o\nproduced 93.8% good-quality questions suitable for operational use in grade\n3-12 contexts; however, only 42.6% of the generated questions accurately\nmatched the targeted inference type. We conclude that combining automatic item\ngeneration with human judgment offers a promising path toward scalable,\nhigh-quality diagnostic RC assessments.", "AI": {"tldr": "This paper explores inference making in reading comprehension, introduces a taxonomy of inference types, and evaluates the use of GPT-4o for generating diagnostic RC items. While GPT-4o produced mostly good-quality questions, it struggled with accurately matching targeted inference types. The authors suggest combining AI generation with human judgment for better assessments.", "motivation": "To improve reading instruction and interventions for students by providing educators with more effective diagnostic tools.", "method": "Introduced a taxonomy of inference types, analyzed an item bank, and conducted experiments using GPT-4o to generate bridging-inference RC items with and without chain-of-thought prompts.", "result": "GPT-4o generated 93.8% good-quality questions but only 42.6% accurately matched the targeted inference type. High inter-rater agreements were achieved in evaluations.", "conclusion": "Combining automatic item generation with human judgment is a promising approach for creating scalable, high-quality diagnostic RC assessments."}}
{"id": "2506.08600", "pdf": "https://arxiv.org/pdf/2506.08600", "abs": "https://arxiv.org/abs/2506.08600", "authors": ["Hiroshi Kera", "Shun Arakawa", "Yuta Sato"], "title": "CALT: A Library for Computer Algebra with Transformer", "categories": ["cs.LG", "cs.SC", "math.AC"], "comment": "ISSAC 2025 Short Communications", "summary": "Recent advances in artificial intelligence have demonstrated the learnability\nof symbolic computation through end-to-end deep learning. Given a sufficient\nnumber of examples of symbolic expressions before and after the target\ncomputation, Transformer models - highly effective learners of\nsequence-to-sequence functions - can be trained to emulate the computation.\nThis development opens up several intriguing challenges and new research\ndirections, which require active contributions from the symbolic computation\ncommunity. In this work, we introduce Computer Algebra with Transformer (CALT),\na user-friendly Python library designed to help non-experts in deep learning\ntrain models for symbolic computation tasks.", "AI": {"tldr": "Recent advances in AI show that symbolic computation can be learned through end-to-end deep learning using Transformer models. A new Python library called Computer Algebra with Transformer (CALT) is introduced to assist non-experts in training models for symbolic computation tasks.", "motivation": "The motivation of this paper is to address the learnability of symbolic computation through end-to-end deep learning and to provide a tool for non-experts in deep learning to train models for symbolic computation tasks.", "method": "The method involves using Transformer models, which are effective learners of sequence-to-sequence functions, to emulate symbolic computations by training them on examples of symbolic expressions before and after the target computation.", "result": "The result is the introduction of CALT, a user-friendly Python library designed to facilitate the training of models for symbolic computation tasks.", "conclusion": "This development opens up several intriguing challenges and new research directions, requiring active contributions from the symbolic computation community."}}
{"id": "2506.08604", "pdf": "https://arxiv.org/pdf/2506.08604", "abs": "https://arxiv.org/abs/2506.08604", "authors": ["Giacomo Baldan", "Qiang Liu", "Alberto Guardone", "Nils Thuerey"], "title": "Flow Matching Meets PDEs: A Unified Framework for Physics-Constrained Generation", "categories": ["cs.LG", "cs.AI", "cs.CE", "cs.NA", "math.NA"], "comment": null, "summary": "Generative machine learning methods, such as diffusion models and flow\nmatching, have shown great potential in modeling complex system behaviors and\nbuilding efficient surrogate models. However, these methods typically learn the\nunderlying physics implicitly from data. We propose Physics-Based Flow Matching\n(PBFM), a novel generative framework that explicitly embeds physical\nconstraints, both PDE residuals and algebraic relations, into the flow matching\nobjective. We also introduce temporal unrolling at training time that improves\nthe accuracy of the final, noise-free sample prediction. Our method jointly\nminimizes the flow matching loss and the physics-based residual loss without\nrequiring hyperparameter tuning of their relative weights. Additionally, we\nanalyze the role of the minimum noise level, $\\sigma_{\\min}$, in the context of\nphysical constraints and evaluate a stochastic sampling strategy that helps to\nreduce physical residuals. Through extensive benchmarks on three representative\nPDE problems, we show that our approach yields up to an $8\\times$ more accurate\nphysical residuals compared to FM, while clearly outperforming existing\nalgorithms in terms of distributional accuracy. PBFM thus provides a principled\nand efficient framework for surrogate modeling, uncertainty quantification, and\naccelerated simulation in physics and engineering applications.", "AI": {"tldr": "The paper introduces Physics-Based Flow Matching (PBFM), a generative framework embedding physical constraints into flow matching to improve modeling accuracy in complex systems. It minimizes both flow matching and physics-based residual losses without hyperparameter tuning, reduces physical residuals via a stochastic sampling strategy, and performs up to 8 times better than existing methods on PDE benchmarks.", "motivation": "Generative machine learning methods like diffusion models and flow matching have shown potential for modeling complex system behaviors but typically learn underlying physics implicitly from data. There is a need for a method that explicitly incorporates physical constraints to enhance the accuracy of predictions.", "method": "Physics-Based Flow Matching (PBFM) is proposed which embeds physical constraints such as PDE residuals and algebraic relations into the flow matching objective. Temporal unrolling during training improves prediction accuracy, and the method jointly minimizes flow matching loss and physics-based residual loss without requiring hyperparameter tuning. A stochastic sampling strategy is also introduced to reduce physical residuals.", "result": "Through extensive benchmarks on three representative PDE problems, PBFM yields up to an 8 times more accurate physical residuals compared to Flow Matching (FM) while clearly outperforming existing algorithms in terms of distributional accuracy.", "conclusion": "PBFM provides a principled and efficient framework for surrogate modeling, uncertainty quantification, and accelerated simulation in physics and engineering applications."}}
{"id": "2506.08607", "pdf": "https://arxiv.org/pdf/2506.08607", "abs": "https://arxiv.org/abs/2506.08607", "authors": ["Kiran Purohit", "V Venktesh", "Sourangshu Bhattacharya", "Avishek Anand"], "title": "Sample Efficient Demonstration Selection for In-Context Learning", "categories": ["cs.LG"], "comment": "Accepted at ICML 2025 , 24 pages", "summary": "The in-context learning paradigm with LLMs has been instrumental in advancing\na wide range of natural language processing tasks. The selection of few-shot\nexamples (exemplars / demonstration samples) is essential for constructing\neffective prompts under context-length budget constraints. In this paper, we\nformulate the exemplar selection task as a top-m best arms identification\nproblem. A key challenge in this setup is the exponentially large number of\narms that need to be evaluated to identify the m-best arms. We propose CASE\n(Challenger Arm Sampling for Exemplar selection), a novel sample-efficient\nselective exploration strategy that maintains a shortlist of \"challenger\" arms,\nwhich are current candidates for the top-m arms. In each iteration, only one of\nthe arms from this shortlist or the current topm set is pulled, thereby\nreducing sample complexity and, consequently, the number of LLM evaluations.\nFurthermore, we model the scores of exemplar subsets (arms) using a\nparameterized linear scoring function, leading to stochastic linear bandits\nsetting. CASE achieves remarkable efficiency gains of up to 7x speedup in\nruntime while requiring 7x fewer LLM calls (87% reduction) without sacrificing\nperformance compared to state-of-the-art exemplar selection methods. We release\nour code and data at https://github.com/kiranpurohit/CASE", "AI": {"tldr": "CASE is a new method for exemplar selection in few-shot learning with LLMs, providing significant efficiency gains without performance loss.", "motivation": "To address the challenge of selecting effective few-shot examples within context-length budget constraints for in-context learning with LLMs.", "method": "Formulate exemplar selection as a top-m best arms identification problem and propose CASE, a sample-efficient selective exploration strategy that reduces sample complexity by maintaining a shortlist of 'challenger' arms. Model exemplar subset scores using a parameterized linear scoring function, resulting in stochastic linear bandits setting.", "result": "CASE achieves up to 7x speedup in runtime and requires 7x fewer LLM calls (87% reduction) compared to state-of-the-art methods, while maintaining similar performance.", "conclusion": "CASE provides significant efficiency improvements in exemplar selection for few-shot learning with LLMs."}}
{"id": "2506.08277", "pdf": "https://arxiv.org/pdf/2506.08277", "abs": "https://arxiv.org/abs/2506.08277", "authors": ["Subba Reddy Oota", "Khushbu Pahwa", "Prachi Jindal", "Satya Sai Srinath Namburi", "Maneesh Singh", "Tanmoy Chakraborty", "Bapi S. Raju", "Manish Gupta"], "title": "Instruction-Tuned Video-Audio Models Elucidate Functional Specialization in the Brain", "categories": ["q-bio.NC", "cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "39 pages, 22 figures", "summary": "Recent voxel-wise multimodal brain encoding studies have shown that\nmultimodal large language models (MLLMs) exhibit a higher degree of brain\nalignment compared to unimodal models in both unimodal and multimodal stimulus\nsettings. More recently, instruction-tuned multimodal models have shown to\ngenerate task-specific representations that align strongly with brain activity.\nHowever, prior work evaluating the brain alignment of MLLMs has primarily\nfocused on unimodal settings or relied on non-instruction-tuned multimodal\nmodels for multimodal stimuli. To address this gap, we investigated brain\nalignment, that is, measuring the degree of predictivity of neural activity\nrecorded while participants were watching naturalistic movies (video along with\naudio) with representations derived from MLLMs. We utilized\ninstruction-specific embeddings from six video and two audio instruction-tuned\nMLLMs. Experiments with 13 video task-specific instructions show that\ninstruction-tuned video MLLMs significantly outperform non-instruction-tuned\nmultimodal (by 15%) and unimodal models (by 20%). Our evaluation of MLLMs for\nboth video and audio tasks using language-guided instructions shows clear\ndisentanglement in task-specific representations from MLLMs, leading to precise\ndifferentiation of multimodal functional processing in the brain. We also find\nthat MLLM layers align hierarchically with the brain, with early sensory areas\nshowing strong alignment with early layers, while higher-level visual and\nlanguage regions align more with middle to late layers. These findings provide\nclear evidence for the role of task-specific instructions in improving the\nalignment between brain activity and MLLMs, and open new avenues for mapping\njoint information processing in both the systems. We make the code publicly\navailable [https://github.com/subbareddy248/mllm_videos].", "AI": {"tldr": "Instruction-tuned multimodal large language models show superior brain alignment compared to non-instruction-tuned and unimodal models, with hierarchical layer alignment in processing video and audio tasks.", "motivation": "To investigate the brain alignment of instruction-tuned multimodal large language models (MLLMs) using naturalistic movies as stimuli, addressing the gap in prior work which mainly focused on unimodal settings or non-instruction-tuned models.", "method": "The study utilized instruction-specific embeddings from six video and two audio instruction-tuned MLLMs. Experiments were conducted with 13 video task-specific instructions to measure predictivity of neural activity recorded while participants watched naturalistic movies.", "result": "Instruction-tuned video MLLMs significantly outperformed non-instruction-tuned multimodal models by 15% and unimodal models by 20%. Task-specific representations from MLLMs showed clear disentanglement, leading to precise differentiation of multimodal functional processing in the brain. MLLM layers align hierarchically with the brain.", "conclusion": "Task-specific instructions play a crucial role in improving the alignment between brain activity and MLLMs, opening new avenues for understanding joint information processing in both systems."}}
{"id": "2506.08618", "pdf": "https://arxiv.org/pdf/2506.08618", "abs": "https://arxiv.org/abs/2506.08618", "authors": ["Xianquan Yan", "Hakan Akg\u00fcn", "Kenji Kawaguchi", "N. Duane Loh", "Ching Hua Lee"], "title": "HSG-12M: A Large-Scale Spatial Multigraph Dataset", "categories": ["cs.LG", "cond-mat.mes-hall", "cond-mat.other", "cs.AI", "cs.CV"], "comment": "39 pages, 13 figures, 3 tables. Code & pipeline:\n  [https://github.com/sarinstein-yan/Poly2Graph] Dataset:\n  [https://github.com/sarinstein-yan/HSG-12M] Dataset released under CC BY 4.0", "summary": "Existing graph benchmarks assume non-spatial, simple edges, collapsing\nphysically distinct paths into a single link. We introduce HSG-12M, the first\nlarge-scale dataset of $\\textbf{spatial multigraphs}-$graphs embedded in a\nmetric space where multiple geometrically distinct trajectories between two\nnodes are retained as separate edges. HSG-12M contains 11.6 million static and\n5.1 million dynamic $\\textit{Hamiltonian spectral graphs}$ across 1401\ncharacteristic-polynomial classes, derived from 177 TB of spectral potential\ndata. Each graph encodes the full geometry of a 1-D crystal's energy spectrum\non the complex plane, producing diverse, physics-grounded topologies that\ntranscend conventional node-coordinate datasets. To enable future extensions,\nwe release $\\texttt{Poly2Graph}$: a high-performance, open-source pipeline that\nmaps arbitrary 1-D crystal Hamiltonians to spectral graphs. Benchmarks with\npopular GNNs expose new challenges in learning from multi-edge geometry at\nscale. Beyond its practical utility, we show that spectral graphs serve as\nuniversal topological fingerprints of polynomials, vectors, and matrices,\nforging a new algebra-to-graph link. HSG-12M lays the groundwork for\ngeometry-aware graph learning and new opportunities of data-driven scientific\ndiscovery in condensed matter physics and beyond.", "AI": {"tldr": "The paper introduces HSG-12M, a large-scale dataset of spatial multigraphs embedded in metric space with multiple geometrically distinct trajectories as separate edges. It also presents Poly2Graph, an open-source pipeline for mapping 1-D crystal Hamiltonians to spectral graphs. The dataset and tool create new opportunities for geometry-aware graph learning and data-driven scientific discovery.", "motivation": "Existing graph benchmarks do not account for spatial, multi-edge geometries, collapsing physically distinct paths into single links. This limits the ability to study complex, physics-grounded topologies.", "method": "The authors created HSG-12M, which contains millions of static and dynamic Hamiltonian spectral graphs derived from spectral potential data. They also developed Poly2Graph, a pipeline that maps arbitrary 1-D crystal Hamiltonians to spectral graphs.", "result": "Benchmarks using popular GNNs reveal challenges in learning from multi-edge geometry at scale. Spectral graphs are shown to be universal topological fingerprints of polynomials, vectors, and matrices.", "conclusion": "HSG-12M provides a foundation for geometry-aware graph learning and opens new avenues for data-driven scientific discovery in fields like condensed matter physics."}}
{"id": "2506.08279", "pdf": "https://arxiv.org/pdf/2506.08279", "abs": "https://arxiv.org/abs/2506.08279", "authors": ["Aditi Sundararaman", "Amogh Adishesha", "Andrew Jaegle", "Dan Bigioi", "Hyoung-Kyu Song", "Jon Kyl", "Justin Mao", "Kevin Lan", "Mojtaba Komeili", "ShahRukh Athar", "Sheila Babayan", "Stanislau Beliasau", "William Buchwalter"], "title": "Seeing Voices: Generating A-Roll Video from Audio with Mirage", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Technical report website: mirage.app/research/seeing-voices, product\n  website: mirage.app", "summary": "From professional filmmaking to user-generated content, creators and\nconsumers have long recognized that the power of video depends on the\nharmonious integration of what we hear (the video's audio track) with what we\nsee (the video's image sequence). Current approaches to video generation either\nignore sound to focus on general-purpose but silent image sequence generation\nor address both visual and audio elements but focus on restricted application\ndomains such as re-dubbing. We introduce Mirage, an audio-to-video foundation\nmodel that excels at generating realistic, expressive output imagery from\nscratch given an audio input. When integrated with existing methods for speech\nsynthesis (text-to-speech, or TTS), Mirage results in compelling multimodal\nvideo. When trained on audio-video footage of people talking (A-roll) and\nconditioned on audio containing speech, Mirage generates video of people\ndelivering a believable interpretation of the performance implicit in input\naudio. Our central technical contribution is a unified method for training\nself-attention-based audio-to-video generation models, either from scratch or\ngiven existing weights. This methodology allows Mirage to retain generality as\nan approach to audio-to-video generation while producing outputs of superior\nsubjective quality to methods that incorporate audio-specific architectures or\nloss components specific to people, speech, or details of how images or audio\nare captured. We encourage readers to watch and listen to the results of Mirage\nfor themselves (see paper and comments for links).", "AI": {"tldr": "Mirage is an audio-to-video foundation model that generates realistic imagery from audio input, producing high-quality multimodal video when combined with speech synthesis methods.", "motivation": "To address the limitation of current video generation approaches which either ignore sound or focus on restricted application domains, the authors aim to create a model that can generate realistic and expressive video imagery from scratch based on audio input.", "method": "The central technical contribution is a unified method for training self-attention-based audio-to-video generation models, either from scratch or using existing weights. This allows Mirage to retain generality while producing high-quality outputs.", "result": "Mirage generates compelling multimodal video, especially when integrated with speech synthesis methods. It produces superior subjective quality compared to methods incorporating audio-specific architectures or loss components.", "conclusion": "Mirage represents a significant advancement in audio-to-video generation, offering a general approach with high-quality outputs. Readers are encouraged to experience the results firsthand."}}
{"id": "2506.08641", "pdf": "https://arxiv.org/pdf/2506.08641", "abs": "https://arxiv.org/abs/2506.08641", "authors": ["Simon Roschmann", "Quentin Bouniot", "Vasilii Feofanov", "Ievgen Redko", "Zeynep Akata"], "title": "Time Series Representations for Classification Lie Hidden in Pretrained Vision Transformers", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Time series classification is a fundamental task in healthcare and industry,\nyet the development of time series foundation models (TSFMs) remains limited by\nthe scarcity of publicly available time series datasets. In this work, we\npropose Time Vision Transformer (TiViT), a framework that converts time series\ninto images to leverage the representational power of frozen Vision\nTransformers (ViTs) pretrained on large-scale image datasets. First, we\ntheoretically motivate our approach by analyzing the 2D patching of ViTs for\ntime series, showing that it can increase the number of label-relevant tokens\nand reduce the sample complexity. Second, we empirically demonstrate that TiViT\nachieves state-of-the-art performance on standard time series classification\nbenchmarks by utilizing the hidden representations of large OpenCLIP models. We\nexplore the structure of TiViT representations and find that intermediate\nlayers with high intrinsic dimension are the most effective for time series\nclassification. Finally, we assess the alignment between TiViT and TSFM\nrepresentation spaces and identify a strong complementarity, with further\nperformance gains achieved by combining their features. Our findings reveal yet\nanother direction for reusing vision representations in a non-visual domain.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTime Vision Transformer (TiViT)\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u5229\u7528\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u9884\u8bad\u7ec3\u7684Vision Transformers\u7684\u80fd\u529b\uff0c\u4ece\u800c\u5728\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u4efb\u52a1\u4e0a\u53d6\u5f97\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u5728\u533b\u7597\u548c\u5de5\u4e1a\u9886\u57df\u662f\u4e00\u9879\u57fa\u7840\u4efb\u52a1\uff0c\u4f46\u7531\u4e8e\u516c\u5f00\u53ef\u7528\u7684\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u96c6\u7a00\u7f3a\uff0c\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u7684\u53d1\u5c55\u53d7\u5230\u9650\u5236\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aTime Vision Transformer (TiViT)\u7684\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\uff0c\u4ee5\u5229\u7528\u5728\u5927\u89c4\u6a21\u56fe\u50cf\u6570\u636e\u96c6\u4e0a\u9884\u8bad\u7ec3\u7684Vision Transformers\uff08ViTs\uff09\u7684\u8868\u793a\u80fd\u529b\u3002\u9996\u5148\uff0c\u7406\u8bba\u5206\u6790\u8868\u660e2D patching\u53ef\u4ee5\u589e\u52a0\u6807\u7b7e\u76f8\u5173\u7684token\u6570\u91cf\u5e76\u964d\u4f4e\u6837\u672c\u590d\u6742\u5ea6\u3002\u5176\u6b21\uff0c\u5b9e\u8bc1\u7814\u7a76\u663e\u793aTiViT\u901a\u8fc7\u4f7f\u7528\u5927\u578bOpenCLIP\u6a21\u578b\u7684\u9690\u85cf\u8868\u793a\uff0c\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002\u63a2\u7d22\u4e86TiViT\u8868\u793a\u7684\u7ed3\u6784\uff0c\u53d1\u73b0\u5177\u6709\u9ad8\u5185\u5728\u7ef4\u5ea6\u7684\u4e2d\u95f4\u5c42\u5bf9\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u6700\u4e3a\u6709\u6548\u3002\u6700\u540e\uff0c\u8bc4\u4f30\u4e86TiViT\u4e0eTSFM\u8868\u793a\u7a7a\u95f4\u4e4b\u95f4\u7684\u5bf9\u9f50\u60c5\u51b5\uff0c\u53d1\u73b0\u5b83\u4eec\u4e4b\u95f4\u5b58\u5728\u5f88\u5f3a\u7684\u4e92\u8865\u6027\uff0c\u7ed3\u5408\u5176\u7279\u5f81\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6027\u80fd\u3002", "result": "TiViT\u5728\u6807\u51c6\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u57fa\u51c6\u4e0a\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u5728\u975e\u89c6\u89c9\u9886\u57df\u91cd\u7528\u89c6\u89c9\u8868\u793a\u7684\u53e6\u4e00\u65b9\u5411\u3002", "conclusion": "TiViT\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u65f6\u95f4\u5e8f\u5217\u8f6c\u6362\u4e3a\u56fe\u50cf\u5e76\u5229\u7528\u9884\u8bad\u7ec3\u7684Vision Transformers\u7684\u80fd\u529b\uff0c\u63d0\u9ad8\u4e86\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6027\u80fd\uff0c\u5c55\u793a\u4e86\u5728\u975e\u89c6\u89c9\u9886\u57df\u91cd\u7528\u89c6\u89c9\u8868\u793a\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08297", "pdf": "https://arxiv.org/pdf/2506.08297", "abs": "https://arxiv.org/abs/2506.08297", "authors": ["Nhat Thanh Tran", "Fanghui Xue", "Shuai Zhang", "Jiancheng Lyu", "Yunling Zheng", "Yingyong Qi", "Jack Xin"], "title": "SEMA: a Scalable and Efficient Mamba like Attention via Token Localization and Averaging", "categories": ["cs.CV", "cs.AI"], "comment": "15 pages, figures 3", "summary": "Attention is the critical component of a transformer. Yet the quadratic\ncomputational complexity of vanilla full attention in the input size and the\ninability of its linear attention variant to focus have been challenges for\ncomputer vision tasks. We provide a mathematical definition of generalized\nattention and formulate both vanilla softmax attention and linear attention\nwithin the general framework. We prove that generalized attention disperses,\nthat is, as the number of keys tends to infinity, the query assigns equal\nweights to all keys. Motivated by the dispersion property and recent\ndevelopment of Mamba form of attention, we design Scalable and Efficient Mamba\nlike Attention (SEMA) which utilizes token localization to avoid dispersion and\nmaintain focusing, complemented by theoretically consistent arithmetic\naveraging to capture global aspect of attention. We support our approach on\nImagenet-1k where classification results show that SEMA is a scalable and\neffective alternative beyond linear attention, outperforming recent vision\nMamba models on increasingly larger scales of images at similar model parameter\nsizes.", "AI": {"tldr": "\u5728\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cSEMA\uff08Scalable and Efficient Mamba like Attention\uff09\u4f5c\u4e3a\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8d85\u8d8a\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u8fd1\u671f\u7684\u89c6\u89c9Mamba\u6a21\u578b\u3002", "motivation": "\u4f20\u7edf\u7684\u5168\u6ce8\u610f\u529b\u673a\u5236\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u800c\u7ebf\u6027\u6ce8\u610f\u529b\u673a\u5236\u53c8\u65e0\u6cd5\u805a\u7126\uff0c\u8fd9\u4e3a\u8ba1\u7b97\u673a\u89c6\u89c9\u4efb\u52a1\u5e26\u6765\u4e86\u6311\u6218\u3002\u53d7\u6ce8\u610f\u529b\u5206\u6563\u7279\u6027\u548cMamba\u5f62\u5f0f\u6ce8\u610f\u529b\u53d1\u5c55\u7684\u542f\u53d1\uff0c\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236SEMA\uff0c\u4ee5\u907f\u514d\u5206\u6563\u5e76\u4fdd\u6301\u805a\u7126\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u63d0\u4f9b\u4e86\u5e7f\u4e49\u6ce8\u610f\u529b\u7684\u6570\u5b66\u5b9a\u4e49\uff0c\u5e76\u5c06\u4f20\u7edf\u7684softmax\u6ce8\u610f\u529b\u548c\u7ebf\u6027\u6ce8\u610f\u529b\u7eb3\u5165\u8fd9\u4e00\u901a\u7528\u6846\u67b6\u3002\u63a5\u7740\u8bc1\u660e\u4e86\u5e7f\u4e49\u6ce8\u610f\u529b\u5177\u6709\u5206\u6563\u7279\u6027\uff0c\u5373\u968f\u7740\u952e\u6570\u91cf\u8d8b\u4e8e\u65e0\u7a77\u5927\uff0c\u67e5\u8be2\u4f1a\u8d4b\u4e88\u6240\u6709\u952e\u76f8\u7b49\u7684\u6743\u91cd\u3002\u57fa\u4e8e\u6b64\u7279\u6027\uff0c\u7814\u7a76\u8005\u8bbe\u8ba1\u4e86SEMA\uff0c\u5229\u7528\u4ee4\u724c\u5b9a\u4f4d\u6765\u907f\u514d\u5206\u6563\u5e76\u4fdd\u6301\u805a\u7126\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u4e0a\u4e00\u81f4\u7684\u7b97\u672f\u5e73\u5747\u6765\u6355\u6349\u6ce8\u610f\u529b\u7684\u5168\u5c40\u65b9\u9762\u3002", "result": "\u5728Imagenet-1k\u6570\u636e\u96c6\u4e0a\u7684\u5206\u7c7b\u7ed3\u679c\u663e\u793a\uff0cSEMA\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u4e14\u6709\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236\u66ff\u4ee3\u65b9\u6848\uff0c\u8d85\u8d8a\u4e86\u7ebf\u6027\u6ce8\u610f\u529b\u548c\u8fd1\u671f\u7684\u89c6\u89c9Mamba\u6a21\u578b\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u66f4\u5927\u89c4\u6a21\u56fe\u50cf\u65f6\u8868\u73b0\u66f4\u4f18\uff0c\u540c\u65f6\u6a21\u578b\u53c2\u6570\u91cf\u76f8\u4f3c\u3002", "conclusion": "SEMA\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u6ce8\u610f\u529b\u673a\u5236\uff0c\u5728\u89e3\u51b3\u4f20\u7edf\u6ce8\u610f\u529b\u673a\u5236\u95ee\u9898\u7684\u540c\u65f6\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u53ef\u6269\u5c55\u6027\u548c\u6709\u6548\u6027\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u3002"}}
{"id": "2506.08644", "pdf": "https://arxiv.org/pdf/2506.08644", "abs": "https://arxiv.org/abs/2506.08644", "authors": ["Woosung Kim", "JunHo Seo", "Jongmin Lee", "Byung-Jun Lee"], "title": "Semi-gradient DICE for Offline Constrained Reinforcement Learning", "categories": ["cs.LG"], "comment": "Constrained Offline Reinforcement Learning", "summary": "Stationary Distribution Correction Estimation (DICE) addresses the mismatch\nbetween the stationary distribution induced by a policy and the target\ndistribution required for reliable off-policy evaluation (OPE) and policy\noptimization. DICE-based offline constrained RL particularly benefits from the\nflexibility of DICE, as it simultaneously maximizes return while estimating\ncosts in offline settings. However, we have observed that recent approaches\ndesigned to enhance the offline RL performance of the DICE framework\ninadvertently undermine its ability to perform OPE, making them unsuitable for\nconstrained RL scenarios. In this paper, we identify the root cause of this\nlimitation: their reliance on a semi-gradient optimization, which solves a\nfundamentally different optimization problem and results in failures in cost\nestimation. Building on these insights, we propose a novel method to enable OPE\nand constrained RL through semi-gradient DICE. Our method ensures accurate cost\nestimation and achieves state-of-the-art performance on the offline constrained\nRL benchmark, DSRL.", "AI": {"tldr": "DICE\u89e3\u51b3\u7b56\u7565\u8bf1\u5bfc\u7684\u5e73\u7a33\u5206\u5e03\u4e0e\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u76ee\u6807\u5206\u5e03\u4e4b\u95f4\u7684\u4e0d\u5339\u914d\u95ee\u9898\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u6539\u8fdb\u65b9\u6cd5\u867d\u7136\u63d0\u5347\u4e86\u79bb\u7ebfRL\u6027\u80fd\uff0c\u5374\u524a\u5f31\u4e86\u5176\u5728\u7ea6\u675fRL\u573a\u666f\u4e2d\u7684OPE\u80fd\u529b\u3002\u672c\u6587\u53d1\u73b0\u5176\u6839\u672c\u539f\u56e0\u5728\u4e8e\u534a\u68af\u5ea6\u4f18\u5316\u6539\u53d8\u4e86\u539f\u59cb\u4f18\u5316\u95ee\u9898\uff0c\u4ece\u800c\u5bfc\u81f4\u6210\u672c\u4f30\u8ba1\u5931\u8d25\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u65b9\u6cd5\uff0c\u5728\u4fdd\u6301DICE\u6846\u67b6\u4f18\u52bf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u51c6\u786e\u7684\u6210\u672c\u4f30\u8ba1\u548c\u5353\u8d8a\u7684\u7ea6\u675fRL\u6027\u80fd\u3002", "motivation": "\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u5206\u5e03\u4e0d\u5339\u914d\u95ee\u9898\u4e25\u91cd\u5f71\u54cd\u4e86\u7b56\u7565\u8bc4\u4f30(OPE)\u548c\u4f18\u5316\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u7ea6\u675f\u5f3a\u5316\u5b66\u4e60\u573a\u666f\u4e0b\uff0c\u9700\u8981\u540c\u65f6\u6700\u5927\u5316\u56de\u62a5\u5e76\u4f30\u8ba1\u6210\u672c\u3002\u73b0\u6709\u6539\u8fdbDICE\u7684\u65b9\u6cd5\u867d\u7136\u63d0\u5347\u4e86\u79bb\u7ebfRL\u6027\u80fd\uff0c\u4f46\u524a\u5f31\u4e86\u5176OPE\u80fd\u529b\uff0c\u9650\u5236\u4e86\u5176\u5728\u7ea6\u675fRL\u4e2d\u7684\u5e94\u7528\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709\u65b9\u6cd5\u7684\u7f3a\u9677\uff0c\u53d1\u73b0\u5176\u4f9d\u8d56\u534a\u68af\u5ea6\u4f18\u5316\u662f\u5bfc\u81f4\u6210\u672c\u4f30\u8ba1\u5931\u8d25\u7684\u6839\u672c\u539f\u56e0\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u6539\u8fdb\u7684\u534a\u68af\u5ea6DICE\u6846\u67b6\uff0c\u786e\u4fdd\u5728\u79bb\u7ebf\u7ea6\u675fRL\u4e2d\u5b9e\u73b0\u51c6\u786e\u7684\u6210\u672c\u4f30\u8ba1\u548c\u6709\u6548\u7684\u7b56\u7565\u4f18\u5316\u3002", "result": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u79bb\u7ebf\u7ea6\u675fRL\u57fa\u51c6\u6d4b\u8bd5DSRL\u4e0a\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\uff0c\u540c\u65f6\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728OPE\u4e2d\u7684\u4e0d\u8db3\uff0c\u5b9e\u73b0\u4e86\u51c6\u786e\u7684\u6210\u672c\u4f30\u8ba1\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b0\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u73b0\u6709DICE\u6539\u8fdb\u65b9\u6cd5\u5728\u7ea6\u675fRL\u4e2d\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u63d0\u4f9b\u4e86\u66f4\u53ef\u9760\u7684\u7b56\u7565\u8bc4\u4f30\u548c\u4f18\u5316\u5de5\u5177\u3002"}}
{"id": "2506.08645", "pdf": "https://arxiv.org/pdf/2506.08645", "abs": "https://arxiv.org/abs/2506.08645", "authors": ["Youqi Wu", "Jingwei Zhang", "Farzan Farnia"], "title": "Fusing Cross-modal and Uni-modal Representations: A Kronecker Product Approach", "categories": ["cs.LG"], "comment": null, "summary": "Cross-modal embeddings, such as CLIP, BLIP and their variants, have achieved\npromising results in aligning representations across modalities. However, these\nembeddings could underperform compared to state-of-the-art single-modality\nembeddings on modality-specific tasks. On the other hand, single-modality\nembeddings excel in their domains but lack cross-modal alignment capabilities.\nIn this work, we focus on the problem of unifying cross-modality and\nsingle-modality embeddings to achieve the performance of modality-expert\nembedding within individual modalities while preserving cross-modal alignment.\nTo this end, we propose RP-KrossFuse, a method that leverages a random\nprojection-based Kronecker product to integrate cross-modal embeddings with\nsingle-modality embeddings. RP-KrossFuse aims to fuse the sample-pairwise\nsimilarity scores of the fused embeddings and operates efficiently in a\nspecified kernel space and supports scalable implementations via random Fourier\nfeatures for shift-invariant kernels such as the Gaussian kernel. We\ndemonstrate the effectiveness of RP-KrossFuse through several numerical\nexperiments, combining CLIP embeddings with uni-modal image and text\nembeddings. Our numerical results indicate that RP-KrossFuse achieves\ncompetitive modality-specific performance while retaining cross-modal\nalignment, bridging the gap between cross-modal and single-modality embeddings.", "AI": {"tldr": "RP-KrossFuse\u878d\u5408\u4e86\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\uff0c\u901a\u8fc7\u968f\u673a\u6295\u5f71\u7684Kronecker\u79ef\u5b9e\u73b0\uff0c\u5728\u4fdd\u6301\u8de8\u6a21\u6001\u5bf9\u9f50\u7684\u540c\u65f6\u63d0\u5347\u7279\u5b9a\u6a21\u6001\u6027\u80fd\u3002", "motivation": "\u8de8\u6a21\u6001\u5d4c\u5165\u5728\u591a\u6a21\u6001\u5bf9\u9f50\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7279\u5b9a\u6a21\u6001\u4efb\u52a1\u4e0a\u53ef\u80fd\u4e0d\u5982\u5355\u6a21\u6001\u5d4c\u5165\uff1b\u800c\u5355\u6a21\u6001\u5d4c\u5165\u867d\u5728\u5176\u9886\u57df\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u7f3a\u4e4f\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u7edf\u4e00\u8fd9\u4e24\u7c7b\u5d4c\u5165\u7684\u4f18\u52bf\u3002", "method": "\u63d0\u51faRP-KrossFuse\u65b9\u6cd5\uff0c\u5229\u7528\u57fa\u4e8e\u968f\u673a\u6295\u5f71\u7684Kronecker\u79ef\u5c06\u8de8\u6a21\u6001\u5d4c\u5165\u4e0e\u5355\u6a21\u6001\u5d4c\u5165\u6574\u5408\uff0c\u5e76\u901a\u8fc7\u968f\u673aFourier\u7279\u5f81\u652f\u6301\u9ad8\u6548\u7684\u5927\u89c4\u6a21\u5b9e\u73b0\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cRP-KrossFuse\u7ed3\u5408CLIP\u5d4c\u5165\u4e0e\u5355\u6a21\u6001\u56fe\u50cf\u548c\u6587\u672c\u5d4c\u5165\u540e\uff0c\u5728\u7279\u5b9a\u6a21\u6001\u4efb\u52a1\u4e0a\u8fbe\u5230\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u7559\u4e86\u8de8\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u3002", "conclusion": "RP-KrossFuse\u6709\u6548\u5f25\u5408\u4e86\u8de8\u6a21\u6001\u548c\u5355\u6a21\u6001\u5d4c\u5165\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u591a\u6a21\u6001\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08311", "pdf": "https://arxiv.org/pdf/2506.08311", "abs": "https://arxiv.org/abs/2506.08311", "authors": ["Ira Ceka", "Saurabh Pujar", "Shyam Ramji", "Luca Buratti", "Gail Kaiser", "Baishakhi Ray"], "title": "Understanding Software Engineering Agents Through the Lens of Traceability: An Empirical Study", "categories": ["cs.SE", "cs.AI"], "comment": null, "summary": "With the advent of large language models (LLMs), software engineering agents\n(SWE agents) have emerged as a powerful paradigm for automating a range of\nsoftware tasks -- from code generation and repair to test case synthesis. These\nagents operate autonomously by interpreting user input and responding to\nenvironmental feedback. While various agent architectures have demonstrated\nstrong empirical performance, the internal decision-making worfklows that drive\ntheir behavior remain poorly understood. Deeper insight into these workflows\nhold promise for improving both agent reliability and efficiency. In this work,\nwe present the first systematic study of SWE agent behavior through the lens of\nexecution traces. Our contributions are as follows: (1) we propose the first\ntaxonomy of decision-making pathways across five representative agents; (2)\nusing this taxonomy, we identify three core components essential to agent\nsuccess -- bug localization, patch generation, and reproduction test generation\n-- and study each in depth; (3) we study the impact of test generation on\nsuccessful patch production; and analyze strategies that can lead to successful\ntest generation; (4) we further conduct the first large-scale code clone\nanalysis comparing agent-generated and developer-written patches and provide a\nqualitative study revealing structural and stylistic differences in patch\ncontent. Together, these findings offer novel insights into agent design and\nopen avenues for building agents that are both more effective and more aligned\nwith human development practices.", "AI": {"tldr": "The paper systematically studies SWE agent behavior via execution traces, proposes a taxonomy of decision-making pathways, identifies core components for agent success, examines the impact of test generation on patch production, and conducts a large-scale code clone analysis.", "motivation": "To deepen the understanding of internal decision-making workflows in SWE agents to improve their reliability and efficiency.", "method": "Propose a taxonomy of decision-making pathways for five representative agents, identify core components for agent success, study the impact of test generation on patch production, and conduct a large-scale code clone analysis.", "result": "Provides insights into successful bug localization, patch generation, and reproduction test generation, as well as strategies leading to successful test generation. Reveals structural and stylistic differences between agent-generated and developer-written patches.", "conclusion": "The findings offer novel insights into agent design and open new avenues for building more effective and human-aligned SWE agents."}}
{"id": "2506.08652", "pdf": "https://arxiv.org/pdf/2506.08652", "abs": "https://arxiv.org/abs/2506.08652", "authors": ["Mahesh Godavarti"], "title": "JoFormer (Journey-based Transformer): Theory and Empirical Analysis on the Tiny Shakespeare Dataset", "categories": ["cs.LG", "cs.AI", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "Transformers have demonstrated remarkable success in sequence modeling, yet\neffectively incorporating positional information remains a challenging and\nactive area of research. In this paper, we introduce JoFormer, a journey-based\nTransformer architecture grounded in a recently proposed non-commutative\nalgebra for composing transformations across positions. JoFormer represents\nrelative positions through learnable directional transforms that are\nsequentially composed along the input, thereby extending and generalizing\nexisting approaches based on relative position representations. We derive the\nJoFormer attention mechanism from first principles and show that it subsumes\nstandard methods such as rotary transformations as special cases. To evaluate\nits effectiveness, we compare JoFormer to the RoFormer baseline on the Tiny\nShakespeare character-level language modeling task. Our results demonstrate\nthat\n  JoFormer consistently achieves lower perplexity and faster convergence,\nhighlighting the advantages of its more expressive, journey-based treatment of\nposition. Notably, the per-token JoFormer is still a primitive, conceptual\nvariant with layer-independent angles, yet it already demonstrates strong\nperformance-underscoring its promise as a proof of concept for more expressive\narchitectures. We conclude by discussing how JoFormer offers a principled\napproach to integrating positional structure into Transformer architectures.\nThe code used in this work is available at\nhttps://github.com/mahesh-godavarti/joformer.", "AI": {"tldr": "JoFormer\u662f\u4e00\u79cd\u57fa\u4e8e\u65c5\u7a0b\u7684Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65b9\u5411\u53d8\u6362\u6765\u8868\u793a\u76f8\u5bf9\u4f4d\u7f6e\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u6574\u5408\u4f4d\u7f6e\u4fe1\u606f\u3002\u5b9e\u9a8c\u8868\u660e\uff0cJoFormer\u5728Tiny Shakespeare\u4efb\u52a1\u4e0a\u76f8\u8f83\u4e8eRoFormer\u57fa\u7ebf\u6a21\u578b\u5177\u6709\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "motivation": "\u5c3d\u7ba1Transformers\u5728\u5e8f\u5217\u5efa\u6a21\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u5982\u4f55\u6709\u6548\u7ed3\u5408\u4f4d\u7f6e\u4fe1\u606f\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u57fa\u4e8e\u65c5\u7a0b\u7684Transformer\u67b6\u6784\u3002", "method": "JoFormer\u5229\u7528\u6700\u8fd1\u63d0\u51fa\u7684\u975e\u4ea4\u6362\u4ee3\u6570\uff0c\u901a\u8fc7\u6cbf\u8f93\u5165\u5e8f\u5217\u987a\u5e8f\u7ec4\u5408\u53ef\u5b66\u4e60\u7684\u65b9\u5411\u53d8\u6362\u6765\u8868\u793a\u76f8\u5bf9\u4f4d\u7f6e\u3002\u5176\u6ce8\u610f\u529b\u673a\u5236\u4ece\u7b2c\u4e00\u6027\u539f\u7406\u63a8\u5bfc\uff0c\u5e76\u6982\u62ec\u4e86\u73b0\u6709\u7684\u65b9\u6cd5\u5982\u65cb\u8f6c\u53d8\u6362\u3002", "result": "\u5728Tiny Shakespeare\u5b57\u7b26\u7ea7\u8bed\u8a00\u5efa\u6a21\u4efb\u52a1\u4e2d\uff0cJoFormer\u76f8\u8f83\u4e8eRoFormer\u57fa\u7ebf\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u4f4e\u7684\u56f0\u60d1\u5ea6\u548c\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u3002", "conclusion": "JoFormer\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u539f\u5219\u7684\u65b9\u6cd5\u5c06\u4f4d\u7f6e\u7ed3\u6784\u6574\u5408\u5230Transformer\u67b6\u6784\u4e2d\uff0c\u5c55\u73b0\u51fa\u4f5c\u4e3a\u66f4\u8868\u8fbe\u6027\u67b6\u6784\u6982\u5ff5\u9a8c\u8bc1\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.08655", "pdf": "https://arxiv.org/pdf/2506.08655", "abs": "https://arxiv.org/abs/2506.08655", "authors": ["Kamil Jerabek", "Jan Luxemburk", "Richard Plny", "Josef Koumar", "Jaroslav Pesek", "Karel Hynek"], "title": "When Simple Model Just Works: Is Network Traffic Classification in Crisis?", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "Machine learning has been applied to network traffic classification (TC) for\nover two decades. While early efforts used shallow models, the latter 2010s saw\na shift toward complex neural networks, often reporting near-perfect accuracy.\nHowever, it was recently revealed that a simple k-NN baseline using packet\nsequences metadata (sizes, times, and directions) can be on par or even\noutperform more complex methods. In this paper, we investigate this phenomenon\nfurther and evaluate this baseline across 12 datasets and 15 TC tasks, and\ninvestigate why it performs so well. Our analysis shows that most datasets\ncontain over 50% redundant samples (identical packet sequences), which\nfrequently appear in both training and test sets due to common splitting\npractices. This redundancy can lead to overestimated model performance and\nreduce the theoretical maximum accuracy when identical flows have conflicting\nlabels. Given its distinct characteristics, we further argue that standard\nmachine learning practices adapted from domains like NLP or computer vision may\nbe ill-suited for TC. Finally, we propose new directions for task formulation\nand evaluation to address these challenges and help realign the field.", "AI": {"tldr": "The paper investigates why a simple k-NN baseline performs well in network traffic classification, finding that dataset redundancy contributes to overestimated model performance. It questions standard ML practices for TC and proposes new directions.", "motivation": "To understand why a simple k-NN baseline using packet sequences metadata can perform as well as or better than complex neural networks in network traffic classification.", "method": "Evaluate the k-NN baseline across 12 datasets and 15 TC tasks, analyze dataset characteristics, and propose new task formulation and evaluation methods.", "result": "Most datasets contain over 50% redundant samples, which leads to overestimated model performance and reduced theoretical maximum accuracy when identical flows have conflicting labels.", "conclusion": "Standard machine learning practices may be unsuited for network traffic classification; new task formulation and evaluation methods are proposed."}}
{"id": "2506.08660", "pdf": "https://arxiv.org/pdf/2506.08660", "abs": "https://arxiv.org/abs/2506.08660", "authors": ["Jinkwan Jang", "Hyungjin Park", "Jinmyeong Choi", "Taesup Kim"], "title": "Towards Robust Real-World Multivariate Time Series Forecasting: A Unified Framework for Dependency, Asynchrony, and Missingness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world time series data are inherently multivariate, often exhibiting\ncomplex inter-channel dependencies. Each channel is typically sampled at its\nown period and is prone to missing values due to various practical and\noperational constraints. These characteristics pose fundamental challenges\nrelated to channel dependency, sampling asynchrony, and missingness, all of\nwhich must be addressed to enable robust and reliable forecasting in practical\nsettings. However, most existing architectures are built on oversimplified\nassumptions, such as identical sampling periods across channels and fully\nobserved inputs at test time, which often do not hold in real-world scenarios.\nTo bridge this gap, we propose ChannelTokenFormer, a Transformer-based\nforecasting model with a flexible architecture designed to explicitly capture\ncross-channel interactions, accommodate channel-wise asynchronous sampling, and\neffectively handle missing values. Extensive experiments on three benchmark\ndatasets modified to reflect practical settings, along with one real-world\nindustrial dataset, demonstrate the superior robustness and accuracy of\nChannelTokenFormer under challenging real-world conditions.", "AI": {"tldr": "The paper proposes ChannelTokenFormer, a Transformer-based model designed to capture cross-channel interactions, handle asynchronous sampling, and manage missing values for robust time series forecasting in real-world scenarios.", "motivation": "Real-world time series data have complexities such as multivariate nature, inter-channel dependencies, asynchronous sampling, and missing values which current models fail to address effectively due to oversimplified assumptions.", "method": "ChannelTokenFormer is a Transformer-based forecasting model with a flexible architecture that explicitly captures cross-channel interactions, accommodates channel-wise asynchronous sampling, and effectively handles missing values.", "result": "Extensive experiments on four datasets (three benchmark datasets modified to reflect practical settings and one real-world industrial dataset) demonstrate superior robustness and accuracy of ChannelTokenFormer under challenging real-world conditions.", "conclusion": "ChannelTokenFormer successfully addresses the challenges of channel dependency, sampling asynchrony, and missingness in real-world time series data, providing robust and reliable forecasting."}}
{"id": "2506.08662", "pdf": "https://arxiv.org/pdf/2506.08662", "abs": "https://arxiv.org/abs/2506.08662", "authors": ["Florian Borzechowski", "Michael Sch\u00e4fer", "Heiko Schwarz", "Jonathan Pfaff", "Detlev Marpe", "Thomas Wiegand"], "title": "Optimizing Learned Image Compression on Scalar and Entropy-Constraint Quantization", "categories": ["cs.LG", "cs.AI", "cs.IT", "math.IT"], "comment": "Accepted at ICIP2024, the IEEE International Conference on Image\n  Processing", "summary": "The continuous improvements on image compression with variational\nautoencoders have lead to learned codecs competitive with conventional\napproaches in terms of rate-distortion efficiency. Nonetheless, taking the\nquantization into account during the training process remains a problem, since\nit produces zero derivatives almost everywhere and needs to be replaced with a\ndifferentiable approximation which allows end-to-end optimization. Though there\nare different methods for approximating the quantization, none of them model\nthe quantization noise correctly and thus, result in suboptimal networks.\nHence, we propose an additional finetuning training step: After conventional\nend-to-end training, parts of the network are retrained on quantized latents\nobtained at the inference stage. For entropy-constraint quantizers like\nTrellis-Coded Quantization, the impact of the quantizer is particularly\ndifficult to approximate by rounding or adding noise as the quantized latents\nare interdependently chosen through a trellis search based on both the entropy\nmodel and a distortion measure. We show that retraining on correctly quantized\ndata consistently yields additional coding gain for both uniform scalar and\nespecially for entropy-constraint quantization, without increasing inference\ncomplexity. For the Kodak test set, we obtain average savings between 1% and\n2%, and for the TecNick test set up to 2.2% in terms of Bj{\\o}ntegaard-Delta\nbitrate.", "AI": {"tldr": "An additional finetuning training step is proposed to retrain parts of the network on quantized latents, yielding additional coding gain without increasing inference complexity.", "motivation": "The problem of taking quantization into account during the training process in image compression with variational autoencoders leads to suboptimal networks due to incorrect modeling of quantization noise.", "method": "Propose an additional finetuning training step where parts of the network are retrained on quantized latents obtained at the inference stage after conventional end-to-end training.", "result": "Retraining on correctly quantized data yields additional coding gain for both uniform scalar and entropy-constraint quantization, obtaining average savings between 1% and 2% for the Kodak test set, and up to 2.2% for the TecNick test set in terms of Bj\u00f8ntegaard-Delta bitrate.", "conclusion": "The proposed method achieves additional coding gain without increasing inference complexity."}}
{"id": "2506.08344", "pdf": "https://arxiv.org/pdf/2506.08344", "abs": "https://arxiv.org/abs/2506.08344", "authors": ["Ne\u015fet \u00dcnver Akmandor", "Sarvesh Prajapati", "Mark Zolotas", "Ta\u015fk\u0131n Pad\u0131r"], "title": "Re4MPC: Reactive Nonlinear MPC for Multi-model Motion Planning via Deep Reinforcement Learning", "categories": ["cs.RO", "cs.AI", "cs.LG", "cs.SY", "eess.SY"], "comment": "Accepted to the 2025 IEEE International Conference on Automation\n  Science and Engineering (CASE)", "summary": "Traditional motion planning methods for robots with many degrees-of-freedom,\nsuch as mobile manipulators, are often computationally prohibitive for\nreal-world settings. In this paper, we propose a novel multi-model motion\nplanning pipeline, termed Re4MPC, which computes trajectories using Nonlinear\nModel Predictive Control (NMPC). Re4MPC generates trajectories in a\ncomputationally efficient manner by reactively selecting the model, cost, and\nconstraints of the NMPC problem depending on the complexity of the task and\nrobot state. The policy for this reactive decision-making is learned via a Deep\nReinforcement Learning (DRL) framework. We introduce a mathematical formulation\nto integrate NMPC into this DRL framework. To validate our methodology and\ndesign choices, we evaluate DRL training and test outcomes in a physics-based\nsimulation involving a mobile manipulator. Experimental results demonstrate\nthat Re4MPC is more computationally efficient and achieves higher success rates\nin reaching end-effector goals than the NMPC baseline, which computes\nwhole-body trajectories without our learning mechanism.", "AI": {"tldr": "The paper presents Re4MPC, a multi-model motion planning pipeline for robots that uses NMPC and DRL to improve computational efficiency and success rates in reaching end-effector goals.", "motivation": "Traditional motion planning methods are computationally prohibitive for real-world settings with many degrees-of-freedom.", "method": "Re4MPC generates trajectories using NMPC and reactively selects the model, cost, and constraints based on task complexity and robot state. The reactive decision-making policy is learned via DRL framework.", "result": "Re4MPC is more computationally efficient and achieves higher success rates than the NMPC baseline in physics-based simulations with a mobile manipulator.", "conclusion": "Re4MPC improves computational efficiency and success rates for motion planning in complex tasks."}}
{"id": "2506.08669", "pdf": "https://arxiv.org/pdf/2506.08669", "abs": "https://arxiv.org/abs/2506.08669", "authors": ["Dongge Han", "Menglin Xia", "Daniel Madrigal Diaz", "Samuel Kessler", "Ankur Mallick", "Xuchao Zhang", "Mirian Del Carmen Hipolito Garcia", "Jin Xu", "Victor R\u00fchle", "Saravan Rajmohan"], "title": "Enhancing Reasoning Capabilities of Small Language Models with Blueprints and Prompt Template Search", "categories": ["cs.LG", "cs.AI"], "comment": "TTODLer-FM Workshop@ICML'25 (Tiny Titans: The next wave of On-Device\n  Learning for Foundational Models)", "summary": "Small language models (SLMs) offer promising and efficient alternatives to\nlarge language models (LLMs). However, SLMs' limited capacity restricts their\nreasoning capabilities and makes them sensitive to prompt variations. To\naddress these challenges, we propose a novel framework that enhances SLM\nreasoning capabilities through LLM generated blueprints. The blueprints provide\nstructured, high-level reasoning guides that help SLMs systematically tackle\nrelated problems. Furthermore, our framework integrates a prompt template\nsearch mechanism to mitigate the SLMs' sensitivity to prompt variations. Our\nframework demonstrates improved SLM performance across various tasks, including\nmath (GSM8K), coding (MBPP), and logic reasoning (BBH). Our approach improves\nthe reasoning capabilities of SLMs without increasing model size or requiring\nadditional training, offering a lightweight and deployment-friendly solution\nfor on-device or resource-constrained environments.", "AI": {"tldr": "This paper presents a framework to boost SLMs reasoning capabilities via LLM generated blueprints and a prompt template search mechanism, enhancing performance in various tasks without increasing model size or training.", "motivation": "Small language models (SLMs) have limited reasoning capabilities and are sensitive to prompt variations due to their restricted capacity compared to large language models (LLMs).", "method": "The method involves creating a novel framework that leverages LLM generated blueprints for structured reasoning guides and integrates a prompt template search mechanism to reduce sensitivity to prompt changes.", "result": "The framework successfully improves the performance of SLMs in math (GSM8K), coding (MBPP), and logic reasoning (BBH) tasks.", "conclusion": "This approach enhances SLM reasoning without increasing model size or requiring additional training, providing a lightweight solution ideal for on-device or resource-constrained settings."}}
{"id": "2506.08346", "pdf": "https://arxiv.org/pdf/2506.08346", "abs": "https://arxiv.org/abs/2506.08346", "authors": ["Wenhan Yao", "Fen Xiao", "Xiarun Chen", "Jia Liu", "YongQiang He", "Weiping Wen"], "title": "SPBA: Utilizing Speech Large Language Model for Backdoor Attacks on Speech Classification Models", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "comment": "Accepted by IJCNN 2025", "summary": "Deep speech classification tasks, including keyword spotting and speaker\nverification, are vital in speech-based human-computer interaction. Recently,\nthe security of these technologies has been revealed to be susceptible to\nbackdoor attacks. Specifically, attackers use noisy disruption triggers and\nspeech element triggers to produce poisoned speech samples that train models to\nbecome vulnerable. However, these methods typically create only a limited\nnumber of backdoors due to the inherent constraints of the trigger function. In\nthis paper, we propose that speech backdoor attacks can strategically focus on\nspeech elements such as timbre and emotion, leveraging the Speech Large\nLanguage Model (SLLM) to generate diverse triggers. Increasing the number of\ntriggers may disproportionately elevate the poisoning rate, resulting in higher\nattack costs and a lower success rate per trigger. We introduce the Multiple\nGradient Descent Algorithm (MGDA) as a mitigation strategy to address this\nchallenge. The proposed attack is called the Speech Prompt Backdoor Attack\n(SPBA). Building on this foundation, we conducted attack experiments on two\nspeech classification tasks, demonstrating that SPBA shows significant trigger\neffectiveness and achieves exceptional performance in attack metrics.", "AI": {"tldr": "The paper proposes Speech Prompt Backdoor Attack (SPBA) that focuses on speech elements using Speech Large Language Model (SLLM) to generate diverse triggers and introduces MGDA as a mitigation strategy. Experiments show SPBA's effectiveness in two speech classification tasks.", "motivation": "To address the limitation of creating only a limited number of backdoors in speech-based human-computer interaction technologies due to the inherent constraints of the trigger function.", "method": "Propose SPBA which strategically focuses on speech elements like timbre and emotion, leveraging SLLM to generate diverse triggers and introduce MGDA as a mitigation strategy.", "result": "SPBA demonstrates significant trigger effectiveness and achieves exceptional performance in attack metrics through experiments on two speech classification tasks.", "conclusion": "SPBA is effective in speech backdoor attacks with diverse triggers and MGDA can be used as a mitigation strategy."}}
{"id": "2506.08673", "pdf": "https://arxiv.org/pdf/2506.08673", "abs": "https://arxiv.org/abs/2506.08673", "authors": ["Diptarka Chakraborty", "Kushagra Chatterjee", "Debarati Das", "Tien Long Nguyen", "Romina Nobahari"], "title": "Towards Fair Representation: Clustering and Consensus", "categories": ["cs.LG", "cs.DS"], "comment": "The paper has been accepted at the Conference on Learning Theory\n  (COLT) 2025", "summary": "Consensus clustering, a fundamental task in machine learning and data\nanalysis, aims to aggregate multiple input clusterings of a dataset,\npotentially based on different non-sensitive attributes, into a single\nclustering that best represents the collective structure of the data. In this\nwork, we study this fundamental problem through the lens of fair clustering, as\nintroduced by Chierichetti et al. [NeurIPS'17], which incorporates the\ndisparate impact doctrine to ensure proportional representation of each\nprotected group in the dataset within every cluster. Our objective is to find a\nconsensus clustering that is not only representative but also fair with respect\nto specific protected attributes. To the best of our knowledge, we are the\nfirst to address this problem and provide a constant-factor approximation.\n  As part of our investigation, we examine how to minimally modify an existing\nclustering to enforce fairness -- an essential postprocessing step in many\nclustering applications that require fair representation. We develop an optimal\nalgorithm for datasets with equal group representation and near-linear time\nconstant factor approximation algorithms for more general scenarios with\ndifferent proportions of two group sizes. We complement our approximation\nresult by showing that the problem is NP-hard for two unequal-sized groups.\nGiven the fundamental nature of this problem, we believe our results on Closest\nFair Clustering could have broader implications for other clustering problems,\nparticularly those for which no prior approximation guarantees exist for their\nfair variants.", "AI": {"tldr": "\u7814\u7a76\u4e86\u901a\u8fc7\u516c\u5e73\u805a\u7c7b\u89c6\u89d2\u7684\u5171\u8bc6\u805a\u7c7b\u95ee\u9898\uff0c\u63d0\u51fa\u9996\u4e2a\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u73b0\u6709\u805a\u7c07\u4fee\u6539\u4e3a\u516c\u5e73\u805a\u7c7b\u7684\u65b9\u6cd5\u3002", "motivation": "\u5171\u8bc6\u805a\u7c7b\u65e8\u5728\u5c06\u6570\u636e\u96c6\u7684\u591a\u4e2a\u8f93\u5165\u805a\u7c7b\u6574\u5408\u4e3a\u4e00\u4e2a\u4ee3\u8868\u6570\u636e\u96c6\u4f53\u7ed3\u6784\u7684\u805a\u7c7b\uff0c\u4f46\u672a\u8003\u8651\u516c\u5e73\u6027\u3002\u672c\u6587\u7ed3\u5408\u516c\u5e73\u805a\u7c7b\u7406\u5ff5\uff0c\u786e\u4fdd\u6bcf\u4e2a\u53d7\u4fdd\u62a4\u7fa4\u4f53\u5728\u6bcf\u4e2a\u7c07\u5185\u90fd\u6709\u6bd4\u4f8b\u4ee3\u8868\u6027\uff0c\u4ece\u800c\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u5171\u8bc6\u805a\u7c7b\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u5177\u6709\u4ee3\u8868\u6027\uff0c\u800c\u4e14\u5bf9\u7279\u5b9a\u4fdd\u62a4\u5c5e\u6027\u516c\u5e73\u3002\n2. \u7814\u7a76\u5982\u4f55\u6700\u5c0f\u4fee\u6539\u73b0\u6709\u805a\u7c7b\u4ee5\u5f3a\u5236\u5b9e\u73b0\u516c\u5e73\u6027\uff0c\u5f00\u53d1\u9488\u5bf9\u4e0d\u540c\u573a\u666f\u7684\u7b97\u6cd5\uff1a\n   - \u5bf9\u4e8e\u7b49\u7fa4\u4f53\u8868\u793a\u7684\u6570\u636e\u96c6\uff0c\u5f00\u53d1\u6700\u4f18\u7b97\u6cd5\u3002\n   - \u5bf9\u4e8e\u4e0d\u540c\u6bd4\u4f8b\u7684\u4e24\u7ec4\u5927\u5c0f\u7684\u66f4\u4e00\u822c\u60c5\u51b5\uff0c\u5f00\u53d1\u8fd1\u7ebf\u6027\u65f6\u95f4\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\u3002\n3. \u8bc1\u660e\u5bf9\u4e8e\u4e24\u4e2a\u4e0d\u7b49\u5927\u5c0f\u7684\u7ec4\uff0c\u8be5\u95ee\u9898\u662fNP\u96be\u7684\u3002", "result": "1. \u63d0\u51fa\u4e86\u9996\u4e2a\u89e3\u51b3\u6b64\u95ee\u9898\u7684\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\u3002\n2. \u5f00\u53d1\u4e86\u9488\u5bf9\u4e0d\u540c\u6570\u636e\u96c6\u7279\u6027\u7684\u6709\u6548\u7b97\u6cd5\u3002\n3. \u8bc1\u660e\u4e86\u95ee\u9898\u7684\u7406\u8bba\u590d\u6742\u6027\uff08NP\u96be\uff09\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u89e3\u51b3\u4e86\u5bfb\u627e\u65e2\u5177\u4ee3\u8868\u6027\u53c8\u516c\u5e73\u7684\u5171\u8bc6\u805a\u7c7b\u7684\u95ee\u9898\uff0c\u63d0\u4f9b\u4e86\u5e38\u6570\u56e0\u5b50\u8fd1\u4f3c\u7b97\u6cd5\u5e76\u8bc1\u660e\u4e86\u95ee\u9898\u7684\u590d\u6742\u6027\u3002\u8fd9\u4e9b\u7ed3\u679c\u53ef\u80fd\u5bf9\u5176\u4ed6\u5c1a\u672a\u6709\u516c\u5e73\u53d8\u4f53\u8fd1\u4f3c\u4fdd\u8bc1\u7684\u805a\u7c7b\u95ee\u9898\u4ea7\u751f\u5e7f\u6cdb\u5f71\u54cd\u3002"}}
{"id": "2506.08349", "pdf": "https://arxiv.org/pdf/2506.08349", "abs": "https://arxiv.org/abs/2506.08349", "authors": ["Yuxuan Zhou", "Xien Liu", "Chenwei Yan", "Chen Ning", "Xiao Zhang", "Boxun Li", "Xiangling Fu", "Shijin Wang", "Guoping Hu", "Yu Wang", "Ji Wu"], "title": "Evaluating LLMs Across Multi-Cognitive Levels: From Medical Knowledge Mastery to Scenario-Based Problem Solving", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 11 figures. Accepted by ICML 2025", "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nvarious medical benchmarks, but their capabilities across different cognitive\nlevels remain underexplored. Inspired by Bloom's Taxonomy, we propose a\nmulti-cognitive-level evaluation framework for assessing LLMs in the medical\ndomain in this study. The framework integrates existing medical datasets and\nintroduces tasks targeting three cognitive levels: preliminary knowledge grasp,\ncomprehensive knowledge application, and scenario-based problem solving. Using\nthis framework, we systematically evaluate state-of-the-art general and medical\nLLMs from six prominent families: Llama, Qwen, Gemma, Phi, GPT, and DeepSeek.\nOur findings reveal a significant performance decline as cognitive complexity\nincreases across evaluated models, with model size playing a more critical role\nin performance at higher cognitive levels. Our study highlights the need to\nenhance LLMs' medical capabilities at higher cognitive levels and provides\ninsights for developing LLMs suited to real-world medical applications.", "AI": {"tldr": "Large language models (LLMs) show great performance on medical benchmarks, but their capabilities across different cognitive levels are underexplored. This study proposes a multi-cognitive-level evaluation framework inspired by Bloom's Taxonomy for assessing LLMs in the medical domain.", "motivation": "To explore the capabilities of LLMs across different cognitive levels in the medical domain.", "method": "Propose a multi-cognitive-level evaluation framework inspired by Bloom's Taxonomy that integrates existing medical datasets and introduces tasks targeting three cognitive levels: preliminary knowledge grasp, comprehensive knowledge application, and scenario-based problem solving.", "result": "State-of-the-art general and medical LLMs from six families were evaluated using this framework. Findings reveal a significant performance decline as cognitive complexity increases, with model size playing a more critical role in performance at higher cognitive levels.", "conclusion": "The study highlights the need to enhance LLMs' medical capabilities at higher cognitive levels and provides insights for developing LLMs suited to real-world medical applications."}}
{"id": "2506.08681", "pdf": "https://arxiv.org/pdf/2506.08681", "abs": "https://arxiv.org/abs/2506.08681", "authors": ["Phuc Minh Nguyen", "Ngoc-Hieu Nguyen", "Duy H. M. Nguyen", "Anji Liu", "An Mai", "Binh T. Nguyen", "Daniel Sonntag", "Khoa D. Doan"], "title": "Mitigating Reward Over-optimization in Direct Alignment Algorithms with Importance Sampling", "categories": ["cs.LG"], "comment": "First version", "summary": "Direct Alignment Algorithms (DAAs) such as Direct Preference Optimization\n(DPO) have emerged as alternatives to the standard Reinforcement Learning from\nHuman Feedback (RLHF) for aligning large language models (LLMs) with human\nvalues. However, these methods are more susceptible to over-optimization, in\nwhich the model drifts away from the reference policy, leading to degraded\nperformance as training progresses. This paper proposes a novel\nimportance-sampling approach to mitigate the over-optimization problem of\noffline DAAs. This approach, called (IS-DAAs), multiplies the DAA objective\nwith an importance ratio that accounts for the reference policy distribution.\nIS-DAAs additionally avoid the high variance issue associated with importance\nsampling by clipping the importance ratio to a maximum value. Our extensive\nexperiments demonstrate that IS-DAAs can effectively mitigate\nover-optimization, especially under low regularization strength, and achieve\nbetter performance than other methods designed to address this problem. Our\nimplementations are provided publicly at this link.", "AI": {"tldr": "Direct Alignment Algorithms (DAAs) like Direct Preference Optimization (DPO) face over-optimization issues where models drift from reference policies. This paper introduces IS-DAAs, an importance-sampling method that adjusts the DAA objective with an importance ratio and clips it to reduce variance. Experiments show IS-DAAs mitigate over-optimization better than other methods under low regularization.", "motivation": "To address the over-optimization problem in DAAs which causes models to drift from reference policies leading to performance degradation.", "method": "Propose IS-DAAs by incorporating an importance ratio into the DAA objective and clipping the ratio to control variance.", "result": "IS-DAAs effectively mitigate over-optimization particularly under low regularization strength, outperforming other methods aimed at solving this issue.", "conclusion": "IS-DAAs provide a solution to the over-optimization challenge in DAAs improving model alignment with human values."}}
{"id": "2506.08351", "pdf": "https://arxiv.org/pdf/2506.08351", "abs": "https://arxiv.org/abs/2506.08351", "authors": ["Huixuan Zhang", "Junzhe Zhang", "Xiaojun Wan"], "title": "How Much To Guide: Revisiting Adaptive Guidance in Classifier-Free Guidance Text-to-Vision Diffusion Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "With the rapid development of text-to-vision generation diffusion models,\nclassifier-free guidance has emerged as the most prevalent method for\nconditioning. However, this approach inherently requires twice as many steps\nfor model forwarding compared to unconditional generation, resulting in\nsignificantly higher costs. While previous study has introduced the concept of\nadaptive guidance, it lacks solid analysis and empirical results, making\nprevious method unable to be applied to general diffusion models. In this work,\nwe present another perspective of applying adaptive guidance and propose Step\nAG, which is a simple, universally applicable adaptive guidance strategy. Our\nevaluations focus on both image quality and image-text alignment. whose results\nindicate that restricting classifier-free guidance to the first several\ndenoising steps is sufficient for generating high-quality, well-conditioned\nimages, achieving an average speedup of 20% to 30%. Such improvement is\nconsistent across different settings such as inference steps, and various\nmodels including video generation models, highlighting the superiority of our\nmethod.", "AI": {"tldr": "In this paper, researchers introduce Step AG, a new adaptive guidance strategy for text-to-vision generation diffusion models which restricts classifier-free guidance to the first several denoising steps. This approach generates high-quality images with an average speedup of 20% to 30%, applicable across different settings and models.", "motivation": "The motivation of this paper is to address the limitation of classifier-free guidance in text-to-vision generation diffusion models, which requires twice as many steps as unconditional generation and thus incurs higher costs. Previous attempts at adaptive guidance lack solid analysis and empirical results, making them inapplicable to general diffusion models.", "method": "The authors propose Step AG, a simple and universally applicable adaptive guidance strategy. This method focuses classifier-free guidance on the initial denoising steps, reducing the number of required steps while maintaining image quality and alignment.", "result": "Step AG achieves an average speedup of 20% to 30% without compromising image quality or image-text alignment. The improvement remains consistent across various inference steps and models, including video generation models.", "conclusion": "Step AG offers a superior alternative to existing methods by providing a cost-effective way to maintain high-quality, well-conditioned image generation in text-to-vision diffusion models."}}
{"id": "2506.08698", "pdf": "https://arxiv.org/pdf/2506.08698", "abs": "https://arxiv.org/abs/2506.08698", "authors": ["Boyu Xie", "Tangtang Xie"], "title": "Variational Autoencoder-Based Approach to Latent Feature Analysis on Efficient Representation of Power Load Monitoring Data", "categories": ["cs.LG", "cs.AI"], "comment": "9 pages, 2 figures", "summary": "With the development of smart grids, High-Dimensional and Incomplete (HDI)\nPower Load Monitoring (PLM) data challenges the performance of Power Load\nForecasting (PLF) models. In this paper, we propose a potential\ncharacterization model VAE-LF based on Variational Autoencoder (VAE) for\nefficiently representing and complementing PLM missing data. VAE-LF learns a\nlow-dimensional latent representation of the data using an Encoder-Decoder\nstructure by splitting the HDI PLM data into vectors and feeding them\nsequentially into the VAE-LF model, and generates the complementary data.\nExperiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark\nmodels in both 5% and 10% sparsity test cases, with significantly lower RMSE\nand MAE, and especially outperforms on low sparsity ratio data. The method\nprovides an efficient data-completion solution for electric load management in\nsmart grids.", "AI": {"tldr": "The paper proposes VAE-LF, a model based on Variational Autoencoder for handling high-dimensional and incomplete power load monitoring data. It efficiently represents and complements missing data, outperforming benchmarks in experiments with the UK-DALE dataset.", "motivation": "Smart grids have led to high-dimensional and incomplete power load monitoring data, which poses challenges for power load forecasting models.", "method": "The VAE-LF model uses an Encoder-Decoder structure to learn a low-dimensional latent representation of the data by splitting high-dimensional and incomplete power load monitoring data into vectors and sequentially feeding them into the model to generate complementary data.", "result": "Experiments on the UK-DALE dataset demonstrated that VAE-LF outperforms other benchmark models in both 5% and 10% sparsity test cases with significantly lower RMSE and MAE, particularly excelling with low sparsity ratio data.", "conclusion": "VAE-LF provides an efficient data-completion solution for electric load management in smart grids."}}
{"id": "2506.08354", "pdf": "https://arxiv.org/pdf/2506.08354", "abs": "https://arxiv.org/abs/2506.08354", "authors": ["Yiqun Sun", "Qiang Huang", "Anthony K. H. Tung", "Jun Yu"], "title": "Text Embeddings Should Capture Implicit Semantics, Not Just Surface Meaning", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "This position paper argues that the text embedding research community should\nmove beyond surface meaning and embrace implicit semantics as a central\nmodeling goal. Text embedding models have become foundational in modern NLP,\npowering a wide range of applications and drawing increasing research\nattention. Yet, much of this progress remains narrowly focused on surface-level\nsemantics. In contrast, linguistic theory emphasizes that meaning is often\nimplicit, shaped by pragmatics, speaker intent, and sociocultural context.\nCurrent embedding models are typically trained on data that lacks such depth\nand evaluated on benchmarks that reward the capture of surface meaning. As a\nresult, they struggle with tasks requiring interpretive reasoning, speaker\nstance, or social meaning. Our pilot study highlights this gap, showing that\neven state-of-the-art models perform only marginally better than simplistic\nbaselines on implicit semantics tasks. To address this, we call for a paradigm\nshift: embedding research should prioritize more diverse and linguistically\ngrounded training data, design benchmarks that evaluate deeper semantic\nunderstanding, and explicitly frame implicit meaning as a core modeling\nobjective, better aligning embeddings with real-world language complexity.", "AI": {"tldr": "This paper argues that text embedding research should focus more on implicit semantics rather than just surface-level semantics to better capture real-world language complexity.", "motivation": "The motivation of this paper is the observation that current text embedding models are predominantly focused on surface-level semantics, which leads to difficulties in handling tasks that require interpretive reasoning, speaker stance, or social meaning. It highlights a gap where even state-of-the-art models perform only marginally better than simple baselines on implicit semantics tasks.", "method": "The authors propose a paradigm shift in text embedding research by prioritizing more diverse and linguistically grounded training data, designing benchmarks that evaluate deeper semantic understanding, and explicitly framing implicit meaning as a core modeling objective.", "result": "A pilot study conducted by the authors shows that there is a significant gap in performance between current models and the requirements for understanding implicit semantics.", "conclusion": "The paper concludes by calling for the text embedding research community to embrace implicit semantics as a central modeling goal to align embeddings with the complexity of real-world language."}}
{"id": "2506.08727", "pdf": "https://arxiv.org/pdf/2506.08727", "abs": "https://arxiv.org/abs/2506.08727", "authors": ["Samarth Sikand", "Rohit Mehra", "Priyavanshi Pathania", "Nikhil Bamby", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Breaking the ICE: Exploring promises and challenges of benchmarks for Inference Carbon & Energy estimation for LLMs", "categories": ["cs.LG", "cs.AI", "cs.CY", "cs.SE"], "comment": "5 pages. To be published in the proceedings of 9th International\n  Workshop on Green and Sustainable Software (GREENS '25), April 29, 2025,\n  Ottawa, Canada (Co-located with ICSE 2025)", "summary": "While Generative AI stands to be one of the fastest adopted technologies\never, studies have made evident that the usage of Large Language Models (LLMs)\nputs significant burden on energy grids and our environment. It may prove a\nhindrance to the Sustainability goals of any organization. A crucial step in\nany Sustainability strategy is monitoring or estimating the energy consumption\nof various components. While there exist multiple tools for monitoring energy\nconsumption, there is a dearth of tools/frameworks for estimating the\nconsumption or carbon emissions. Current drawbacks of both monitoring and\nestimation tools include high input data points, intrusive nature, high error\nmargin, etc. We posit that leveraging emerging LLM benchmarks and related data\npoints can help overcome aforementioned challenges while balancing accuracy of\nthe emission estimations. To that extent, we discuss the challenges of current\napproaches and present our evolving framework, R-ICE, which estimates prompt\nlevel inference carbon emissions by leveraging existing state-of-the-art(SOTA)\nbenchmark. This direction provides a more practical and non-intrusive way to\nenable emerging use-cases like dynamic LLM routing, carbon accounting, etc. Our\npromising validation results suggest that benchmark-based modelling holds great\npotential for inference emission estimation and warrants further exploration\nfrom the scientific community.", "AI": {"tldr": "Generative AI, including Large Language Models (LLMs), has a significant impact on energy consumption and carbon emissions, posing challenges to sustainability goals. Existing tools for monitoring and estimating energy usage have limitations such as requiring high input data, being intrusive, and having a large error margin. To address these issues, the authors propose R-ICE, a framework that uses existing benchmarks to estimate carbon emissions at the prompt level for LLM inferences. This approach is non-intrusive and supports applications like dynamic LLM routing and carbon accounting. Initial validation results are promising, indicating the potential of benchmark-based modeling for emission estimation.", "motivation": "The motivation behind this paper is the need for better tools to monitor and estimate the energy consumption and carbon emissions associated with the use of Large Language Models (LLMs). Current tools suffer from drawbacks such as requiring extensive input data, being intrusive, and having high error margins. There is a clear demand for a more practical and accurate method to support sustainability goals.", "method": "The method involves leveraging existing state-of-the-art (SOTA) benchmarks related to LLMs to develop a framework called R-ICE. This framework estimates prompt-level inference carbon emissions by using benchmark data points. It aims to provide a non-intrusive way to estimate emissions, supporting emerging use-cases such as dynamic LLM routing and carbon accounting.", "result": "The validation results of the R-ICE framework are promising, suggesting that benchmark-based modeling holds great potential for accurately estimating inference emissions. This approach could lead to further exploration and advancements in emission estimation techniques.", "conclusion": "The conclusion drawn from this study is that utilizing benchmark-based modeling for estimating carbon emissions from LLM inferences is a viable and promising direction. The proposed R-ICE framework demonstrates potential in providing accurate, non-intrusive emission estimations, which could facilitate various sustainability-related applications."}}
{"id": "2506.08357", "pdf": "https://arxiv.org/pdf/2506.08357", "abs": "https://arxiv.org/abs/2506.08357", "authors": ["Franck Meyer", "Kyunghoon Hur", "Edward Choi"], "title": "MD-ViSCo: A Unified Model for Multi-Directional Vital Sign Waveform Conversion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Main paper (16 pages, 5 figures). Paper submitted for review. Code\n  available at https://github.com/fr-meyer/MD-ViSCo", "summary": "Despite the remarkable progress of deep-learning methods generating a target\nvital sign waveform from a source vital sign waveform, most existing models are\ndesigned exclusively for a specific source-to-target pair. This requires\ndistinct model architectures, optimization procedures, and pre-processing\npipelines, resulting in multiple models that hinder usability in clinical\nsettings. To address this limitation, we propose the Multi-Directional\nVital-Sign Converter (MD-ViSCo), a unified framework capable of generating any\ntarget waveform such as electrocardiogram (ECG), photoplethysmogram (PPG), or\narterial blood pressure (ABP) from any single input waveform with a single\nmodel. MD-ViSCo employs a shallow 1-Dimensional U-Net integrated with a Swin\nTransformer that leverages Adaptive Instance Normalization (AdaIN) to capture\ndistinct waveform styles. To evaluate the efficacy of MD-ViSCo, we conduct\nmulti-directional waveform generation on two publicly available datasets. Our\nframework surpasses state-of-the-art baselines (NabNet & PPG2ABP) on average\nacross all waveform types, lowering Mean absolute error (MAE) by 8.8% and\nimproving Pearson correlation (PC) by 4.9% over two datasets. In addition, the\ngenerated ABP waveforms satisfy the Association for the Advancement of Medical\nInstrumentation (AAMI) criterion and achieve Grade B on the British\nHypertension Society (BHS) standard, outperforming all baselines. By\neliminating the need for developing a distinct model for each task, we believe\nthat this work offers a unified framework that can deal with any kind of vital\nsign waveforms with a single model in healthcare monitoring.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7edf\u4e00\u6846\u67b6MD-ViSCo\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u4e00\u6a21\u578b\u4ece\u4efb\u610f\u5355\u4e00\u8f93\u5165\u6ce2\u5f62\u751f\u6210\u76ee\u6807\u6ce2\u5f62\uff08\u5982ECG\u3001PPG\u6216ABP\uff09\uff0c\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff0c\u5e76\u6ee1\u8db3\u533b\u5b66\u6807\u51c6\u3002", "motivation": "\u73b0\u6709\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5927\u591a\u4e13\u4e3a\u7279\u5b9a\u7684\u6e90\u5230\u76ee\u6807\u6ce2\u5f62\u5bf9\u8bbe\u8ba1\uff0c\u9700\u8981\u4e0d\u540c\u7684\u6a21\u578b\u67b6\u6784\u3001\u4f18\u5316\u8fc7\u7a0b\u548c\u9884\u5904\u7406\u6d41\u7a0b\uff0c\u5bfc\u81f4\u5728\u4e34\u5e8a\u5e94\u7528\u4e2d\u4e0d\u4fbf\u3002", "method": "\u63d0\u51fa\u4e86Multi-Directional Vital-Sign Converter (MD-ViSCo)\uff0c\u4e00\u79cd\u7edf\u4e00\u6846\u67b6\uff0c\u91c7\u7528\u6d45\u5c421D U-Net\u7ed3\u5408Swin Transformer\uff0c\u5e76\u5229\u7528Adaptive Instance Normalization (AdaIN)\u6355\u6349\u4e0d\u540c\u6ce2\u5f62\u98ce\u683c\uff0c\u4ece\u800c\u5b9e\u73b0\u4ece\u4efb\u4f55\u5355\u4e00\u8f93\u5165\u6ce2\u5f62\u751f\u6210\u76ee\u6807\u6ce2\u5f62\u7684\u529f\u80fd\u3002", "result": "\u5728\u4e24\u4e2a\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u7684\u591a\u65b9\u5411\u6ce2\u5f62\u751f\u6210\u5b9e\u9a8c\u4e2d\uff0cMD-ViSCo\u5e73\u5747\u8d85\u8d8a\u4e86\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\uff08NabNet & PPG2ABP\uff09\uff0cMAE\u964d\u4f4e8.8%\uff0cPC\u63d0\u9ad84.9%\uff1b\u751f\u6210\u7684ABP\u6ce2\u5f62\u6ee1\u8db3AAMI\u6807\u51c6\u5e76\u8fbe\u5230BHS Grade B\uff0c\u4f18\u4e8e\u6240\u6709\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "MD-ViSCo\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u5355\u4e00\u6a21\u578b\u5904\u7406\u5404\u79cd\u751f\u547d\u4f53\u5f81\u6ce2\u5f62\uff0c\u5728\u533b\u7597\u76d1\u63a7\u9886\u57df\u5177\u6709\u6f5c\u5728\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2506.08737", "pdf": "https://arxiv.org/pdf/2506.08737", "abs": "https://arxiv.org/abs/2506.08737", "authors": ["Haozhe Ma", "Guoji Fu", "Zhengding Luo", "Jiele Wu", "Tze-Yun Leong"], "title": "Exploration by Random Reward Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce Random Reward Perturbation (RRP), a novel exploration strategy\nfor reinforcement learning (RL). Our theoretical analyses demonstrate that\nadding zero-mean noise to environmental rewards effectively enhances policy\ndiversity during training, thereby expanding the range of exploration. RRP is\nfully compatible with the action-perturbation-based exploration strategies,\nsuch as $\\epsilon$-greedy, stochastic policies, and entropy regularization,\nproviding additive improvements to exploration effects. It is general,\nlightweight, and can be integrated into existing RL algorithms with minimal\nimplementation effort and negligible computational overhead. RRP establishes a\ntheoretical connection between reward shaping and noise-driven exploration,\nhighlighting their complementary potential. Experiments show that RRP\nsignificantly boosts the performance of Proximal Policy Optimization and Soft\nActor-Critic, achieving higher sample efficiency and escaping local optima\nacross various tasks, under both sparse and dense reward scenarios.", "AI": {"tldr": "An abstract about Random Reward Perturbation (RRP) in reinforcement learning.", "motivation": "To enhance policy diversity during training and expand the range of exploration in reinforcement learning.", "method": "Introduce RRP, which adds zero-mean noise to environmental rewards and is compatible with action-perturbation-based exploration strategies.", "result": "Experiments show that RRP significantly improves the performance of Proximal Policy Optimization and Soft Actor-Critic, achieving higher sample efficiency and escaping local optima.", "conclusion": "RRP is a general, lightweight strategy that can be easily integrated into existing RL algorithms and has a theoretical connection between reward shaping and noise-driven exploration."}}
{"id": "2506.08373", "pdf": "https://arxiv.org/pdf/2506.08373", "abs": "https://arxiv.org/abs/2506.08373", "authors": ["Kevin Galim", "Ethan Ewer", "Wonjun Kang", "Minjae Lee", "Hyung Il Koo", "Kangwook Lee"], "title": "Draft-based Approximate Inference for LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Optimizing inference for long-context Large Language Models (LLMs) is\nincreasingly important due to the quadratic compute and linear memory\ncomplexity of Transformers. Existing approximation methods, such as key-value\n(KV) cache dropping, sparse attention, and prompt compression, typically rely\non rough predictions of token or KV pair importance. We propose a novel\nframework for approximate LLM inference that leverages small draft models to\nmore accurately predict the importance of tokens and KV pairs. Specifically, we\nintroduce two instantiations of our proposed framework: (i) SpecKV, which\nleverages a draft output to accurately assess the importance of each KV pair\nfor more effective KV cache dropping, and (ii) SpecPC, which uses the draft\nmodel's attention activations to identify and discard unimportant prompt\ntokens. To the best of our knowledge, this is the first work to use draft\nmodels for approximate LLM inference acceleration, extending their utility\nbeyond traditional lossless speculative decoding. We motivate our methods with\ntheoretical and empirical analyses, and show a strong correlation between the\nattention patterns of draft and target models. Extensive experiments on\nlong-context benchmarks show that our methods consistently achieve higher\naccuracy than existing baselines, while preserving the same improvements in\nmemory usage, latency, and throughput. Our code is available at\nhttps://github.com/furiosa-ai/draft-based-approx-llm.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u66f4\u51c6\u786e\u5730\u9884\u6d4btoken\u548cKV\u5bf9\u7684\u91cd\u8981\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684LLM\u63a8\u7406\u8fd1\u4f3c\u6846\u67b6SpecKV\u548cSpecPC\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u5185\u5b58\u4f7f\u7528\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u6539\u8fdb\u7684\u540c\u65f6\uff0c\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u5177\u6709\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u4f18\u5316\u957f\u4e0a\u4e0b\u6587\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u63a8\u7406\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u4e3aTransformer\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3a\u4e8c\u6b21\u65b9\uff0c\u800c\u5185\u5b58\u590d\u6742\u5ea6\u4e3a\u7ebf\u6027\u3002\u73b0\u6709\u7684\u8fd1\u4f3c\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u5bf9token\u6216KV\u5bf9\u91cd\u8981\u6027\u7684\u7c97\u7565\u9884\u6d4b\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u7684\u6709\u6548\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5229\u7528\u5c0f\u578b\u8349\u7a3f\u6a21\u578b\u6765\u66f4\u51c6\u786e\u9884\u6d4btoken\u548cKV\u5bf9\u91cd\u8981\u6027\u7684\u65b0\u6846\u67b6\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u5f15\u5165\u4e86\u4e24\u4e2a\u5b9e\u4f8b\uff1aSpecKV\uff08\u5229\u7528\u8349\u7a3f\u8f93\u51fa\u8bc4\u4f30\u6bcf\u4e2aKV\u5bf9\u7684\u91cd\u8981\u6027\u4ee5\u8fdb\u884c\u66f4\u6709\u6548\u7684KV\u7f13\u5b58\u4e22\u5f03\uff09\u548cSpecPC\uff08\u4f7f\u7528\u8349\u7a3f\u6a21\u578b\u7684\u6ce8\u610f\u529b\u6fc0\u6d3b\u6765\u8bc6\u522b\u548c\u4e22\u5f03\u4e0d\u91cd\u8981\u7684\u63d0\u793atoken\uff09\u3002\u8fd9\u662f\u9996\u6b21\u5c06\u8349\u7a3f\u6a21\u578b\u7528\u4e8e\u52a0\u901fLLM\u63a8\u7406\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4fdd\u6301\u76f8\u540c\u7684\u5185\u5b58\u4f7f\u7528\u3001\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u6539\u8fdb\u7684\u540c\u65f6\uff0c\u59cb\u7ec8\u6bd4\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u5b9e\u73b0\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4f7f\u7528\u8349\u7a3f\u6a21\u578b\u63d0\u9ad8LLM\u63a8\u7406\u7684\u51c6\u786e\u6027\u3002SpecKV\u548cSpecPC\u5c55\u793a\u4e86\u663e\u8457\u7684\u4f18\u52bf\uff0c\u4e14\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.08740", "pdf": "https://arxiv.org/pdf/2506.08740", "abs": "https://arxiv.org/abs/2506.08740", "authors": ["Sidhika Balachandar", "Shuvom Sadhuka", "Bonnie Berger", "Emma Pierson", "Nikhil Garg"], "title": "Urban Incident Prediction with Graph Neural Networks: Integrating Government Ratings and Crowdsourced Reports", "categories": ["cs.LG"], "comment": null, "summary": "Graph neural networks (GNNs) are widely used in urban spatiotemporal\nforecasting, such as predicting infrastructure problems. In this setting,\ngovernment officials wish to know in which neighborhoods incidents like\npotholes or rodent issues occur. The true state of incidents (e.g., street\nconditions) for each neighborhood is observed via government inspection\nratings. However, these ratings are only conducted for a sparse set of\nneighborhoods and incident types. We also observe the state of incidents via\ncrowdsourced reports, which are more densely observed but may be biased due to\nheterogeneous reporting behavior. First, for such settings, we propose a\nmultiview, multioutput GNN-based model that uses both unbiased rating data and\nbiased reporting data to predict the true latent state of incidents. Second, we\ninvestigate a case study of New York City urban incidents and collect,\nstandardize, and make publicly available a dataset of 9,615,863 crowdsourced\nreports and 1,041,415 government inspection ratings over 3 years and across 139\ntypes of incidents. Finally, we show on both real and semi-synthetic data that\nour model can better predict the latent state compared to models that use only\nreporting data or models that use only rating data, especially when rating data\nis sparse and reports are predictive of ratings. We also quantify demographic\nbiases in crowdsourced reporting, e.g., higher-income neighborhoods report\nproblems at higher rates. Our analysis showcases a widely applicable approach\nfor latent state prediction using heterogeneous, sparse, and biased data.", "AI": {"tldr": "The paper proposes a multiview, multioutput GNN-based model for urban incident prediction using both government inspection ratings and crowdsourced reports. It also provides a dataset of NYC incidents and shows the model's effectiveness on real and semi-synthetic data.", "motivation": "Government officials need to know where incidents occur in cities, but inspection ratings are sparse and crowdsourced reports may be biased. There is a need for a model that can effectively predict the true latent state of incidents using these heterogeneous data sources.", "method": "The authors developed a multiview, multioutput GNN-based model that integrates unbiased rating data and biased reporting data. They also collected and standardized a large dataset of crowdsourced reports and government inspection ratings from New York City.", "result": "The model outperforms those using only reporting or rating data, especially when rating data is sparse and reports are predictive of ratings. The study also quantified demographic biases in crowdsourced reporting.", "conclusion": "This approach offers a widely applicable method for latent state prediction using heterogeneous, sparse, and biased data."}}
{"id": "2506.08764", "pdf": "https://arxiv.org/pdf/2506.08764", "abs": "https://arxiv.org/abs/2506.08764", "authors": ["Benjamin Dadoun", "Soufiane Hayou", "Hanan Salam", "Mohamed El Amine Seddik", "Pierre Youssef"], "title": "On the Stability of the Jacobian Matrix in Deep Neural Networks", "categories": ["cs.LG", "68T07, 60B20"], "comment": "16 pages, 26 figures", "summary": "Deep neural networks are known to suffer from exploding or vanishing\ngradients as depth increases, a phenomenon closely tied to the spectral\nbehavior of the input-output Jacobian. Prior work has identified critical\ninitialization schemes that ensure Jacobian stability, but these analyses are\ntypically restricted to fully connected networks with i.i.d. weights. In this\nwork, we go significantly beyond these limitations: we establish a general\nstability theorem for deep neural networks that accommodates sparsity (such as\nthat introduced by pruning) and non-i.i.d., weakly correlated weights (e.g.\ninduced by training). Our results rely on recent advances in random matrix\ntheory, and provide rigorous guarantees for spectral stability in a much\nbroader class of network models. This extends the theoretical foundation for\ninitialization schemes in modern neural networks with structured and dependent\nrandomness.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u901a\u8fc7\u5229\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5efa\u7acb\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u4e00\u822c\u7a33\u5b9a\u6027\u5b9a\u7406\u3002\u8be5\u5b9a\u7406\u4e0d\u4ec5\u8003\u8651\u4e86\u7a00\u758f\u6027\uff08\u5982\u4fee\u526a\u5f15\u5165\u7684\u7a00\u758f\u6027\uff09\uff0c\u8fd8\u8003\u8651\u4e86\u975e\u72ec\u7acb\u540c\u5206\u5e03\u3001\u5f31\u76f8\u5173\u7684\u6743\u91cd\uff08\u4f8b\u5982\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u6743\u91cd\uff09\u3002\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u73b0\u4ee3\u5177\u6709\u7ed3\u6784\u5316\u548c\u76f8\u5173\u968f\u673a\u6027\u7684\u795e\u7ecf\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6848\u7684\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u968f\u7740\u6df1\u5ea6\u589e\u52a0\uff0c\u5bb9\u6613\u51fa\u73b0\u68af\u5ea6\u7206\u70b8\u6216\u6d88\u5931\u7684\u95ee\u9898\uff0c\u8fd9\u4e0e\u8f93\u5165-\u8f93\u51fa\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u8c31\u884c\u4e3a\u5bc6\u5207\u76f8\u5173\u3002\u5c3d\u7ba1\u5148\u524d\u7684\u7814\u7a76\u5df2\u7ecf\u786e\u5b9a\u4e86\u4e00\u4e9b\u5173\u952e\u7684\u521d\u59cb\u5316\u7b56\u7565\u4ee5\u786e\u4fdd\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u7a33\u5b9a\u6027\uff0c\u4f46\u8fd9\u4e9b\u5206\u6790\u901a\u5e38\u5c40\u9650\u4e8e\u5168\u8fde\u63a5\u7f51\u7edc\u4e14\u6743\u91cd\u4e3a\u72ec\u7acb\u540c\u5206\u5e03\u7684\u60c5\u51b5\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7a33\u5b9a\u6027\u5b9a\u7406\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u7f51\u7edc\u6a21\u578b\u3002\u8fd9\u4e2a\u5b9a\u7406\u5229\u7528\u4e86\u968f\u673a\u77e9\u9635\u7406\u8bba\u7684\u6700\u65b0\u6210\u679c\uff0c\u80fd\u591f\u5904\u7406\u7a00\u758f\u6027\u548c\u975e\u72ec\u7acb\u540c\u5206\u5e03\u3001\u5f31\u76f8\u5173\u7684\u6743\u91cd\u60c5\u51b5\uff0c\u6bd4\u5982\u7531\u4fee\u526a\u5f15\u8d77\u7684\u7a00\u758f\u6027\u548c\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u7684\u6743\u91cd\u76f8\u5173\u6027\u3002", "result": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5173\u4e8e\u8c31\u7a33\u5b9a\u6027\u7684\u4e25\u683c\u7406\u8bba\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u7f51\u7edc\u6a21\u578b\uff0c\u5305\u62ec\u90a3\u4e9b\u5177\u6709\u7ed3\u6784\u5316\u548c\u76f8\u5173\u968f\u673a\u6027\u7684\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u6269\u5c55\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u521d\u59cb\u5316\u65b9\u6848\u7684\u7406\u8bba\u57fa\u7840\uff0c\u4f7f\u5176\u53ef\u4ee5\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u7f51\u7edc\u67b6\u6784\u548c\u5b9e\u9645\u573a\u666f\u4e2d\u3002"}}
{"id": "2506.08837", "pdf": "https://arxiv.org/pdf/2506.08837", "abs": "https://arxiv.org/abs/2506.08837", "authors": ["Luca Beurer-Kellner", "Beat Buesser Ana-Maria Cre\u0163u", "Edoardo Debenedetti", "Daniel Dobos", "Daniel Fabian", "Marc Fischer", "David Froelicher", "Kathrin Grosse", "Daniel Naeff", "Ezinwanne Ozoani", "Andrew Paverd", "Florian Tram\u00e8r", "V\u00e1clav Volhejn"], "title": "Design Patterns for Securing LLM Agents against Prompt Injections", "categories": ["cs.LG", "cs.CR"], "comment": null, "summary": "As AI agents powered by Large Language Models (LLMs) become increasingly\nversatile and capable of addressing a broad spectrum of tasks, ensuring their\nsecurity has become a critical challenge. Among the most pressing threats are\nprompt injection attacks, which exploit the agent's resilience on natural\nlanguage inputs -- an especially dangerous threat when agents are granted tool\naccess or handle sensitive information. In this work, we propose a set of\nprincipled design patterns for building AI agents with provable resistance to\nprompt injection. We systematically analyze these patterns, discuss their\ntrade-offs in terms of utility and security, and illustrate their real-world\napplicability through a series of case studies.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u6784\u5efa\u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5177\u6709\u53ef\u8bc1\u660e\u62b5\u6297\u529b\u7684AI\u4ee3\u7406\u7684\u539f\u5219\u6027\u8bbe\u8ba1\u6a21\u5f0f\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u5206\u6790\u4e86\u8fd9\u4e9b\u6a21\u5f0f\u5728\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u6743\u8861\u3002", "motivation": "\u968f\u7740\u7531\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9a71\u52a8\u7684AI\u4ee3\u7406\u53d8\u5f97\u8d8a\u6765\u8d8a\u591a\u529f\u80fd\u5316\uff0c\u80fd\u591f\u5904\u7406\u5e7f\u6cdb\u7684\u4efb\u52a1\uff0c\u786e\u4fdd\u5176\u5b89\u5168\u6027\u5df2\u6210\u4e3a\u4e00\u4e2a\u5173\u952e\u6311\u6218\uff0c\u5c24\u5176\u662f\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u8fd9\u4e00\u5a01\u80c1\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u5957\u539f\u5219\u6027\u7684\u8bbe\u8ba1\u6a21\u5f0f\u6765\u6784\u5efa\u5bf9\u63d0\u793a\u6ce8\u5165\u653b\u51fb\u5177\u6709\u62b5\u6297\u529b\u7684AI\u4ee3\u7406\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u4e86\u7cfb\u7edf\u5206\u6790\u3002", "result": "\u8fd9\u4e9b\u8bbe\u8ba1\u6a21\u5f0f\u88ab\u8bc1\u660e\u5728\u63d0\u4f9b\u5b89\u5168\u6027\u7684\u540c\u65f6\u4e5f\u5b58\u5728\u5b9e\u7528\u6027\u7684\u6743\u8861\uff0c\u5e76\u4e14\u901a\u8fc7\u4e00\u7cfb\u5217\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u5176\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\u7684\u9002\u7528\u6027\u3002", "conclusion": "\u6784\u5efa\u5b89\u5168\u7684AI\u4ee3\u7406\u9700\u8981\u5728\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u4e4b\u95f4\u505a\u51fa\u6743\u8861\uff0c\u800c\u672c\u6587\u63d0\u51fa\u7684\u8bbe\u8ba1\u6a21\u5f0f\u4e3a\u5b9e\u73b0\u8fd9\u4e00\u76ee\u6807\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u6307\u5bfc\u3002"}}
{"id": "2506.08844", "pdf": "https://arxiv.org/pdf/2506.08844", "abs": "https://arxiv.org/abs/2506.08844", "authors": ["Siyi Sun", "David Antony Selby", "Yunchuan Huang", "Sebastian Vollmer", "Seth Flaxman", "Anisoara Calinescu"], "title": "IMAGIC-500: IMputation benchmark on A Generative Imaginary Country (500k samples)", "categories": ["cs.LG", "cs.CE"], "comment": null, "summary": "Missing data imputation in tabular datasets remains a pivotal challenge in\ndata science and machine learning, particularly within socioeconomic research.\nHowever, real-world socioeconomic datasets are typically subject to strict data\nprotection protocols, which often prohibit public sharing, even for synthetic\nderivatives. This severely limits the reproducibility and accessibility of\nbenchmark studies in such settings. Further, there are very few publicly\navailable synthetic datasets. Thus, there is limited availability of benchmarks\nfor systematic evaluation of imputation methods on socioeconomic datasets,\nwhether real or synthetic. In this study, we utilize the World Bank's publicly\navailable synthetic dataset, Synthetic Data for an Imaginary Country, which\nclosely mimics a real World Bank household survey while being fully public,\nenabling broad access for methodological research. With this as a starting\npoint, we derived the IMAGIC-500 dataset: we select a subset of 500k\nindividuals across approximately 100k households with 19 socioeconomic\nfeatures, designed to reflect the hierarchical structure of real-world\nhousehold surveys. This paper introduces a comprehensive missing data\nimputation benchmark on IMAGIC-500 under various missing mechanisms (MCAR, MAR,\nMNAR) and missingness ratios (10\\%, 20\\%, 30\\%, 40\\%, 50\\%). Our evaluation\nconsiders the imputation accuracy for continuous and categorical variables,\ncomputational efficiency, and impact on downstream predictive tasks, such as\nestimating educational attainment at the individual level. The results\nhighlight the strengths and weaknesses of statistical, traditional machine\nlearning, and deep learning imputation techniques, including recent\ndiffusion-based methods. The IMAGIC-500 dataset and benchmark aim to facilitate\nthe development of robust imputation algorithms and foster reproducible social\nscience research.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528\u4e16\u754c\u94f6\u884c\u516c\u5f00\u7684\u5408\u6210\u6570\u636e\u96c6\u521b\u5efa\u4e86IMAGIC-500\u6570\u636e\u96c6\uff0c\u8be5\u6570\u636e\u96c6\u5305\u542b50\u4e07\u4e2a\u4eba\u548c\u7ea610\u4e07\u6237\u5bb6\u5ead\u768419\u4e2a\u793e\u4f1a\u7ecf\u6d4e\u7279\u5f81\u3002\u57fa\u4e8e\u6b64\u6570\u636e\u96c6\uff0c\u5728\u4e0d\u540c\u7f3a\u5931\u673a\u5236\uff08MCAR\u3001MAR\u3001MNAR\uff09\u548c\u7f3a\u5931\u7387\u4e0b\u8fdb\u884c\u4e86\u5168\u9762\u7684\u7f3a\u5931\u6570\u636e\u586b\u8865\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u4e86\u7edf\u8ba1\u5b66\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u586b\u8865\u6280\u672f\u7684\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u53ca\u5bf9\u4e0b\u6e38\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "motivation": "\u5b9e\u9645\u7684\u793e\u4f1a\u7ecf\u6d4e\u6570\u636e\u96c6\u53d7\u6570\u636e\u4fdd\u62a4\u534f\u8bae\u9650\u5236\uff0c\u96be\u4ee5\u516c\u5f00\u5206\u4eab\uff0c\u5bfc\u81f4\u7f3a\u5931\u6570\u636e\u586b\u8865\u65b9\u6cd5\u5728\u8be5\u9886\u57df\u7684\u7cfb\u7edf\u8bc4\u4f30\u7f3a\u4e4f\u8db3\u591f\u7684\u57fa\u51c6\u3002\u540c\u65f6\uff0c\u516c\u5f00\u53ef\u7528\u7684\u5408\u6210\u6570\u636e\u96c6\u4e5f\u5341\u5206\u6709\u9650\u3002", "method": "\u5229\u7528\u4e16\u754c\u94f6\u884c\u516c\u5f00\u7684\u5408\u6210\u6570\u636e\u96c6\u6784\u5efaIMAGIC-500\u6570\u636e\u96c6\uff0c\u5e76\u5728\u6b64\u57fa\u7840\u4e0a\u9488\u5bf9\u591a\u79cd\u7f3a\u5931\u673a\u5236\u548c\u7f3a\u5931\u7387\u8fdb\u884c\u7f3a\u5931\u6570\u636e\u586b\u8865\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc4\u4f30\u6307\u6807\u5305\u62ec\u8fde\u7eed\u548c\u5206\u7c7b\u53d8\u91cf\u7684\u586b\u8865\u51c6\u786e\u6027\u3001\u8ba1\u7b97\u6548\u7387\u4ee5\u53ca\u5bf9\u4e0b\u6e38\u9884\u6d4b\u4efb\u52a1\u7684\u5f71\u54cd\u3002", "result": "\u63ed\u793a\u4e86\u7edf\u8ba1\u5b66\u3001\u4f20\u7edf\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\uff08\u5305\u62ec\u6700\u65b0\u7684\u6269\u6563\u6a21\u578b\u65b9\u6cd5\uff09\u586b\u8865\u6280\u672f\u5404\u81ea\u7684\u4f18\u7f3a\u70b9\u3002", "conclusion": "IMAGIC-500\u6570\u636e\u96c6\u548c\u57fa\u51c6\u6d4b\u8bd5\u4e3a\u63a8\u52a8\u7a33\u5065\u7684\u7f3a\u5931\u6570\u636e\u586b\u8865\u7b97\u6cd5\u7684\u53d1\u5c55\u4ee5\u53ca\u4fc3\u8fdb\u53ef\u91cd\u590d\u7684\u793e\u4f1a\u79d1\u5b66\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u652f\u6301\u3002"}}
{"id": "2506.08403", "pdf": "https://arxiv.org/pdf/2506.08403", "abs": "https://arxiv.org/abs/2506.08403", "authors": ["Weiya Li", "Junjie Chen", "Bei Li", "Boyang Liu", "Zichen Wen", "Nuanqiao Shan", "Xiaoqian Liu", "Anping Liu", "Huajie Liu", "Youyan Wang", "Wujiuge Yin", "Hu Song", "Bing Huang", "Zhiyuan Xia", "Jialiang Chen", "Linfeng Zhang"], "title": "TACTIC: Translation Agents with Cognitive-Theoretic Interactive Collaboration", "categories": ["cs.CL", "cs.AI"], "comment": "20 pages, 4 figures, Under review. Code:\n  https://github.com/weiyali126/TACTIC", "summary": "Machine translation has long been a central task in natural language\nprocessing. With the rapid advancement of large language models (LLMs), there\nhas been remarkable progress in translation quality. However, fully realizing\nthe translation potential of LLMs remains an open challenge. Recent studies\nhave explored multi-agent systems to decompose complex translation tasks into\ncollaborative subtasks, showing initial promise in enhancing translation\nquality through agent cooperation and specialization. Nevertheless, existing\nmulti-agent translation frameworks largely neglect foundational insights from\ncognitive translation studies. These insights emphasize how human translators\nemploy different cognitive strategies, such as balancing literal and free\ntranslation, refining expressions based on context, and iteratively evaluating\noutputs. To address this limitation, we propose a cognitively informed\nmulti-agent framework called TACTIC, which stands for T ranslation A gents with\nCognitive- T heoretic Interactive Collaboration. The framework comprises six\nfunctionally distinct agents that mirror key cognitive processes observed in\nhuman translation behavior. These include agents for drafting, refinement,\nevaluation, scoring, context reasoning, and external knowledge gathering. By\nsimulating an interactive and theory-grounded translation workflow, TACTIC\neffectively leverages the full capacity of LLMs for high-quality translation.\nExperimental results on diverse language pairs from the FLORES-200 and WMT24\nbenchmarks show that our method consistently achieves state-of-the-art\nperformance. Using DeepSeek-V3 as the base model, TACTIC surpasses GPT-4.1 by\nan average of +0.6 XCOMET and +1.18 COMETKIWI-23. Compared to DeepSeek-R1, it\nfurther improves by +0.84 XCOMET and +2.99 COMETKIWI-23. Code is available at\nhttps://github.com/weiyali126/TACTIC.", "AI": {"tldr": "The paper proposes TACTIC, a multi-agent framework for machine translation inspired by cognitive translation strategies. It consists of six agents handling different translation aspects and shows state-of-the-art performance.", "motivation": "To enhance machine translation quality by leveraging cognitive insights from human translators that existing multi-agent systems largely ignore.", "method": "TACTIC is composed of six functionally distinct agents: drafting, refinement, evaluation, scoring, context reasoning, and external knowledge gathering. These agents simulate the interactive translation workflow observed in human translators.", "result": "On benchmarks FLORES-200 and WMT24, TACTIC surpasses GPT-4.1 by +0.6 XCOMET and +1.18 COMETKIWI-23, and improves over DeepSeek-R1 by +0.84 XCOMET and +2.99 COMETKIWI-23.", "conclusion": "TACTIC effectively utilizes the full capacity of LLMs for high-quality translation through cognitively informed multi-agent collaboration."}}
{"id": "2506.08850", "pdf": "https://arxiv.org/pdf/2506.08850", "abs": "https://arxiv.org/abs/2506.08850", "authors": ["Amin Avan", "Akramul Azim", "Qusay Mahmoud"], "title": "Agile Reinforcement Learning for Real-Time Task Scheduling in Edge Computing", "categories": ["cs.LG"], "comment": null, "summary": "Soft real-time applications are becoming increasingly complex, posing\nsignificant challenges for scheduling offloaded tasks in edge computing\nenvironments while meeting task timing constraints. Moreover, the exponential\ngrowth of the search space, presence of multiple objectives and parameters, and\nhighly dynamic nature of edge computing environments further exacerbate the\ncomplexity of task scheduling. As a result, schedulers based on heuristic and\nmetaheuristic algorithms frequently encounter difficulties in generating\noptimal or near-optimal task schedules due to their constrained ability to\nadapt to the dynamic conditions and complex environmental characteristics of\nedge computing. Accordingly, reinforcement learning algorithms have been\nincorporated into schedulers to address the complexity and dynamic conditions\ninherent in task scheduling in edge computing. However, a significant\nlimitation of reinforcement learning algorithms is the prolonged learning time\nrequired to adapt to new environments and to address medium- and large-scale\nproblems. This challenge arises from the extensive global action space and\nfrequent random exploration of irrelevant actions. Therefore, this study\nproposes Agile Reinforcement learning (aRL), in which the RL-agent performs\ninformed exploration and executes only relevant actions. Consequently, the\npredictability of the RL-agent is enhanced, leading to rapid adaptation and\nconvergence, which positions aRL as a suitable candidate for scheduling the\ntasks of soft real-time applications in edge computing. The experiments\ndemonstrate that the combination of informed exploration and action-masking\nmethods enables aRL to achieve a higher hit-ratio and converge faster than the\nbaseline approaches.", "AI": {"tldr": "In this paper, researchers tackle the challenge of task scheduling in edge computing for soft real-time applications. They propose Agile Reinforcement learning (aRL), which performs informed exploration and executes only relevant actions to enhance predictability and rapid adaptation. Experiments show that aRL outperforms baseline approaches in terms of hit-ratio and convergence speed.", "motivation": "Soft real-time applications are becoming increasingly complex, leading to significant challenges in task scheduling within edge computing environments. Current heuristic/metaheuristic algorithms and reinforcement learning methods face difficulties due to dynamic conditions, exponential search space growth, and prolonged learning times.", "method": "The study introduces Agile Reinforcement learning (aRL), where the RL-agent conducts informed exploration and executes only relevant actions. This approach reduces extensive global action space and frequent random exploration, improving predictability and adaptation speed.", "result": "Experimental results indicate that the combination of informed exploration and action-masking methods allows aRL to achieve a higher hit-ratio and faster convergence compared to baseline approaches.", "conclusion": "Agile Reinforcement learning (aRL) is presented as a suitable candidate for scheduling tasks of soft real-time applications in edge computing, effectively addressing the complexity and dynamic conditions through enhanced predictability and rapid adaptation."}}
{"id": "2506.08871", "pdf": "https://arxiv.org/pdf/2506.08871", "abs": "https://arxiv.org/abs/2506.08871", "authors": ["Victor M. Tenorio", "Madeline Navarro", "Samuel Rey", "Santiago Segarra", "Antonio G. Marques"], "title": "Adapting to Heterophilic Graph Data with Structure-Guided Neighbor Discovery", "categories": ["cs.LG", "eess.SP"], "comment": null, "summary": "Graph Neural Networks (GNNs) often struggle with heterophilic data, where\nconnected nodes may have dissimilar labels, as they typically assume homophily\nand rely on local message passing. To address this, we propose creating\nalternative graph structures by linking nodes with similar structural\nattributes (e.g., role-based or global), thereby fostering higher label\nhomophily on these new graphs. We theoretically prove that GNN performance can\nbe improved by utilizing graphs with fewer false positive edges (connections\nbetween nodes of different classes) and that considering multiple graph views\nincreases the likelihood of finding such beneficial structures. Building on\nthese insights, we introduce Structure-Guided GNN (SG-GNN), an architecture\nthat processes the original graph alongside the newly created structural\ngraphs, adaptively learning to weigh their contributions. Extensive experiments\non various benchmark datasets, particularly those with heterophilic\ncharacteristics, demonstrate that our SG-GNN achieves state-of-the-art or\nhighly competitive performance, highlighting the efficacy of exploiting\nstructural information to guide GNNs.", "AI": {"tldr": "Graph Neural Networks (GNNs) often struggle with heterophilic data, where connected nodes may have dissimilar labels. This paper proposes creating alternative graph structures by linking nodes with similar structural attributes and introduces Structure-Guided GNN (SG-GNN), which processes the original graph alongside the newly created structural graphs, achieving state-of-the-art performance.", "motivation": "GNNs typically assume homophily and rely on local message passing, struggling with heterophilic data. The authors aim to improve GNN performance on such data by creating alternative graph structures with higher label homophily.", "method": "The method involves theoretically proving that GNN performance can be improved by utilizing graphs with fewer false positive edges and considering multiple graph views. They then introduce SG-GNN, an architecture that processes the original graph alongside newly created structural graphs, adaptively learning to weigh their contributions.", "result": "Extensive experiments on various benchmark datasets, particularly those with heterophilic characteristics, demonstrate that SG-GNN achieves state-of-the-art or highly competitive performance.", "conclusion": "The conclusion is that exploiting structural information to guide GNNs, as done in SG-GNN, is effective in improving performance on heterophilic data."}}
{"id": "2506.08882", "pdf": "https://arxiv.org/pdf/2506.08882", "abs": "https://arxiv.org/abs/2506.08882", "authors": ["Dimitrios Amaxilatis", "Themistoklis Sarantakos", "Ioannis Chatzigiannakis", "Georgios Mylonas"], "title": "Filling in the Blanks: Applying Data Imputation in incomplete Water Metering Data", "categories": ["cs.LG"], "comment": null, "summary": "In this work, we explore the application of recent data imputation techniques\nto enhance monitoring and management of water distribution networks using smart\nwater meters, based on data derived from a real-world IoT water grid monitoring\ndeployment. Despite the detailed data produced by such meters, data gaps due to\ntechnical issues can significantly impact operational decisions and efficiency.\nOur results, by comparing various imputation methods, such as k-Nearest\nNeighbors, MissForest, Transformers, and Recurrent Neural Networks, indicate\nthat effective data imputation can substantially enhance the quality of the\ninsights derived from water consumption data as we study their effect on\naccuracy and reliability of water metering data to provide solutions in\napplications like leak detection and predictive maintenance scheduling.", "AI": {"tldr": "Recent data imputation techniques are explored to improve water distribution networks' management via smart water meters. Results show effective data imputation can enhance insights from water consumption data for applications like leak detection and predictive maintenance scheduling.", "motivation": "To address the issue of data gaps caused by technical problems in smart water meters which affect operational decisions and efficiency in water distribution networks.", "method": "Comparison of various data imputation methods including k-Nearest Neighbors, MissForest, Transformers, and Recurrent Neural Networks.", "result": "Effective data imputation methods can significantly improve the quality of insights derived from water consumption data, enhancing accuracy and reliability for applications such as leak detection and predictive maintenance scheduling.", "conclusion": "Applying advanced data imputation techniques can lead to better management and monitoring of water distribution networks through improved smart water meter data."}}
{"id": "2506.08884", "pdf": "https://arxiv.org/pdf/2506.08884", "abs": "https://arxiv.org/abs/2506.08884", "authors": ["Shiqin Tang", "Shujian Yu"], "title": "InfoDPCCA: Information-Theoretic Dynamic Probabilistic Canonical Correlation Analysis", "categories": ["cs.LG", "cs.IT", "math.IT"], "comment": "accepted by UAI-25, code is available at\n  \\url{https://github.com/marcusstang/InfoDPCCA}", "summary": "Extracting meaningful latent representations from high-dimensional sequential\ndata is a crucial challenge in machine learning, with applications spanning\nnatural science and engineering. We introduce InfoDPCCA, a dynamic\nprobabilistic Canonical Correlation Analysis (CCA) framework designed to model\ntwo interdependent sequences of observations. InfoDPCCA leverages a novel\ninformation-theoretic objective to extract a shared latent representation that\ncaptures the mutual structure between the data streams and balances\nrepresentation compression and predictive sufficiency while also learning\nseparate latent components that encode information specific to each sequence.\nUnlike prior dynamic CCA models, such as DPCCA, our approach explicitly\nenforces the shared latent space to encode only the mutual information between\nthe sequences, improving interpretability and robustness. We further introduce\na two-step training scheme to bridge the gap between information-theoretic\nrepresentation learning and generative modeling, along with a residual\nconnection mechanism to enhance training stability. Through experiments on\nsynthetic and medical fMRI data, we demonstrate that InfoDPCCA excels as a tool\nfor representation learning. Code of InfoDPCCA is available at\nhttps://github.com/marcusstang/InfoDPCCA.", "AI": {"tldr": "InfoDPCCA is a novel dynamic probabilistic CCA framework that extracts shared and separate latent representations from two interdependent sequences using an information-theoretic objective. It introduces a two-step training scheme and residual connections, showing strong performance in representation learning on synthetic and medical fMRI data.", "motivation": "Extract meaningful latent representations from high-dimensional sequential data via Canonical Correlation Analysis (CCA) while balancing compression and predictive sufficiency.", "method": "Leverages a novel information-theoretic objective to extract shared and separate latent representations. Introduces a two-step training scheme and residual connection mechanism for enhanced stability.", "result": "Outperforms previous dynamic CCA models in experiments with synthetic and medical fMRI data, excelling as a tool for representation learning.", "conclusion": "InfoDPCCA provides a robust and interpretable approach to modeling interdependent sequences of observations."}}
{"id": "2506.08459", "pdf": "https://arxiv.org/pdf/2506.08459", "abs": "https://arxiv.org/abs/2506.08459", "authors": ["Juanran Wang", "Marc R. Schlichting", "Harrison Delecki", "Mykel J. Kochenderfer"], "title": "Diffusion Models for Safety Validation of Autonomous Driving Systems", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Safety validation of autonomous driving systems is extremely challenging due\nto the high risks and costs of real-world testing as well as the rarity and\ndiversity of potential failures. To address these challenges, we train a\ndenoising diffusion model to generate potential failure cases of an autonomous\nvehicle given any initial traffic state. Experiments on a four-way intersection\nproblem show that in a variety of scenarios, the diffusion model can generate\nrealistic failure samples while capturing a wide variety of potential failures.\nOur model does not require any external training dataset, can perform training\nand inference with modest computing resources, and does not assume any prior\nknowledge of the system under test, with applicability to safety validation for\ntraffic intersections.", "AI": {"tldr": "This paper proposes a denoising diffusion model for generating potential failure cases of autonomous vehicles without needing an external training dataset, performing efficiently with modest computing resources and no prior system knowledge.", "motivation": "Safety validation of autonomous driving systems is difficult due to high risks and costs in real-world testing, along with the rarity and diversity of potential failures.", "method": "A denoising diffusion model is trained to generate potential failure cases of an autonomous vehicle given any initial traffic state. The model doesn't require any external training dataset or prior knowledge of the system under test.", "result": "Experiments on a four-way intersection problem demonstrate that the diffusion model can generate realistic failure samples while capturing a wide variety of potential failures.", "conclusion": "The proposed diffusion model is effective for safety validation in traffic intersections as it can perform training and inference with modest computing resources."}}
{"id": "2506.08889", "pdf": "https://arxiv.org/pdf/2506.08889", "abs": "https://arxiv.org/abs/2506.08889", "authors": ["Yizhao Gao", "Shuming Guo", "Shijie Cao", "Yuqing Xia", "Yu Cheng", "Lei Wang", "Lingxiao Ma", "Yutao Sun", "Tianzhu Ye", "Li Dong", "Hayden Kwok-Hay So", "Yu Hua", "Ting Cao", "Fan Yang", "Mao Yang"], "title": "SeerAttention-R: Sparse Attention Adaptation for Long Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "We introduce SeerAttention-R, a sparse attention framework specifically\ntailored for the long decoding of reasoning models. Extended from\nSeerAttention, SeerAttention-R retains the design of learning attention\nsparsity through a self-distilled gating mechanism, while removing query\npooling to accommodate auto-regressive decoding. With a lightweight plug-in\ngating, SeerAttention-R is flexible and can be easily integrated into existing\npretrained model without modifying the original parameters. We demonstrate that\nSeerAttention-R, trained on just 0.4B tokens, maintains near-lossless reasoning\naccuracy with 4K token budget in AIME benchmark under large sparse attention\nblock sizes (64/128). Using TileLang, we develop a highly optimized sparse\ndecoding kernel that achieves near-theoretical speedups of up to 9x over\nFlashAttention-3 on H100 GPU at 90% sparsity. Code is available at:\nhttps://github.com/microsoft/SeerAttention.", "AI": {"tldr": "The paper introduces SeerAttention-R, a sparse attention framework for long decoding in reasoning models. It retains the self-distilled gating mechanism from SeerAttention but removes query pooling to suit auto-regressive decoding. Trained on 0.4B tokens, it maintains high reasoning accuracy within a 4K token budget and achieves significant speedups over FlashAttention-3 at 90% sparsity.", "motivation": "To develop a sparse attention framework that can handle long decoding tasks in reasoning models efficiently while maintaining reasoning accuracy.", "method": "SeerAttention-R is an extension of SeerAttention which incorporates a self-distilled gating mechanism for learning attention sparsity. It removes query pooling to allow for auto-regressive decoding and is designed as a lightweight plug-in that can be integrated into existing pretrained models without altering original parameters.", "result": "SeerAttention-R achieves near-lossless reasoning accuracy with a 4K token budget when trained on just 0.4B tokens. Additionally, using TileLang, it demonstrates up to 9x speedups over FlashAttention-3 on H100 GPU at 90% sparsity.", "conclusion": "SeerAttention-R provides a flexible and efficient solution for incorporating sparse attention into reasoning models, achieving both high accuracy and significant computational speedups."}}
{"id": "2506.08902", "pdf": "https://arxiv.org/pdf/2506.08902", "abs": "https://arxiv.org/abs/2506.08902", "authors": ["Chongyi Zheng", "Seohong Park", "Sergey Levine", "Benjamin Eysenbach"], "title": "Intention-Conditioned Flow Occupancy Models", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large-scale pre-training has fundamentally changed how machine learning\nresearch is done today: large foundation models are trained once, and then can\nbe used by anyone in the community (including those without data or compute\nresources to train a model from scratch) to adapt and fine-tune to specific\ntasks. Applying this same framework to reinforcement learning (RL) is appealing\nbecause it offers compelling avenues for addressing core challenges in RL,\nincluding sample efficiency and robustness. However, there remains a\nfundamental challenge to pre-train large models in the context of RL: actions\nhave long-term dependencies, so training a foundation model that reasons across\ntime is important. Recent advances in generative AI have provided new tools for\nmodeling highly complex distributions. In this paper, we build a probabilistic\nmodel to predict which states an agent will visit in the temporally distant\nfuture (i.e., an occupancy measure) using flow matching. As large datasets are\noften constructed by many distinct users performing distinct tasks, we include\nin our model a latent variable capturing the user intention. This intention\nincreases the expressivity of our model, and enables adaptation with\ngeneralized policy improvement. We call our proposed method\nintention-conditioned flow occupancy models (InFOM). Comparing with alternative\nmethods for pre-training, our experiments on $36$ state-based and $4$\nimage-based benchmark tasks demonstrate that the proposed method achieves $1.8\n\\times$ median improvement in returns and increases success rates by $36\\%$.\nWebsite: https://chongyi-zheng.github.io/infom Code:\nhttps://github.com/chongyi-zheng/infom", "AI": {"tldr": "The paper introduces InFOM, a probabilistic model using flow matching to predict future states in reinforcement learning. It incorporates user intention as a latent variable and shows significant improvements over other pre-training methods.", "motivation": "To address the challenge of pre-training large models in reinforcement learning where actions have long-term dependencies, leveraging recent advances in generative AI for modeling complex distributions.", "method": "Builds a probabilistic model called InFOM which predicts an agent's future states (occupancy measure) using flow matching, including a latent variable for user intention to enhance model expressivity and enable generalized policy improvement.", "result": "Experiments on 36 state-based and 4 image-based benchmark tasks demonstrate a 1.8 times median improvement in returns and a 36% increase in success rates compared to alternative pre-training methods.", "conclusion": "InFOM provides a compelling approach for pre-training in RL, achieving substantial performance improvements and offering a promising direction for addressing core challenges like sample efficiency and robustness."}}
{"id": "2506.08916", "pdf": "https://arxiv.org/pdf/2506.08916", "abs": "https://arxiv.org/abs/2506.08916", "authors": ["Maria-Veronica Ciocanel", "John T. Nardini", "Kevin B. Flores", "Erica M. Rutter", "Suzanne S. Sindi", "Alexandria Volkening"], "title": "Enhancing generalizability of model discovery across parameter space with multi-experiment equation learning (ME-EQL)", "categories": ["cs.LG", "math.DS", "q-bio.QM"], "comment": "31 pages, 10 figures", "summary": "Agent-based modeling (ABM) is a powerful tool for understanding\nself-organizing biological systems, but it is computationally intensive and\noften not analytically tractable. Equation learning (EQL) methods can derive\ncontinuum models from ABM data, but they typically require extensive\nsimulations for each parameter set, raising concerns about generalizability. In\nthis work, we extend EQL to Multi-experiment equation learning (ME-EQL) by\nintroducing two methods: one-at-a-time ME-EQL (OAT ME-EQL), which learns\nindividual models for each parameter set and connects them via interpolation,\nand embedded structure ME-EQL (ES ME-EQL), which builds a unified model library\nacross parameters. We demonstrate these methods using a birth--death mean-field\nmodel and an on-lattice agent-based model of birth, death, and migration with\nspatial structure. Our results show that both methods significantly reduce the\nrelative error in recovering parameters from agent-based simulations, with OAT\nME-EQL offering better generalizability across parameter space. Our findings\nhighlight the potential of equation learning from multiple experiments to\nenhance the generalizability and interpretability of learned models for complex\nbiological systems.", "AI": {"tldr": "Agent-based modeling (ABM) is a powerful tool for understanding self-organizing biological systems, but it is computationally intensive and often not analytically tractable. To address this, the paper introduces Multi-experiment equation learning (ME-EQL) as an extension of Equation learning (EQL), with two methods: one-at-a-time ME-EQL (OAT ME-EQL) and embedded structure ME-EQL (ES ME-EQL). These methods significantly reduce the relative error in recovering parameters from agent-based simulations, with OAT ME-EQL offering better generalizability across parameter space.", "motivation": "The motivation behind this work is to improve the generalizability and interpretability of learned models for complex biological systems by extending Equation learning (EQL) methods to Multi-experiment equation learning (ME-EQL).", "method": "The study introduces two methods under ME-EQL framework: one-at-a-time ME-EQL (OAT ME-EQL) which learns individual models for each parameter set and connects them via interpolation, and embedded structure ME-EQL (ES ME-EQL) which builds a unified model library across parameters.", "result": "Both methods significantly reduce the relative error in recovering parameters from agent-based simulations. OAT ME-EQL offers better generalizability across parameter space.", "conclusion": "The findings highlight the potential of equation learning from multiple experiments to enhance the generalizability and interpretability of learned models for complex biological systems."}}
{"id": "2506.08479", "pdf": "https://arxiv.org/pdf/2506.08479", "abs": "https://arxiv.org/abs/2506.08479", "authors": ["Chihiro Taguchi", "Seiji Maekawa", "Nikita Bhutani"], "title": "Efficient Context Selection for Long-Context QA: No Tuning, No Iteration, Just Adaptive-$k$", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "26 pages, 16 tables, 5 figures", "summary": "Retrieval-augmented generation (RAG) and long-context language models (LCLMs)\nboth address context limitations of LLMs in open-domain question answering\n(QA). However, optimal external context to retrieve remains an open problem:\nfixing the retrieval size risks either wasting tokens or omitting key evidence.\nExisting adaptive methods like Self-RAG and Self-Route rely on iterative LLM\nprompting and perform well on factoid QA, but struggle with aggregation QA,\nwhere the optimal context size is both unknown and variable. We present\nAdaptive-$k$ retrieval, a simple and effective single-pass method that\nadaptively selects the number of passages based on the distribution of the\nsimilarity scores between the query and the candidate passages. It does not\nrequire model fine-tuning, extra LLM inferences or changes to existing\nretriever-reader pipelines. On both factoid and aggregation QA benchmarks,\nAdaptive-$k$ matches or outperforms fixed-$k$ baselines while using up to 10x\nfewer tokens than full-context input, yet still retrieves 70% of relevant\npassages. It improves accuracy across five LCLMs and two embedding models,\nhighlighting that dynamically adjusting context size leads to more efficient\nand accurate QA.", "AI": {"tldr": "Adaptive-k retrieval is a single-pass method that adaptively selects the number of passages based on similarity scores, improving accuracy and efficiency in QA tasks with up to 10x fewer tokens.", "motivation": "To address the limitations of fixed retrieval size in existing methods which either waste tokens or omit key evidence, especially in aggregation QA where context size varies.", "method": "Adaptive-k retrieval uses the distribution of similarity scores between the query and candidate passages to select an optimal number of passages without needing model fine-tuning, extra LLM inferences, or changes to retriever-reader pipelines.", "result": "Matches or outperforms fixed-k baselines on both factoid and aggregation QA benchmarks, uses up to 10x fewer tokens than full-context input while retrieving 70% of relevant passages, and improves accuracy across multiple LCLMs and embedding models.", "conclusion": "Dynamically adjusting context size via Adaptive-k retrieval leads to more efficient and accurate QA systems."}}
{"id": "2506.08928", "pdf": "https://arxiv.org/pdf/2506.08928", "abs": "https://arxiv.org/abs/2506.08928", "authors": ["Zhongyuan Liang", "Zachary T. Rewolinski", "Abhineet Agarwal", "Tiffany M. Tang", "Bin Yu"], "title": "Local MDI+: Local Feature Importances for Tree-Based Models", "categories": ["cs.LG", "stat.ME", "stat.ML"], "comment": null, "summary": "Tree-based ensembles such as random forests remain the go-to for tabular data\nover deep learning models due to their prediction performance and computational\nefficiency. These advantages have led to their widespread deployment in\nhigh-stakes domains, where interpretability is essential for ensuring\ntrustworthy predictions. This has motivated the development of popular local\n(i.e. sample-specific) feature importance (LFI) methods such as LIME and\nTreeSHAP. However, these approaches rely on approximations that ignore the\nmodel's internal structure and instead depend on potentially unstable\nperturbations. These issues are addressed in the global setting by MDI+, a\nfeature importance method which exploits an equivalence between decision trees\nand linear models on a transformed node basis. However, the global MDI+ scores\nare not able to explain predictions when faced with heterogeneous individual\ncharacteristics. To address this gap, we propose Local MDI+ (LMDI+), a novel\nextension of the MDI+ framework to the sample specific setting. LMDI+\noutperforms existing baselines LIME and TreeSHAP in identifying\ninstance-specific signal features, averaging a 10% improvement in downstream\ntask performance across twelve real-world benchmark datasets. It further\ndemonstrates greater stability by consistently producing similar instance-level\nfeature importance rankings across multiple random forest fits. Finally, LMDI+\nenables local interpretability use cases, including the identification of\ncloser counterfactuals and the discovery of homogeneous subgroups.", "AI": {"tldr": "\u5c3d\u7ba1\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u5728\u8868\u683c\u6570\u636e\u4e0a\u6bd4\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5177\u6709\u9884\u6d4b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u7684\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08\u5982LIME\u548cTreeSHAP\uff09\u5b58\u5728\u4f9d\u8d56\u8fd1\u4f3c\u503c\u3001\u5ffd\u7565\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u4ee5\u53ca\u53ef\u80fd\u4ea7\u751f\u4e0d\u7a33\u5b9a\u6270\u52a8\u7684\u95ee\u9898\u3002\u867d\u7136\u5168\u5c40\u65b9\u6cd5MDI+\u901a\u8fc7\u5c06\u51b3\u7b56\u6811\u4e0e\u7ebf\u6027\u6a21\u578b\u7b49\u6548\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5b83\u65e0\u6cd5\u89e3\u91ca\u5177\u6709\u5f02\u8d28\u4e2a\u4f53\u7279\u6027\u7684\u9884\u6d4b\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6269\u5c55\u6846\u67b6Local MDI+ (LMDI+)\uff0c\u7528\u4e8e\u6837\u672c\u7279\u5b9a\u8bbe\u7f6e\u3002LMDI+\u5728\u8bc6\u522b\u5b9e\u4f8b\u7279\u5b9a\u4fe1\u53f7\u7279\u5f81\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\uff0c\u5e76\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002\u6b64\u5916\uff0cLMDI+\u8fd8\u652f\u6301\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u7528\u4f8b\uff0c\u5305\u62ec\u66f4\u63a5\u8fd1\u7684\u53cd\u4e8b\u5b9e\u8bc6\u522b\u548c\u540c\u8d28\u5b50\u7ec4\u7684\u53d1\u73b0\u3002", "motivation": "\u57fa\u4e8e\u6811\u7684\u96c6\u6210\u6a21\u578b\uff08\u5982\u968f\u673a\u68ee\u6797\uff09\u5728\u8868\u683c\u6570\u636e\u4e0a\u7684\u4f18\u52bf\u4f7f\u5176\u5e7f\u6cdb\u5e94\u7528\u4e8e\u9ad8\u98ce\u9669\u9886\u57df\uff0c\u56e0\u6b64\u5bf9\u8fd9\u4e9b\u6a21\u578b\u8fdb\u884c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u73b0\u6709\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff08\u5982LIME\u548cTreeSHAP\uff09\u5b58\u5728\u4f9d\u8d56\u8fd1\u4f3c\u503c\u3001\u5ffd\u7565\u6a21\u578b\u5185\u90e8\u7ed3\u6784\u4ee5\u53ca\u53ef\u80fd\u4ea7\u751f\u4e0d\u7a33\u5b9a\u6270\u52a8\u7684\u95ee\u9898\u3002\u540c\u65f6\uff0c\u5168\u5c40\u65b9\u6cd5MDI+\u867d\u7136\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u5b83\u65e0\u6cd5\u89e3\u91ca\u5177\u6709\u5f02\u8d28\u4e2a\u4f53\u7279\u6027\u7684\u9884\u6d4b\u3002\u8fd9\u4fc3\u4f7f\u4e86\u5bf9\u66f4\u7cbe\u786e\u548c\u7a33\u5b9a\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\u7684\u9700\u6c42\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86Local MDI+ (LMDI+)\uff0c\u8fd9\u662fMDI+\u6846\u67b6\u5728\u6837\u672c\u7279\u5b9a\u8bbe\u7f6e\u4e0b\u7684\u6269\u5c55\u3002LMDI+\u5229\u7528\u51b3\u7b56\u6811\u4e0e\u7ebf\u6027\u6a21\u578b\u4e4b\u95f4\u7684\u7b49\u6548\u5173\u7cfb\uff0c\u5728\u53d8\u6362\u540e\u7684\u8282\u70b9\u57fa\u7840\u4e0a\u8ba1\u7b97\u7279\u5f81\u91cd\u8981\u6027\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ee5\u4e0b\u65b9\u5f0f\u6539\u8fdb\u4e86\u73b0\u6709\u65b9\u6cd5\uff1a1. \u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5b9e\u4f8b\u7279\u5b9a\u4fe1\u53f7\u7279\u5f81\u8bc6\u522b\uff1b2. \u5728\u591a\u6b21\u968f\u673a\u68ee\u6797\u62df\u5408\u4e2d\u4fdd\u6301\u4e86\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff1b3. \u652f\u6301\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u7528\u4f8b\uff0c\u5982\u8bc6\u522b\u66f4\u63a5\u8fd1\u7684\u53cd\u4e8b\u5b9e\u548c\u53d1\u73b0\u540c\u8d28\u5b50\u7ec4\u3002", "result": "LMDI+\u5728\u5341\u4e8c\u4e2a\u771f\u5b9e\u4e16\u754c\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5b83\u5728\u8bc6\u522b\u5b9e\u4f8b\u7279\u5b9a\u4fe1\u53f7\u7279\u5f81\u65b9\u9762\u5e73\u5747\u6bd4LIME\u548cTreeSHAP\u9ad8\u51fa10%\u7684\u4e0b\u6e38\u4efb\u52a1\u6027\u80fd\u3002\u6b64\u5916\uff0cLMDI+\u5728\u591a\u6b21\u968f\u673a\u68ee\u6797\u62df\u5408\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\uff0c\u80fd\u591f\u4e00\u81f4\u5730\u751f\u6210\u76f8\u4f3c\u7684\u5b9e\u4f8b\u7ea7\u7279\u5f81\u91cd\u8981\u6027\u6392\u540d\u3002", "conclusion": "LMDI+\u662f\u4e00\u79cd\u6709\u6548\u7684\u5c40\u90e8\u7279\u5f81\u91cd\u8981\u6027\u65b9\u6cd5\uff0c\u80fd\u591f\u66f4\u51c6\u786e\u5730\u8bc6\u522b\u5b9e\u4f8b\u7279\u5b9a\u4fe1\u53f7\u7279\u5f81\u5e76\u63d0\u4f9b\u66f4\u9ad8\u7684\u7a33\u5b9a\u6027\u3002\u5176\u5e94\u7528\u4e0d\u4ec5\u9650\u4e8e\u89e3\u91ca\u968f\u673a\u68ee\u6797\u6a21\u578b\uff0c\u8fd8\u53ef\u4ee5\u7528\u4e8e\u5176\u4ed6\u5c40\u90e8\u53ef\u89e3\u91ca\u6027\u4efb\u52a1\uff0c\u5982\u8bc6\u522b\u66f4\u63a5\u8fd1\u7684\u53cd\u4e8b\u5b9e\u548c\u53d1\u73b0\u540c\u8d28\u5b50\u7ec4\u3002"}}
{"id": "2506.08480", "pdf": "https://arxiv.org/pdf/2506.08480", "abs": "https://arxiv.org/abs/2506.08480", "authors": ["Huixuan Zhang", "Xiaojun Wan"], "title": "Re-Thinking the Automatic Evaluation of Image-Text Alignment in Text-to-Image Models", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Text-to-image models often struggle to generate images that precisely match\ntextual prompts. Prior research has extensively studied the evaluation of\nimage-text alignment in text-to-image generation. However, existing evaluations\nprimarily focus on agreement with human assessments, neglecting other critical\nproperties of a trustworthy evaluation framework. In this work, we first\nidentify two key aspects that a reliable evaluation should address. We then\nempirically demonstrate that current mainstream evaluation frameworks fail to\nfully satisfy these properties across a diverse range of metrics and models.\nFinally, we propose recommendations for improving image-text alignment\nevaluation.", "AI": {"tldr": "The paper explores the shortcomings of current text-to-image model evaluations and proposes improvements.", "motivation": "To enhance the evaluation frameworks for text-to-image models by identifying critical properties that are currently overlooked.", "method": "Identifying key aspects of reliable evaluations, demonstrating failures of current frameworks across metrics and models, and proposing recommendations for improvement.", "result": "Current mainstream evaluation frameworks fail to fully satisfy the identified properties, necessitating improvements.", "conclusion": "Recommendations are provided to improve image-text alignment evaluation in text-to-image generation."}}
{"id": "2506.08936", "pdf": "https://arxiv.org/pdf/2506.08936", "abs": "https://arxiv.org/abs/2506.08936", "authors": ["Amina Mollaysa", "Artem Moskale", "Pushpak Pati", "Tommaso Mansi", "Mangal Prakash", "Rui Liao"], "title": "BioLangFusion: Multimodal Fusion of DNA, mRNA, and Protein Language Models", "categories": ["cs.LG"], "comment": "Proceedings of ICML 2025 Workshop on Multi-modal Foundation\n  Proceedings of ICML 2025 Workshop on Multi-modal Foundation Proceedings of\n  ICML 2025 Workshop on Multi-modal Foundation Models and Large Language Models\n  for Life Sciences", "summary": "We present BioLangFusion, a simple approach for integrating pre-trained DNA,\nmRNA, and protein language models into unified molecular representations.\nMotivated by the central dogma of molecular biology (information flow from gene\nto transcript to protein), we align per-modality embeddings at the biologically\nmeaningful codon level (three nucleotides encoding one amino acid) to ensure\ndirect cross-modal correspondence. BioLangFusion studies three standard fusion\ntechniques: (i) codon-level embedding concatenation, (ii) entropy-regularized\nattention pooling inspired by multiple-instance learning, and (iii) cross-modal\nmulti-head attention -- each technique providing a different inductive bias for\ncombining modality-specific signals. These methods require no additional\npre-training or modification of the base models, allowing straightforward\nintegration with existing sequence-based foundation models. Across five\nmolecular property prediction tasks, BioLangFusion outperforms strong unimodal\nbaselines, showing that even simple fusion of pre-trained models can capture\ncomplementary multi-omic information with minimal overhead.", "AI": {"tldr": "The paper introduces BioLangFusion, a method for integrating pre-trained DNA, mRNA, and protein language models into unified molecular representations by aligning embeddings at the codon level. It studies three fusion techniques and demonstrates improved performance on molecular property prediction tasks compared to unimodal baselines.", "motivation": "To create a unified molecular representation that integrates information from DNA, mRNA, and protein using pre-trained language models, motivated by the central dogma of molecular biology.", "method": "BioLangFusion uses three standard fusion techniques: codon-level embedding concatenation, entropy-regularized attention pooling, and cross-modal multi-head attention. These methods align per-modality embeddings at the biologically meaningful codon level.", "result": "BioLangFusion outperforms strong unimodal baselines across five molecular property prediction tasks, showing that even simple fusion of pre-trained models can capture complementary multi-omic information with minimal overhead.", "conclusion": "Integrating pre-trained DNA, mRNA, and protein language models into unified molecular representations through simple fusion techniques can effectively capture complementary multi-omic information."}}
{"id": "2506.08487", "pdf": "https://arxiv.org/pdf/2506.08487", "abs": "https://arxiv.org/abs/2506.08487", "authors": ["Sumanth Manduru", "Carlotta Domeniconi"], "title": "Fairness is Not Silence: Unmasking Vacuous Neutrality in Small Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid adoption of Small Language Models (SLMs) for on-device and\nresource-constrained deployments has outpaced our understanding of their\nethical risks. To the best of our knowledge, we present the first large-scale\naudit of instruction-tuned SLMs spanning 0.5 to 5 billion parameters-an\noverlooked \"middle tier\" between BERT-class encoders and flagship LLMs. Our\nevaluation includes nine open-source models from the Qwen 2.5, LLaMA 3.2, Gemma\n3, and Phi families. Using the BBQ benchmark under zero-shot prompting, we\nanalyze both utility and fairness across ambiguous and disambiguated contexts.\nThis evaluation reveals three key insights. First, competence and fairness need\nnot be antagonistic: Phi models achieve F1 scores exceeding 90 percent while\nexhibiting minimal bias, showing that efficient and ethical NLP is attainable.\nSecond, social bias varies significantly by architecture: Qwen 2.5 models may\nappear fair, but this often reflects vacuous neutrality, random guessing, or\nevasive behavior rather than genuine ethical alignment. In contrast, LLaMA 3.2\nmodels exhibit stronger stereotypical bias, suggesting overconfidence rather\nthan neutrality. Third, compression introduces nuanced trade-offs: 4-bit AWQ\nquantization improves F1 scores in ambiguous settings for LLaMA 3.2-3B but\nincreases disability-related bias in Phi-4-Mini by over 7 percentage points.\nThese insights provide practical guidance for the responsible deployment of\nSLMs in applications demanding fairness and efficiency, particularly benefiting\nsmall enterprises and resource-constrained environments.", "AI": {"tldr": "The first large-scale audit of instruction-tuned Small Language Models (SLMs) with 0.5 to 5 billion parameters reveals insights into the balance between competence, fairness, and ethical risks. Phi models achieve high F1 scores with minimal bias, Qwen 2.5 models show vacuous neutrality, LLaMA 3.2 models exhibit stereotypical bias, and compression through quantization introduces trade-offs in performance and bias.", "motivation": "To understand the ethical risks associated with the rapid adoption of Small Language Models (SLMs) for on-device and resource-constrained deployments, particularly focusing on the 'middle tier' models that have been overlooked in previous studies.", "method": "Audited nine open-source SLMs from Qwen 2.5, LLaMA 3.2, Gemma 3, and Phi families using the BBQ benchmark under zero-shot prompting to evaluate utility and fairness across ambiguous and disambiguated contexts.", "result": "Phi models achieve high F1 scores with minimal bias; Qwen 2.5 models appear fair due to neutrality or random guessing; LLaMA 3.2 models exhibit strong stereotypical bias; 4-bit AWQ quantization improves F1 scores but increases disability-related bias in some models.", "conclusion": "Provides practical guidance for responsibly deploying SLMs in applications demanding fairness and efficiency, especially beneficial for small enterprises and resource-constrained environments."}}
{"id": "2506.08939", "pdf": "https://arxiv.org/pdf/2506.08939", "abs": "https://arxiv.org/abs/2506.08939", "authors": ["Hang Ye", "Gaoxiang Duan", "Haoran Zeng", "Yangxin Zhu", "Lingxue Meng", "Xiaoying Zheng", "Yongxin Zhu"], "title": "KARMA: A Multilevel Decomposition Hybrid Mamba Framework for Multivariate Long-Term Time Series Forecasting", "categories": ["cs.LG"], "comment": "10 pages,3 figures, published to WASA2025", "summary": "Multivariate long-term and efficient time series forecasting is a key\nrequirement for a variety of practical applications, and there are complex\ninterleaving time dynamics in time series data that require decomposition\nmodeling. Traditional time series decomposition methods are single and rely on\nfixed rules, which are insufficient for mining the potential information of the\nseries and adapting to the dynamic characteristics of complex series. On the\nother hand, the Transformer-based models for time series forecasting struggle\nto effectively model long sequences and intricate dynamic relationships due to\ntheir high computational complexity. To overcome these limitations, we\nintroduce KARMA, with an Adaptive Time Channel Decomposition module (ATCD) to\ndynamically extract trend and seasonal components. It further integrates a\nHybrid Frequency-Time Decomposition module (HFTD) to further decompose Series\ninto frequency-domain and time-domain. These components are coupled with\nmulti-scale Mamba-based KarmaBlock to efficiently process global and local\ninformation in a coordinated manner. Experiments on eight real-world datasets\nfrom diverse domains well demonstrated that KARMA significantly outperforms\nmainstream baseline methods in both predictive accuracy and computational\nefficiency. Code and full results are available at this repository:\nhttps://github.com/yedadasd/KARMA", "AI": {"tldr": "KARMA is a new model for multivariate long-term time series forecasting which uses Adaptive Time Channel Decomposition and Hybrid Frequency-Time Decomposition modules to improve prediction accuracy and computational efficiency.", "motivation": "Existing traditional time series decomposition methods are limited by fixed rules and insufficient potential information mining. Transformer-based models have high computational complexity that limits their ability to effectively model long sequences and intricate dynamic relationships.", "method": "KARMA incorporates an Adaptive Time Channel Decomposition module (ATCD) for extracting trend and seasonal components dynamically, and a Hybrid Frequency-Time Decomposition module (HFTD) for further decomposing series into frequency and time domains. The model also utilizes multi-scale Mamba-based KarmaBlock for efficient processing of global and local information in a coordinated way.", "result": "Experiments on eight real-world datasets from diverse domains showed that KARMA significantly outperforms mainstream baseline methods in both predictive accuracy and computational efficiency.", "conclusion": "KARMA addresses the limitations of traditional decomposition methods and Transformer-based models by introducing ATCD, HFTD, and KarmaBlock, leading to superior performance in multivariate long-term time series forecasting."}}
{"id": "2506.08488", "pdf": "https://arxiv.org/pdf/2506.08488", "abs": "https://arxiv.org/abs/2506.08488", "authors": ["Ashutosh Dwivedi", "Siddhant Shivdutt Singh", "Ashutosh Modi"], "title": "EtiCor++: Towards Understanding Etiquettical Bias in LLMs", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted at ACL Findings 2025, 22 pages (9 pages main content + 4\n  pages references + 9 pages appendix)", "summary": "In recent years, researchers have started analyzing the cultural sensitivity\nof LLMs. In this respect, Etiquettes have been an active area of research.\nEtiquettes are region-specific and are an essential part of the culture of a\nregion; hence, it is imperative to make LLMs sensitive to etiquettes. However,\nthere needs to be more resources in evaluating LLMs for their understanding and\nbias with regard to etiquettes. In this resource paper, we introduce EtiCor++,\na corpus of etiquettes worldwide. We introduce different tasks for evaluating\nLLMs for knowledge about etiquettes across various regions. Further, we\nintroduce various metrics for measuring bias in LLMs. Extensive experimentation\nwith LLMs shows inherent bias towards certain regions.", "AI": {"tldr": "This paper introduces EtiCor++, a corpus of worldwide etiquettes, and proposes tasks and metrics to evaluate LLMs' understanding and bias regarding etiquettes.", "motivation": "Cultural sensitivity in LLMs is crucial, especially concerning region-specific etiquettes, but there lacks sufficient resources for evaluating LLMs on this aspect.", "method": "Introduced EtiCor++ as a resource, designed tasks for assessing LLMs' knowledge about global etiquettes, and proposed metrics to measure bias in LLMs.", "result": "Experiments revealed inherent bias in LLMs towards certain regions.", "conclusion": "EtiCor++ provides a valuable tool for improving cultural sensitivity in LLMs by evaluating their understanding and biases related to global etiquettes."}}
{"id": "2506.08961", "pdf": "https://arxiv.org/pdf/2506.08961", "abs": "https://arxiv.org/abs/2506.08961", "authors": ["Chenxu Wang", "Huaping Liu"], "title": "Towards Robust Deep Reinforcement Learning against Environmental State Perturbation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Adversarial attacks and robustness in Deep Reinforcement Learning (DRL) have\nbeen widely studied in various threat models; however, few consider\nenvironmental state perturbations, which are natural in embodied scenarios. To\nimprove the robustness of DRL agents, we formulate the problem of environmental\nstate perturbation, introducing a preliminary non-targeted attack method as a\ncalibration adversary, and then propose a defense framework, named Boosted\nAdversarial Training (BAT), which first tunes the agents via supervised\nlearning to avoid catastrophic failure and subsequently adversarially trains\nthe agent with reinforcement learning. Extensive experimental results\nsubstantiate the vulnerability of mainstream agents under environmental state\nperturbations and the effectiveness of our proposed attack. The defense results\ndemonstrate that while existing robust reinforcement learning algorithms may\nnot be suitable, our BAT framework can significantly enhance the robustness of\nagents against environmental state perturbations across various situations.", "AI": {"tldr": "This paper explores adversarial attacks and robustness in Deep Reinforcement Learning (DRL) by focusing on environmental state perturbations, proposing a defense framework called Boosted Adversarial Training (BAT).", "motivation": "To improve the robustness of DRL agents against environmental state perturbations which are natural in embodied scenarios.", "method": "The problem of environmental state perturbation is formulated, introducing a preliminary non-targeted attack method as a calibration adversary. Then, a defense framework named Boosted Adversarial Training (BAT) is proposed which tunes the agents via supervised learning to avoid catastrophic failure and subsequently adversarially trains the agent with reinforcement learning.", "result": "Experimental results show mainstream agents' vulnerability under environmental state perturbations and the effectiveness of the proposed attack. Defense results indicate existing robust reinforcement learning algorithms may not be suitable but the BAT framework can significantly enhance agents' robustness against environmental state perturbations across various situations.", "conclusion": "Environmental state perturbations pose a challenge for DRL agents' robustness. The BAT framework effectively enhances the robustness of DRL agents."}}
{"id": "2506.08500", "pdf": "https://arxiv.org/pdf/2506.08500", "abs": "https://arxiv.org/abs/2506.08500", "authors": ["Arie Cattan", "Alon Jacovi", "Ori Ram", "Jonathan Herzig", "Roee Aharoni", "Sasha Goldshtein", "Eran Ofek", "Idan Szpektor", "Avi Caciularu"], "title": "DRAGged into Conflicts: Detecting and Addressing Conflicting Sources in Search-Augmented LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Retrieval Augmented Generation (RAG) is a commonly used approach for\nenhancing large language models (LLMs) with relevant and up-to-date\ninformation. However, the retrieved sources can often contain conflicting\ninformation and it remains unclear how models should address such\ndiscrepancies. In this work, we first propose a novel taxonomy of knowledge\nconflict types in RAG, along with the desired model behavior for each type. We\nthen introduce CONFLICTS, a high-quality benchmark with expert annotations of\nconflict types in a realistic RAG setting. CONFLICTS is the first benchmark\nthat enables tracking progress on how models address a wide range of knowledge\nconflicts. We conduct extensive experiments on this benchmark, showing that\nLLMs often struggle to appropriately resolve conflicts between sources. While\nprompting LLMs to explicitly reason about the potential conflict in the\nretrieved documents significantly improves the quality and appropriateness of\ntheir responses, substantial room for improvement in future research remains.", "AI": {"tldr": "\u5728\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u51b2\u7a81\u7c7b\u578b\u5206\u7c7b\u6cd5\u4ee5\u53ca\u76f8\u5e94\u7684\u6a21\u578b\u884c\u4e3a\uff0c\u5e76\u5f15\u5165\u4e86CONFLICTS\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\u3002\u5c3d\u7ba1\u63d0\u793aLLM\u663e\u5f0f\u63a8\u7406\u68c0\u7d22\u5230\u7684\u6587\u6863\u4e2d\u7684\u6f5c\u5728\u51b2\u7a81\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5176\u54cd\u5e94\u7684\u8d28\u91cf\u548c\u9002\u5f53\u6027\uff0c\u4f46\u672a\u6765\u7684\u7814\u7a76\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\u3002", "motivation": "\u73b0\u6709\u7684RAG\u65b9\u6cd5\u867d\u7136\u80fd\u591f\u589e\u5f3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\uff0c\u4f46\u68c0\u7d22\u5230\u7684\u6765\u6e90\u53ef\u80fd\u5305\u542b\u51b2\u7a81\u7684\u4fe1\u606f\uff0c\u800c\u6a21\u578b\u5e94\u8be5\u5982\u4f55\u5904\u7406\u8fd9\u4e9b\u5dee\u5f02\u5c1a\u4e0d\u660e\u786e\u3002", "method": "1. \u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u77e5\u8bc6\u51b2\u7a81\u7c7b\u578b\u5206\u7c7b\u6cd5\u4ee5\u53ca\u6bcf\u79cd\u7c7b\u578b\u7684\u671f\u671b\u6a21\u578b\u884c\u4e3a\u3002\n2. \u5f15\u5165CONFLICTS\u57fa\u51c6\uff0c\u8fd9\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u7684\u57fa\u51c6\uff0c\u5177\u6709\u4e13\u5bb6\u5bf9\u73b0\u5b9eRAG\u8bbe\u7f6e\u4e2d\u51b2\u7a81\u7c7b\u578b\u7684\u6ce8\u91ca\u3002\n3. \u5728\u8be5\u57fa\u51c6\u4e0a\u8fdb\u884c\u5e7f\u6cdb\u7684\u5b9e\u9a8c\uff0c\u4ee5\u8bc4\u4f30LLM\u89e3\u51b3\u77e5\u8bc6\u51b2\u7a81\u7684\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cLLM\u7ecf\u5e38\u96be\u4ee5\u9002\u5f53\u5730\u89e3\u51b3\u6765\u6e90\u4e4b\u95f4\u7684\u51b2\u7a81\u3002\u7136\u800c\uff0c\u63d0\u793aLLM\u663e\u5f0f\u63a8\u7406\u68c0\u7d22\u5230\u7684\u6587\u6863\u4e2d\u7684\u6f5c\u5728\u51b2\u7a81\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5176\u54cd\u5e94\u7684\u8d28\u91cf\u548c\u9002\u5f53\u6027\u3002", "conclusion": "\u5c3d\u7ba1\u901a\u8fc7\u63d0\u793aLLM\u663e\u5f0f\u63a8\u7406\u53ef\u4ee5\u6539\u5584\u5176\u89e3\u51b3\u51b2\u7a81\u7684\u80fd\u529b\uff0c\u4f46\u672a\u6765\u7684\u7814\u7a76\u4ecd\u9700\u52aa\u529b\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6a21\u578b\u5728\u8fd9\u65b9\u9762\u7684\u8868\u73b0\u3002"}}
{"id": "2506.08965", "pdf": "https://arxiv.org/pdf/2506.08965", "abs": "https://arxiv.org/abs/2506.08965", "authors": ["Yiyang Zhao", "Huiyu Bai", "Xuejiao Zhao"], "title": "GFRIEND: Generative Few-shot Reward Inference through EfficieNt DPO", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The ability to train high-performing reward models with few-shot data is\ncritical for enhancing the efficiency and scalability of Reinforcement Learning\nfrom Human Feedback (RLHF). We propose a data augmentation and expansion\nframework that enables generative reward models trained on small datasets to\nachieve comparable performance to those trained on large-scale datasets.\nTraditional methods to train a generative reward model, such as Direct\nPreference Optimization (DPO), are constrained by inefficiencies in sample\npairing and limited data diversity. This work introduces preference refinement,\nwhich employs Chain-of-Thought (CoT) sampling to uncover diverse and\nhigh-quality preference relationships. It also incorporates a perplexity-based\nscoring mechanism to assign nuanced preference levels and utilizes Multi-level\nDirect Preference Optimization (M-DPO) to enable the model to capture\nfiner-grained preference differences between samples. Experimental results\ndemonstrate that the proposed method significantly enhances data efficiency and\nmodel performance, enabling reward models trained in a few-shot setting to\nachieve results on par with those trained on large-scale datasets. This study\nunderscores the potential of data-efficient strategies in advancing reward\nmodel optimization, offering a robust solution for low-resource RLHF\napplications.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u589e\u5f3a\u548c\u6269\u5c55\u6846\u67b6\uff0c\u901a\u8fc7\u5f15\u5165\u504f\u597d\u7cbe\u70bc\u3001Chain-of-Thought (CoT) \u91c7\u6837\u3001\u56f0\u60d1\u5ea6\u8bc4\u5206\u673a\u5236\u548c\u591a\u7ea7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08M-DPO\uff09\u7b49\u6280\u672f\uff0c\u4f7f\u5728\u5c11\u91cf\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u80fd\u591f\u8fbe\u5230\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u4f4e\u8d44\u6e90\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u751f\u6210\u5f0f\u5956\u52b1\u6a21\u578b\u7684\u8bad\u7ec3\u65b9\u6cd5\u5982\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08DPO\uff09\u53d7\u5230\u6837\u672c\u914d\u5bf9\u6548\u7387\u4f4e\u4e0b\u548c\u6570\u636e\u591a\u6837\u6027\u4e0d\u8db3\u7684\u9650\u5236\uff0c\u5c24\u5176\u662f\u5728\u5c0f\u6570\u636e\u96c6\u60c5\u51b5\u4e0b\u8868\u73b0\u4e0d\u4f73\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6846\u67b6\u6765\u63d0\u9ad8\u5956\u52b1\u6a21\u578b\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u7684\u8bad\u7ec3\u6548\u679c\u548c\u6570\u636e\u5229\u7528\u6548\u7387\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u6570\u636e\u589e\u5f3a\u548c\u6269\u5c55\u6846\u67b6\uff0c\u5177\u4f53\u5305\u62ec\uff1a1) \u504f\u597d\u7cbe\u70bc\uff0c\u4f7f\u7528Chain-of-Thought (CoT) \u91c7\u6837\u53d1\u73b0\u591a\u6837\u4e14\u9ad8\u8d28\u91cf\u7684\u504f\u597d\u5173\u7cfb\uff1b2) \u56f0\u60d1\u5ea6\u8bc4\u5206\u673a\u5236\uff0c\u5206\u914d\u7ec6\u81f4\u7684\u504f\u597d\u7b49\u7ea7\uff1b3) \u591a\u7ea7\u76f4\u63a5\u504f\u597d\u4f18\u5316\uff08M-DPO\uff09\uff0c\u5e2e\u52a9\u6a21\u578b\u6355\u6349\u6837\u672c\u95f4\u7684\u7ec6\u5fae\u504f\u597d\u5dee\u5f02\u3002\u8fd9\u4e9b\u65b9\u6cd5\u5171\u540c\u63d0\u5347\u4e86\u5956\u52b1\u6a21\u578b\u5728\u5c0f\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\u548c\u6a21\u578b\u6027\u80fd\uff0c\u4f7f\u5f97\u5728\u5c11\u91cf\u6570\u636e\u4e0a\u8bad\u7ec3\u7684\u5956\u52b1\u6a21\u578b\u53ef\u4ee5\u8fbe\u5230\u4e0e\u5927\u89c4\u6a21\u6570\u636e\u96c6\u8bad\u7ec3\u6a21\u578b\u76f8\u5ab2\u7f8e\u7684\u6548\u679c\u3002\u8fd9\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u5f3a\u5316\u5b66\u4e60\u5e94\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u6570\u636e\u9ad8\u6548\u7b56\u7565\u5728\u63d0\u5347\u5956\u52b1\u6a21\u578b\u4f18\u5316\u65b9\u9762\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u5f3a\u5316\u5b66\u4e60\u53cd\u9988\u5e94\u7528\u4e2d\uff0c\u53ef\u4f5c\u4e3a\u4e00\u79cd\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.08504", "pdf": "https://arxiv.org/pdf/2506.08504", "abs": "https://arxiv.org/abs/2506.08504", "authors": ["Divyaksh Shukla", "Ritesh Baviskar", "Dwijesh Gohil", "Aniket Tiwari", "Atul Shree", "Ashutosh Modi"], "title": "CoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in conversations", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Accepted at ACL Findings 2025 (16 pages: 5 pages main content + 3\n  pages references + 8 pages appendix)", "summary": "Discourse parsing is an important task useful for NLU applications such as\nsummarization, machine comprehension, and emotion recognition. The current\ndiscourse parsing datasets based on conversations consists of written English\ndialogues restricted to a single domain. In this resource paper, we introduce\nCoMuMDR: Code-mixed Multi-modal Multi-domain corpus for Discourse paRsing in\nconversations. The corpus (code-mixed in Hindi and English) has both audio and\ntranscribed text and is annotated with nine discourse relations. We experiment\nwith various SoTA baseline models; the poor performance of SoTA models\nhighlights the challenges of multi-domain code-mixed corpus, pointing towards\nthe need for developing better models for such realistic settings.", "AI": {"tldr": "The paper introduces CoMuMDR, a new corpus for discourse parsing in conversations that is code-mixed in Hindi and English, multi-modal (audio and text), and multi-domain. Experiments with SoTA models show poor performance, indicating challenges in handling such complex data.", "motivation": "Existing discourse parsing datasets are limited to written English dialogues within a single domain, failing to represent the complexity of real-world conversations.", "method": "Created a new corpus called CoMuMDR which includes audio and transcribed text, annotated with nine discourse relations. Tested various state-of-the-art baseline models on this corpus.", "result": "State-of-the-art models performed poorly on the CoMuMDR corpus, demonstrating the difficulties posed by multi-domain and code-mixed data.", "conclusion": "There is a need for developing better models that can handle the complexities of multi-domain and code-mixed conversational data."}}
{"id": "2506.08977", "pdf": "https://arxiv.org/pdf/2506.08977", "abs": "https://arxiv.org/abs/2506.08977", "authors": ["Victoria Hankemeier", "Malte Schilling"], "title": "Tailored Architectures for Time Series Forecasting: Evaluating Deep Learning Models on Gaussian Process-Generated Data", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at IJCNN25, Code: https://github.com/vicky-hnk/time-flex", "summary": "Developments in Deep Learning have significantly improved time series\nforecasting by enabling more accurate modeling of complex temporal dependencies\ninherent in sequential data. The effectiveness of such models is often\ndemonstrated on limited sets of specific real-world data. Although this allows\nfor comparative analysis, it still does not demonstrate how specific data\ncharacteristics align with the architectural strengths of individual models.\nOur research aims at uncovering clear connections between time series\ncharacteristics and particular models. We introduce a novel dataset generated\nusing Gaussian Processes, specifically designed to display distinct, known\ncharacteristics for targeted evaluations of model adaptability to them.\nFurthermore, we present TimeFlex, a new model that incorporates a modular\narchitecture tailored to handle diverse temporal dynamics, including trends and\nperiodic patterns. This model is compared to current state-of-the-art models,\noffering a deeper understanding of how models perform under varied time series\nconditions.", "AI": {"tldr": "The paper explores connections between time series characteristics and model performance, introduces a Gaussian Processes-generated dataset for targeted evaluations, and presents TimeFlex, a modular architecture model designed to handle diverse temporal dynamics.", "motivation": "To uncover clear connections between time series characteristics and the strengths of individual models, addressing the limitation of demonstrating model effectiveness on limited real-world data sets.", "method": "Introduction of a novel dataset generated using Gaussian Processes with distinct, known characteristics for targeted evaluations. Development of TimeFlex, a modular architecture model designed to handle diverse temporal dynamics including trends and periodic patterns.", "result": "TimeFlex is compared against current state-of-the-art models providing deeper insights into model performance under varied time series conditions.", "conclusion": "Clear connections exist between time series characteristics and specific model architectures; the use of tailored datasets and flexible models like TimeFlex can enhance understanding and improve forecasting accuracy."}}
{"id": "2506.08978", "pdf": "https://arxiv.org/pdf/2506.08978", "abs": "https://arxiv.org/abs/2506.08978", "authors": ["Anna Langedijk", "Jaap Jumelet", "Willem Zuidema"], "title": "Propositional Logic for Probing Generalization in Neural Networks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The extent to which neural networks are able to acquire and represent\nsymbolic rules remains a key topic of research and debate. Much current work\nfocuses on the impressive capabilities of large language models, as well as\ntheir often ill-understood failures on a wide range of reasoning tasks. In this\npaper, in contrast, we investigate the generalization behavior of three key\nneural architectures (Transformers, Graph Convolution Networks and LSTMs) in a\ncontrolled task rooted in propositional logic. The task requires models to\ngenerate satisfying assignments for logical formulas, making it a structured\nand interpretable setting for studying compositionality. We introduce a\nbalanced extension of an existing dataset to eliminate superficial patterns and\nenable testing on unseen operator combinations. Using this dataset, we evaluate\nthe ability of the three architectures to generalize beyond the training\ndistribution. While all models perform well in-distribution, we find that\ngeneralization to unseen patterns, particularly those involving negation,\nremains a significant challenge. Transformers fail to apply negation\ncompositionally, unless structural biases are introduced. Our findings\nhighlight persistent limitations in the ability of standard architectures to\nlearn systematic representations of logical operators, suggesting the need for\nstronger inductive biases to support robust rule-based reasoning.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4e09\u79cd\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728\u547d\u9898\u903b\u8f91\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u884c\u4e3a\uff0c\u53d1\u73b0\u5373\u4f7f\u5728\u5f15\u5165\u7ed3\u6784\u504f\u5dee\u7684\u60c5\u51b5\u4e0b\uff0c\u5bf9\u672a\u89c1\u6a21\u5f0f\uff08\u5c24\u5176\u662f\u6d89\u53ca\u5426\u5b9a\u7684\u6a21\u5f0f\uff09\u7684\u6cdb\u5316\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u6311\u6218\u3002", "motivation": "\u63a2\u8ba8\u795e\u7ecf\u7f51\u7edc\u83b7\u53d6\u548c\u8868\u793a\u7b26\u53f7\u89c4\u5219\u7684\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u547d\u9898\u903b\u8f91\u4efb\u52a1\u4e2d\u7814\u7a76\u5176\u7ec4\u6210\u6027\u6cdb\u5316\u7684\u5c40\u9650\u6027\u3002", "method": "\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8e\u547d\u9898\u903b\u8f91\u7684\u4efb\u52a1\uff0c\u8bc4\u4f30Transformer\u3001\u56fe\u5377\u79ef\u7f51\u7edc\u548cLSTM\u4e09\u79cd\u67b6\u6784\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u5e76\u5f15\u5165\u5e73\u8861\u6269\u5c55\u7684\u6570\u636e\u96c6\u4ee5\u6d88\u9664\u8868\u9762\u6a21\u5f0f\u5e76\u6d4b\u8bd5\u672a\u89c1\u64cd\u4f5c\u7b26\u7ec4\u5408\u3002", "result": "\u6240\u6709\u6a21\u578b\u5728\u8bad\u7ec3\u5206\u5e03\u5185\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u6cdb\u5316\u5230\u672a\u89c1\u6a21\u5f0f\u65f6\u9047\u5230\u56f0\u96be\uff0c\u7279\u522b\u662f\u6d89\u53ca\u5426\u5b9a\u7684\u6a21\u5f0f\u3002Transformer\u53ea\u6709\u5728\u5f15\u5165\u7ed3\u6784\u504f\u5dee\u65f6\u624d\u80fd\u8f83\u597d\u5730\u5904\u7406\u5426\u5b9a\u7684\u7ec4\u6210\u6027\u5e94\u7528\u3002", "conclusion": "\u6807\u51c6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u5728\u5b66\u4e60\u7cfb\u7edf\u6027\u7684\u903b\u8f91\u8fd0\u7b97\u7b26\u8868\u793a\u65b9\u9762\u5b58\u5728\u6301\u7eed\u7684\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u5f3a\u7684\u5f52\u7eb3\u504f\u5dee\u6765\u652f\u6301\u7a33\u5065\u7684\u57fa\u4e8e\u89c4\u5219\u7684\u63a8\u7406\u3002"}}
{"id": "2506.08507", "pdf": "https://arxiv.org/pdf/2506.08507", "abs": "https://arxiv.org/abs/2506.08507", "authors": ["Kuo Yang", "Xingjie Yang", "Linhui Yu", "Qing Xu", "Yan Fang", "Xu Wang", "Zhengyang Zhou", "Yang Wang"], "title": "MasHost Builds It All: Autonomous Multi-Agent System Directed by Reinforcement Learning", "categories": ["cs.MA", "cs.AI", "cs.LG"], "comment": null, "summary": "Large Language Model (LLM)-driven Multi-agent systems (Mas) have recently\nemerged as a powerful paradigm for tackling complex real-world tasks. However,\nexisting Mas construction methods typically rely on manually crafted\ninteraction mechanisms or heuristic rules, introducing human biases and\nconstraining the autonomous ability. Even with recent advances in adaptive Mas\nconstruction, existing systems largely remain within the paradigm of\nsemi-autonomous patterns. In this work, we propose MasHost, a Reinforcement\nLearning (RL)-based framework for autonomous and query-adaptive Mas design. By\nformulating Mas construction as a graph search problem, our proposed MasHost\njointly samples agent roles and their interactions through a unified\nprobabilistic sampling mechanism. Beyond the accuracy and efficiency objectives\npursued in prior works, we introduce component rationality as an additional and\nnovel design principle in Mas. To achieve this multi-objective optimization, we\npropose Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy\nthat collaboratively integrates group-relative advantages and action-wise\nrewards. To our knowledge, our proposed MasHost is the first RL-driven\nframework for autonomous Mas graph construction. Extensive experiments on six\nbenchmarks demonstrate that MasHost consistently outperforms most competitive\nbaselines, validating its effectiveness, efficiency, and structure rationality.", "AI": {"tldr": "Large Language Model (LLM)-driven Multi-agent systems (Mas) are powerful for complex tasks, but existing construction methods have limitations. This work proposes MasHost, a Reinforcement Learning (RL)-based framework for autonomous and query-adaptive Mas design, which introduces component rationality as a new principle.", "motivation": "Existing Multi-agent systems (Mas) construction methods rely on manually crafted interaction mechanisms or heuristic rules, introducing human biases and constraining the autonomous ability. Even with recent advances in adaptive Mas construction, existing systems largely remain within the paradigm of semi-autonomous patterns.", "method": "The proposed method, MasHost, formulates Mas construction as a graph search problem and jointly samples agent roles and their interactions through a unified probabilistic sampling mechanism. It uses Hierarchical Relative Policy Optimization (HRPO), a novel RL strategy that collaboratively integrates group-relative advantages and action-wise rewards.", "result": "Extensive experiments on six benchmarks demonstrate that MasHost consistently outperforms most competitive baselines, validating its effectiveness, efficiency, and structure rationality.", "conclusion": "MasHost is the first RL-driven framework for autonomous Mas graph construction and shows superior performance in various benchmarks."}}
{"id": "2506.08982", "pdf": "https://arxiv.org/pdf/2506.08982", "abs": "https://arxiv.org/abs/2506.08982", "authors": ["Ivan Rubachev", "Akim Kotelnikov", "Nikolay Kartashev"], "title": "On Finetuning Tabular Foundation Models", "categories": ["cs.LG"], "comment": null, "summary": "Foundation models are an emerging research direction in tabular deep\nlearning. Notably, TabPFNv2 recently claimed superior performance over\ntraditional GBDT-based methods on small-scale datasets using an in-context\nlearning paradigm, which does not adapt model parameters to target datasets.\nHowever, the optimal finetuning approach for adapting tabular foundational\nmodels, and how this adaptation reshapes their internal mechanisms, remains\nunderexplored. While prior works studied finetuning for earlier foundational\nmodels, inconsistent findings and TabPFNv2's unique architecture necessitate\nfresh investigation. To address these questions, we first systematically\nevaluate various finetuning strategies on diverse datasets. Our findings\nestablish full finetuning as the most practical solution for TabPFNv2 in terms\nof time-efficiency and effectiveness. We then investigate how finetuning alters\nTabPFNv2's inner mechanisms, drawing an analogy to retrieval-augmented models.\nWe reveal that the success of finetuning stems from the fact that after\ngradient-based adaptation, the dot products of the query-representations of\ntest objects and the key-representations of in-context training objects more\naccurately reflect their target similarity. This improved similarity allows\nfinetuned TabPFNv2 to better approximate target dependency by appropriately\nweighting relevant in-context samples, improving the retrieval-based prediction\nlogic. From the practical perspective, we managed to finetune TabPFNv2 on\ndatasets with up to 50K objects, observing performance improvements on almost\nall tasks. More precisely, on academic datasets with I.I.D. splits, finetuning\nallows TabPFNv2 to achieve state-of-the-art results, while on datasets with\ngradual temporal shifts and rich feature sets, TabPFNv2 is less stable and\nprior methods remain better.", "AI": {"tldr": "\u7814\u7a76\u4e86TabPFNv2\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u5fae\u8c03\u7b56\u7565\uff0c\u53d1\u73b0\u5168\u91cf\u5fae\u8c03\u662f\u6700\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u5e76\u63ed\u793a\u4e86\u5fae\u8c03\u5982\u4f55\u6539\u53d8\u6a21\u578b\u5185\u90e8\u673a\u5236\u3002\u5fae\u8c03\u6210\u529f\u7684\u5173\u952e\u5728\u4e8e\u901a\u8fc7\u68af\u5ea6\u9002\u5e94\uff0c\u4f7f\u6d4b\u8bd5\u5bf9\u8c61\u548c\u4e0a\u4e0b\u6587\u8bad\u7ec3\u5bf9\u8c61\u7684\u8868\u793a\u66f4\u51c6\u786e\u5730\u53cd\u6620\u76ee\u6807\u76f8\u4f3c\u6027\uff0c\u4ece\u800c\u63d0\u5347\u57fa\u4e8e\u68c0\u7d22\u7684\u9884\u6d4b\u903b\u8f91\u3002\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u5fae\u8c03\u540e\u7684TabPFNv2\u5728\u591a\u8fbe5\u4e07\u6837\u672c\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5177\u6709\u6e10\u53d8\u65f6\u95f4\u504f\u79fb\u548c\u4e30\u5bcc\u7279\u5f81\u96c6\u7684\u6570\u636e\u96c6\u4e0a\u7a33\u5b9a\u6027\u8f83\u5dee\u3002", "motivation": "\u5c3d\u7ba1TabPFNv2\u5728\u5c0f\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u4f46\u5176\u6700\u4f18\u5fae\u8c03\u65b9\u6cd5\u53ca\u5176\u5bf9\u6a21\u578b\u5185\u90e8\u673a\u5236\u7684\u5f71\u54cd\u5c1a\u672a\u88ab\u5145\u5206\u7814\u7a76\u3002\u7531\u4e8e\u5148\u524d\u5de5\u4f5c\u7684\u53d1\u73b0\u4e0d\u4e00\u81f4\u4ee5\u53caTabPFNv2\u7684\u72ec\u7279\u67b6\u6784\uff0c\u9700\u8981\u8fdb\u884c\u65b0\u7684\u63a2\u7d22\u3002", "method": "\u7cfb\u7edf\u8bc4\u4f30\u4e86\u591a\u79cd\u5fae\u8c03\u7b56\u7565\u5728\u591a\u6837\u6570\u636e\u96c6\u4e0a\u7684\u6548\u679c\uff0c\u786e\u5b9a\u5168\u91cf\u5fae\u8c03\u4e3aTabPFNv2\u7684\u6700\u4f73\u9009\u62e9\u3002\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u5fae\u8c03\u5982\u4f55\u6539\u53d8TabPFNv2\u7684\u5185\u90e8\u673a\u5236\uff0c\u5c06\u5176\u4e0e\u68c0\u7d22\u589e\u5f3a\u6a21\u578b\u7c7b\u6bd4\u3002\u63ed\u793a\u4e86\u5fae\u8c03\u540e\u6d4b\u8bd5\u5bf9\u8c61\u4e0e\u4e0a\u4e0b\u6587\u8bad\u7ec3\u5bf9\u8c61\u8868\u793a\u4e4b\u95f4\u7684\u70b9\u79ef\u66f4\u80fd\u51c6\u786e\u53cd\u6620\u76ee\u6807\u76f8\u4f3c\u6027\u3002", "result": "\u5fae\u8c03\u540e\u7684TabPFNv2\u5728\u9ad8\u8fbe5\u4e07\u6837\u672c\u7684\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u51fa\u6027\u80fd\u63d0\u5347\uff0c\u5728\u5b66\u672f\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff1b\u4f46\u5728\u5177\u6709\u6e10\u53d8\u65f6\u95f4\u504f\u79fb\u548c\u4e30\u5bcc\u7279\u5f81\u96c6\u7684\u6570\u636e\u96c6\u4e0a\u7a33\u5b9a\u6027\u4e0d\u8db3\uff0c\u5148\u524d\u65b9\u6cd5\u4ecd\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "\u5168\u91cf\u5fae\u8c03\u662fTabPFNv2\u6700\u5b9e\u7528\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\u5e76\u6539\u5584\u5176\u5185\u90e8\u673a\u5236\uff0c\u4f46\u5728\u7279\u5b9a\u7c7b\u578b\u6570\u636e\u96c6\u4e0a\u7684\u7a33\u5b9a\u6027\u4ecd\u6709\u5f85\u6539\u8fdb\u3002"}}
{"id": "2506.08512", "pdf": "https://arxiv.org/pdf/2506.08512", "abs": "https://arxiv.org/abs/2506.08512", "authors": ["Zhiyi Zhu", "Xiaoyu Wu", "Zihao Liu", "Linlin Yang"], "title": "MLVTG: Mamba-Based Feature Alignment and LLM-Driven Purification for Multi-Modal Video Temporal Grounding", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Video Temporal Grounding (VTG), which aims to localize video clips\ncorresponding to natural language queries, is a fundamental yet challenging\ntask in video understanding. Existing Transformer-based methods often suffer\nfrom redundant attention and suboptimal multi-modal alignment. To address these\nlimitations, we propose MLVTG, a novel framework that integrates two key\nmodules: MambaAligner and LLMRefiner. MambaAligner uses stacked Vision Mamba\nblocks as a backbone instead of Transformers to model temporal dependencies and\nextract robust video representations for multi-modal alignment. LLMRefiner\nleverages the specific frozen layer of a pre-trained Large Language Model (LLM)\nto implicitly transfer semantic priors, enhancing multi-modal alignment without\nfine-tuning. This dual alignment strategy, temporal modeling via structured\nstate-space dynamics and semantic purification via textual priors, enables more\nprecise localization. Extensive experiments on QVHighlights, Charades-STA, and\nTVSum demonstrate that MLVTG achieves state-of-the-art performance and\nsignificantly outperforms existing baselines.", "AI": {"tldr": "A new framework MLVTG with MambaAligner and LLMRefiner is proposed for Video Temporal Grounding, achieving SOTA performance.", "motivation": "Existing Transformer-based methods for Video Temporal Grounding suffer from redundant attention and suboptimal multi-modal alignment.", "method": "MLVTG integrates MambaAligner using Vision Mamba blocks for temporal dependencies and robust video representations, and LLMRefiner leveraging a frozen layer of pre-trained LLM for semantic priors to enhance multi-modal alignment without fine-tuning.", "result": "MLVTG achieves state-of-the-art performance on QVHighlights, Charades-STA, and TVSum datasets.", "conclusion": "MLVTG significantly outperforms existing baselines in Video Temporal Grounding."}}
{"id": "2506.08989", "pdf": "https://arxiv.org/pdf/2506.08989", "abs": "https://arxiv.org/abs/2506.08989", "authors": ["Xiao Liang", "Zhong-Zhi Li", "Yeyun Gong", "Yang Wang", "Hengyuan Zhang", "Yelong Shen", "Ying Nian Wu", "Weizhu Chen"], "title": "SwS: Self-aware Weakness-driven Problem Synthesis in Reinforcement Learning for LLM Reasoning", "categories": ["cs.LG", "cs.CL"], "comment": "Reinforcement Learning; Large Language Models; LLM Reasoning", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has proven effective\nfor training large language models (LLMs) on complex reasoning tasks, such as\nmathematical problem solving. A prerequisite for the scalability of RLVR is a\nhigh-quality problem set with precise and verifiable answers. However, the\nscarcity of well-crafted human-labeled math problems and limited-verification\nanswers in existing distillation-oriented synthetic datasets limit their\neffectiveness in RL. Additionally, most problem synthesis strategies\nindiscriminately expand the problem set without considering the model's\ncapabilities, leading to low efficiency in generating useful questions. To\nmitigate this issue, we introduce a Self-aware Weakness-driven problem\nSynthesis framework (SwS) that systematically identifies model deficiencies and\nleverages them for problem augmentation. Specifically, we define weaknesses as\nquestions that the model consistently fails to learn through its iterative\nsampling during RL training. We then extract the core concepts from these\nfailure cases and synthesize new problems to strengthen the model's weak areas\nin subsequent augmented training, enabling it to focus on and gradually\novercome its weaknesses. Without relying on external knowledge distillation,\nour framework enables robust generalization byempowering the model to\nself-identify and address its weaknesses in RL, yielding average performance\ngains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning\nbenchmarks.", "AI": {"tldr": "RLVR is effective for training LLMs on complex reasoning tasks like mathematical problem solving. The scalability of RLVR requires high-quality problem sets with precise and verifiable answers. To address the scarcity of well-crafted human-labeled math problems, a Self-aware Weakness-driven problem Synthesis framework (SwS) is introduced to systematically identify model deficiencies and leverage them for problem augmentation. This enables robust generalization by empowering the model to self-identify and address its weaknesses in RL, yielding average performance gains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning benchmarks.", "motivation": "The motivation of this paper is to improve the scalability of RLVR for training LLMs on complex reasoning tasks by addressing the limitations of existing datasets and problem synthesis strategies. Existing distillation-oriented synthetic datasets have limited verification answers and indiscriminately expand the problem set without considering the model's capabilities, leading to low efficiency in generating useful questions.", "method": "The method involves defining weaknesses as questions that the model consistently fails to learn through its iterative sampling during RL training. Core concepts are extracted from these failure cases to synthesize new problems that strengthen the model's weak areas in subsequent augmented training. This allows the model to focus on and gradually overcome its weaknesses without relying on external knowledge distillation.", "result": "The SwS framework yields average performance gains of 10.0% and 7.7% on 7B and 32B models across eight mainstream reasoning benchmarks.", "conclusion": "The Self-aware Weakness-driven problem Synthesis framework enables robust generalization by empowering the model to self-identify and address its weaknesses in RL, thus improving the effectiveness and scalability of RLVR for training LLMs on complex reasoning tasks."}}
{"id": "2506.08524", "pdf": "https://arxiv.org/pdf/2506.08524", "abs": "https://arxiv.org/abs/2506.08524", "authors": ["Weiguo Wang", "Andy Nie", "Wenrui Zhou", "Yi Kai", "Chengchen Hu"], "title": "Teaching Physical Awareness to LLMs through Sounds", "categories": ["cs.SD", "cs.AI", "cs.MM", "cs.RO", "eess.AS"], "comment": "ICML 2025", "summary": "Large Language Models (LLMs) have shown remarkable capabilities in text and\nmultimodal processing, yet they fundamentally lack physical\nawareness--understanding of real-world physical phenomena. In this work, we\npresent ACORN, a framework that teaches LLMs physical awareness through sound,\nfocusing on fundamental physical phenomena like the Doppler effect, multipath\neffect, and spatial relationships. To overcome data scarcity, ACORN introduce a\nphysics-based simulator combining real-world sound sources with controlled\nphysical channels to generate diverse training data. Using this simulator, we\nbuild AQA-PHY, a comprehensive Audio Question-Answer dataset, and propose an\naudio encoder that processes both magnitude and phase information. By\nconnecting our audio encoder to state-of-the-art LLMs, we demonstrate\nreasonable results in both simulated and real-world tasks, such as\nline-of-sight detection, Doppler effect estimation, and Direction-of-Arrival\nestimation, paving the way for enabling LLMs to understand physical world.", "AI": {"tldr": "ACORN is a framework that teaches LLMs physical awareness through sound by introducing a physics-based simulator, building an Audio Question-Answer dataset (AQA-PHY), and proposing an audio encoder. This enables LLMs to perform tasks like line-of-sight detection and Doppler effect estimation.", "motivation": "To address the limitation of LLMs lacking physical awareness, especially in understanding real-world physical phenomena such as the Doppler effect and spatial relationships.", "method": "Developed ACORN framework which includes a physics-based simulator for generating diverse training data, constructed AQA-PHY dataset, and proposed an audio encoder processing magnitude and phase information. Connected this audio encoder with state-of-the-art LLMs.", "result": "Demonstrated reasonable results in simulated and real-world tasks including line-of-sight detection, Doppler effect estimation, and Direction-of-Arrival estimation.", "conclusion": "The ACORN framework paves the way for enabling LLMs to understand the physical world through sound."}}
{"id": "2506.09007", "pdf": "https://arxiv.org/pdf/2506.09007", "abs": "https://arxiv.org/abs/2506.09007", "authors": ["Sophia Tang", "Yinuo Zhang", "Alexander Tong", "Pranam Chatterjee"], "title": "Branched Schr\u00f6dinger Bridge Matching", "categories": ["cs.LG"], "comment": null, "summary": "Predicting the intermediate trajectories between an initial and target\ndistribution is a central problem in generative modeling. Existing approaches,\nsuch as flow matching and Schr\\\"odinger Bridge Matching, effectively learn\nmappings between two distributions by modeling a single stochastic path.\nHowever, these methods are inherently limited to unimodal transitions and\ncannot capture branched or divergent evolution from a common origin to multiple\ndistinct outcomes. To address this, we introduce Branched Schr\\\"odinger Bridge\nMatching (BranchSBM), a novel framework that learns branched Schr\\\"odinger\nbridges. BranchSBM parameterizes multiple time-dependent velocity fields and\ngrowth processes, enabling the representation of population-level divergence\ninto multiple terminal distributions. We show that BranchSBM is not only more\nexpressive but also essential for tasks involving multi-path surface\nnavigation, modeling cell fate bifurcations from homogeneous progenitor states,\nand simulating diverging cellular responses to perturbations.", "AI": {"tldr": "The paper introduces Branched Schr\u00f6dinger Bridge Matching (BranchSBM), a new framework that overcomes limitations of existing methods by modeling branched transitions, making it more expressive for tasks such as multi-path surface navigation and modeling cell fate bifurcations.", "motivation": "Current methods for learning mappings between two distributions, such as flow matching and Schr\u00f6dinger Bridge Matching, are limited to unimodal transitions and cannot capture branched or divergent evolution from a common origin to multiple distinct outcomes.", "method": "Branched Schr\u00f6dinger Bridge Matching (BranchSBM) parameterizes multiple time-dependent velocity fields and growth processes, enabling the representation of population-level divergence into multiple terminal distributions.", "result": "BranchSBM is shown to be more expressive and essential for tasks involving multi-path surface navigation, modeling cell fate bifurcations from homogeneous progenitor states, and simulating diverging cellular responses to perturbations.", "conclusion": "BranchSBM provides a novel framework that learns branched Schr\u00f6dinger bridges, overcoming the limitations of existing methods in capturing complex transitions."}}
{"id": "2506.09010", "pdf": "https://arxiv.org/pdf/2506.09010", "abs": "https://arxiv.org/abs/2506.09010", "authors": ["Sebastian Schmidt", "Prasanga Dhungel", "Christoffer L\u00f6ffler", "Bj\u00f6rn Nieth", "Stephan G\u00fcnnemann", "Leo Schwinn"], "title": "Effective Data Pruning through Score Extrapolation", "categories": ["cs.LG"], "comment": null, "summary": "Training advanced machine learning models demands massive datasets, resulting\nin prohibitive computational costs. To address this challenge, data pruning\ntechniques identify and remove redundant training samples while preserving\nmodel performance. Yet, existing pruning techniques predominantly require a\nfull initial training pass to identify removable samples, negating any\nefficiency benefits for single training runs. To overcome this limitation, we\nintroduce a novel importance score extrapolation framework that requires\ntraining on only a small subset of data. We present two initial approaches in\nthis framework - k-nearest neighbors and graph neural networks - to accurately\npredict sample importance for the entire dataset using patterns learned from\nthis minimal subset. We demonstrate the effectiveness of our approach for 2\nstate-of-the-art pruning methods (Dynamic Uncertainty and TDDS), 4 different\ndatasets (CIFAR-10, CIFAR-100, Places-365, and ImageNet), and 3 training\nparadigms (supervised, unsupervised, and adversarial). Our results indicate\nthat score extrapolation is a promising direction to scale expensive score\ncalculation methods, such as pruning, data attribution, or other tasks.", "AI": {"tldr": "A new importance score extrapolation framework is introduced which needs training on only a small subset of data. Two approaches, k-nearest neighbors and graph neural networks, are presented to predict sample importance for the entire dataset. The effectiveness is demonstrated for several pruning methods, datasets, and training paradigms.", "motivation": "Training advanced machine learning models requires massive datasets causing prohibitive computational costs. Data pruning techniques help but require a full initial training pass to identify removable samples, negating efficiency benefits for single training runs.", "method": "Introduced a novel importance score extrapolation framework requiring training on only a small subset of data. Presented two approaches within this framework - k-nearest neighbors and graph neural networks - to predict sample importance for the entire dataset using patterns learned from the minimal subset.", "result": "Demonstrated the effectiveness of the approach for 2 state-of-the-art pruning methods, 4 different datasets, and 3 training paradigms. Results indicate that score extrapolation is promising to scale expensive score calculation methods.", "conclusion": "Score extrapolation is a promising direction to scale expensive score calculation methods like pruning, data attribution, or other tasks."}}
{"id": "2506.08534", "pdf": "https://arxiv.org/pdf/2506.08534", "abs": "https://arxiv.org/abs/2506.08534", "authors": ["Donglian Li", "Hui Guo", "Minglang Chen", "Huizhen Chen", "Jialing Chen", "Bocheng Liang", "Pengchen Liang", "Ying Tan"], "title": "DCD: A Semantic Segmentation Model for Fetal Ultrasound Four-Chamber View", "categories": ["eess.IV", "cs.AI", "cs.CV"], "comment": null, "summary": "Accurate segmentation of anatomical structures in the apical four-chamber\n(A4C) view of fetal echocardiography is essential for early diagnosis and\nprenatal evaluation of congenital heart disease (CHD). However, precise\nsegmentation remains challenging due to ultrasound artifacts, speckle noise,\nanatomical variability, and boundary ambiguity across different gestational\nstages. To reduce the workload of sonographers and enhance segmentation\naccuracy, we propose DCD, an advanced deep learning-based model for automatic\nsegmentation of key anatomical structures in the fetal A4C view. Our model\nincorporates a Dense Atrous Spatial Pyramid Pooling (Dense ASPP) module,\nenabling superior multi-scale feature extraction, and a Convolutional Block\nAttention Module (CBAM) to enhance adaptive feature representation. By\neffectively capturing both local and global contextual information, DCD\nachieves precise and robust segmentation, contributing to improved prenatal\ncardiac assessment.", "AI": {"tldr": "An advanced deep learning model, DCD, is proposed for accurate segmentation of anatomical structures in fetal A4C view to help diagnose CHD.", "motivation": "Accurate segmentation of anatomical structures in the apical four-chamber (A4C) view of fetal echocardiography is crucial for early diagnosis and prenatal evaluation of congenital heart disease (CHD). But it's difficult due to ultrasound artifacts, speckle noise, anatomical variability, and boundary ambiguity.", "method": "The proposed model DCD incorporates Dense Atrous Spatial Pyramid Pooling (Dense ASPP) module for multi-scale feature extraction and Convolutional Block Attention Module (CBAM) for adaptive feature representation. It captures both local and global contextual information effectively.", "result": "DCD achieves precise and robust segmentation which can reduce sonographers' workload and improve segmentation accuracy.", "conclusion": "DCD contributes to improved prenatal cardiac assessment by providing an automatic way for precise segmentation of key anatomical structures in the fetal A4C view."}}
{"id": "2506.09016", "pdf": "https://arxiv.org/pdf/2506.09016", "abs": "https://arxiv.org/abs/2506.09016", "authors": ["Ruiqi Zhang", "Daman Arora", "Song Mei", "Andrea Zanette"], "title": "SPEED-RL: Faster Training of Reasoning Models via Online Curriculum Learning", "categories": ["cs.LG"], "comment": "pre-print", "summary": "Training large language models with reinforcement learning (RL) against\nverifiable rewards significantly enhances their reasoning abilities, yet\nremains computationally expensive due to inefficient uniform prompt sampling.\nWe introduce Selective Prompting with Efficient Estimation of Difficulty\n(SPEED), an adaptive online RL curriculum that selectively chooses training\nexamples of intermediate difficulty to maximize learning efficiency.\nTheoretically, we establish that intermediate-difficulty prompts improve the\ngradient estimator's signal-to-noise ratio, accelerating convergence.\nEmpirically, our efficient implementation leads to 2x to 6x faster training\nwithout degrading accuracy, requires no manual tuning, and integrates\nseamlessly into standard RL algorithms.", "AI": {"tldr": "\u901a\u8fc7\u5f15\u5165SPEED\u65b9\u6cd5\uff0c\u9009\u62e9\u6027\u5730\u4f7f\u7528\u4e2d\u7b49\u96be\u5ea6\u7684\u8bad\u7ec3\u6837\u672c\u8fdb\u884c\u5f3a\u5316\u5b66\u4e60\uff0c\u53ef\u4ee5\u63d0\u9ad8\u5927\u8bed\u8a00\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u4e14\u52a0\u901f\u8bad\u7ec3\u8fc7\u7a0b2\u52306\u500d\u3002", "motivation": "\u5c3d\u7ba1\u7528\u5f3a\u5316\u5b66\u4e60\u8bad\u7ec3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u80fd\u663e\u8457\u63d0\u9ad8\u5176\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u56e0\u975e\u9ad8\u6548\u7684\u5747\u5300\u63d0\u793a\u91c7\u6837\uff0c\u8ba1\u7b97\u6210\u672c\u4ecd\u7136\u5f88\u9ad8\u3002", "method": "\u63d0\u51fa\u4e86SPEED\uff08Selective Prompting with Efficient Estimation of Difficulty\uff09\uff0c\u4e00\u79cd\u81ea\u9002\u5e94\u5728\u7ebf\u5f3a\u5316\u5b66\u4e60\u8bfe\u7a0b\uff0c\u5b83\u9009\u62e9\u6027\u5730\u6311\u9009\u4e2d\u7b49\u96be\u5ea6\u7684\u8bad\u7ec3\u6837\u672c\u6765\u6700\u5927\u5316\u5b66\u4e60\u6548\u7387\u3002\u7406\u8bba\u548c\u5b9e\u8bc1\u4e0a\u8bc1\u660e\u4e86\u8fd9\u79cd\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u4f7f\u8bad\u7ec3\u901f\u5ea6\u52a0\u5feb\u4e862\u81f36\u500d\uff0c\u540c\u65f6\u4e0d\u964d\u4f4e\u51c6\u786e\u6027\uff0c\u65e0\u9700\u624b\u52a8\u8c03\u6574\u53c2\u6570\uff0c\u5e76\u4e14\u53ef\u4ee5\u65e0\u7f1d\u96c6\u6210\u5230\u6807\u51c6\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e2d\u3002", "conclusion": "SPEED\u65b9\u6cd5\u901a\u8fc7\u9009\u62e9\u4e2d\u7b49\u96be\u5ea6\u7684\u63d0\u793a\u63d0\u9ad8\u4e86\u68af\u5ea6\u4f30\u8ba1\u5668\u7684\u4fe1\u566a\u6bd4\uff0c\u4ece\u800c\u52a0\u901f\u4e86\u6536\u655b\u8fc7\u7a0b\uff0c\u63d0\u5347\u4e86\u8bad\u7ec3\u6548\u7387\u3002"}}
{"id": "2506.08541", "pdf": "https://arxiv.org/pdf/2506.08541", "abs": "https://arxiv.org/abs/2506.08541", "authors": ["Qi Yan", "Brian Zhang", "Yutong Zhang", "Daniel Yang", "Joshua White", "Di Chen", "Jiachao Liu", "Langechuan Liu", "Binnan Zhuang", "Shaoshuai Shi", "Renjie Liao"], "title": "TrajFlow: Multi-modal Motion Prediction via Flow Matching", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Efficient and accurate motion prediction is crucial for ensuring safety and\ninformed decision-making in autonomous driving, particularly under dynamic\nreal-world conditions that necessitate multi-modal forecasts. We introduce\nTrajFlow, a novel flow matching-based motion prediction framework that\naddresses the scalability and efficiency challenges of existing generative\ntrajectory prediction methods. Unlike conventional generative approaches that\nemploy i.i.d. sampling and require multiple inference passes to capture diverse\noutcomes, TrajFlow predicts multiple plausible future trajectories in a single\npass, significantly reducing computational overhead while maintaining coherence\nacross predictions. Moreover, we propose a ranking loss based on the\nPlackett-Luce distribution to improve uncertainty estimation of predicted\ntrajectories. Additionally, we design a self-conditioning training technique\nthat reuses the model's own predictions to construct noisy inputs during a\nsecond forward pass, thereby improving generalization and accelerating\ninference. Extensive experiments on the large-scale Waymo Open Motion Dataset\n(WOMD) demonstrate that TrajFlow achieves state-of-the-art performance across\nvarious key metrics, underscoring its effectiveness for safety-critical\nautonomous driving applications. The code and other details are available on\nthe project website https://traj-flow.github.io/.", "AI": {"tldr": "TrajFlow is a new motion prediction framework for autonomous driving that predicts multiple future trajectories efficiently and accurately.", "motivation": "Efficient and accurate motion prediction is crucial for ensuring safety and informed decision-making in autonomous driving, particularly under dynamic real-world conditions that necessitate multi-modal forecasts.", "method": "TrajFlow uses flow matching-based approach to predict multiple plausible future trajectories in a single pass. It also proposes a ranking loss based on the Plackett-Luce distribution for uncertainty estimation and a self-conditioning training technique for improving generalization and accelerating inference.", "result": "Extensive experiments on the Waymo Open Motion Dataset show TrajFlow achieves state-of-the-art performance across various key metrics.", "conclusion": "TrajFlow addresses scalability and efficiency challenges of existing generative trajectory prediction methods and is effective for safety-critical autonomous driving applications."}}
{"id": "2506.09018", "pdf": "https://arxiv.org/pdf/2506.09018", "abs": "https://arxiv.org/abs/2506.09018", "authors": ["Marton Havasi", "Brian Karrer", "Itai Gat", "Ricky T. Q. Chen"], "title": "Edit Flows: Flow Matching with Edit Operations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Autoregressive generative models naturally generate variable-length\nsequences, while non-autoregressive models struggle, often imposing rigid,\ntoken-wise structures. We propose Edit Flows, a non-autoregressive model that\novercomes these limitations by defining a discrete flow over sequences through\nedit operations-insertions, deletions, and substitutions. By modeling these\noperations within a Continuous-time Markov Chain over the sequence space, Edit\nFlows enable flexible, position-relative generation that aligns more closely\nwith the structure of sequence data. Our training method leverages an expanded\nstate space with auxiliary variables, making the learning process efficient and\ntractable. Empirical results show that Edit Flows outperforms both\nautoregressive and mask models on image captioning and significantly\noutperforms the mask construction in text and code generation.", "AI": {"tldr": "Edit Flows\u662f\u4e00\u79cd\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u8f91\u64cd\u4f5c\uff08\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\uff09\u5b9a\u4e49\u5e8f\u5217\u4e0a\u7684\u79bb\u6563\u6d41\uff0c\u5176\u5728\u56fe\u50cf\u63cf\u8ff0\u3001\u6587\u672c\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u975e\u81ea\u56de\u5f52\u6a21\u578b\u5728\u751f\u6210\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\u65f6\u9762\u4e34\u56f0\u96be\uff0c\u901a\u5e38\u4f1a\u65bd\u52a0\u50f5\u5316\u7684\u9010\u6807\u8bb0\u7ed3\u6784\u3002\u4e3a\u4e86\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u975e\u81ea\u56de\u5f52\u6a21\u578b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEdit Flows\u7684\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u901a\u8fc7\u7f16\u8f91\u64cd\u4f5c\uff08\u63d2\u5165\u3001\u5220\u9664\u548c\u66ff\u6362\uff09\u5b9a\u4e49\u5e8f\u5217\u4e0a\u7684\u79bb\u6563\u6d41\uff0c\u5e76\u5c06\u5176\u5efa\u6a21\u4e3a\u5e8f\u5217\u7a7a\u95f4\u4e0a\u7684\u8fde\u7eed\u65f6\u95f4\u9a6c\u5c14\u53ef\u592b\u94fe\uff0c\u4ece\u800c\u5b9e\u73b0\u7075\u6d3b\u7684\u4f4d\u7f6e\u76f8\u5173\u751f\u6210\u3002\u8bad\u7ec3\u65b9\u6cd5\u5229\u7528\u6269\u5c55\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u8f85\u52a9\u53d8\u91cf\uff0c\u4f7f\u5b66\u4e60\u8fc7\u7a0b\u9ad8\u6548\u4e14\u53ef\u884c\u3002", "result": "\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cEdit Flows\u5728\u56fe\u50cf\u63cf\u8ff0\u4efb\u52a1\u4e2d\u4f18\u4e8e\u81ea\u56de\u5f52\u548c\u63a9\u7801\u6a21\u578b\uff0c\u5728\u6587\u672c\u548c\u4ee3\u7801\u751f\u6210\u4efb\u52a1\u4e2d\u663e\u8457\u4f18\u4e8e\u63a9\u7801\u6784\u9020\u3002", "conclusion": "Edit Flows\u4f5c\u4e3a\u4e00\u79cd\u975e\u81ea\u56de\u5f52\u6a21\u578b\uff0c\u80fd\u591f\u6709\u6548\u514b\u670d\u4f20\u7edf\u975e\u81ea\u56de\u5f52\u6a21\u578b\u7684\u5c40\u9650\u6027\uff0c\u751f\u6210\u66f4\u7b26\u5408\u5e8f\u5217\u6570\u636e\u7ed3\u6784\u7684\u53ef\u53d8\u957f\u5ea6\u5e8f\u5217\uff0c\u5e76\u5728\u591a\u4e2a\u751f\u6210\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2506.08552", "pdf": "https://arxiv.org/pdf/2506.08552", "abs": "https://arxiv.org/abs/2506.08552", "authors": ["Xinyuan Wang", "Dongjie Wang", "Wangyang Ying", "Haoyue Bai", "Nanxu Gong", "Sixun Dong", "Kunpeng Liu", "Yanjie Fu"], "title": "Efficient Post-Training Refinement of Latent Reasoning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning is a key component of language understanding in Large Language\nModels. While Chain-of-Thought prompting enhances performance via explicit\nintermediate steps, it suffers from sufficient token overhead and a fixed\nreasoning trajectory, preventing step-wise refinement. Recent advances in\nlatent reasoning address these limitations by refining internal reasoning\nprocesses directly in the model's latent space, without producing explicit\noutputs. However, a key challenge remains: how to effectively update reasoning\nembeddings during post-training to guide the model toward more accurate\nsolutions. To overcome this challenge, we propose a lightweight post-training\nframework that refines latent reasoning trajectories using two novel\nstrategies: 1) Contrastive reasoning feedback, which compares reasoning\nembeddings against strong and weak baselines to infer effective update\ndirections via embedding enhancement; 2) Residual embedding refinement, which\nstabilizes updates by progressively integrating current and historical\ngradients, enabling fast yet controlled convergence. Extensive experiments and\ncase studies are conducted on five reasoning benchmarks to demonstrate the\neffectiveness of the proposed framework. Notably, a 5\\% accuracy gain on MathQA\nwithout additional training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u540e\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6bd4\u63a8\u7406\u53cd\u9988\u548c\u6b8b\u5dee\u5d4c\u5165\u7ec6\u5316\u7b56\u7565\u6539\u8fdb\u6f5c\u5728\u63a8\u7406\u8f68\u8ff9\uff0c\u63d0\u5347\u6a21\u578b\u51c6\u786e\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u5728MathQA\u4e0a\u63d0\u5347\u4e865%\u7684\u51c6\u786e\u7387\uff0c\u4e14\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u3002", "motivation": "\u5f53\u524d\u94fe\u5f0f\u601d\u7ef4\u63d0\u793a\u65b9\u6cd5\u5b58\u5728\u4ee4\u724c\u5f00\u9500\u5927\u548c\u56fa\u5b9a\u63a8\u7406\u8f68\u8ff9\u7684\u95ee\u9898\uff0c\u800c\u6f5c\u5728\u63a8\u7406\u867d\u7136\u6539\u8fdb\u4e86\u8fd9\u4e9b\u9650\u5236\uff0c\u4f46\u5728\u540e\u8bad\u7ec3\u671f\u95f4\u6709\u6548\u66f4\u65b0\u63a8\u7406\u5d4c\u5165\u4ecd\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u91c7\u7528\u4e86\u4e24\u79cd\u65b0\u7b56\u7565\uff1a1\uff09\u5bf9\u6bd4\u63a8\u7406\u53cd\u9988\uff0c\u901a\u8fc7\u4e0e\u5f3a\u5f31\u57fa\u7ebf\u6bd4\u8f83\u63a8\u7406\u5d4c\u5165\u6765\u63a8\u65ad\u6709\u6548\u7684\u66f4\u65b0\u65b9\u5411\uff1b2\uff09\u6b8b\u5dee\u5d4c\u5165\u7ec6\u5316\uff0c\u901a\u8fc7\u9010\u6b65\u6574\u5408\u5f53\u524d\u548c\u5386\u53f2\u68af\u5ea6\u6765\u7a33\u5b9a\u66f4\u65b0\uff0c\u5b9e\u73b0\u5feb\u901f\u4e14\u53d7\u63a7\u7684\u6536\u655b\u3002", "result": "\u5728\u4e94\u4e2a\u63a8\u7406\u57fa\u51c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u548c\u6848\u4f8b\u7814\u7a76\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728MathQA\u4e0a\u5b9e\u73b0\u4e865%\u7684\u51c6\u786e\u7387\u63d0\u5347\uff0c\u4e14\u6ca1\u6709\u589e\u52a0\u989d\u5916\u7684\u8bad\u7ec3\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u540e\u8bad\u7ec3\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u4f18\u5316\u6f5c\u5728\u63a8\u7406\u8f68\u8ff9\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3\u6570\u636e\u6216\u8ba1\u7b97\u8d44\u6e90\u3002"}}
{"id": "2506.09026", "pdf": "https://arxiv.org/pdf/2506.09026", "abs": "https://arxiv.org/abs/2506.09026", "authors": ["Amrith Setlur", "Matthew Y. R. Yang", "Charlie Snell", "Jeremy Greer", "Ian Wu", "Virginia Smith", "Max Simchowitz", "Aviral Kumar"], "title": "e3: Learning to Explore Enables Extrapolation of Test-Time Compute for LLMs", "categories": ["cs.LG", "cs.CL"], "comment": null, "summary": "Test-time scaling offers a promising path to improve LLM reasoning by\nutilizing more compute at inference time; however, the true promise of this\nparadigm lies in extrapolation (i.e., improvement in performance on hard\nproblems as LLMs keep \"thinking\" for longer, beyond the maximum token budget\nthey were trained on). Surprisingly, we find that most existing reasoning\nmodels do not extrapolate well. We show that one way to enable extrapolation is\nby training the LLM to perform in-context exploration: training the LLM to\neffectively spend its test time budget by chaining operations (such as\ngeneration, verification, refinement, etc.), or testing multiple hypotheses\nbefore it commits to an answer. To enable in-context exploration, we identify\nthree key ingredients as part of our recipe e3: (1) chaining skills that the\nbase LLM has asymmetric competence in, e.g., chaining verification (easy) with\ngeneration (hard), as a way to implement in-context search; (2) leveraging\n\"negative\" gradients from incorrect traces to amplify exploration during RL,\nresulting in longer search traces that chains additional asymmetries; and (3)\ncoupling task difficulty with training token budget during training via a\nspecifically-designed curriculum to structure in-context exploration. Our\nrecipe e3 produces the best known 1.7B model according to AIME'25 and HMMT'25\nscores, and extrapolates to 2x the training token budget. Our e3-1.7B model not\nonly attains high pass@1 scores, but also improves pass@k over the base model.", "AI": {"tldr": "\u901a\u8fc7\u8bad\u7ec3LLM\u8fdb\u884c\u60c5\u5883\u63a2\u7d22\uff0c\u63d0\u51fa\u914d\u65b9e3\u4ee5\u5b9e\u73b0\u66f4\u597d\u7684\u63a8\u7406\u6a21\u578b\u5916\u63a8\u80fd\u529b\uff0c\u5e76\u4ea7\u751f\u4e86\u6700\u4f73\u76841.7B\u6a21\u578b\u3002", "motivation": "\u5927\u591a\u6570\u73b0\u6709\u7684\u63a8\u7406\u6a21\u578b\u5728\u5916\u63a8\u80fd\u529b\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u4f7fLLM\u80fd\u591f\u66f4\u6709\u6548\u5730\u5229\u7528\u6d4b\u8bd5\u65f6\u95f4\u9884\u7b97\u6765\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3LLM\u6267\u884c\u60c5\u5883\u63a2\u7d22\uff0c\u5305\u62ec\u94fe\u63a5\u64cd\u4f5c\u3001\u6d4b\u8bd5\u591a\u4e2a\u5047\u8bbe\u7b49\uff1b\u8bc6\u522b\u914d\u65b9e3\u7684\u4e09\u4e2a\u5173\u952e\u6210\u5206\uff1a\u94fe\u63a5\u4e0d\u5bf9\u79f0\u80fd\u529b\u6280\u80fd\u3001\u5229\u7528\u9519\u8bef\u8f68\u8ff9\u7684'\u8d1f\u68af\u5ea6'\u653e\u5927\u63a2\u7d22\u4ee5\u53ca\u7ed3\u5408\u4efb\u52a1\u96be\u5ea6\u4e0e\u8bad\u7ec3\u4ee4\u724c\u9884\u7b97\u8bbe\u8ba1\u7279\u5b9a\u8bfe\u7a0b\u3002", "result": "\u914d\u65b9e3\u751f\u6210\u4e86\u5df2\u77e5\u6700\u597d\u76841.7B\u6a21\u578b\uff0c\u5728AIME'25\u548cHMMT'25\u8bc4\u5206\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5e76\u80fd\u5916\u63a8\u5230\u4e24\u500d\u4e8e\u8bad\u7ec3\u4ee4\u724c\u9884\u7b97\u3002\u8be5\u6a21\u578b\u4e0d\u4ec5\u83b7\u5f97\u9ad8pass@1\u5206\u6570\uff0c\u8fd8\u63d0\u9ad8\u4e86pass@k\u5206\u6570\u3002", "conclusion": "\u901a\u8fc7\u60c5\u5883\u63a2\u7d22\u8bad\u7ec3LLM\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u5176\u63a8\u7406\u80fd\u529b\u53ca\u5916\u63a8\u6027\u80fd\uff0c\u914d\u65b9e3\u4e3a\u6784\u5efa\u9ad8\u6548\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2506.08563", "pdf": "https://arxiv.org/pdf/2506.08563", "abs": "https://arxiv.org/abs/2506.08563", "authors": ["Siyuan Yang", "Cheng Song", "Zhilu Lai", "Wenjia Wang"], "title": "KP-PINNs: Kernel Packet Accelerated Physics Informed Neural Networks", "categories": ["cs.CE", "cs.AI", "math-ph", "math.MP", "physics.comp-ph"], "comment": "Accepted to IJCAI 2025", "summary": "Differential equations are involved in modeling many engineering problems.\nMany efforts have been devoted to solving differential equations. Due to the\nflexibility of neural networks, Physics Informed Neural Networks (PINNs) have\nrecently been proposed to solve complex differential equations and have\ndemonstrated superior performance in many applications. While the L2 loss\nfunction is usually a default choice in PINNs, it has been shown that the\ncorresponding numerical solution is incorrect and unstable for some complex\nequations. In this work, we propose a new PINNs framework named Kernel Packet\naccelerated PINNs (KP-PINNs), which gives a new expression of the loss function\nusing the reproducing kernel Hilbert space (RKHS) norm and uses the Kernel\nPacket (KP) method to accelerate the computation. Theoretical results show that\nKP-PINNs can be stable across various differential equations. Numerical\nexperiments illustrate that KP-PINNs can solve differential equations\neffectively and efficiently. This framework provides a promising direction for\nimproving the stability and accuracy of PINNs-based solvers in scientific\ncomputing.", "AI": {"tldr": "An improved PINNs framework called KP-PINNs is proposed, which uses RKHS norm for loss function and KP method for acceleration. It shows stability and effectiveness in solving differential equations.", "motivation": "The L2 loss function used in traditional PINNs can lead to incorrect and unstable solutions for complex differential equations.", "method": "Propose KP-PINNs that redefine the loss function with RKHS norm and use Kernel Packet method to speed up computation.", "result": "Theoretical analysis proves stability across different differential equations, and numerical experiments confirm its efficiency and effectiveness.", "conclusion": "KP-PINNs provides a promising way to enhance stability and accuracy of PINNs-based solvers in scientific computing."}}
{"id": "2506.09034", "pdf": "https://arxiv.org/pdf/2506.09034", "abs": "https://arxiv.org/abs/2506.09034", "authors": ["Sizhe Dang", "Yangyang Guo", "Yanjun Zhao", "Haishan Ye", "Xiaodong Zheng", "Guang Dai", "Ivor Tsang"], "title": "FZOO: Fast Zeroth-Order Optimizer for Fine-Tuning Large Language Models towards Adam-Scale Speed", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Fine-tuning large language models (LLMs) often faces GPU memory bottlenecks:\nthe backward pass of first-order optimizers like Adam increases memory usage to\nmore than 10 times the inference level (e.g., 633 GB for OPT-30B). Zeroth-order\n(ZO) optimizers avoid this cost by estimating gradients only from forward\npasses, yet existing methods like MeZO usually require many more steps to\nconverge. Can this trade-off between speed and memory in ZO be fundamentally\nimproved? Normalized-SGD demonstrates strong empirical performance with greater\nmemory efficiency than Adam. In light of this, we introduce FZOO, a Fast\nZeroth-Order Optimizer toward Adam-Scale Speed. FZOO reduces the total forward\npasses needed for convergence by employing batched one-sided estimates that\nadapt step sizes based on the standard deviation of batch losses. It also\naccelerates per-batch computation through the use of Rademacher random vector\nperturbations coupled with CUDA's parallel processing. Extensive experiments on\ndiverse models, including RoBERTa-large, OPT (350M-66B), Phi-2, and Llama3,\nacross 11 tasks validate FZOO's effectiveness. On average, FZOO outperforms\nMeZO by 3 percent in accuracy while requiring 3 times fewer forward passes. For\nRoBERTa-large, FZOO achieves average improvements of 5.6 percent in accuracy\nand an 18 times reduction in forward passes compared to MeZO, achieving\nconvergence speeds comparable to Adam. We also provide theoretical analysis\nproving FZOO's formal equivalence to a normalized-SGD update rule and its\nconvergence guarantees. FZOO integrates smoothly into PEFT techniques, enabling\neven larger memory savings. Overall, our results make single-GPU, high-speed,\nfull-parameter fine-tuning practical and point toward future work on\nmemory-efficient pre-training.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5feb\u901f\u96f6\u9636\u4f18\u5316\u5668FZOO\uff0c\u901a\u8fc7\u51cf\u5c11\u524d\u5411\u4f20\u9012\u6b21\u6570\u548c\u52a0\u901f\u6bcf\u6279\u8ba1\u7b97\uff0c\u5b9e\u73b0\u4e86\u4e0eAdam\u76f8\u8fd1\u7684\u901f\u5ea6\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u5185\u5b58\u4f7f\u7528\u3002", "motivation": "\u5fae\u8c03\u5927\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u5e38\u9047\u5230GPU\u5185\u5b58\u74f6\u9888\u95ee\u9898\u3002\u4e00\u9636\u4f18\u5316\u5668\u5982Adam\u5728\u53cd\u5411\u4f20\u64ad\u65f6\u4f1a\u5927\u5e45\u589e\u52a0\u5185\u5b58\u4f7f\u7528\uff0c\u800c\u73b0\u6709\u7684\u96f6\u9636\u4f18\u5316\u65b9\u6cd5\u5982MeZO\u867d\u7136\u907f\u514d\u4e86\u8fd9\u4e00\u6210\u672c\uff0c\u4f46\u901a\u5e38\u9700\u8981\u66f4\u591a\u6b65\u9aa4\u624d\u80fd\u6536\u655b\u3002\u4e3a\u89e3\u51b3\u901f\u5ea6\u4e0e\u5185\u5b58\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u63d0\u51fa\u4e86FZOO\uff08\u5feb\u901f\u96f6\u9636\u4f18\u5316\u5668\uff09\u3002", "method": "FZOO\u91c7\u7528\u6279\u91cf\u5355\u4fa7\u4f30\u8ba1\u6765\u9002\u5e94\u57fa\u4e8e\u6279\u6b21\u635f\u5931\u6807\u51c6\u5dee\u7684\u6b65\u957f\uff0c\u5e76\u901a\u8fc7Rademacher\u968f\u673a\u5411\u91cf\u6270\u52a8\u4e0eCUDA\u7684\u5e76\u884c\u5904\u7406\u52a0\u901f\u6bcf\u6279\u6b21\u8ba1\u7b97\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u8bc1\u660eFZOO\u7684\u5f62\u5f0f\u7b49\u4ef7\u4e8e\u5f52\u4e00\u5316SGD\u66f4\u65b0\u89c4\u5219\u53ca\u5176\u6536\u655b\u6027\u4fdd\u8bc1\u3002FZOO\u53ef\u4ee5\u5e73\u6ed1\u5730\u96c6\u6210\u5230PEFT\u6280\u672f\u4e2d\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u5927\u7684\u5185\u5b58\u8282\u7701\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFZOO\u572811\u4e2a\u4efb\u52a1\u4e0a\u5e73\u5747\u6bd4MeZO\u9ad8\u51fa3%\u7684\u51c6\u786e\u7387\uff0c\u4e14\u6240\u9700\u7684\u524d\u5411\u4f20\u9012\u6b21\u6570\u51cf\u5c11\u4e863\u500d\u3002\u5bf9\u4e8eRoBERTa-large\u6a21\u578b\uff0cFZOO\u5728\u51c6\u786e\u7387\u4e0a\u5e73\u5747\u63d0\u9ad8\u4e865.6%\uff0c\u524d\u5411\u4f20\u9012\u6b21\u6570\u51cf\u5c11\u4e8618\u500d\uff0c\u6536\u655b\u901f\u5ea6\u4e0eAdam\u76f8\u5f53\u3002", "conclusion": "FZOO\u4f7f\u5f97\u5355GPU\u3001\u9ad8\u901f\u3001\u5168\u53c2\u6570\u5fae\u8c03\u6210\u4e3a\u53ef\u80fd\uff0c\u5e76\u4e3a\u672a\u6765\u7684\u9ad8\u6548\u9884\u8bad\u7ec3\u5de5\u4f5c\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2506.08569", "pdf": "https://arxiv.org/pdf/2506.08569", "abs": "https://arxiv.org/abs/2506.08569", "authors": ["Erwan Plantec", "Gautier Hamon", "Mayalen Etcheverry", "Bert Wang-Chak Chan", "Pierre-Yves Oudeyer", "Cl\u00e9ment Moulin-Frier"], "title": "Flow-Lenia: Emergent evolutionary dynamics in mass conservative continuous cellular automata", "categories": ["nlin.CG", "cs.AI"], "comment": "This manuscript has been accepted for publication in the Artificial\n  Life journal (https://direct.mit.edu/artl)", "summary": "Central to the artificial life endeavour is the creation of artificial\nsystems spontaneously generating properties found in the living world such as\nautopoiesis, self-replication, evolution and open-endedness. While numerous\nmodels and paradigms have been proposed, cellular automata (CA) have taken a\nvery important place in the field notably as they enable the study of\nphenomenons like self-reproduction and autopoiesis. Continuous CA like Lenia\nhave been showed to produce life-like patterns reminiscent, on an aesthetic and\nontological point of view, of biological organisms we call creatures. We\npropose in this paper Flow-Lenia, a mass conservative extension of Lenia. We\npresent experiments demonstrating its effectiveness in generating\nspatially-localized patters (SLPs) with complex behaviors and show that the\nupdate rule parameters can be optimized to generate complex creatures showing\nbehaviors of interest. Furthermore, we show that Flow-Lenia allows us to embed\nthe parameters of the model, defining the properties of the emerging patterns,\nwithin its own dynamics thus allowing for multispecies simulations. By using\nthe evolutionary activity framework as well as other metrics, we shed light on\nthe emergent evolutionary dynamics taking place in this system.", "AI": {"tldr": "The paper introduces Flow-Lenia, a mass conservative extension of Lenia (a continuous cellular automaton), which can generate complex life-like patterns and behaviors. Experiments show its effectiveness in creating spatially-localized patterns with interesting behaviors, and the model parameters can be embedded within its own dynamics for multispecies simulations. The evolutionary activity framework and other metrics reveal emergent evolutionary dynamics.", "motivation": "To create artificial systems capable of spontaneously generating properties found in living organisms such as autopoiesis, self-replication, evolution, and open-endedness, particularly focusing on extending Lenia to conserve mass and produce more complex life-like behaviors.", "method": "Flow-Lenia is proposed as a mass conservative extension of Lenia. It involves experiments demonstrating the generation of spatially-localized patterns with complex behaviors, optimization of update rule parameters, embedding model parameters within its dynamics for multispecies simulations, and using the evolutionary activity framework and other metrics to study emergent evolutionary dynamics.", "result": "Flow-Lenia effectively generates spatially-localized patterns with complex behaviors. The update rule parameters can be optimized to produce creatures showing behaviors of interest. The model allows embedding of parameters within its own dynamics for multispecies simulations and reveals emergent evolutionary dynamics through various metrics.", "conclusion": "Flow-Lenia represents an advancement in creating artificial systems with lifelike properties by conserving mass, producing complex patterns and behaviors, enabling multispecies simulations, and revealing emergent evolutionary dynamics."}}
{"id": "2506.09044", "pdf": "https://arxiv.org/pdf/2506.09044", "abs": "https://arxiv.org/abs/2506.09044", "authors": ["Javier Sanguino", "Thomas Kehrenberg", "Jose A. Lozano", "Novi Quadrianto"], "title": "The Decoupled Risk Landscape in Performative Prediction", "categories": ["cs.LG"], "comment": null, "summary": "Performative Prediction addresses scenarios where deploying a model induces a\ndistribution shift in the input data, such as individuals modifying their\nfeatures and reapplying for a bank loan after rejection. Literature has had a\ntheoretical perspective giving mathematical guarantees for convergence (either\nto the stable or optimal point). We believe that visualization of the loss\nlandscape can complement this theoretical advances with practical insights.\nTherefore, (1) we introduce a simple decoupled risk visualization method\ninspired in the two-step process that performative prediction is. Our approach\nvisualizes the risk landscape with respect to two parameter vectors: model\nparameters and data parameters. We use this method to propose new properties of\nthe interest points, to examine how existing algorithms traverse the risk\nlandscape and perform under more realistic conditions, including strategic\nclassification with non-linear models. (2) Building on this decoupled risk\nvisualization, we introduce a novel setting - extended Performative Prediction\n- which captures scenarios where the distribution reacts to a model different\nfrom the decision-making one, reflecting the reality that agents often lack\nfull access to the deployed model.", "AI": {"tldr": "The paper discusses performative prediction scenarios where deploying a model induces distribution shifts in input data. It introduces a decoupled risk visualization method and an extended performative prediction setting.", "motivation": "To address the issue of distribution shift caused by deploying models, and to provide practical insights into theoretical advances in performative prediction.", "method": "Introduce a decoupled risk visualization method for analyzing the risk landscape with respect to model parameters and data parameters. Propose an extended performative prediction setting capturing scenarios where data distribution reacts to a model different from the decision-making one.", "result": "The decoupled risk visualization method provides new properties of interest points and examines algorithm performance under realistic conditions. The extended performative prediction setting reflects real-world situations where agents lack full access to deployed models.", "conclusion": "Visualization of loss landscape can complement theoretical guarantees with practical insights in performative prediction. The proposed methods offer valuable tools for understanding and improving algorithms in dynamic environments."}}
{"id": "2506.08570", "pdf": "https://arxiv.org/pdf/2506.08570", "abs": "https://arxiv.org/abs/2506.08570", "authors": ["Or Tal", "Felix Kreuk", "Yossi Adi"], "title": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "comment": null, "summary": "Recent progress in text-to-music generation has enabled models to synthesize\nhigh-quality musical segments, full compositions, and even respond to\nfine-grained control signals, e.g. chord progressions. State-of-the-art (SOTA)\nsystems differ significantly across many dimensions, such as training datasets,\nmodeling paradigms, and architectural choices. This diversity complicates\nefforts to evaluate models fairly and pinpoint which design choices most\ninfluence performance. While factors like data and architecture are important,\nin this study we focus exclusively on the modeling paradigm. We conduct a\nsystematic empirical analysis to isolate its effects, offering insights into\nassociated trade-offs and emergent behaviors that can guide future\ntext-to-music generation systems. Specifically, we compare the two arguably\nmost common modeling paradigms: Auto-Regressive decoding and Conditional\nFlow-Matching. We conduct a controlled comparison by training all models from\nscratch using identical datasets, training configurations, and similar backbone\narchitectures. Performance is evaluated across multiple axes, including\ngeneration quality, robustness to inference configurations, scalability,\nadherence to both textual and temporally aligned conditioning, and editing\ncapabilities in the form of audio inpainting. This comparative study sheds\nlight on distinct strengths and limitations of each paradigm, providing\nactionable insights that can inform future architectural and training decisions\nin the evolving landscape of text-to-music generation. Audio sampled examples\nare available at: https://huggingface.co/spaces/ortal1602/ARvsFM", "AI": {"tldr": "Recent progress in text-to-music generation motivates a systematic empirical analysis focusing on modeling paradigm, specifically comparing Auto-Regressive decoding and Conditional Flow-Matching. This study provides insights into trade-offs and behaviors to guide future systems.", "motivation": "The motivation of this paper is to evaluate the effects of different modeling paradigms in text-to-music generation models, providing insights into which design choices most influence performance.", "method": "The method involves conducting a systematic empirical analysis by comparing two common modeling paradigms: Auto-Regressive decoding and Conditional Flow-Matching. The comparison is controlled by training all models from scratch using identical datasets, training configurations, and similar backbone architectures.", "result": "The results highlight distinct strengths and limitations of each paradigm across multiple evaluation axes such as generation quality, robustness, scalability, adherence to conditioning, and editing capabilities.", "conclusion": "This comparative study offers actionable insights that can inform future architectural and training decisions in text-to-music generation."}}
{"id": "2506.09046", "pdf": "https://arxiv.org/pdf/2506.09046", "abs": "https://arxiv.org/abs/2506.09046", "authors": ["Xiaowen Ma", "Chenyang Lin", "Yao Zhang", "Volker Tresp", "Yunpu Ma"], "title": "Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation", "categories": ["cs.LG", "cs.AI", "cs.MA"], "comment": null, "summary": "Leveraging multiple Large Language Models(LLMs) has proven effective for\naddressing complex, high-dimensional tasks, but current approaches often rely\non static, manually engineered multi-agent configurations. To overcome these\nconstraints, we present the Agentic Neural Network(ANN), a framework that\nconceptualizes multi-agent collaboration as a layered neural network\narchitecture. In this design, each agent operates as a node, and each layer\nforms a cooperative \"team\" focused on a specific subtask. Agentic Neural\nNetwork follows a two-phase optimization strategy: (1) Forward Phase-Drawing\ninspiration from neural network forward passes, tasks are dynamically\ndecomposed into subtasks, and cooperative agent teams with suitable aggregation\nmethods are constructed layer by layer. (2) Backward Phase-Mirroring\nbackpropagation, we refine both global and local collaboration through\niterative feedback, allowing agents to self-evolve their roles, prompts, and\ncoordination. This neuro-symbolic approach enables ANN to create new or\nspecialized agent teams post-training, delivering notable gains in accuracy and\nadaptability. Across four benchmark datasets, ANN surpasses leading multi-agent\nbaselines under the same configurations, showing consistent performance\nimprovements. Our findings indicate that ANN provides a scalable, data-driven\nframework for multi-agent systems, combining the collaborative capabilities of\nLLMs with the efficiency and flexibility of neural network principles. We plan\nto open-source the entire framework.", "AI": {"tldr": "ANN is a novel framework that treats multi-agent collaboration as a layered neural network architecture, surpassing existing multi-agent systems in accuracy and adaptability.", "motivation": "Current methods for leveraging multiple LLMs often rely on static, manually engineered multi-agent configurations which limits their flexibility and scalability.", "method": "The Agentic Neural Network (ANN) conceptualizes multi-agent collaboration as a layered neural network architecture. Each agent operates as a node and each layer forms a cooperative team focused on a specific subtask. ANN follows a two-phase optimization strategy: Forward Phase for task decomposition and team construction, and Backward Phase for refining global and local collaboration through iterative feedback.", "result": "ANN surpasses leading multi-agent baselines under the same configurations across four benchmark datasets, showing consistent performance improvements in accuracy and adaptability.", "conclusion": "ANN provides a scalable, data-driven framework for multi-agent systems, combining the collaborative capabilities of LLMs with the efficiency and flexibility of neural network principles."}}
{"id": "2506.09048", "pdf": "https://arxiv.org/pdf/2506.09048", "abs": "https://arxiv.org/abs/2506.09048", "authors": ["Yuxin Dong", "Jiachen Jiang", "Zhihui Zhu", "Xia Ning"], "title": "Understanding Task Vectors in In-Context Learning: Emergence, Functionality, and Limitations", "categories": ["cs.LG"], "comment": null, "summary": "Task vectors offer a compelling mechanism for accelerating inference in\nin-context learning (ICL) by distilling task-specific information into a\nsingle, reusable representation. Despite their empirical success, the\nunderlying principles governing their emergence and functionality remain\nunclear. This work proposes the Linear Combination Conjecture, positing that\ntask vectors act as single in-context demonstrations formed through linear\ncombinations of the original ones. We provide both theoretical and empirical\nsupport for this conjecture. First, we show that task vectors naturally emerge\nin linear transformers trained on triplet-formatted prompts through loss\nlandscape analysis. Next, we predict the failure of task vectors on\nrepresenting high-rank mappings and confirm this on practical LLMs. Our\nfindings are further validated through saliency analyses and parameter\nvisualization, suggesting an enhancement of task vectors by injecting multiple\nones into few-shot prompts. Together, our results advance the understanding of\ntask vectors and shed light on the mechanisms underlying ICL in\ntransformer-based models.", "AI": {"tldr": "Task vectors in in-context learning (ICL) are explored through the Linear Combination Conjecture, which explains their emergence and limitations. Findings suggest task vectors result from linear combinations of original demonstrations, fail at high-rank mappings, and can be improved with multiple injections.", "motivation": "To understand the underlying principles governing the emergence and functionality of task vectors in ICL, as their empirical success lacks clear theoretical explanation.", "method": "Propose the Linear Combination Conjecture suggesting task vectors form through linear combinations of original demonstrations. Validate this conjecture using loss landscape analysis in linear transformers trained on triplet-formatted prompts, predict and confirm task vector failures in high-rank mappings, and validate findings through saliency analyses and parameter visualization.", "result": "Confirmed that task vectors naturally emerge in linear transformers through loss landscape analysis. Predicted and confirmed their failure to represent high-rank mappings. Suggested improvement of task vectors by injecting multiple ones into few-shot prompts.", "conclusion": "This work advances the understanding of task vectors and sheds light on the mechanisms underlying ICL in transformer-based models."}}
{"id": "2506.08594", "pdf": "https://arxiv.org/pdf/2506.08594", "abs": "https://arxiv.org/abs/2506.08594", "authors": ["Yixuan Ma", "Chang Liu", "Weikang Li", "Shun-Yao Zhang", "L. -M. Duan", "Yukai Wu", "Dong-Ling Deng"], "title": "Solving excited states for long-range interacting trapped ions with neural networks", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.AI", "cs.LG"], "comment": null, "summary": "The computation of excited states in strongly interacting quantum many-body\nsystems is of fundamental importance. Yet, it is notoriously challenging due to\nthe exponential scaling of the Hilbert space dimension with the system size.\nHere, we introduce a neural network-based algorithm that can simultaneously\noutput multiple low-lying excited states of a quantum many-body spin system in\nan accurate and efficient fashion. This algorithm, dubbed the neural quantum\nexcited-state (NQES) algorithm, requires no explicit orthogonalization of the\nstates and is generally applicable to higher dimensions. We demonstrate,\nthrough concrete examples including the Haldane-Shastry model with all-to-all\ninteractions, that the NQES algorithm is capable of efficiently computing\nmultiple excited states and their related observable expectations. In addition,\nwe apply the NQES algorithm to two classes of long-range interacting\ntrapped-ion systems in a two-dimensional Wigner crystal. For non-decaying\nall-to-all interactions with alternating signs, our computed low-lying excited\nstates bear spatial correlation patterns similar to those of the ground states,\nwhich closely match recent experimental observations that the\nquasi-adiabatically prepared state accurately reproduces analytical\nground-state correlations. For a system of up to 300 ions with power-law\ndecaying antiferromagnetic interactions, we successfully uncover its gap\nscaling and correlation features. Our results establish a scalable and\nefficient algorithm for computing excited states of interacting quantum\nmany-body systems, which holds potential applications ranging from benchmarking\nquantum devices to photoisomerization.", "AI": {"tldr": "This paper presents a neural network-based algorithm, NQES, which can accurately and efficiently compute multiple low-lying excited states of quantum many-body spin systems without explicit orthogonalization. Demonstrated through various models, including Haldane-Shastry model and trapped-ion systems, the algorithm reveals spatial correlation patterns matching experimental observations and uncovers gap scaling and correlation features for large ion systems.", "motivation": "The computation of excited states in strongly interacting quantum many-body systems is crucial but challenging due to the exponential growth of Hilbert space dimension with system size.", "method": "A neural network-based algorithm (NQES) is introduced to simultaneously output multiple low-lying excited states of quantum many-body spin systems, without requiring explicit orthogonalization and applicable to higher dimensions.", "result": "Through examples like the Haldane-Shastry model and trapped-ion systems, the NQES algorithm successfully computes multiple excited states and their observable expectations, revealing spatial correlation patterns and uncovering gap scaling and correlation features.", "conclusion": "The NQES algorithm is established as a scalable and efficient tool for computing excited states in interacting quantum many-body systems, with potential applications in benchmarking quantum devices and processes like photoisomerization."}}
{"id": "2506.08596", "pdf": "https://arxiv.org/pdf/2506.08596", "abs": "https://arxiv.org/abs/2506.08596", "authors": ["Guyang Zhang", "Waleed Abdulla"], "title": "Transformers Meet Hyperspectral Imaging: A Comprehensive Study of Models, Challenges and Open Problems", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Transformers have become the architecture of choice for learning long-range\ndependencies, yet their adoption in hyperspectral imaging (HSI) is still\nemerging. We reviewed more than 300 papers published up to 2025 and present the\nfirst end-to-end survey dedicated to Transformer-based HSI classification. The\nstudy categorizes every stage of a typical pipeline-pre-processing, patch or\npixel tokenization, positional encoding, spatial-spectral feature extraction,\nmulti-head self-attention variants, skip connections, and loss design-and\ncontrasts alternative design choices with the unique spatial-spectral\nproperties of HSI. We map the field's progress against persistent obstacles:\nscarce labeled data, extreme spectral dimensionality, computational overhead,\nand limited model explainability. Finally, we outline a research agenda\nprioritizing valuable public data sets, lightweight on-edge models,\nillumination and sensor shifts robustness, and intrinsically interpretable\nattention mechanisms. Our goal is to guide researchers in selecting, combining,\nor extending Transformer components that are truly fit for purpose for\nnext-generation HSI applications.", "AI": {"tldr": "Transformers are becoming important for learning long-range dependencies, but their use in hyperspectral imaging (HSI) is still developing. This paper reviews over 300 papers to provide the first comprehensive survey of Transformer-based HSI classification methods, covering every stage from preprocessing to loss design. It addresses challenges such as limited labeled data and computational overhead while suggesting future research directions including public datasets, lightweight models, robustness, and interpretable attention mechanisms.", "motivation": "The motivation of this paper is to address the gap in understanding and utilizing Transformers for hyperspectral imaging (HSI) classification, by providing a comprehensive survey that covers all stages of a typical pipeline and compares design choices with respect to the unique properties of HSI data.", "method": "The method involves reviewing more than 300 papers published up to 2025 and categorizing each stage of the Transformer-based HSI classification pipeline, including pre-processing, tokenization, positional encoding, feature extraction, self-attention variants, skip connections, and loss design. The study also contrasts these choices with the spatial-spectral properties of HSI.", "result": "The result is a detailed mapping of the field's progress against persistent obstacles like scarce labeled data, high spectral dimensionality, computational costs, and limited model explainability. Additionally, the paper outlines a research agenda to guide future work.", "conclusion": "The conclusion emphasizes guiding researchers in selecting, combining, or extending Transformer components that are appropriate for next-generation HSI applications, ensuring they are fit-for-purpose."}}
{"id": "2506.08030", "pdf": "https://arxiv.org/pdf/2506.08030", "abs": "https://arxiv.org/abs/2506.08030", "authors": ["Brian Liu", "Rahul Mazumder"], "title": "MOSS: Multi-Objective Optimization for Stable Rule Sets", "categories": ["math.OC", "cs.LG", "stat.ML"], "comment": null, "summary": "We present MOSS, a multi-objective optimization framework for constructing\nstable sets of decision rules. MOSS incorporates three important criteria for\ninterpretability: sparsity, accuracy, and stability, into a single\nmulti-objective optimization framework. Importantly, MOSS allows a practitioner\nto rapidly evaluate the trade-off between accuracy and stability in sparse rule\nsets in order to select an appropriate model. We develop a specialized cutting\nplane algorithm in our framework to rapidly compute the Pareto frontier between\nthese two objectives, and our algorithm scales to problem instances beyond the\ncapabilities of commercial optimization solvers. Our experiments show that MOSS\noutperforms state-of-the-art rule ensembles in terms of both predictive\nperformance and stability.", "AI": {"tldr": "The paper introduces MOSS, a framework for creating stable decision rule sets with a focus on interpretability through sparsity, accuracy, and stability. It provides a tool for practitioners to evaluate the trade-off between accuracy and stability using a specialized cutting plane algorithm that computes the Pareto frontier and scales beyond commercial solvers. Experiments demonstrate MOSS outperforms current rule ensembles in predictive performance and stability.", "motivation": "There is a need for interpretable decision rule sets that balance accuracy, sparsity, and stability, which are crucial for understanding and trusting machine learning models. Existing methods may not adequately address these aspects simultaneously or efficiently explore the trade-offs between them.", "method": "MOSS integrates three criteria (sparsity, accuracy, and stability) into a multi-objective optimization framework. A specialized cutting plane algorithm is developed to compute the Pareto frontier between accuracy and stability, allowing users to explore trade-offs and select suitable models. This algorithm can handle larger problem instances than commercial solvers.", "result": "Experiments indicate that MOSS surpasses state-of-the-art rule ensembles in both predictive performance and stability, demonstrating its effectiveness and efficiency.", "conclusion": "MOSS provides an effective framework for constructing interpretable decision rule sets with a good balance of sparsity, accuracy, and stability. The specialized cutting plane algorithm enables rapid evaluation of trade-offs and selection of appropriate models, outperforming existing methods."}}
{"id": "2506.08033", "pdf": "https://arxiv.org/pdf/2506.08033", "abs": "https://arxiv.org/abs/2506.08033", "authors": ["Axel TahmasebiMoradi", "Vincent Ren", "Benjamin Le-Creurer", "Chetra Mang"], "title": "Feasibility Study of CNNs and MLPs for Radiation Heat Transfer in 2-D Furnaces with Spectrally Participative Gases", "categories": ["eess.SY", "cs.LG", "cs.SY"], "comment": null, "summary": "Aiming to reduce the computational cost of numerical simulations, a\nconvolutional neural network (CNN) and a multi-layer perceptron (MLP) are\nintroduced to build a surrogate model to approximate radiative heat transfer\nsolutions in a 2-D walled domain with participative gases. The originality of\nthis work lays in the adaptation of the inputs of the problem (gas and wall\nproperties) in order to fit with the CNN architecture, more commonly used for\nimage processing. Two precision datasets have been created with the classical\nsolver, ICARUS2D, that uses the discrete transfer radiation method with the\nstatistical narrow bands model. The performance of the CNN architecture is\ncompared to a more classical MLP architecture in terms of speed and accuracy.\nThanks to Optuna, all results are obtained using the optimized hyper parameters\nnetworks. The results show a significant speedup with industrially acceptable\nrelative errors compared to the classical solver for both architectures.\nAdditionally, the CNN outperforms the MLP in terms of precision and is more\nrobust and stable to changes in hyper-parameters. A performance analysis on the\ndataset size of the samples have also been carried out to gain a deeper\nunderstanding of the model behavior.", "AI": {"tldr": "To decrease the computational cost of numerical simulations, this paper introduces a CNN and an MLP to create a surrogate model for approximating radiative heat transfer solutions in a 2D domain with participative gases. The inputs (gas and wall properties) are adapted to fit the CNN architecture. Two precision datasets were created using ICARUS2D solver. Performance of both architectures is compared in terms of speed and accuracy with optimized hyperparameters via Optuna. Results indicate significant speedup with acceptable errors, with CNN outperforming MLP in precision, robustness, and stability. A performance analysis on dataset size was also conducted.", "motivation": "The motivation of this paper is to reduce the computational cost associated with numerical simulations of radiative heat transfer in a 2-D walled domain with participative gases by employing machine learning techniques, specifically convolutional neural networks (CNNs) and multi-layer perceptrons (MLPs).", "method": "The method involves adapting the inputs of the problem (gas and wall properties) to fit the CNN architecture and creating two precision datasets using the classical solver, ICARUS2D. Both CNN and MLP architectures are used to build surrogate models for approximating radiative heat transfer solutions. Hyperparameters are optimized using Optuna, and the performance of both architectures is compared in terms of speed and accuracy.", "result": "The results show a significant speedup with industrially acceptable relative errors compared to the classical solver for both architectures. Additionally, the CNN outperforms the MLP in terms of precision and is more robust and stable to changes in hyper-parameters. A deeper understanding of the model behavior was gained through a performance analysis on the dataset size of the samples.", "conclusion": "In conclusion, the use of CNN and MLP architectures as surrogate models significantly reduces computational cost while maintaining acceptable accuracy in approximating radiative heat transfer solutions. The CNN shows superior performance in terms of precision, robustness, and stability."}}
{"id": "2506.08629", "pdf": "https://arxiv.org/pdf/2506.08629", "abs": "https://arxiv.org/abs/2506.08629", "authors": ["Feixiang Du", "Shengkun Wu"], "title": "ECMNet:Lightweight Semantic Segmentation with Efficient CNN-Mamba Network", "categories": ["cs.CV", "cs.AI"], "comment": "16 pages, 2 figures, 4 tables", "summary": "In the past decade, Convolutional Neural Networks (CNNs) and Transformers\nhave achieved wide applicaiton in semantic segmentation tasks. Although CNNs\nwith Transformer models greatly improve performance, the global context\nmodeling remains inadequate. Recently, Mamba achieved great potential in vision\ntasks, showing its advantages in modeling long-range dependency. In this paper,\nwe propose a lightweight Efficient CNN-Mamba Network for semantic segmentation,\ndubbed as ECMNet. ECMNet combines CNN with Mamba skillfully in a capsule-based\nframework to address their complementary weaknesses. Specifically, We design a\nEnhanced Dual-Attention Block (EDAB) for lightweight bottleneck. In order to\nimprove the representations ability of feature, We devise a Multi-Scale\nAttention Unit (MSAU) to integrate multi-scale feature aggregation, spatial\naggregation and channel aggregation. Moreover, a Mamba enhanced Feature Fusion\nModule (FFM) merges diverse level feature, significantly enhancing segmented\naccuracy. Extensive experiments on two representative datasets demonstrate that\nthe proposed model excels in accuracy and efficiency balance, achieving 70.6%\nmIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M\nparameters and 8.27G FLOPs on a single RTX 3090 GPU platform.", "AI": {"tldr": "This paper proposes ECMNet, a lightweight Efficient CNN-Mamba Network for semantic segmentation that combines CNN with Mamba in a capsule-based framework to address their complementary weaknesses.", "motivation": "Although CNNs with Transformer models greatly improve performance, the global context modeling remains inadequate. Mamba has shown advantages in modeling long-range dependency, which motivates this work.", "method": "The authors propose ECMNet which integrates Enhanced Dual-Attention Block (EDAB) for lightweight bottleneck, Multi-Scale Attention Unit (MSAU) for integrating multi-scale feature aggregation, spatial aggregation and channel aggregation, and Mamba enhanced Feature Fusion Module (FFM) for merging diverse level features.", "result": "Extensive experiments on two representative datasets demonstrate that the proposed model excels in accuracy and efficiency balance, achieving 70.6% mIoU on Cityscapes and 73.6% mIoU on CamVid test datasets, with 0.87M parameters and 8.27G FLOPs on a single RTX 3090 GPU platform.", "conclusion": "ECMNet achieves superior performance in semantic segmentation tasks, effectively balancing accuracy and efficiency."}}
{"id": "2506.08043", "pdf": "https://arxiv.org/pdf/2506.08043", "abs": "https://arxiv.org/abs/2506.08043", "authors": ["Ashkan Shahbazi", "Kyvia Pereira", "Jon S. Heiselman", "Elaheh Akbari", "Annie C. Benson", "Sepehr Seifi", "Xinyuan Liu", "Garrison L. Johnston", "Erwin Terpstra", "Anne Draaisma", "Jan-Jaap Severes", "Jie Ying Wu", "Nabil Simaan", "Michael L. Miga", "Soheil Kolouri"], "title": "Neural-Augmented Kelvinlet: Real-Time Soft Tissue Deformation with Multiple Graspers", "categories": ["cs.GR", "cs.CV", "cs.LG", "cs.RO"], "comment": null, "summary": "Fast and accurate simulation of soft tissue deformation is a critical factor\nfor surgical robotics and medical training. In this paper, we introduce a novel\nphysics-informed neural simulator that approximates soft tissue deformations in\na realistic and real-time manner. Our framework integrates Kelvinlet-based\npriors into neural simulators, making it the first approach to leverage\nKelvinlets for residual learning and regularization in data-driven soft tissue\nmodeling. By incorporating large-scale Finite Element Method (FEM) simulations\nof both linear and nonlinear soft tissue responses, our method improves neural\nnetwork predictions across diverse architectures, enhancing accuracy and\nphysical consistency while maintaining low latency for real-time performance.\nWe demonstrate the effectiveness of our approach by performing accurate\nsurgical maneuvers that simulate the use of standard laparoscopic tissue\ngrasping tools with high fidelity. These results establish Kelvinlet-augmented\nlearning as a powerful and efficient strategy for real-time, physics-aware soft\ntissue simulation in surgical applications.", "AI": {"tldr": "This paper presents a novel physics-informed neural simulator for fast and accurate soft tissue deformation simulation, integrating Kelvinlet-based priors into neural simulators for real-time surgical applications.", "motivation": "Fast and accurate simulation of soft tissue deformation is crucial in surgical robotics and medical training, but existing methods lack the balance between speed and accuracy.", "method": "The authors introduce a physics-informed neural simulator that incorporates Kelvinlet-based priors into neural networks. This approach uses large-scale Finite Element Method (FEM) simulations to improve predictions across different network architectures, ensuring both accuracy and physical consistency while maintaining low latency.", "result": "The simulator successfully performs accurate surgical maneuvers, simulating standard laparoscopic tissue grasping tools with high fidelity. This demonstrates the effectiveness of Kelvinlet-augmented learning in enhancing real-time, physics-aware soft tissue simulation.", "conclusion": "Kelvinlet-augmented learning represents a powerful and efficient strategy for real-time, physics-aware soft tissue simulation in surgical applications, improving both accuracy and performance."}}
{"id": "2506.08634", "pdf": "https://arxiv.org/pdf/2506.08634", "abs": "https://arxiv.org/abs/2506.08634", "authors": ["Alvaro Becerra", "Daniel Andres", "Pablo Villegas", "Roberto Daza", "Ruth Cobos"], "title": "MOSAIC-F: A Framework for Enhancing Students' Oral Presentation Skills through Personalized Feedback", "categories": ["cs.HC", "cs.AI", "cs.CV"], "comment": "Accepted in LASI Spain 25: Learning Analytics Summer Institute Spain\n  2025", "summary": "In this article, we present a novel multimodal feedback framework called\nMOSAIC-F, an acronym for a data-driven Framework that integrates Multimodal\nLearning Analytics (MMLA), Observations, Sensors, Artificial Intelligence (AI),\nand Collaborative assessments for generating personalized feedback on student\nlearning activities. This framework consists of four key steps. First, peers\nand professors' assessments are conducted through standardized rubrics (that\ninclude both quantitative and qualitative evaluations). Second, multimodal data\nare collected during learning activities, including video recordings, audio\ncapture, gaze tracking, physiological signals (heart rate, motion data), and\nbehavioral interactions. Third, personalized feedback is generated using AI,\nsynthesizing human-based evaluations and data-based multimodal insights such as\nposture, speech patterns, stress levels, and cognitive load, among others.\nFinally, students review their own performance through video recordings and\nengage in self-assessment and feedback visualization, comparing their own\nevaluations with peers and professors' assessments, class averages, and\nAI-generated recommendations. By combining human-based and data-based\nevaluation techniques, this framework enables more accurate, personalized and\nactionable feedback. We tested MOSAIC-F in the context of improving oral\npresentation skills.", "AI": {"tldr": "The paper introduces MOSAIC-F, a multimodal feedback framework that combines human-based and data-driven evaluations to generate personalized feedback on student learning activities. Tested for improving oral presentation skills, it integrates assessments, multimodal data collection, AI analysis, and self-assessment.", "motivation": "To address the need for more accurate, personalized, and actionable feedback in student learning activities by integrating human-based evaluations with advanced data-driven techniques such as AI and multimodal analytics.", "method": "MOSAIC-F consists of four steps: standardized assessments by peers and professors, multimodal data collection during learning activities (video, audio, gaze, physiological signals, etc.), AI-generated personalized feedback combining human evaluations and multimodal insights, and student self-assessment involving video review and comparison with external evaluations.", "result": "The framework was tested for improving oral presentation skills, demonstrating its potential to enhance feedback accuracy and personalization by effectively integrating diverse evaluation methods.", "conclusion": "MOSAIC-F successfully merges human-based and data-driven approaches to provide richer, more actionable feedback for students, setting a promising direction for future educational feedback systems."}}
{"id": "2506.08646", "pdf": "https://arxiv.org/pdf/2506.08646", "abs": "https://arxiv.org/abs/2506.08646", "authors": ["Mingyu Zheng", "Zhifan Feng", "Jia Wang", "Lanrui Wang", "Zheng Lin", "Yang Hao", "Weiping Wang"], "title": "TableDreamer: Progressive and Weakness-guided Data Synthesis from Scratch for Table Instruction Tuning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "27 pages, 19 figures, Findings of ACL 2025", "summary": "Despite the commendable progress of recent LLM-based data synthesis methods,\nthey face two limitations in generating table instruction tuning data. First,\nthey can not thoroughly explore the vast input space of table understanding\ntasks, leading to limited data diversity. Second, they ignore the weaknesses in\ntable understanding ability of the target LLM and blindly pursue the increase\nof data quantity, resulting in suboptimal data efficiency. In this paper, we\nintroduce a progressive and weakness-guided data synthesis framework tailored\nfor table instruction tuning, named TableDreamer, to mitigate the above issues.\nSpecifically, we first synthesize diverse tables and related instructions as\nseed data, and then perform an iterative exploration of the input space under\nthe guidance of the newly identified weakness data, which eventually serve as\nthe final training data for fine-tuning the target LLM. Extensive experiments\non 10 tabular benchmarks demonstrate the effectiveness of the proposed\nframework, which boosts the average accuracy of Llama3.1-8B-instruct by 11.62%\n(49.07% to 60.69%) with 27K GPT-4o synthetic data and outperforms\nstate-of-the-art data synthesis baselines which use more training data. The\ncode and data is available at https://github.com/SpursGoZmy/TableDreamer", "AI": {"tldr": "TableDreamer is a progressive and weakness-guided data synthesis framework for table instruction tuning which enhances LLM's table understanding ability.", "motivation": "Recent LLM-based data synthesis methods have limitations in generating table instruction tuning data, including insufficient data diversity and suboptimal data efficiency due to ignoring the weaknesses in table understanding.", "method": "The method involves synthesizing diverse tables and related instructions as seed data, followed by an iterative exploration of the input space guided by newly identified weakness data. This serves as the final training data for fine-tuning the target LLM.", "result": "Experiments on 10 tabular benchmarks show that TableDreamer boosts the average accuracy of Llama3.1-8B-instruct by 11.62% using 27K GPT-4o synthetic data, outperforming state-of-the-art baselines with more training data.", "conclusion": "TableDreamer effectively addresses the limitations of current LLM-based data synthesis methods for table instruction tuning, improving both data diversity and efficiency."}}
{"id": "2506.08647", "pdf": "https://arxiv.org/pdf/2506.08647", "abs": "https://arxiv.org/abs/2506.08647", "authors": ["Oumaima El Khettari", "Solen Quiniou", "Samuel Chaffron"], "title": "Summarization for Generative Relation Extraction in the Microbiome Domain", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We explore a generative relation extraction (RE) pipeline tailored to the\nstudy of interactions in the intestinal microbiome, a complex and low-resource\nbiomedical domain. Our method leverages summarization with large language\nmodels (LLMs) to refine context before extracting relations via\ninstruction-tuned generation. Preliminary results on a dedicated corpus show\nthat summarization improves generative RE performance by reducing noise and\nguiding the model. However, BERT-based RE approaches still outperform\ngenerative models. This ongoing work demonstrates the potential of generative\nmethods to support the study of specialized domains in low-resources setting.", "AI": {"tldr": "The paper explores a generative relation extraction pipeline for studying interactions in the intestinal microbiome, using summarization with LLMs to refine context before extracting relations. Summarization improves performance by reducing noise but BERT-based methods still outperform generative models.", "motivation": "To develop a method tailored for relation extraction in the complex and low-resource domain of the intestinal microbiome.", "method": "Using a generative relation extraction pipeline that leverages summarization with large language models to refine context before extracting relations via instruction-tuned generation.", "result": "Preliminary results show that summarization improves generative RE performance by reducing noise and guiding the model, although BERT-based RE approaches still outperform generative models.", "conclusion": "This work shows the potential of generative methods to support the study of specialized domains in low-resource settings."}}
{"id": "2506.08065", "pdf": "https://arxiv.org/pdf/2506.08065", "abs": "https://arxiv.org/abs/2506.08065", "authors": ["Ye Zhu", "Duo Xu", "Zhiwei Deng", "Jonathon C. Tan", "Olga Russakovsky"], "title": "Dynamic Diffusion Schr\u00f6dinger Bridge in Astrophysical Observational Inversions", "categories": ["astro-ph.IM", "cs.LG"], "comment": "Preprint. Code will be available at\n  https://github.com/L-YeZhu/AstroDSB", "summary": "We study Diffusion Schr\\\"odinger Bridge (DSB) models in the context of\ndynamical astrophysical systems, specifically tackling observational inverse\nprediction tasks within Giant Molecular Clouds (GMCs) for star formation. We\nintroduce the Astro-DSB model, a variant of DSB with the pairwise domain\nassumption tailored for astrophysical dynamics. By investigating its learning\nprocess and prediction performance in both physically simulated data and in\nreal observations (the Taurus B213 data), we present two main takeaways. First,\nfrom the astrophysical perspective, our proposed paired DSB method improves\ninterpretability, learning efficiency, and prediction performance over\nconventional astrostatistical and other machine learning methods. Second, from\nthe generative modeling perspective, probabilistic generative modeling reveals\nimprovements over discriminative pixel-to-pixel modeling in Out-Of-Distribution\n(OOD) testing cases of physical simulations with unseen initial conditions and\ndifferent dominant physical processes. Our study expands research into\ndiffusion models beyond the traditional visual synthesis application and\nprovides evidence of the models' learning abilities beyond pure data\nstatistics, paving a path for future physics-aware generative models which can\nalign dynamics between machine learning and real (astro)physical systems.", "AI": {"tldr": "The paper introduces Astro-DSB, a variant of Diffusion Schr\u00f6dinger Bridge models designed for astrophysical dynamics. It enhances interpretability, learning efficiency, and prediction performance in star formation tasks within GMCs compared to traditional methods. Additionally, it highlights the advantages of probabilistic generative modeling over discriminative pixel-to-pixel modeling in OOD testing.", "motivation": "To improve interpretability, learning efficiency, and prediction performance in dynamical astrophysical systems, specifically for inverse prediction tasks related to star formation in GMCs.", "method": "Astro-DSB model is introduced, which is a variant of DSB with the pairwise domain assumption tailored for astrophysical dynamics. The method investigates learning process and prediction performance using both physically simulated data and real observations (Taurus B213 data).", "result": "Astro-DSB improves interpretability, learning efficiency, and prediction performance over conventional astrostatistical and machine learning methods. Probabilistic generative modeling shows improvements over discriminative pixel-to-pixel modeling in OOD testing cases.", "conclusion": "The study expands research into diffusion models beyond visual synthesis applications and provides evidence that these models can learn beyond pure data statistics, paving the way for future physics-aware generative models."}}
{"id": "2506.08121", "pdf": "https://arxiv.org/pdf/2506.08121", "abs": "https://arxiv.org/abs/2506.08121", "authors": ["Qi Feng", "Gu Wang"], "title": "Continuous Policy and Value Iteration for Stochastic Control Problems and Its Convergence", "categories": ["math.OC", "cs.LG", "93E20, 93E35, 60H10"], "comment": "37 pages", "summary": "We introduce a continuous policy-value iteration algorithm where the\napproximations of the value function of a stochastic control problem and the\noptimal control are simultaneously updated through Langevin-type dynamics. This\nframework applies to both the entropy-regularized relaxed control problems and\nthe classical control problems, with infinite horizon. We establish policy\nimprovement and demonstrate convergence to the optimal control under the\nmonotonicity condition of the Hamiltonian. By utilizing Langevin-type\nstochastic differential equations for continuous updates along the policy\niteration direction, our approach enables the use of distribution sampling and\nnon-convex learning techniques in machine learning to optimize the value\nfunction and identify the optimal control simultaneously.", "AI": {"tldr": "A continuous policy-value iteration algorithm is introduced, which updates value function and optimal control via Langevin-type dynamics for both entropy-regularized and classical control problems.", "motivation": "To develop an algorithm that can simultaneously update approximations of the value function and optimal control in stochastic control problems using Langevin-type dynamics.", "method": "The algorithm applies to both entropy-regularized relaxed control and classical control problems with infinite horizon. It uses policy improvement and converges to the optimal control under a monotonicity condition of the Hamiltonian. It employs Langevin-type stochastic differential equations for continuous updates along the policy iteration direction.", "result": "The approach enables distribution sampling and non-convex learning techniques in machine learning to optimize the value function and identify the optimal control simultaneously.", "conclusion": "This method provides a novel way to solve stochastic control problems by integrating machine learning techniques into the optimization process."}}
{"id": "2506.08127", "pdf": "https://arxiv.org/pdf/2506.08127", "abs": "https://arxiv.org/abs/2506.08127", "authors": ["Cyrille Kone", "Emilie Kaufmann", "Laura Richert"], "title": "Constrained Pareto Set Identification with Bandit Feedback", "categories": ["stat.ML", "cs.LG"], "comment": "To appear in Proceedings of ICML2025", "summary": "In this paper, we address the problem of identifying the Pareto Set under\nfeasibility constraints in a multivariate bandit setting. Specifically, given a\n$K$-armed bandit with unknown means $\\mu_1, \\dots, \\mu_K \\in \\mathbb{R}^d$, the\ngoal is to identify the set of arms whose mean is not uniformly worse than that\nof another arm (i.e., not smaller for all objectives), while satisfying some\nknown set of linear constraints, expressing, for example, some minimal\nperformance on each objective. Our focus lies in fixed-confidence\nidentification, for which we introduce an algorithm that significantly\noutperforms racing-like algorithms and the intuitive two-stage approach that\nfirst identifies feasible arms and then their Pareto Set. We further prove an\ninformation-theoretic lower bound on the sample complexity of any algorithm for\nconstrained Pareto Set identification, showing that the sample complexity of\nour approach is near-optimal. Our theoretical results are supported by an\nextensive empirical evaluation on a series of benchmarks.", "AI": {"tldr": "\u672c\u8bba\u6587\u63a2\u8ba8\u4e86\u5728\u591a\u53d8\u91cf\u8001\u864e\u673a\u60c5\u5883\u4e0b\uff0c\u5982\u4f55\u5728\u53ef\u884c\u6027\u7ea6\u675f\u6761\u4ef6\u4e0b\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u7684\u95ee\u9898\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u7ed9\u5b9a\u4e00\u4e2aK\u81c2\u8001\u864e\u673a\uff0c\u76ee\u6807\u662f\u5728\u6ee1\u8db3\u67d0\u4e9b\u7ebf\u6027\u7ea6\u675f\u6761\u4ef6\u4e0b\uff0c\u8bc6\u522b\u51fa\u5747\u503c\u5411\u91cf\u4e0d\u88ab\u5176\u4ed6\u4efb\u4f55\u81c2\u5747\u503c\u5411\u91cf\u5b8c\u5168\u652f\u914d\u7684\u81c2\u96c6\u5408\u3002\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u5728\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u8bc6\u522b\u95ee\u9898\u4e0a\u663e\u8457\u4f18\u4e8e\u7ade\u8d5b\u7c7b\u7b97\u6cd5\u548c\u4e24\u9636\u6bb5\u65b9\u6cd5\u3002\u6b64\u5916\uff0c\u8fd8\u8bc1\u660e\u4e86\u4e00\u4e2a\u4fe1\u606f\u8bba\u4e0b\u7684\u6837\u672c\u590d\u6742\u5ea6\u4e0b\u754c\uff0c\u8868\u660e\u8be5\u7b97\u6cd5\u63a5\u8fd1\u6700\u4f18\u3002\u6700\u540e\u901a\u8fc7\u4e00\u7cfb\u5217\u57fa\u51c6\u6d4b\u8bd5\u8fdb\u884c\u4e86\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u8bc4\u4f30\u3002", "motivation": "\u5728\u73b0\u5b9e\u4e16\u754c\u4e2d\uff0c\u5f88\u591a\u51b3\u7b56\u95ee\u9898\u9700\u8981\u540c\u65f6\u8003\u8651\u591a\u4e2a\u76ee\u6807\uff0c\u5e76\u4e14\u8fd9\u4e9b\u76ee\u6807\u4e4b\u95f4\u53ef\u80fd\u5b58\u5728\u51b2\u7a81\u3002\u4f8b\u5982\uff0c\u5728\u8d44\u6e90\u5206\u914d\u3001\u6295\u8d44\u7ec4\u5408\u4f18\u5316\u7b49\u9886\u57df\uff0c\u6211\u4eec\u9700\u8981\u627e\u5230\u4e00\u7ec4\u6298\u8877\u65b9\u6848\uff0c\u4f7f\u5f97\u4efb\u4f55\u4e00\u4e2a\u76ee\u6807\u90fd\u4e0d\u4f1a\u53d8\u5f97\u66f4\u5dee\u3002\u8fd9\u5c31\u5f15\u51fa\u4e86\u5e15\u7d2f\u6258\u6700\u4f18\u7684\u6982\u5ff5\u3002\u7136\u800c\uff0c\u5f53\u52a0\u5165\u53ef\u884c\u6027\u7ea6\u675f\u6761\u4ef6\u65f6\uff08\u5982\u6bcf\u4e2a\u76ee\u6807\u81f3\u5c11\u9700\u8981\u8fbe\u5230\u67d0\u4e2a\u6700\u4f4e\u8981\u6c42\uff09\uff0c\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u5728\u7ea6\u675f\u6761\u4ef6\u4e0b\u5982\u4f55\u9ad8\u6548\u5730\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u7ea6\u675f\u5e15\u7d2f\u6258\u96c6\u8bc6\u522b\u7684\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u7b97\u6cd5\u3002\u8be5\u7b97\u6cd5\u907f\u514d\u4e86\u4f20\u7edf\u7ade\u8d5b\u7c7b\u7b97\u6cd5\u6216\u4e24\u9636\u6bb5\u65b9\u6cd5\u53ef\u80fd\u5e26\u6765\u7684\u6548\u7387\u4f4e\u4e0b\u95ee\u9898\u3002\u5177\u4f53\u800c\u8a00\uff0c\u65b0\u7b97\u6cd5\u76f4\u63a5\u5728\u8003\u8651\u7ea6\u675f\u7684\u540c\u65f6\u8fdb\u884c\u81c2\u7684\u63a2\u7d22\u4e0e\u6dd8\u6c70\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5229\u7528\u6837\u672c\u4fe1\u606f\u3002", "result": "\u76f8\u6bd4\u7ade\u8d5b\u7c7b\u7b97\u6cd5\u548c\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8bc6\u522b\u6548\u7387\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u8be5\u7b97\u6cd5\u7684\u6837\u672c\u590d\u6742\u5ea6\u63a5\u8fd1\u4fe1\u606f\u8bba\u4e0b\u754c\uff0c\u610f\u5473\u7740\u5176\u6027\u80fd\u51e0\u4e4e\u65e0\u6cd5\u8fdb\u4e00\u6b65\u63d0\u5347\u3002\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u672c\u7814\u7a76\u89e3\u51b3\u4e86\u5728\u591a\u76ee\u6807\u5e26\u7ea6\u675f\u6761\u4ef6\u4e0b\u8bc6\u522b\u5e15\u7d2f\u6258\u96c6\u7684\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u9ad8\u6548\u7684\u56fa\u5b9a\u7f6e\u4fe1\u5ea6\u7b97\u6cd5\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u63a5\u8fd1\u6700\u4f18\u7684\u6837\u672c\u590d\u6742\u5ea6\u3002\u8fd9\u4e3a\u89e3\u51b3\u5b9e\u9645\u4e2d\u7684\u591a\u76ee\u6807\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u529b\u5de5\u5177\u3002"}}
{"id": "2506.08712", "pdf": "https://arxiv.org/pdf/2506.08712", "abs": "https://arxiv.org/abs/2506.08712", "authors": ["Hee Suk Yoon", "Eunseop Yoon", "Mark A. Hasegawa-Johnson", "Sungwoong Kim", "Chang D. Yoo"], "title": "ConfPO: Exploiting Policy Model Confidence for Critical Token Selection in Large Language Model Preference Optimization", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "We introduce ConfPO, a method for preference learning in Large Language\nModels (LLMs) that identifies and optimizes preference-critical tokens based\nsolely on the training policy's confidence, without requiring any auxiliary\nmodels or compute. Unlike prior Direct Alignment Algorithms (DAAs) such as\nDirect Preference Optimization (DPO), which uniformly adjust all token\nprobabilities regardless of their relevance to preference, ConfPO focuses\noptimization on the most impactful tokens. This targeted approach improves\nalignment quality while mitigating overoptimization (i.e., reward hacking) by\nusing the KL divergence budget more efficiently. In contrast to recent\ntoken-level methods that rely on credit-assignment models or AI annotators,\nraising concerns about scalability and reliability, ConfPO is simple,\nlightweight, and model-free. Experimental results on challenging alignment\nbenchmarks, including AlpacaEval 2 and Arena-Hard, demonstrate that ConfPO\nconsistently outperforms uniform DAAs across various LLMs, delivering better\nalignment with zero additional computational overhead.", "AI": {"tldr": "The paper introduces ConfPO, a method for preference learning in LLMs that optimizes preference-critical tokens based on training policy's confidence. It improves alignment quality and mitigates overoptimization without extra computational cost.", "motivation": "To address the limitations of existing Direct Alignment Algorithms (DAAs) that adjust all token probabilities uniformly regardless of their relevance to preference, leading to inefficiency and potential reward hacking.", "method": "ConfPO identifies and optimizes preference-critical tokens solely based on the training policy's confidence, focusing optimization on the most impactful tokens using KL divergence budget more efficiently. It does not require any auxiliary models or compute.", "result": "Experimental results on challenging alignment benchmarks show that ConfPO consistently outperforms uniform DAAs across various LLMs with zero additional computational overhead.", "conclusion": "ConfPO is a simple, lightweight, and model-free method that improves alignment quality while mitigating overoptimization in LLMs."}}
{"id": "2506.08726", "pdf": "https://arxiv.org/pdf/2506.08726", "abs": "https://arxiv.org/abs/2506.08726", "authors": ["Nelvin Tan", "Zian Seng", "Liang Zhang", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Improved LLM Agents for Financial Document Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": "12 pages, 5 figures", "summary": "Large language models (LLMs) have shown impressive capabilities on numerous\nnatural language processing tasks. However, LLMs still struggle with numerical\nquestion answering for financial documents that include tabular and textual\ndata. Recent works have showed the effectiveness of critic agents (i.e.,\nself-correction) for this task given oracle labels. Building upon this\nframework, this paper examines the effectiveness of the traditional critic\nagent when oracle labels are not available, and show, through experiments, that\nthis critic agent's performance deteriorates in this scenario. With this in\nmind, we present an improved critic agent, along with the calculator agent\nwhich outperforms the previous state-of-the-art approach (program-of-thought)\nand is safer. Furthermore, we investigate how our agents interact with each\nother, and how this interaction affects their performance.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u8bb8\u591a\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u5904\u7406\u5305\u542b\u8868\u683c\u548c\u6587\u672c\u6570\u636e\u7684\u91d1\u878d\u6587\u4ef6\u7684\u6570\u503c\u95ee\u9898\u56de\u7b54\u65f6\u4ecd\u7136\u5b58\u5728\u56f0\u96be\u3002\u672c\u6587\u63a2\u8ba8\u4e86\u5728\u6ca1\u6709\u6807\u51c6\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u4f20\u7edf\u6279\u8bc4\u8005\u4ee3\u7406\u7684\u8868\u73b0\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6279\u8bc4\u8005\u4ee3\u7406\u548c\u8ba1\u7b97\u5668\u4ee3\u7406\uff0c\u5176\u8868\u73b0\u4f18\u4e8e\u4e4b\u524d\u7684\u6700\u5148\u8fdb\u65b9\u6cd5\uff08\u601d\u7ef4\u7a0b\u5e8f\uff09\uff0c\u5e76\u4e14\u66f4\u5b89\u5168\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u4ee3\u7406\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u6d89\u53ca\u8868\u683c\u548c\u6587\u672c\u6570\u636e\u7684\u91d1\u878d\u6587\u4ef6\u6570\u503c\u95ee\u9898\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u5148\u524d\u7684\u7814\u7a76\u8868\u660e\uff0c\u5728\u7ed9\u5b9a\u6807\u51c6\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\uff0c\u6279\u8bc4\u8005\u4ee3\u7406\uff08\u5373\u81ea\u6211\u4fee\u6b63\uff09\u5bf9\u6b64\u4efb\u52a1\u975e\u5e38\u6709\u6548\u3002", "method": "1. \u7814\u7a76\u5728\u65e0\u6807\u51c6\u6807\u7b7e\u60c5\u51b5\u4e0b\u4f20\u7edf\u6279\u8bc4\u8005\u4ee3\u7406\u7684\u6548\u679c\u3002\n2. \u63d0\u51fa\u4e00\u79cd\u6539\u8fdb\u7684\u6279\u8bc4\u8005\u4ee3\u7406\u548c\u8ba1\u7b97\u5668\u4ee3\u7406\u3002\n3. \u5206\u6790\u4ee3\u7406\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u53ca\u5176\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u6539\u8fdb\u7684\u6279\u8bc4\u8005\u4ee3\u7406\u548c\u8ba1\u7b97\u5668\u4ee3\u7406\u5728\u6570\u503c\u95ee\u9898\u56de\u7b54\u4efb\u52a1\u4e0a\u8d85\u8d8a\u4e86\u5148\u524d\u6700\u5148\u8fdb\u7684\u65b9\u6cd5\uff08\u601d\u7ef4\u7a0b\u5e8f\uff09\uff0c\u5e76\u4e14\u8868\u73b0\u66f4\u52a0\u7a33\u5b9a\u548c\u5b89\u5168\u3002", "conclusion": "\u6539\u8fdb\u7684\u6279\u8bc4\u8005\u4ee3\u7406\u548c\u8ba1\u7b97\u5668\u4ee3\u7406\u4e3a\u6570\u503c\u95ee\u9898\u56de\u7b54\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6ca1\u6709\u6807\u51c6\u6807\u7b7e\u7684\u60c5\u51b5\u4e0b\u3002\u4ee3\u7406\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u4e5f\u5bf9\u5176\u6027\u80fd\u4ea7\u751f\u4e86\u91cd\u8981\u5f71\u54cd\u3002"}}
{"id": "2506.08729", "pdf": "https://arxiv.org/pdf/2506.08729", "abs": "https://arxiv.org/abs/2506.08729", "authors": ["Dieuwertje Alblas", "Patryk Rygiel", "Julian Suk", "Kaj O. Kappe", "Marieke Hofman", "Christoph Brune", "Kak Khee Yeung", "Jelmer M. Wolterink"], "title": "Geometric deep learning for local growth prediction on abdominal aortic aneurysm surfaces", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Abdominal aortic aneurysms (AAAs) are progressive focal dilatations of the\nabdominal aorta. AAAs may rupture, with a survival rate of only 20\\%. Current\nclinical guidelines recommend elective surgical repair when the maximum AAA\ndiameter exceeds 55 mm in men or 50 mm in women. Patients that do not meet\nthese criteria are periodically monitored, with surveillance intervals based on\nthe maximum AAA diameter. However, this diameter does not take into account the\ncomplex relation between the 3D AAA shape and its growth, making standardized\nintervals potentially unfit. Personalized AAA growth predictions could improve\nmonitoring strategies. We propose to use an SE(3)-symmetric transformer model\nto predict AAA growth directly on the vascular model surface enriched with\nlocal, multi-physical features. In contrast to other works which have\nparameterized the AAA shape, this representation preserves the vascular\nsurface's anatomical structure and geometric fidelity. We train our model using\na longitudinal dataset of 113 computed tomography angiography (CTA) scans of 24\nAAA patients at irregularly sampled intervals. After training, our model\npredicts AAA growth to the next scan moment with a median diameter error of\n1.18 mm. We further demonstrate our model's utility to identify whether a\npatient will become eligible for elective repair within two years (acc = 0.93).\nFinally, we evaluate our model's generalization on an external validation set\nconsisting of 25 CTAs from 7 AAA patients from a different hospital. Our\nresults show that local directional AAA growth prediction from the vascular\nsurface is feasible and may contribute to personalized surveillance strategies.", "AI": {"tldr": "The paper proposes an SE(3)-symmetric transformer model for predicting abdominal aortic aneurysm (AAA) growth using 3D vascular models and multi-physical features. The model is trained on longitudinal CTA scans, achieving a median diameter error of 1.18 mm and high accuracy in identifying patients likely to need repair within two years.", "motivation": "Current clinical guidelines for monitoring AAAs rely solely on maximum diameter thresholds, which do not account for the complex relationship between 3D AAA shape and its growth. This can lead to suboptimal surveillance intervals. Personalized growth predictions could improve patient monitoring strategies.", "method": "An SE(3)-symmetric transformer model is used to predict AAA growth directly on the vascular surface enriched with local, multi-physical features. The model preserves anatomical structure and geometric fidelity unlike other parameterized approaches. It is trained on a longitudinal dataset of 113 CTA scans from 24 patients at irregular intervals.", "result": "The model achieves a median diameter error of 1.18 mm when predicting AAA growth to the next scan moment. It also accurately identifies patients who will become eligible for elective repair within two years with an accuracy of 0.93. External validation on a different hospital's dataset demonstrates generalization potential.", "conclusion": "Local directional AAA growth prediction from the vascular surface is feasible and may contribute to personalized surveillance strategies for AAA patients."}}
{"id": "2506.08263", "pdf": "https://arxiv.org/pdf/2506.08263", "abs": "https://arxiv.org/abs/2506.08263", "authors": ["Pouya Agheli", "Tugce Kobal", "Fran\u00e7ois Durand", "Matthew Andrews"], "title": "Learning-Based Multiuser Scheduling in MIMO-OFDM Systems with Hybrid Beamforming", "categories": ["cs.IT", "cs.LG", "eess.SP", "math.IT"], "comment": "To appear in the proceedings of the European Conference on Networks\n  and Communications (EuCNC) & 6G Summit, 2025", "summary": "We investigate the multiuser scheduling problem in multiple-input\nmultiple-output (MIMO) systems using orthogonal frequency division multiplexing\n(OFDM) and hybrid beamforming in which a base station (BS) communicates with\nmultiple users over millimeter wave (mmWave) channels in the downlink. Improved\nscheduling is critical for enhancing spectral efficiency and the long-term\nperformance of the system from the perspective of proportional fairness (PF)\nmetric in hybrid beamforming systems due to its limited multiplexing gain. Our\nobjective is to maximize PF by properly designing the analog and digital\nprecoders within the hybrid beamforming and selecting the users subject to the\nnumber of radio frequency (RF) chains. Leveraging the characteristics of mmWave\nchannels, we apply a two-timescale protocol. On a long timescale, we assign an\nanalog beam to each user. Scheduling the users and designing the digital\nprecoder are done accordingly on a short timescale. To conduct scheduling, we\npropose combinatorial solutions, such as greedy and sorting algorithms,\nfollowed by a machine learning (ML) approach. Our numerical results highlight\nthe trade-off between the performance and complexity of the proposed\napproaches. Consequently, we show that the choice of approach depends on the\nspecific criteria within a given scenario.", "AI": {"tldr": "In this paper, we investigate the multiuser scheduling problem in MIMO systems using OFDM and hybrid beamforming for mmWave channels. We aim to maximize proportional fairness by designing analog and digital precoders and selecting users based on the number of RF chains.", "motivation": "Improved scheduling is critical for enhancing spectral efficiency and long-term performance from the perspective of proportional fairness (PF) metric in hybrid beamforming systems due to its limited multiplexing gain.", "method": "Leveraging the characteristics of mmWave channels, a two-timescale protocol is applied. On a long timescale, an analog beam is assigned to each user. Scheduling the users and designing the digital precoder are done accordingly on a short timescale. Combinatorial solutions like greedy and sorting algorithms followed by a machine learning approach are proposed for scheduling.", "result": "Numerical results show the trade-off between the performance and complexity of the proposed approaches.", "conclusion": "The choice of approach depends on the specific criteria within a given scenario."}}
{"id": "2506.08276", "pdf": "https://arxiv.org/pdf/2506.08276", "abs": "https://arxiv.org/abs/2506.08276", "authors": ["Yichuan Wang", "Shu Liu", "Zhifei Li", "Yongji Wu", "Ziming Mao", "Yilong Zhao", "Xiao Yan", "Zhiying Xu", "Yang Zhou", "Ion Stoica", "Sewon Min", "Matei Zaharia", "Joseph E. Gonzalez"], "title": "LEANN: A Low-Storage Vector Index", "categories": ["cs.DB", "cs.LG"], "comment": null, "summary": "Embedding-based search is widely used in applications such as recommendation\nand retrieval-augmented generation (RAG). Recently, there is a growing demand\nto support these capabilities over personal data stored locally on devices.\nHowever, maintaining the necessary data structure associated with the\nembedding-based search is often infeasible due to its high storage overhead.\nFor example, indexing 100 GB of raw data requires 150 to 700 GB of storage,\nmaking local deployment impractical. Reducing this overhead while maintaining\nsearch quality and latency becomes a critical challenge. In this paper, we\npresent LEANN, a storage-efficient approximate nearest neighbor (ANN) search\nindex optimized for resource-constrained personal devices. LEANN combines a\ncompact graph-based structure with an efficient on-the-fly recomputation\nstrategy to enable fast and accurate retrieval with minimal storage overhead.\nOur evaluation shows that LEANN reduces index size to under 5% of the original\nraw data, achieving up to 50 times smaller storage than standard indexes, while\nmaintaining 90% top-3 recall in under 2 seconds on real-world question\nanswering benchmarks.", "AI": {"tldr": "LEANN is a storage-efficient ANN search index for personal devices, reducing index size to 5% of raw data with 90% recall and fast retrieval.", "motivation": "There is a growing need to perform embedding-based search on personal data stored locally on devices, but the high storage overhead of traditional methods makes local deployment impractical.", "method": "LEANN combines a compact graph-based structure with an efficient recomputation strategy to achieve fast and accurate retrieval with minimal storage.", "result": "LEANN reduces index size to under 5% of the original data, achieving 50 times smaller storage than standard indexes, while maintaining 90% top-3 recall in under 2 seconds.", "conclusion": "LEANN provides a solution for resource-constrained personal devices by significantly reducing storage requirements for embedding-based search without sacrificing quality or speed."}}
{"id": "2506.08738", "pdf": "https://arxiv.org/pdf/2506.08738", "abs": "https://arxiv.org/abs/2506.08738", "authors": ["Dror Kris Markus", "Fabrizio Gilardi", "Daria Stetsenko"], "title": "Societal AI Research Has Become Less Interdisciplinary", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": null, "summary": "As artificial intelligence (AI) systems become deeply embedded in everyday\nlife, calls to align AI development with ethical and societal values have\nintensified. Interdisciplinary collaboration is often championed as a key\npathway for fostering such engagement. Yet it remains unclear whether\ninterdisciplinary research teams are actually leading this shift in practice.\nThis study analyzes over 100,000 AI-related papers published on ArXiv between\n2014 and 2024 to examine how ethical values and societal concerns are\nintegrated into technical AI research. We develop a classifier to identify\nsocietal content and measure the extent to which research papers express these\nconsiderations. We find a striking shift: while interdisciplinary teams remain\nmore likely to produce societally-oriented research, computer science-only\nteams now account for a growing share of the field's overall societal output.\nThese teams are increasingly integrating societal concerns into their papers\nand tackling a wide range of domains - from fairness and safety to healthcare\nand misinformation. These findings challenge common assumptions about the\ndrivers of societal AI and raise important questions. First, what are the\nimplications for emerging understandings of AI safety and governance if most\nsocietally-oriented research is being undertaken by exclusively technical\nteams? Second, for scholars in the social sciences and humanities: in a\ntechnical field increasingly responsive to societal demands, what distinctive\nperspectives can we still offer to help shape the future of AI?", "AI": {"tldr": "This study analyzes over 100,000 AI-related papers to examine how ethical values and societal concerns are integrated into technical AI research.", "motivation": "To determine whether interdisciplinary research teams are leading the shift towards aligning AI development with ethical and societal values.", "method": "Developed a classifier to identify societal content in AI-related papers published on ArXiv between 2014 and 2024.", "result": "Interdisciplinary teams remain more likely to produce societally-oriented research, but computer science-only teams now account for a growing share of the field's overall societal output.", "conclusion": "The findings challenge common assumptions about the drivers of societal AI and raise questions about the implications for AI safety and governance if most societally-oriented research is being undertaken by exclusively technical teams."}}
{"id": "2506.08743", "pdf": "https://arxiv.org/pdf/2506.08743", "abs": "https://arxiv.org/abs/2506.08743", "authors": ["Michael F\u00e4rber", "David Lamprecht", "Yuni Susanti"], "title": "Bridging RDF Knowledge Graphs with Graph Neural Networks for Semantically-Rich Recommender Systems", "categories": ["cs.IR", "cs.AI", "cs.DB", "cs.LG"], "comment": "Accepted at DASFAA 2025", "summary": "Graph Neural Networks (GNNs) have substantially advanced the field of\nrecommender systems. However, despite the creation of more than a thousand\nknowledge graphs (KGs) under the W3C standard RDF, their rich semantic\ninformation has not yet been fully leveraged in GNN-based recommender systems.\nTo address this gap, we propose a comprehensive integration of RDF KGs with\nGNNs that utilizes both the topological information from RDF object properties\nand the content information from RDF datatype properties. Our main focus is an\nin-depth evaluation of various GNNs, analyzing how different semantic feature\ninitializations and types of graph structure heterogeneity influence their\nperformance in recommendation tasks. Through experiments across multiple\nrecommendation scenarios involving multi-million-node RDF graphs, we\ndemonstrate that harnessing the semantic richness of RDF KGs significantly\nimproves recommender systems and lays the groundwork for GNN-based recommender\nsystems for the Linked Open Data cloud. The code and data are available on our\nGitHub repository: https://github.com/davidlamprecht/rdf-gnn-recommendation", "AI": {"tldr": "Graph Neural Networks (GNNs) have advanced recommender systems, but the semantic information of RDF knowledge graphs hasn't been fully utilized. This paper proposes integrating RDF KGs with GNNs, demonstrating that using RDF's rich semantics enhances recommendation performance.", "motivation": "To leverage the rich semantic information from over a thousand RDF knowledge graphs in GNN-based recommender systems.", "method": "Comprehensive integration of RDF KGs with GNNs using both topological and content information from RDF properties. In-depth evaluation of various GNNs considering different semantic feature initializations and graph structure heterogeneity.", "result": "Experiments with multi-million-node RDF graphs show significant improvement in recommender systems by utilizing the semantic richness of RDF KGs.", "conclusion": "The approach lays the foundation for future GNN-based recommender systems for the Linked Open Data cloud."}}
{"id": "2506.08753", "pdf": "https://arxiv.org/pdf/2506.08753", "abs": "https://arxiv.org/abs/2506.08753", "authors": ["Pradyoth Hegde", "Santosh Kesiraju", "Jan \u0160vec", "\u0160imon Sedl\u00e1\u010dek", "Bolaji Yusuf", "Old\u0159ich Plchot", "Deepak K T", "Jan \u010cernock\u00fd"], "title": "Factors affecting the in-context learning abilities of LLMs for dialogue state tracking", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to Interspeech 2025", "summary": "This study explores the application of in-context learning (ICL) to the\ndialogue state tracking (DST) problem and investigates the factors that\ninfluence its effectiveness. We use a sentence embedding based k-nearest\nneighbour method to retrieve the suitable demonstrations for ICL. The selected\ndemonstrations, along with the test samples, are structured within a template\nas input to the LLM. We then conduct a systematic study to analyse the impact\nof factors related to demonstration selection and prompt context on DST\nperformance. This work is conducted using the MultiWoZ2.4 dataset and focuses\nprimarily on the OLMo-7B-instruct, Mistral-7B-Instruct-v0.3, and\nLlama3.2-3B-Instruct models. Our findings provide several useful insights on\nin-context learning abilities of LLMs for dialogue state tracking.", "AI": {"tldr": "This study explores the application of in-context learning (ICL) to dialogue state tracking (DST), using a sentence embedding based k-nearest neighbour method for demonstration selection and testing on the MultiWoZ2.4 dataset with several LLMs.", "motivation": "To investigate the effectiveness of in-context learning in dialogue state tracking and understand the factors influencing its performance.", "method": "A sentence embedding based k-nearest neighbour method is used to retrieve suitable demonstrations for ICL, which are then structured within a template as input to LLMs such as OLMo-7B-instruct, Mistral-7B-Instruct-v0.3, and Llama3.2-3B-Instruct.", "result": "The systematic study analyses the impact of factors related to demonstration selection and prompt context on DST performance, providing useful insights into the in-context learning abilities of LLMs.", "conclusion": "In-context learning can be effectively applied to dialogue state tracking, with significant impacts from demonstration selection and prompt context."}}
{"id": "2506.08325", "pdf": "https://arxiv.org/pdf/2506.08325", "abs": "https://arxiv.org/abs/2506.08325", "authors": ["Marcos Matabuena", "Rahul Ghosal", "Pavlo Mozharovskyi", "Oscar Hernan Madrid Padilla", "Jukka-Pekka Onnela"], "title": "Model-Free Kernel Conformal Depth Measures Algorithm for Uncertainty Quantification in Regression Models in Separable Hilbert Spaces", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": "arXiv admin note: substantial text overlap with arXiv:2405.13970", "summary": "Depth measures are powerful tools for defining level sets in emerging,\nnon--standard, and complex random objects such as high-dimensional multivariate\ndata, functional data, and random graphs. Despite their favorable theoretical\nproperties, the integration of depth measures into regression modeling to\nprovide prediction regions remains a largely underexplored area of research. To\naddress this gap, we propose a novel, model-free uncertainty quantification\nalgorithm based on conditional depth measures--specifically, conditional kernel\nmean embeddings and an integrated depth measure. These new algorithms can be\nused to define prediction and tolerance regions when predictors and responses\nare defined in separable Hilbert spaces. The use of kernel mean embeddings\nensures faster convergence rates in prediction region estimation. To enhance\nthe practical utility of the algorithms with finite samples, we also introduce\na conformal prediction variant that provides marginal, non-asymptotic\nguarantees for the derived prediction regions. Additionally, we establish both\nconditional and unconditional consistency results, as well as fast convergence\nrates in certain homoscedastic settings. We evaluate the finite--sample\nperformance of our model in extensive simulation studies involving various\ntypes of functional data and traditional Euclidean scenarios. Finally, we\ndemonstrate the practical relevance of our approach through a digital health\napplication related to physical activity, aiming to provide personalized\nrecommendations", "AI": {"tldr": "\u672c\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6df1\u5ea6\u6d4b\u91cf\u7684\u65e0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b97\u6cd5\uff0c\u7ed3\u5408\u6838\u5747\u503c\u5d4c\u5165\u548c\u4e00\u81f4\u6027\u9884\u6d4b\u53d8\u4f53\uff0c\u7528\u4e8e\u5b9a\u4e49\u9884\u6d4b\u548c\u5bb9\u5fcd\u533a\u57df\uff0c\u5e76\u8bc1\u660e\u4e86\u5176\u5728\u529f\u80fd\u6570\u636e\u548c\u6b27\u51e0\u91cc\u5f97\u573a\u666f\u4e2d\u7684\u6709\u6548\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u6df1\u5ea6\u6d4b\u91cf\u662f\u5904\u7406\u9ad8\u7ef4\u591a\u53d8\u91cf\u6570\u636e\u3001\u529f\u80fd\u6570\u636e\u548c\u968f\u673a\u56fe\u7b49\u590d\u6742\u968f\u673a\u5bf9\u8c61\u7684\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u5c06\u5176\u6574\u5408\u5230\u56de\u5f52\u6a21\u578b\u4e2d\u4ee5\u63d0\u4f9b\u9884\u6d4b\u533a\u57df\u7684\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6df1\u5ea6\u6d4b\u91cf\u7684\u65b0\u9896\u65e0\u6a21\u578b\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u7b97\u6cd5\uff0c\u5229\u7528\u6761\u4ef6\u6838\u5747\u503c\u5d4c\u5165\u548c\u7efc\u5408\u6df1\u5ea6\u6d4b\u91cf\u6765\u5b9a\u4e49\u9884\u6d4b\u548c\u5bb9\u5fcd\u533a\u57df\uff1b\u5f15\u5165\u4e86\u7b26\u5408\u9884\u6d4b\u53d8\u4f53\u4ee5\u63d0\u9ad8\u6709\u9650\u6837\u672c\u7684\u5b9e\u9645\u6548\u7528\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6a21\u62df\u7814\u7a76\u9a8c\u8bc1\u4e86\u8be5\u6a21\u578b\u5728\u5404\u79cd\u529f\u80fd\u6570\u636e\u548c\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u573a\u666f\u4e2d\u7684\u6709\u9650\u6837\u672c\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u6570\u5b57\u5065\u5eb7\u5e94\u7528\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u76f8\u5173\u6027\u3002", "conclusion": "\u8be5\u7b97\u6cd5\u5728\u9884\u6d4b\u533a\u57df\u4f30\u8ba1\u4e2d\u5177\u6709\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u4e14\u5728\u67d0\u4e9b\u540c\u65b9\u5dee\u8bbe\u7f6e\u4e0b\u5177\u6709\u4e00\u81f4\u6027\u548c\u5feb\u901f\u6536\u655b\u7387\u3002"}}
{"id": "2506.08756", "pdf": "https://arxiv.org/pdf/2506.08756", "abs": "https://arxiv.org/abs/2506.08756", "authors": ["Octavio Arriaga", "Rebecca Adam", "Melvin Laux", "Lisa Gutzeit", "Marco Ragni", "Jan Peters", "Frank Kirchner"], "title": "Bayesian Inverse Physics for Neuro-Symbolic Robot Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Real-world robotic applications, from autonomous exploration to assistive\ntechnologies, require adaptive, interpretable, and data-efficient learning\nparadigms. While deep learning architectures and foundation models have driven\nsignificant advances in diverse robotic applications, they remain limited in\ntheir ability to operate efficiently and reliably in unknown and dynamic\nenvironments. In this position paper, we critically assess these limitations\nand introduce a conceptual framework for combining data-driven learning with\ndeliberate, structured reasoning. Specifically, we propose leveraging\ndifferentiable physics for efficient world modeling, Bayesian inference for\nuncertainty-aware decision-making, and meta-learning for rapid adaptation to\nnew tasks. By embedding physical symbolic reasoning within neural models,\nrobots could generalize beyond their training data, reason about novel\nsituations, and continuously expand their knowledge. We argue that such hybrid\nneuro-symbolic architectures are essential for the next generation of\nautonomous systems, and to this end, we provide a research roadmap to guide and\naccelerate their development.", "AI": {"tldr": "\u5728\u5b9e\u9645\u7684\u673a\u5668\u4eba\u5e94\u7528\u4e2d\uff0c\u5c3d\u7ba1\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u548c\u57fa\u7840\u6a21\u578b\u63a8\u52a8\u4e86\u591a\u6837\u5316\u673a\u5668\u4eba\u5e94\u7528\u7684\u663e\u8457\u8fdb\u6b65\uff0c\u4f46\u5b83\u4eec\u5728\u672a\u77e5\u548c\u52a8\u6001\u73af\u5883\u4e2d\u7684\u9ad8\u6548\u548c\u53ef\u9760\u64cd\u4f5c\u80fd\u529b\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u7684\u6982\u5ff5\u6846\u67b6\uff0c\u5f3a\u8c03\u4f7f\u7528\u53ef\u5fae\u7269\u7406\u8fdb\u884c\u4e16\u754c\u5efa\u6a21\u3001\u8d1d\u53f6\u65af\u63a8\u65ad\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u51b3\u7b56\u4ee5\u53ca\u5143\u5b66\u4e60\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\u65b0\u4efb\u52a1\u3002\u8fd9\u79cd\u6df7\u5408\u795e\u7ecf-\u7b26\u53f7\u67b6\u6784\u5bf9\u4e8e\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u5e76\u63d0\u4f9b\u4e86\u7814\u7a76\u8def\u7ebf\u56fe\u4ee5\u6307\u5bfc\u5176\u53d1\u5c55\u3002", "motivation": "\u5f53\u524d\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u548c\u57fa\u7840\u6a21\u578b\u867d\u7136\u5728\u8bb8\u591a\u673a\u5668\u4eba\u5e94\u7528\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u9762\u5bf9\u672a\u77e5\u548c\u52a8\u6001\u73af\u5883\u65f6\uff0c\u5176\u6570\u636e\u6548\u7387\u3001\u9002\u5e94\u6027\u548c\u53ef\u9760\u6027\u4ecd\u663e\u4e0d\u8db3\u3002\u8fd9\u4fc3\u4f7f\u7814\u7a76\u8005\u63a2\u7d22\u4e00\u79cd\u65b0\u7684\u5b66\u4e60\u8303\u5f0f\uff0c\u80fd\u591f\u66f4\u597d\u5730\u9002\u5e94\u8fd9\u4e9b\u6311\u6218\u6027\u573a\u666f\u3002", "method": "\u63d0\u51fa\u7ed3\u5408\u6570\u636e\u9a71\u52a8\u5b66\u4e60\u4e0e\u7ed3\u6784\u5316\u63a8\u7406\u7684\u6846\u67b6\uff0c\u5177\u4f53\u5305\u62ec\uff1a1) \u4f7f\u7528\u53ef\u5fae\u7269\u7406\u8fdb\u884c\u9ad8\u6548\u7684\u4e16\u754c\u5efa\u6a21\uff1b2) \u5229\u7528\u8d1d\u53f6\u65af\u63a8\u65ad\u8fdb\u884c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7684\u51b3\u7b56\uff1b3) \u901a\u8fc7\u5143\u5b66\u4e60\u5b9e\u73b0\u5bf9\u65b0\u4efb\u52a1\u7684\u5feb\u901f\u9002\u5e94\u3002\u6b64\u5916\uff0c\u8fd8\u5efa\u8bae\u5c06\u7269\u7406\u7b26\u53f7\u63a8\u7406\u5d4c\u5165\u795e\u7ecf\u6a21\u578b\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u8be5\u6982\u5ff5\u6846\u67b6\u6709\u671b\u4f7f\u673a\u5668\u4eba\u8d85\u8d8a\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u6cdb\u5316\uff0c\u5728\u65b0\u60c5\u51b5\u4e0b\u8fdb\u884c\u63a8\u7406\uff0c\u5e76\u6301\u7eed\u6269\u5c55\u77e5\u8bc6\uff0c\u4ece\u800c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u9002\u5e94\u548c\u66f4\u53ef\u9760\u7684\u6027\u80fd\u3002", "conclusion": "\u6df7\u5408\u795e\u7ecf-\u7b26\u53f7\u67b6\u6784\u5bf9\u4e8e\u5f00\u53d1\u4e0b\u4e00\u4ee3\u81ea\u4e3b\u7cfb\u7edf\u81f3\u5173\u91cd\u8981\uff0c\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7814\u7a76\u8def\u7ebf\u56fe\uff0c\u4ee5\u4fc3\u8fdb\u6b64\u7c7b\u67b6\u6784\u7684\u53d1\u5c55\u548c\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2506.08774", "pdf": "https://arxiv.org/pdf/2506.08774", "abs": "https://arxiv.org/abs/2506.08774", "authors": ["Fan Xu", "Luis A. Leiva"], "title": "Multimodal Representation Alignment for Cross-modal Information Retrieval", "categories": ["cs.IR", "cs.AI"], "comment": null, "summary": "Different machine learning models can represent the same underlying concept\nin different ways. This variability is particularly valuable for in-the-wild\nmultimodal retrieval, where the objective is to identify the corresponding\nrepresentation in one modality given another modality as input. This challenge\ncan be effectively framed as a feature alignment problem. For example, given a\nsentence encoded by a language model, retrieve the most semantically aligned\nimage based on features produced by an image encoder, or vice versa. In this\nwork, we first investigate the geometric relationships between visual and\ntextual embeddings derived from both vision-language models and combined\nunimodal models. We then align these representations using four standard\nsimilarity metrics as well as two learned ones, implemented via neural\nnetworks. Our findings indicate that the Wasserstein distance can serve as an\ninformative measure of the modality gap, while cosine similarity consistently\noutperforms alternative metrics in feature alignment tasks. Furthermore, we\nobserve that conventional architectures such as multilayer perceptrons are\ninsufficient for capturing the complex interactions between image and text\nrepresentations. Our study offers novel insights and practical considerations\nfor researchers working in multimodal information retrieval, particularly in\nreal-world, cross-modal applications.", "AI": {"tldr": "This paper explores the alignment of visual and textual embeddings using various similarity metrics for multimodal retrieval. It finds that cosine similarity performs best and highlights challenges in capturing complex interactions between modalities.", "motivation": "To improve multimodal retrieval by understanding how to effectively align representations from different modalities, such as images and text.", "method": "Investigating geometric relationships between embeddings from vision-language models and unimodal models, then aligning them using six similarity metrics (four standard and two learned via neural networks).", "result": "Wasserstein distance is useful for measuring modality gaps, cosine similarity outperforms other metrics in feature alignment tasks, and simple architectures like multilayer perceptrons are insufficient for complex interactions.", "conclusion": "The study provides insights and practical advice for multimodal information retrieval, especially for real-world cross-modal applications."}}
{"id": "2506.08338", "pdf": "https://arxiv.org/pdf/2506.08338", "abs": "https://arxiv.org/abs/2506.08338", "authors": ["Ryoichi Asashiba", "Reiji Kozuma", "Hirokazu Iwasawa"], "title": "midr: Learning from Black-Box Models by Maximum Interpretation Decomposition", "categories": ["stat.ME", "cs.LG"], "comment": "20 pages, 10 figures", "summary": "The use of appropriate methods of Interpretable Machine Learning (IML) and\neXplainable Artificial Intelligence (XAI) is essential for adopting black-box\npredictive models in fields where model and prediction explainability is\nrequired. As a novel tool for interpreting black-box models, we introduce the R\npackage midr, which implements Maximum Interpretation Decomposition (MID). MID\nis a functional decomposition approach that derives a low-order additive\nrepresentation of a black-box model by minimizing the squared error between the\nmodel's prediction function and this additive representation. midr enables\nlearning from black-box models by constructing a global surrogate model with\nadvanced analytical capabilities. After reviewing related work and the\ntheoretical foundation of MID, we demonstrate the package's usage and discuss\nsome of its key features.", "AI": {"tldr": "This paper presents the R package midr, which implements Maximum Interpretation Decomposition (MID) as a tool for interpreting black-box models through constructing a global surrogate model.", "motivation": "There is a need for interpretable machine learning methods in fields where model explainability is required. The authors aim to provide a novel tool for interpreting black-box models.", "method": "The method introduced is Maximum Interpretation Decomposition (MID), implemented in the R package midr. MID creates a low-order additive representation of a black-box model by minimizing the squared error between the model's prediction function and this representation.", "result": "The package midr was created and demonstrated, providing a way to learn from black-box models using a global surrogate model with advanced analytical capabilities.", "conclusion": "midr offers a valuable tool for interpreting black-box models via the MID approach, contributing to the field of Interpretable Machine Learning."}}
{"id": "2506.08785", "pdf": "https://arxiv.org/pdf/2506.08785", "abs": "https://arxiv.org/abs/2506.08785", "authors": ["Mukul Lokhande", "Santosh Kumar Vishvakarma"], "title": "POLARON: Precision-aware On-device Learning and Adaptive Runtime-cONfigurable AI acceleration", "categories": ["cs.AR", "cs.AI", "cs.CC", "eess.IV"], "comment": null, "summary": "The increasing complexity of AI models requires flexible hardware capable of\nsupporting diverse precision formats, particularly for energy-constrained edge\nplatforms. This work presents PARV-CE, a SIMD-enabled, multi-precision MAC\nengine that performs efficient multiply-accumulate operations using a unified\ndata-path for 4/8/16-bit fixed-point, floating point, and posit formats. The\narchitecture incorporates a layer adaptive precision strategy to align\ncomputational accuracy with workload sensitivity, optimizing both performance\nand energy usage. PARV-CE integrates quantization-aware execution with a\nreconfigurable SIMD pipeline, enabling high-throughput processing with minimal\noverhead through hardware-software co-design. The results demonstrate up to 2x\nimprovement in PDP and 3x reduction in resource usage compared to SoTA designs,\nwhile retaining accuracy within 1.8% FP32 baseline. The architecture supports\nboth on-device training and inference across a range of workloads, including\nDNNs, RNNs, RL, and Transformer models. The empirical analysis establish PARVCE\nincorporated POLARON as a scalable and energy-efficient solution for\nprecision-adaptive AI acceleration at edge.", "AI": {"tldr": "PARV-CE is a multi-precision MAC engine that efficiently handles various precision formats, optimizes performance and energy usage with layer adaptive precision strategy, shows significant improvements over current designs, and supports both training and inference for multiple AI models at the edge.", "motivation": "The motivation is to develop flexible hardware capable of supporting diverse precision formats in increasingly complex AI models, especially for energy-constrained edge platforms.", "method": "The method involves creating PARV-CE, a SIMD-enabled, multi-precision MAC engine that uses a unified data-path for different bit fixed-point, floating point, and posit formats. It incorporates a layer adaptive precision strategy and integrates quantization-aware execution with a reconfigurable SIMD pipeline.", "result": "The results show up to 2x improvement in PDP and 3x reduction in resource usage compared to state-of-the-art designs while retaining accuracy within 1.8% FP32 baseline.", "conclusion": "PARV-CE incorporated POLARON is established as a scalable and energy-efficient solution for precision-adaptive AI acceleration at the edge."}}
{"id": "2506.08790", "pdf": "https://arxiv.org/pdf/2506.08790", "abs": "https://arxiv.org/abs/2506.08790", "authors": ["Samarth Sikand", "Rohit Mehra", "Vibhu Saujanya Sharma", "Vikrant Kaulgud", "Sanjay Podder", "Adam P. Burden"], "title": "Do Generative AI Tools Ensure Green Code? An Investigative Study", "categories": ["cs.SE", "cs.AI", "cs.CY"], "comment": "4 pages. To be published in the proceedings of 2nd International\n  Workshop on Responsible AI Engineering (RAIE '24), co-located with ICSE '24,\n  Lisbon, Portugal", "summary": "Software sustainability is emerging as a primary concern, aiming to optimize\nresource utilization, minimize environmental impact, and promote a greener,\nmore resilient digital ecosystem. The sustainability or \"greenness\" of software\nis typically determined by the adoption of sustainable coding practices. With a\nmaturing ecosystem around generative AI, many software developers now rely on\nthese tools to generate code using natural language prompts. Despite their\npotential advantages, there is a significant lack of studies on the\nsustainability aspects of AI-generated code. Specifically, how environmentally\nfriendly is the AI-generated code based upon its adoption of sustainable coding\npractices? In this paper, we present the results of an early investigation into\nthe sustainability aspects of AI-generated code across three popular generative\nAI tools - ChatGPT, BARD, and Copilot. The results highlight the default\nnon-green behavior of tools for generating code, across multiple rules and\nscenarios. It underscores the need for further in-depth investigations and\neffective remediation strategies.", "AI": {"tldr": "This paper explores the sustainability of AI-generated code from three popular tools, finding them generally non-green and in need of improvement.", "motivation": "To understand how environmentally friendly AI-generated code is based on its adoption of sustainable coding practices.", "method": "Investigation into the sustainability aspects of AI-generated code across ChatGPT, BARD, and Copilot.", "result": "These generative AI tools exhibit default non-green behavior in producing code across multiple rules and scenarios.", "conclusion": "There is a need for further investigations and remediation strategies to enhance the sustainability of AI-generated code."}}
{"id": "2506.08362", "pdf": "https://arxiv.org/pdf/2506.08362", "abs": "https://arxiv.org/abs/2506.08362", "authors": ["Lesi Chen", "Chengchang Liu", "Luo Luo", "Jingzhao Zhang"], "title": "Solving Convex-Concave Problems with $\\tilde{\\mathcal{O}}(\u03b5^{-4/7})$ Second-Order Oracle Complexity", "categories": ["math.OC", "cs.LG"], "comment": "COLT 2025", "summary": "Previous algorithms can solve convex-concave minimax problems $\\min_{x \\in\n\\mathcal{X}} \\max_{y \\in \\mathcal{Y}} f(x,y)$ with\n$\\mathcal{O}(\\epsilon^{-2/3})$ second-order oracle calls using Newton-type\nmethods. This result has been speculated to be optimal because the upper bound\nis achieved by a natural generalization of the optimal first-order method. In\nthis work, we show an improved upper bound of\n$\\tilde{\\mathcal{O}}(\\epsilon^{-4/7})$ by generalizing the optimal second-order\nmethod for convex optimization to solve the convex-concave minimax problem. We\nfurther apply a similar technique to lazy Hessian algorithms and show that our\nproposed algorithm can also be seen as a second-order ``Catalyst'' framework\n(Lin et al., JMLR 2018) that could accelerate any globally convergent\nalgorithms for solving minimax problems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.08795", "pdf": "https://arxiv.org/pdf/2506.08795", "abs": "https://arxiv.org/abs/2506.08795", "authors": ["Kaijie Shi", "Wanglong Lu", "Hanli Zhao", "Vinicius Prado da Fonseca", "Ting Zou", "Xianta Jiang"], "title": "Towards Biosignals-Free Autonomous Prosthetic Hand Control via Imitation Learning", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Limb loss affects millions globally, impairing physical function and reducing\nquality of life. Most traditional surface electromyographic (sEMG) and\nsemi-autonomous methods require users to generate myoelectric signals for each\ncontrol, imposing physically and mentally taxing demands. This study aims to\ndevelop a fully autonomous control system that enables a prosthetic hand to\nautomatically grasp and release objects of various shapes using only a camera\nattached to the wrist. By placing the hand near an object, the system will\nautomatically execute grasping actions with a proper grip force in response to\nthe hand's movements and the environment. To release the object being grasped,\njust naturally place the object close to the table and the system will\nautomatically open the hand. Such a system would provide individuals with limb\nloss with a very easy-to-use prosthetic control interface and greatly reduce\nmental effort while using. To achieve this goal, we developed a teleoperation\nsystem to collect human demonstration data for training the prosthetic hand\ncontrol model using imitation learning, which mimics the prosthetic hand\nactions from human. Through training the model using only a few objects' data\nfrom one single participant, we have shown that the imitation learning\nalgorithm can achieve high success rates, generalizing to more individuals and\nunseen objects with a variation of weights. The demonstrations are available at\n\\href{https://sites.google.com/view/autonomous-prosthetic-hand}{https://sites.google.com/view/autonomous-prosthetic-hand}", "AI": {"tldr": "This paper presents a fully autonomous prosthetic hand control system using a camera, reducing the physical and mental burden on users with limb loss.", "motivation": "To address the challenges faced by individuals with limb loss when using traditional sEMG and semi-autonomous methods that require generating myoelectric signals for each control.", "method": "Developed a teleoperation system to collect human demonstration data for training the prosthetic hand control model using imitation learning, which mimics prosthetic hand actions from humans.", "result": "The imitation learning algorithm achieved high success rates, generalizing to more individuals and unseen objects with a variation of weights, using data from only a few objects and one participant.", "conclusion": "This autonomous system provides an easy-to-use prosthetic control interface, significantly reducing the mental effort required for operation."}}
{"id": "2506.08381", "pdf": "https://arxiv.org/pdf/2506.08381", "abs": "https://arxiv.org/abs/2506.08381", "authors": ["He Yang", "Fei Ren", "Hai-Sui Yu", "Xueyu Geng", "Pei-Zhi Zhuang"], "title": "TS-PIELM: Time-Stepping Physics-Informed Extreme Learning Machine Facilitates Soil Consolidation Analyses", "categories": ["physics.geo-ph", "cs.LG"], "comment": null, "summary": "Accuracy and efficiency of the conventional physics-informed neural network\n(PINN) need to be improved before it can be a competitive alternative for soil\nconsolidation analyses. This paper aims to overcome these limitations by\nproposing a highly accurate and efficient physics-informed machine learning\n(PIML) approach, termed time-stepping physics-informed extreme learning machine\n(TS-PIELM). In the TS-PIELM framework the consolidation process is divided into\nnumerous time intervals, which helps overcome the limitation of PIELM in\nsolving differential equations with sharp gradients. To accelerate network\ntraining, the solution is approximated by a single-layer feedforward extreme\nlearning machine (ELM), rather than using a fully connected neural network in\nPINN. The input layer weights of the ELM network are generated randomly and\nfixed during the training process. Subsequently, the output layer weights are\ndirectly computed by solving a system of linear equations, which significantly\nenhances the training efficiency compared to the time-consuming gradient\ndescent method in PINN. Finally, the superior performance of TS-PIELM is\ndemonstrated by solving three typical Terzaghi consolidation problems. Compared\nto PINN, results show that the computational efficiency and accuracy of the\nnovel TS-PIELM framework are improved by more than 1000 times and 100 times for\none-dimensional cases, respectively. This paper provides compelling evidence\nthat PIML can be a powerful tool for computational geotechnics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u65b9\u6cd5TS-PIELM\uff0c\u7528\u4e8e\u571f\u58e4\u56fa\u7ed3\u5206\u6790\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684PINN\uff0c\u5176\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u5206\u522b\u63d0\u9ad8\u4e861000\u500d\u548c100\u500d\u3002", "motivation": "\u4f20\u7edf\u7684\u7269\u7406\u4fe1\u606f\u795e\u7ecf\u7f51\u7edc\uff08PINN\uff09\u5728\u571f\u58e4\u56fa\u7ed3\u5206\u6790\u4e2d\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u9700\u8981\u6539\u8fdb\u3002", "method": "\u901a\u8fc7\u5c06\u56fa\u7ed3\u8fc7\u7a0b\u5212\u5206\u4e3a\u591a\u4e2a\u65f6\u95f4\u95f4\u9694\uff0c\u5e76\u91c7\u7528\u5355\u5c42\u524d\u9988\u6781\u9650\u5b66\u4e60\u673a\uff08ELM\uff09\u8fd1\u4f3c\u89e3\uff0c\u800c\u4e0d\u662fPINN\u4e2d\u7684\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u3002\u8f93\u5165\u5c42\u6743\u91cd\u968f\u673a\u751f\u6210\u5e76\u56fa\u5b9a\uff0c\u8f93\u51fa\u5c42\u6743\u91cd\u901a\u8fc7\u6c42\u89e3\u7ebf\u6027\u65b9\u7a0b\u7ec4\u76f4\u63a5\u8ba1\u7b97\uff0c\u4ece\u800c\u663e\u8457\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387\u3002", "result": "\u5bf9\u4e8e\u4e00\u7ef4\u60c5\u51b5\uff0c\u4e0ePINN\u76f8\u6bd4\uff0c\u65b0\u578bTS-PIELM\u6846\u67b6\u7684\u8ba1\u7b97\u6548\u7387\u548c\u51c6\u786e\u6027\u5206\u522b\u63d0\u9ad8\u4e861000\u500d\u548c100\u500d\u3002", "conclusion": "TS-PIELM\u5c55\u793a\u4e86\u5353\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u53ef\u4ee5\u6210\u4e3a\u8ba1\u7b97\u5ca9\u571f\u529b\u5b66\u7684\u5f3a\u5927\u5de5\u5177\u3002"}}
{"id": "2506.08822", "pdf": "https://arxiv.org/pdf/2506.08822", "abs": "https://arxiv.org/abs/2506.08822", "authors": ["Yifei Su", "Ning Liu", "Dong Chen", "Zhen Zhao", "Kun Wu", "Meng Li", "Zhiyuan Xu", "Zhengping Che", "Jian Tang"], "title": "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Generative modeling-based visuomotor policies have been widely adopted in\nrobotic manipulation attributed to their ability to model multimodal action\ndistributions. However, the high inference cost of multi-step sampling limits\ntheir applicability in real-time robotic systems. To address this issue,\nexisting approaches accelerate the sampling process in generative\nmodeling-based visuomotor policies by adapting acceleration techniques\noriginally developed for image generation. Despite this progress, a major\ndistinction remains: image generation typically involves producing independent\nsamples without temporal dependencies, whereas robotic manipulation involves\ngenerating time-series action trajectories that require continuity and temporal\ncoherence. To effectively exploit temporal information in robotic manipulation,\nwe propose FreqPolicy, a novel approach that first imposes frequency\nconsistency constraints on flow-based visuomotor policies. Our work enables the\naction model to capture temporal structure effectively while supporting\nefficient, high-quality one-step action generation. We introduce a frequency\nconsistency constraint that enforces alignment of frequency-domain action\nfeatures across different timesteps along the flow, thereby promoting\nconvergence of one-step action generation toward the target distribution. In\naddition, we design an adaptive consistency loss to capture structural temporal\nvariations inherent in robotic manipulation tasks. We assess FreqPolicy on 53\ntasks across 3 simulation benchmarks, proving its superiority over existing\none-step action generators. We further integrate FreqPolicy into the\nvision-language-action (VLA) model and achieve acceleration without performance\ndegradation on the 40 tasks of Libero. Besides, we show efficiency and\neffectiveness in real-world robotic scenarios with an inference frequency\n93.5Hz. The code will be publicly available.", "AI": {"tldr": "The paper introduces FreqPolicy, a new method that improves real-time robotic manipulation by efficiently generating high-quality action sequences with temporal coherence.", "motivation": "Generative modeling-based visuomotor policies are effective for robotic manipulation but suffer from high inference costs due to multi-step sampling. Current acceleration techniques adapted from image generation do not fully address the temporal dependencies required in robotic manipulation.", "method": "The authors propose FreqPolicy, which incorporates frequency consistency constraints into flow-based visuomotor policies. This allows for efficient one-step action generation while maintaining temporal coherence. An adaptive consistency loss is also introduced to handle structural temporal variations in robotic tasks.", "result": "FreqPolicy outperforms existing one-step action generators on 53 tasks across 3 simulation benchmarks. When integrated into the VLA model, it maintains performance without degradation on 40 Libero tasks and demonstrates efficiency in real-world scenarios with an inference frequency of 93.5Hz.", "conclusion": "FreqPolicy successfully exploits temporal information for robotic manipulation, providing both efficiency and effectiveness in generating action trajectories. The approach shows superiority over existing methods and will be made publicly available."}}
{"id": "2506.08827", "pdf": "https://arxiv.org/pdf/2506.08827", "abs": "https://arxiv.org/abs/2506.08827", "authors": ["Francisco Vargas", "Alejandro Gonz\u00e1lez Coene", "Gaston Escalante", "Exequiel Lob\u00f3n", "Manuel Pulido"], "title": "The impact of fine tuning in LLaMA on hallucinations for named entity extraction in legal documentation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The extraction of information about traffic accidents from legal documents is\ncrucial for quantifying insurance company costs. Extracting entities such as\npercentages of physical and/or psychological disability and the involved\ncompensation amounts is a challenging process, even for experts, due to the\nsubtle arguments and reasoning in the court decision. A two-step procedure is\nproposed: first, segmenting the document identifying the most relevant\nsegments, and then extracting the entities. For text segmentation, two\nmethodologies are compared: a classic method based on regular expressions and a\nsecond approach that divides the document into blocks of n-tokens, which are\nthen vectorized using multilingual models for semantic searches\n(text-embedding-ada-002/MiniLM-L12-v2 ). Subsequently, large language models\n(LLaMA-2 7b, 70b, LLaMA-3 8b, and GPT-4 Turbo) are applied with prompting to\nthe selected segments for entity extraction. For the LLaMA models, fine-tuning\nis performed using LoRA. LLaMA-2 7b, even with zero temperature, shows a\nsignificant number of hallucinations in extractions which are an important\ncontention point for named entity extraction. This work shows that these\nhallucinations are substantially reduced after finetuning the model. The\nperformance of the methodology based on segment vectorization and subsequent\nuse of LLMs significantly surpasses the classic method which achieves an\naccuracy of 39.5%. Among open-source models, LLaMA-2 70B with finetuning\nachieves the highest accuracy 79.4%, surpassing its base version 61.7%.\nNotably, the base LLaMA-3 8B model already performs comparably to the finetuned\nLLaMA-2 70B model, achieving 76.6%, highlighting the rapid progress in model\ndevelopment. Meanwhile, GPT-4 Turbo achieves the highest accuracy at 86.1%.", "AI": {"tldr": "\u4fdd\u9669\u6587\u4ef6\u4e2d\u4ea4\u901a\u4e8b\u6545\u4fe1\u606f\u7684\u63d0\u53d6\u5bf9\u91cf\u5316\u4fdd\u9669\u516c\u53f8\u6210\u672c\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u6b65\u6cd5\uff1a\u9996\u5148\u901a\u8fc7\u4e24\u79cd\u65b9\u6cd5\u5206\u5272\u6587\u6863\u4ee5\u8bc6\u522b\u6700\u76f8\u5173\u7684\u6bb5\u843d\uff0c\u7136\u540e\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\u3002\u7ecf\u8fc7\u5fae\u8c03\uff0cLLaMA-2 7b \u7684\u5e7b\u89c9\u95ee\u9898\u663e\u8457\u51cf\u5c11\u3002\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\uff0c\u5fae\u8c03\u540e\u7684LLaMA-2 70B\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u8fbe79.4%\uff0c\u800cGPT-4 Turbo\u5219\u8fbe\u5230\u4e8686.1%\u7684\u6700\u9ad8\u51c6\u786e\u7387\u3002", "motivation": "\u4ece\u6cd5\u5f8b\u6587\u4ef6\u4e2d\u63d0\u53d6\u6709\u5173\u4ea4\u901a\u610f\u5916\u7684\u4fe1\u606f\u5bf9\u4e8e\u91cf\u5316\u4fdd\u9669\u516c\u53f8\u7684\u6210\u672c\u81f3\u5173\u91cd\u8981\uff0c\u7136\u800c\u8fd9\u4e00\u8fc7\u7a0b\u5145\u6ee1\u6311\u6218\uff0c\u5373\u4f7f\u662f\u5bf9\u4e13\u5bb6\u6765\u8bf4\u4e5f\u662f\u5982\u6b64\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u6b65\u6cd5\uff1a\u9996\u5148\uff0c\u901a\u8fc7\u57fa\u4e8e\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u65b9\u6cd5\u548c\u5c06\u6587\u6863\u5206\u4e3an\u4e2a\u6807\u8bb0\u5757\u5e76\u4f7f\u7528\u591a\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u8bed\u4e49\u641c\u7d22\u7684\u65b9\u6cd5\u6765\u5206\u5272\u6587\u6863\uff1b\u5176\u6b21\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982LLaMA-2\u3001GPT-4 Turbo\u7b49\uff09\u8fdb\u884c\u5b9e\u4f53\u63d0\u53d6\uff0c\u5e76\u5bf9LLaMA\u6a21\u578b\u8fdb\u884c\u4e86LoRA\u5fae\u8c03\u3002", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u57fa\u4e8e\u6bb5\u843d\u5411\u91cf\u5316\u548c\u540e\u7eed\u4f7f\u7528LLMs\u7684\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u6027\u80fd\u3002\u5728\u5f00\u6e90\u6a21\u578b\u4e2d\uff0c\u5fae\u8c03\u540e\u7684LLaMA-2 70B\u51c6\u786e\u7387\u8fbe\u523079.4%\uff0c\u8d85\u8fc7\u57fa\u7840\u7248\u672c\u768461.7%\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u57fa\u7840LLaMA-3 8B\u6a21\u578b\u7684\u8868\u73b0\u5df2\u4e0e\u5fae\u8c03\u540e\u7684LLaMA-2 70B\u76f8\u5f53\uff0c\u8fbe\u523076.6%\u3002\u540c\u65f6\uff0cGPT-4 Turbo\u7684\u51c6\u786e\u7387\u6700\u9ad8\uff0c\u8fbe\u523086.1%\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u5b9e\u4f53\u63d0\u53d6\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c24\u5176\u5728\u5fae\u8c03\u540e\u5927\u5e45\u51cf\u5c11\u4e86LLaMA-2 7b\u7684\u5e7b\u89c9\u95ee\u9898\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5176\u4e2dGPT-4 Turbo\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u5f00\u6e90\u6a21\u578b\u4e5f\u53d6\u5f97\u4e86\u4ee4\u4eba\u77a9\u76ee\u7684\u8fdb\u6b65\u3002"}}
{"id": "2506.08400", "pdf": "https://arxiv.org/pdf/2506.08400", "abs": "https://arxiv.org/abs/2506.08400", "authors": ["Luel Hagos Beyene", "Vivek Verma", "Min Ma", "Jesujoba O. Alabi", "Fabian David Schmidt", "Joyce Nakatumba-Nabende", "David Ifeoluwa Adelani"], "title": "mSTEB: Massively Multilingual Evaluation of LLMs on Speech and Text Tasks", "categories": ["cs.CL", "cs.LG", "cs.SD", "eess.AS"], "comment": "working paper", "summary": "Large Language models (LLMs) have demonstrated impressive performance on a\nwide range of tasks, including in multimodal settings such as speech. However,\ntheir evaluation is often limited to English and a few high-resource languages.\nFor low-resource languages, there is no standardized evaluation benchmark. In\nthis paper, we address this gap by introducing mSTEB, a new benchmark to\nevaluate the performance of LLMs on a wide range of tasks covering language\nidentification, text classification, question answering, and translation tasks\non both speech and text modalities. We evaluated the performance of leading\nLLMs such as Gemini 2.0 Flash and GPT-4o (Audio) and state-of-the-art open\nmodels such as Qwen 2 Audio and Gemma 3 27B. Our evaluation shows a wide gap in\nperformance between high-resource and low-resource languages, especially for\nlanguages spoken in Africa and Americas/Oceania. Our findings show that more\ninvestment is needed to address their under-representation in LLMs coverage.", "AI": {"tldr": "Large Language Models (LLMs) excel in various tasks but lack standardized evaluation for low-resource languages. This paper introduces mSTEB, a benchmark addressing this gap by evaluating LLMs on tasks like language identification, text classification, question answering, and translation across speech and text modalities. Evaluations of leading LLMs reveal significant performance disparities between high and low-resource languages, particularly in Africa and Americas/Oceania, indicating the need for more investment to address under-representation.", "motivation": "To create a standardized evaluation benchmark for low-resource languages, which are currently underrepresented in the evaluation of Large Language Models (LLMs).", "method": "Introduction of mSTEB, a new benchmark that evaluates LLMs on tasks including language identification, text classification, question answering, and translation across both speech and text modalities.", "result": "Significant performance gaps exist between high-resource and low-resource languages, especially affecting languages spoken in Africa and Americas/Oceania.", "conclusion": "More investment is required to improve the representation of low-resource languages in LLMs."}}
{"id": "2506.08835", "pdf": "https://arxiv.org/pdf/2506.08835", "abs": "https://arxiv.org/abs/2506.08835", "authors": ["Shravan Nayak", "Mehar Bhatia", "Xiaofeng Zhang", "Verena Rieser", "Lisa Anne Hendricks", "Sjoerd van Steenkiste", "Yash Goyal", "Karolina Sta\u0144czak", "Aishwarya Agrawal"], "title": "CulturalFrames: Assessing Cultural Expectation Alignment in Text-to-Image Models and Evaluation Metrics", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "The increasing ubiquity of text-to-image (T2I) models as tools for visual\ncontent generation raises concerns about their ability to accurately represent\ndiverse cultural contexts. In this work, we present the first study to\nsystematically quantify the alignment of T2I models and evaluation metrics with\nrespect to both explicit as well as implicit cultural expectations. To this\nend, we introduce CulturalFrames, a novel benchmark designed for rigorous human\nevaluation of cultural representation in visual generations. Spanning 10\ncountries and 5 socio-cultural domains, CulturalFrames comprises 983 prompts,\n3637 corresponding images generated by 4 state-of-the-art T2I models, and over\n10k detailed human annotations. We find that T2I models not only fail to meet\nthe more challenging implicit expectations but also the less challenging\nexplicit expectations. Across models and countries, cultural expectations are\nmissed an average of 44% of the time. Among these failures, explicit\nexpectations are missed at a surprisingly high average rate of 68%, while\nimplicit expectation failures are also significant, averaging 49%. Furthermore,\nwe demonstrate that existing T2I evaluation metrics correlate poorly with human\njudgments of cultural alignment, irrespective of their internal reasoning.\nCollectively, our findings expose critical gaps, providing actionable\ndirections for developing more culturally informed T2I models and evaluation\nmethodologies.", "AI": {"tldr": "The paper presents CulturalFrames, a benchmark for evaluating how well text-to-image models meet cultural expectations across 10 countries and 5 socio-cultural domains. It finds that these models fail to meet both explicit and implicit cultural expectations at high rates, and current evaluation metrics poorly correlate with human judgments.", "motivation": "There is growing concern about the ability of text-to-image (T2I) models to accurately represent diverse cultural contexts as they become more prevalent in visual content generation.", "method": "Introduced CulturalFrames, a novel benchmark consisting of 983 prompts, 3637 images generated by 4 state-of-the-art T2I models, and over 10k human annotations. This benchmark evaluates cultural representation in visual generations across 10 countries and 5 socio-cultural domains.", "result": "T2I models fail to meet cultural expectations an average of 44% of the time, with explicit expectations missed at a rate of 68% and implicit expectation failures averaging 49%. Existing T2I evaluation metrics poorly correlate with human judgments of cultural alignment.", "conclusion": "The findings reveal critical gaps in T2I models and evaluation methodologies, providing directions for developing more culturally informed T2I models."}}
{"id": "2506.08423", "pdf": "https://arxiv.org/pdf/2506.08423", "abs": "https://arxiv.org/abs/2506.08423", "authors": ["Utkarsh Pratiush", "Austin Houston", "Kamyar Barakati", "Aditya Raghavan", "Dasol Yoon", "Harikrishnan KP", "Zhaslan Baraissov", "Desheng Ma", "Samuel S. Welborn", "Mikolaj Jakowski", "Shawn-Patrick Barhorst", "Alexander J. Pattison", "Panayotis Manganaris", "Sita Sirisha Madugula", "Sai Venkata Gayathri Ayyagari", "Vishal Kennedy", "Ralph Bulanadi", "Michelle Wang", "Kieran J. Pang", "Ian Addison-Smith", "Willy Menacho", "Horacio V. Guzman", "Alexander Kiefer", "Nicholas Furth", "Nikola L. Kolev", "Mikhail Petrov", "Viktoriia Liu", "Sergey Ilyev", "Srikar Rairao", "Tommaso Rodani", "Ivan Pinto-Huguet", "Xuli Chen", "Josep Crua\u00f1es", "Marta Torrens", "Jovan Pomar", "Fanzhi Su", "Pawan Vedanti", "Zhiheng Lyu", "Xingzhi Wang", "Lehan Yao", "Amir Taqieddin", "Forrest Laskowski", "Xiangyu Yin", "Yu-Tsun Shao", "Benjamin Fein-Ashley", "Yi Jiang", "Vineet Kumar", "Himanshu Mishra", "Yogesh Paul", "Adib Bazgir", "Rama chandra Praneeth Madugula", "Yuwen Zhang", "Pravan Omprakash", "Jian Huang", "Eric Montufar-Morales", "Vivek Chawla", "Harshit Sethi", "Jie Huang", "Lauri Kurki", "Grace Guinan", "Addison Salvador", "Arman Ter-Petrosyan", "Madeline Van Winkle", "Steven R. Spurgeon", "Ganesh Narasimha", "Zijie Wu", "Richard Liu", "Yongtao Liu", "Boris Slautin", "Andrew R Lupini", "Rama Vasudevan", "Gerd Duscher", "Sergei V. Kalinin"], "title": "Mic-hackathon 2024: Hackathon on Machine Learning for Electron and Scanning Probe Microscopy", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.ins-det"], "comment": null, "summary": "Microscopy is a primary source of information on materials structure and\nfunctionality at nanometer and atomic scales. The data generated is often\nwell-structured, enriched with metadata and sample histories, though not always\nconsistent in detail or format. The adoption of Data Management Plans (DMPs) by\nmajor funding agencies promotes preservation and access. However, deriving\ninsights remains difficult due to the lack of standardized code ecosystems,\nbenchmarks, and integration strategies. As a result, data usage is inefficient\nand analysis time is extensive. In addition to post-acquisition analysis, new\nAPIs from major microscope manufacturers enable real-time, ML-based analytics\nfor automated decision-making and ML-agent-controlled microscope operation.\nYet, a gap remains between the ML and microscopy communities, limiting the\nimpact of these methods on physics, materials discovery, and optimization.\nHackathons help bridge this divide by fostering collaboration between ML\nresearchers and microscopy experts. They encourage the development of novel\nsolutions that apply ML to microscopy, while preparing a future workforce for\ninstrumentation, materials science, and applied ML. This hackathon produced\nbenchmark datasets and digital twins of microscopes to support community growth\nand standardized workflows. All related code is available at GitHub:\nhttps://github.com/KalininGroup/Mic-hackathon-2024-codes-publication/tree/1.0.0.1", "AI": {"tldr": "Hackathons foster collaboration between ML researchers and microscopy experts to bridge the gap, producing benchmark datasets and digital twins of microscopes.", "motivation": "To address the inefficiency in data usage and extensive analysis time in microscopy due to lack of standardized code ecosystems, benchmarks, and integration strategies.", "method": "Organizing hackathons that bring together ML researchers and microscopy experts to develop novel solutions applying ML to microscopy.", "result": "Produced benchmark datasets and digital twins of microscopes, supporting community growth and standardized workflows.", "conclusion": "All related code is made available publicly on GitHub to facilitate further development and collaboration."}}
{"id": "2506.08854", "pdf": "https://arxiv.org/pdf/2506.08854", "abs": "https://arxiv.org/abs/2506.08854", "authors": ["Junzhuo Liu", "Markus Eckstein", "Zhixiang Wang", "Friedrich Feuerhake", "Dorit Merhof"], "title": "Spatial Transcriptomics Expression Prediction from Histopathology Based on Cross-Modal Mask Reconstruction and Contrastive Learning", "categories": ["cs.CV", "cs.AI"], "comment": "20 pages, 7 figures", "summary": "Spatial transcriptomics is a technology that captures gene expression levels\nat different spatial locations, widely used in tumor microenvironment analysis\nand molecular profiling of histopathology, providing valuable insights into\nresolving gene expression and clinical diagnosis of cancer. Due to the high\ncost of data acquisition, large-scale spatial transcriptomics data remain\nchallenging to obtain. In this study, we develop a contrastive learning-based\ndeep learning method to predict spatially resolved gene expression from\nwhole-slide images. Evaluation across six different disease datasets\ndemonstrates that, compared to existing studies, our method improves Pearson\nCorrelation Coefficient (PCC) in the prediction of highly expressed genes,\nhighly variable genes, and marker genes by 6.27%, 6.11%, and 11.26%\nrespectively. Further analysis indicates that our method preserves gene-gene\ncorrelations and applies to datasets with limited samples. Additionally, our\nmethod exhibits potential in cancer tissue localization based on biomarker\nexpression.", "AI": {"tldr": "An abstract about a study developing a contrastive learning-based deep learning method to predict spatially resolved gene expression from whole-slide images, improving prediction accuracy and exhibiting potential in cancer tissue localization.", "motivation": "To address the challenge of obtaining large-scale spatial transcriptomics data due to high cost, and to improve the prediction accuracy of spatially resolved gene expression from whole-slide images.", "method": "Develop a contrastive learning-based deep learning method for predicting spatially resolved gene expression from whole-slide images.", "result": "Improved Pearson Correlation Coefficient (PCC) in predicting highly expressed genes, highly variable genes, and marker genes by 6.27%, 6.11%, and 11.26% respectively, preserved gene-gene correlations, and applied to datasets with limited samples.", "conclusion": "The developed method improves prediction accuracy of spatially resolved gene expression and shows potential in cancer tissue localization based on biomarker expression."}}
{"id": "2506.08428", "pdf": "https://arxiv.org/pdf/2506.08428", "abs": "https://arxiv.org/abs/2506.08428", "authors": ["Evan Markou", "Thalaiyasingam Ajanthan", "Stephen Gould"], "title": "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings", "categories": ["math.OC", "cs.LG"], "comment": "37 pages, 5 figures", "summary": "Many high-dimensional optimisation problems exhibit rich geometric structures\nin their set of minimisers, often forming smooth manifolds due to\nover-parametrisation or symmetries. When this structure is known, at least\nlocally, it can be exploited through reduction mappings that reparametrise part\nof the parameter space to lie on the solution manifold. These reductions\nnaturally arise from inner optimisation problems and effectively remove\nredundant directions, yielding a lower-dimensional objective. In this work, we\nintroduce a general framework to understand how such reductions influence the\noptimisation landscape. We show that well-designed reduction mappings improve\ncurvature properties of the objective, leading to better-conditioned problems\nand theoretically faster convergence for gradient-based methods. Our analysis\nunifies a range of scenarios where structural information at optimality is\nleveraged to accelerate convergence, offering a principled explanation for the\nempirical gains observed in such optimisation algorithms.", "AI": {"tldr": "The paper explores how reduction mappings that exploit geometric structures in high-dimensional optimisation problems can improve the optimisation landscape, leading to faster convergence for gradient-based methods.", "motivation": "Many high-dimensional optimisation problems have rich geometric structures in their minimisers, which can form smooth manifolds due to over-parametrisation or symmetries. Exploiting these structures could potentially enhance optimisation algorithms.", "method": "The authors introduce a general framework to understand the influence of reduction mappings on the optimisation landscape. These mappings reparametrise part of the parameter space to lie on the solution manifold, effectively removing redundant directions and yielding a lower-dimensional objective.", "result": "Well-designed reduction mappings are shown to improve curvature properties of the objective, resulting in better-conditioned problems and theoretically faster convergence for gradient-based methods.", "conclusion": "This analysis unifies various scenarios where structural information is used to accelerate convergence, providing a principled explanation for the empirical gains observed in such optimisation algorithms."}}
{"id": "2506.08860", "pdf": "https://arxiv.org/pdf/2506.08860", "abs": "https://arxiv.org/abs/2506.08860", "authors": ["Samah Kansab", "Francis Bordeleau", "Ali Tizghadam"], "title": "On The Impact of Merge Request Deviations on Code Review Practices", "categories": ["cs.SE", "cs.AI", "cs.LG"], "comment": null, "summary": "Code review is a key practice in software engineering, ensuring quality and\ncollaboration. However, industrial Merge Request (MR) workflows often deviate\nfrom standardized review processes, with many MRs serving non-review purposes\n(e.g., drafts, rebases, or dependency updates). We term these cases deviations\nand hypothesize that ignoring them biases analytics and undermines ML models\nfor review analysis.\n  We identify seven deviation categories, occurring in 37.02% of MRs, and\npropose a few-shot learning detection method (91% accuracy). By excluding\ndeviations, ML models predicting review completion time improve performance in\n53.33% of cases (up to 2.25x) and exhibit significant shifts in feature\nimportance (47% overall, 60% top-*k*).\n  Our contributions include: (1) a taxonomy of MR deviations, (2) an AI-driven\ndetection approach, and (3) empirical evidence of their impact on ML-based\nreview analytics. This work aids practitioners in optimizing review efforts and\nensuring reliable insights.", "AI": {"tldr": "In code review, many Merge Requests (MRs) deviate from standard review processes. These deviations, found in 37.02% of MRs and categorized into seven types, can bias analytics and ML models for review analysis. The authors propose a few-shot learning detection method with 91% accuracy to identify these deviations, which improves ML model performance on predicting review completion time by up to 2.25 times.", "motivation": "Code reviews are essential in software engineering, but many MRs in industrial workflows do not follow standardized review processes. Ignoring these deviations may bias analytics and undermine the reliability of ML models used for review analysis.", "method": "The researchers identified seven categories of deviations that occur in MRs and proposed a few-shot learning method to detect them with 91% accuracy. By excluding these deviations, they retrained ML models to predict review completion time and analyzed changes in model performance and feature importance.", "result": "Excluding deviations led to improved ML model performance in 53.33% of cases, with some models performing up to 2.25 times better. There were also significant shifts in feature importance, indicating the impact of deviations on model behavior.", "conclusion": "This work contributes a taxonomy of MR deviations, an AI-driven detection approach, and empirical evidence of their effects on ML-based review analytics. It helps practitioners optimize code review processes and ensures more reliable insights."}}
{"id": "2506.08433", "pdf": "https://arxiv.org/pdf/2506.08433", "abs": "https://arxiv.org/abs/2506.08433", "authors": ["Hern\u00e1n Maina", "Nicol\u00e1s Wolovick", "Luciana Benotti"], "title": "Low-resource domain adaptation while minimizing energy and hardware resource consumption", "categories": ["cs.CL", "cs.DC", "cs.LG"], "comment": "A shorter version of this work was accepted as a two-page abstract\n  for presentation at the Widening Natural Language Processing (WiNLP) 2023\n  Workshop. That version was not publicly released, and this is the first\n  public version of the work", "summary": "Training Large Language Models (LLMs) is costly in terms of energy, hardware,\nand annotated data, often resulting in a positionality rooted in predominant\ncultures and values (Santy et al., 2023). Domain adaptation has emerged as a\npromising strategy to better align models with diverse cultural and value\ncontexts (Hershcovich et al., 2022), but its computational cost remains a\nsignificant barrier, particularly for research groups lacking access to\nlarge-scale infrastructure. In this paper, we evaluate how the use of different\nnumerical precisions and data parallelization strategies impacts both training\nspeed (as a proxy to energy and hardware consumption) and model accuracy, with\nthe goal of facilitating domain adaptation in low-resource environments. Our\nfindings are relevant to any setting where energy efficiency, accessibility, or\nlimited hardware availability are key concerns.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4e0d\u540c\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u5bf9\u8bad\u7ec3\u901f\u5ea6\u53ca\u6a21\u578b\u51c6\u786e\u6027\u7684\u5f71\u54cd\uff0c\u65e8\u5728\u4e3a\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u9886\u57df\u9002\u914d\u63d0\u4f9b\u652f\u6301\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u8bad\u7ec3\u5728\u80fd\u6e90\u3001\u786c\u4ef6\u548c\u6807\u6ce8\u6570\u636e\u65b9\u9762\u6210\u672c\u9ad8\u6602\uff0c\u5e76\u4e14\u5f80\u5f80\u5bfc\u81f4\u6839\u690d\u4e8e\u4e3b\u6d41\u6587\u5316\u4e0e\u4ef7\u503c\u89c2\u7684\u503e\u5411\u6027\u3002\u5c3d\u7ba1\u9886\u57df\u9002\u914d\u80fd\u66f4\u597d\u5730\u4f7f\u6a21\u578b\u4e0e\u591a\u5143\u6587\u5316\u548c\u4ef7\u503c\u80cc\u666f\u76f8\u5339\u914d\uff0c\u4f46\u5176\u8ba1\u7b97\u6210\u672c\u4ecd\u7136\u662f\u4e00\u4e2a\u91cd\u5927\u969c\u788d\uff0c\u5c24\u5176\u5bf9\u4e8e\u7f3a\u4e4f\u5927\u89c4\u6a21\u57fa\u7840\u8bbe\u65bd\u7684\u7814\u7a76\u56e2\u961f\u800c\u8a00\u3002", "method": "\u8bc4\u4f30\u4f7f\u7528\u4e0d\u540c\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\u5bf9\u8bad\u7ec3\u901f\u5ea6\uff08\u4f5c\u4e3a\u80fd\u6e90\u548c\u786c\u4ef6\u6d88\u8017\u7684\u4ee3\u7406\uff09\u4ee5\u53ca\u6a21\u578b\u51c6\u786e\u6027\u7684\u53cc\u91cd\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u7ed3\u679c\u9002\u7528\u4e8e\u4efb\u4f55\u4ee5\u80fd\u6e90\u6548\u7387\u3001\u53ef\u8bbf\u95ee\u6027\u6216\u6709\u9650\u786c\u4ef6\u53ef\u7528\u6027\u4e3a\u6838\u5fc3\u5173\u6ce8\u70b9\u7684\u573a\u666f\u3002", "conclusion": "\u901a\u8fc7\u4f18\u5316\u6570\u503c\u7cbe\u5ea6\u548c\u6570\u636e\u5e76\u884c\u5316\u7b56\u7565\uff0c\u53ef\u4ee5\u6709\u6548\u63d0\u5347\u8bad\u7ec3\u6548\u7387\uff0c\u964d\u4f4e\u8d44\u6e90\u9700\u6c42\uff0c\u4ece\u800c\u63a8\u52a8\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u9886\u57df\u7684\u9002\u914d\u8fdb\u7a0b\u3002"}}
{"id": "2506.08436", "pdf": "https://arxiv.org/pdf/2506.08436", "abs": "https://arxiv.org/abs/2506.08436", "authors": ["Jiujun He", "Huazhen Lin"], "title": "Olica: Efficient Structured Pruning of Large Language Models without Retraining", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Most existing structured pruning methods for Large Language Models (LLMs)\nrequire substantial computational and data resources for retraining to\nreestablish the corrupted correlations, making them prohibitively expensive. To\naddress this, we propose a pruning framework for LLMs called Orthogonal\ndecomposition and Linear Calibration (Olica), which eliminates the need for\nretraining. A key observation is that the multi-head attention (MHA) layer\ndepends on two types of matrix products. By treating these matrix products as\nunified entities and applying principal component analysis (PCA), we extract\nthe most important information to compress LLMs without sacrificing accuracy or\ndisrupting their original structure. Consequently, retraining becomes\nunnecessary. A fast decomposition method is devised, reducing the complexity of\nPCA by a factor of the square of the number of attention heads. Additionally,\nto mitigate error accumulation problem caused by pruning the feed-forward\nnetwork (FFN) layer, we introduce a linear calibration method to reconstruct\nthe residual errors of pruned layers using low-rank matrices. By leveraging\nsingular value decomposition (SVD) on the solution of the least-squares\nproblem, these matrices are obtained without requiring retraining. Extensive\nexperiments show that the proposed Olica is efficient in terms of data usage,\nGPU memory, and running time, while delivering superior performance across\nmultiple benchmarks.", "AI": {"tldr": "The paper proposes Olica, a pruning framework for LLMs that eliminates the need for retraining by using PCA and linear calibration method, achieving efficient compression without sacrificing accuracy.", "motivation": "Most structured pruning methods for LLMs require significant computational and data resources for retraining to restore disrupted correlations.", "method": "Olica uses PCA to extract important information from unified matrix products in MHA layers and a linear calibration method involving SVD for low-rank reconstruction of residual errors in FFN layers.", "result": "Olica reduces the complexity of PCA, mitigates error accumulation, and delivers superior performance across benchmarks while being efficient in data usage, GPU memory, and running time.", "conclusion": "Olica is an efficient pruning framework for LLMs that eliminates the need for retraining."}}
{"id": "2506.08894", "pdf": "https://arxiv.org/pdf/2506.08894", "abs": "https://arxiv.org/abs/2506.08894", "authors": ["Yunzhi Zhang", "Carson Murtuza-Lanier", "Zizhang Li", "Yilun Du", "Jiajun Wu"], "title": "Product of Experts for Visual Generation", "categories": ["cs.CV", "cs.AI"], "comment": "Project page: https://product-of-experts.github.io/", "summary": "Modern neural models capture rich priors and have complementary knowledge\nover shared data domains, e.g., images and videos. Integrating diverse\nknowledge from multiple sources -- including visual generative models, visual\nlanguage models, and sources with human-crafted knowledge such as graphics\nengines and physics simulators -- remains under-explored. We propose a Product\nof Experts (PoE) framework that performs inference-time knowledge composition\nfrom heterogeneous models. This training-free approach samples from the product\ndistribution across experts via Annealed Importance Sampling (AIS). Our\nframework shows practical benefits in image and video synthesis tasks, yielding\nbetter controllability than monolithic methods and additionally providing\nflexible user interfaces for specifying visual generation goals.", "AI": {"tldr": "This paper proposes a Product of Experts (PoE) framework that performs inference-time knowledge composition from heterogeneous models using Annealed Importance Sampling (AIS), demonstrating its effectiveness in image and video synthesis tasks.", "motivation": "Modern neural models have rich priors and complementary knowledge over shared data domains, but integrating diverse knowledge from multiple sources remains under-explored.", "method": "The proposed method uses a Product of Experts (PoE) framework to perform inference-time knowledge composition from heterogeneous models. This training-free approach samples from the product distribution across experts via Annealed Importance Sampling (AIS).", "result": "The framework shows practical benefits in image and video synthesis tasks, yielding better controllability than monolithic methods and providing flexible user interfaces for specifying visual generation goals.", "conclusion": "The PoE framework with AIS provides an effective way to integrate diverse knowledge from multiple sources, enhancing controllability and user interaction in visual generation tasks."}}
{"id": "2506.08448", "pdf": "https://arxiv.org/pdf/2506.08448", "abs": "https://arxiv.org/abs/2506.08448", "authors": ["Hyakka Nakada", "Shu Tanaka"], "title": "Systematic and Efficient Construction of Quadratic Unconstrained Binary Optimization Forms for High-order and Dense Interactions", "categories": ["quant-ph", "cs.LG"], "comment": null, "summary": "Quantum Annealing (QA) can efficiently solve combinatorial optimization\nproblems whose objective functions are represented by Quadratic Unconstrained\nBinary Optimization (QUBO) formulations. For broader applicability of QA,\nquadratization methods are used to transform higher-order problems into QUBOs.\nHowever, quadratization methods for complex problems involving Machine Learning\n(ML) remain largely unknown. In these problems, strong nonlinearity and dense\ninteractions prevent conventional methods from being applied. Therefore, we\nmodel target functions by the sum of rectified linear unit bases, which not\nonly have the ability of universal approximation, but also have an equivalent\nquadratic-polynomial representation. In this study, the proof of concept is\nverified both numerically and analytically. In addition, by combining QA with\nthe proposed quadratization, we design a new black-box optimization scheme, in\nwhich ML surrogate regressors are inputted to QA after the quadratization\nprocess.", "AI": {"tldr": "Quantum Annealing (QA) can solve QUBO problems efficiently. To apply QA to higher-order problems in Machine Learning, this paper proposes modeling target functions with the sum of rectified linear unit bases. This method is proven effective both numerically and analytically. A new black-box optimization scheme combining QA and the proposed quadratization is designed for ML surrogate regressors.", "motivation": "To broaden the applicability of Quantum Annealing to complex Machine Learning problems that involve strong nonlinearity and dense interactions, which cannot be addressed by conventional quadratization methods.", "method": "Model target functions using the sum of rectified linear unit bases, which allows universal approximation and has an equivalent quadratic-polynomial representation. Verify the concept through numerical and analytical means. Combine Quantum Annealing with the proposed quadratization to create a new black-box optimization scheme for Machine Learning surrogate regressors.", "result": "The proof of concept was verified both numerically and analytically, demonstrating the effectiveness of the proposed method. A new optimization scheme was successfully designed.", "conclusion": "The proposed method of modeling target functions with rectified linear unit bases and combining it with Quantum Annealing provides a viable solution for complex Machine Learning problems, expanding the applicability of Quantum Annealing."}}
{"id": "2506.08897", "pdf": "https://arxiv.org/pdf/2506.08897", "abs": "https://arxiv.org/abs/2506.08897", "authors": ["Hiba Khey", "Amine Lakhder", "Salma Rouichi", "Imane El Ghabi", "Kamal Hejjaoui", "Younes En-nahli", "Fahd Kalloubi", "Moez Amri"], "title": "PlantBert: An Open Source Language Model for Plant Science", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The rapid advancement of transformer-based language models has catalyzed\nbreakthroughs in biomedical and clinical natural language processing; however,\nplant science remains markedly underserved by such domain-adapted tools. In\nthis work, we present PlantBert, a high-performance, open-source language model\nspecifically tailored for extracting structured knowledge from plant\nstress-response literature. Built upon the DeBERTa architecture-known for its\ndisentangled attention and robust contextual encoding-PlantBert is fine-tuned\non a meticulously curated corpus of expert-annotated abstracts, with a primary\nfocus on lentil (Lens culinaris) responses to diverse abiotic and biotic\nstressors. Our methodology combines transformer-based modeling with\nrule-enhanced linguistic post-processing and ontology-grounded entity\nnormalization, enabling PlantBert to capture biologically meaningful\nrelationships with precision and semantic fidelity. The underlying corpus is\nannotated using a hierarchical schema aligned with the Crop Ontology,\nencompassing molecular, physiological, biochemical, and agronomic dimensions of\nplant adaptation. PlantBert exhibits strong generalization capabilities across\nentity types and demonstrates the feasibility of robust domain adaptation in\nlow-resource scientific fields. By providing a scalable and reproducible\nframework for high-resolution entity recognition, PlantBert bridges a critical\ngap in agricultural NLP and paves the way for intelligent, data-driven systems\nin plant genomics, phenomics, and agronomic knowledge discovery. Our model is\npublicly released to promote transparency and accelerate cross-disciplinary\ninnovation in computational plant science.", "AI": {"tldr": "The paper introduces PlantBert, a domain-specific language model for plant stress-response literature based on DeBERTa architecture. It is fine-tuned on a corpus focused on lentil responses to stressors and combines transformer-based modeling with rule-enhanced linguistic post-processing. The model shows strong generalization capabilities and provides a framework for entity recognition in agricultural NLP.", "motivation": "There is a lack of domain-adapted tools in plant science despite advancements in transformer-based language models for biomedical and clinical natural language processing.", "method": "PlantBert is built upon the DeBERTa architecture and fine-tuned on a curated corpus of expert-annotated abstracts focusing on lentil stress responses. The methodology integrates transformer-based modeling with rule-enhanced linguistic post-processing and ontology-grounded entity normalization.", "result": "PlantBert demonstrates strong generalization capabilities across entity types and proves the feasibility of robust domain adaptation in low-resource scientific fields related to plant science.", "conclusion": "PlantBert addresses a critical gap in agricultural NLP by providing a scalable and reproducible framework for high-resolution entity recognition, promoting transparency and accelerating innovation in computational plant science."}}
{"id": "2506.08455", "pdf": "https://arxiv.org/pdf/2506.08455", "abs": "https://arxiv.org/abs/2506.08455", "authors": ["Julian Berberich", "Tobias Fellner", "Christian Holm"], "title": "The interplay of robustness and generalization in quantum machine learning", "categories": ["quant-ph", "cs.LG", "cs.SY", "eess.SY"], "comment": null, "summary": "While adversarial robustness and generalization have individually received\nsubstantial attention in the recent literature on quantum machine learning,\ntheir interplay is much less explored. In this chapter, we address this\ninterplay for variational quantum models, which were recently proposed as\nfunction approximators in supervised learning. We discuss recent results\nquantifying both robustness and generalization via Lipschitz bounds, which\nexplicitly depend on model parameters. Thus, they give rise to a\nregularization-based training approach for robust and generalizable quantum\nmodels, highlighting the importance of trainable data encoding strategies. The\npractical implications of the theoretical results are demonstrated with an\napplication to time series analysis.", "AI": {"tldr": "\u672c\u7ae0\u63a2\u8ba8\u4e86\u53d8\u5206\u91cf\u5b50\u6a21\u578b\u4e2d\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eLipschitz\u754c\u7684\u7ed3\u679c\uff0c\u5f3a\u8c03\u4e86\u53ef\u8bad\u7ec3\u6570\u636e\u7f16\u7801\u7b56\u7565\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5c55\u793a\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u3002", "motivation": "\u5c3d\u7ba1\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u5728\u91cf\u5b50\u673a\u5668\u5b66\u4e60\u7684\u8fd1\u671f\u6587\u732e\u4e2d\u5206\u522b\u53d7\u5230\u4e86\u5927\u91cf\u5173\u6ce8\uff0c\u4f46\u5b83\u4eec\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u5374\u5f88\u5c11\u88ab\u7814\u7a76\u3002", "method": "\u8ba8\u8bba\u4e86\u6700\u8fd1\u4f7f\u7528Lipschitz\u754c\u91cf\u5316\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u6027\u7684\u7ed3\u679c\uff0c\u8fd9\u4e9b\u7ed3\u679c\u660e\u786e\u4f9d\u8d56\u4e8e\u6a21\u578b\u53c2\u6570\uff0c\u4ece\u800c\u5f15\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u5316\u7684\u8bad\u7ec3\u65b9\u6cd5\u3002", "result": "\u8fd9\u79cd\u65b9\u6cd5\u7a81\u663e\u4e86\u53ef\u8bad\u7ec3\u6570\u636e\u7f16\u7801\u7b56\u7565\u5bf9\u4e8e\u6784\u5efa\u9c81\u68d2\u4e14\u5177\u6709\u6cdb\u5316\u80fd\u529b\u7684\u91cf\u5b50\u6a21\u578b\u7684\u91cd\u8981\u6027\uff0c\u5e76\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u5206\u6790\u5c55\u793a\u4e86\u7406\u8bba\u7ed3\u679c\u7684\u5b9e\u9645\u5f71\u54cd\u3002", "conclusion": "\u53ef\u8bad\u7ec3\u7684\u6570\u636e\u7f16\u7801\u7b56\u7565\u5bf9\u4e8e\u63d0\u9ad8\u53d8\u5206\u91cf\u5b50\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2506.08899", "pdf": "https://arxiv.org/pdf/2506.08899", "abs": "https://arxiv.org/abs/2506.08899", "authors": ["Elias Horner", "Cristinel Mateis", "Guido Governatori", "Agata Ciabattoni"], "title": "From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LO"], "comment": null, "summary": "We present a novel approach to the automated semantic analysis of legal texts\nusing large language models (LLMs), targeting their transformation into formal\nrepresentations in Defeasible Deontic Logic (DDL). We propose a structured\npipeline that segments complex normative language into atomic snippets,\nextracts deontic rules, and evaluates them for syntactic and semantic\ncoherence. Our methodology is evaluated across various LLM configurations,\nincluding prompt engineering strategies, fine-tuned models, and multi-stage\npipelines, focusing on legal norms from the Australian Telecommunications\nConsumer Protections Code. Empirical results demonstrate promising alignment\nbetween machine-generated and expert-crafted formalizations, showing that LLMs\n- particularly when prompted effectively - can significantly contribute to\nscalable legal informatics.", "AI": {"tldr": "The paper introduces an approach using LLMs for automating semantic analysis of legal texts, transforming them into formal representations in Defeasible Deontic Logic (DDL). It proposes a pipeline that segments normative language, extracts deontic rules, and evaluates coherence. Evaluated across various LLM configurations, the results indicate promising alignment between machine-generated and expert-crafted formalizations.", "motivation": "To automate the semantic analysis of legal texts and transform them into formal representations using Defeasible Deontic Logic (DDL) to improve scalability and accuracy in legal informatics.", "method": "A structured pipeline is proposed which includes segmenting complex normative language into atomic snippets, extracting deontic rules, and evaluating these rules for syntactic and semantic coherence. This methodology is tested across different LLM configurations including prompt engineering strategies, fine-tuned models, and multi-stage pipelines.", "result": "Empirical results show a promising alignment between machine-generated formalizations and those crafted by experts, especially when LLMs are effectively prompted.", "conclusion": "LLMs can significantly contribute to scalable legal informatics, particularly when appropriate prompting techniques are applied."}}
{"id": "2506.08915", "pdf": "https://arxiv.org/pdf/2506.08915", "abs": "https://arxiv.org/abs/2506.08915", "authors": ["Ananthu Aniraj", "Cassio F. Dantas", "Dino Ienco", "Diego Marcos"], "title": "Inherently Faithful Attention Maps for Vision Transformers", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We introduce an attention-based method that uses learned binary attention\nmasks to ensure that only attended image regions influence the prediction.\nContext can strongly affect object perception, sometimes leading to biased\nrepresentations, particularly when objects appear in out-of-distribution\nbackgrounds. At the same time, many image-level object-centric tasks require\nidentifying relevant regions, often requiring context. To address this\nconundrum, we propose a two-stage framework: stage 1 processes the full image\nto discover object parts and identify task-relevant regions, while stage 2\nleverages input attention masking to restrict its receptive field to these\nregions, enabling a focused analysis while filtering out potentially spurious\ninformation. Both stages are trained jointly, allowing stage 2 to refine stage\n1. Extensive experiments across diverse benchmarks demonstrate that our\napproach significantly improves robustness against spurious correlations and\nout-of-distribution backgrounds.", "AI": {"tldr": "An attention-based method with learned binary masks is introduced to ensure only attended image regions influence prediction, improving robustness against spurious correlations and out-of-distribution backgrounds.", "motivation": "Context can strongly affect object perception, sometimes leading to biased representations, particularly when objects appear in out-of-distribution backgrounds. Many image-level object-centric tasks require identifying relevant regions, often requiring context.", "method": "A two-stage framework is proposed: stage 1 processes the full image to discover object parts and identify task-relevant regions, while stage 2 leverages input attention masking to restrict its receptive field to these regions, enabling a focused analysis while filtering out potentially spurious information. Both stages are trained jointly.", "result": "Extensive experiments across diverse benchmarks demonstrate that the approach significantly improves robustness against spurious correlations and out-of-distribution backgrounds.", "conclusion": "The attention-based method using learned binary attention masks successfully ensures that only attended image regions influence the prediction, enhancing the model's robustness."}}
{"id": "2506.08917", "pdf": "https://arxiv.org/pdf/2506.08917", "abs": "https://arxiv.org/abs/2506.08917", "authors": ["Sascha M\u00fccke", "Raoul Heese", "Thore Gerlach", "David Biesner", "Loong Kuan Lee", "Nico Piatkowski"], "title": "Quantum Adiabatic Generation of Human-Like Passwords", "categories": ["quant-ph", "cs.AI"], "comment": "9 pages, 4 figures", "summary": "Generative Artificial Intelligence (GenAI) for Natural Language Processing\n(NLP) is the predominant AI technology to date. An important perspective for\nQuantum Computing (QC) is the question whether QC has the potential to reduce\nthe vast resource requirements for training and operating GenAI models. While\nlarge-scale generative NLP tasks are currently out of reach for practical\nquantum computers, the generation of short semantic structures such as\npasswords is not. Generating passwords that mimic real user behavior has many\napplications, for example to test an authentication system against realistic\nthreat models. Classical password generation via deep learning have recently\nbeen investigated with significant progress in their ability to generate novel,\nrealistic password candidates. In the present work we investigate the utility\nof adiabatic quantum computers for this task. More precisely, we study\ndifferent encodings of token strings and propose novel approaches based on the\nQuadratic Unconstrained Binary Optimization (QUBO) and the Unit-Disk Maximum\nIndependent Set (UD-MIS) problems. Our approach allows us to estimate the token\ndistribution from data and adiabatically prepare a quantum state from which we\neventually sample the generated passwords via measurements. Our results show\nthat relatively small samples of 128 passwords, generated on the QuEra Aquila\n256-qubit neutral atom quantum computer, contain human-like passwords such as\n\"Tunas200992\" or \"teedem28iglove\".", "AI": {"tldr": "This paper explores the use of adiabatic quantum computers for password generation, proposing novel approaches based on QUBO and UD-MIS problems. The results demonstrate that small samples of passwords generated on a quantum computer can contain human-like passwords.", "motivation": "The motivation is to investigate whether Quantum Computing (QC) has the potential to reduce the vast resource requirements for training and operating GenAI models, specifically focusing on the task of generating passwords that mimic real user behavior.", "method": "The study focuses on different encodings of token strings and proposes novel approaches based on Quadratic Unconstrained Binary Optimization (QUBO) and Unit-Disk Maximum Independent Set (UD-MIS) problems. They estimate the token distribution from data and adiabatically prepare a quantum state from which they eventually sample the generated passwords via measurements.", "result": "Relatively small samples of 128 passwords, generated on the QuEra Aquila 256-qubit neutral atom quantum computer, contain human-like passwords such as 'Tunas200992' or 'teedem28iglove'.", "conclusion": "Adiabatic quantum computers show utility in generating human-like passwords using the proposed QUBO and UD-MIS methods."}}
{"id": "2506.08920", "pdf": "https://arxiv.org/pdf/2506.08920", "abs": "https://arxiv.org/abs/2506.08920", "authors": ["Zeyu Leo Liu", "Greg Durrett", "Eunsol Choi"], "title": "PropMEND: Hypernetworks for Knowledge Propagation in LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under review", "summary": "Knowledge editing techniques for large language models (LLMs) can inject\nknowledge that is later reproducible verbatim, but they fall short on\npropagating that knowledge: models cannot answer questions that require\nreasoning with the injected knowledge. We present a hypernetwork-based approach\nfor knowledge propagation, named PropMEND, where we meta-learn how to modify\ngradients of a language modeling loss to encourage injected information to\npropagate. Our approach extends the meta-objective of MEND [29] so that\ngradient updates on knowledge are transformed to enable answering multi-hop\nquestions involving that knowledge. We show improved performance on the\nRippleEdit dataset, showing almost 2x accuracy on challenging multi-hop\nquestions whose answers are not explicitly stated in the injected fact. We\nfurther introduce a new dataset, Controlled RippleEdit, to evaluate the\ngeneralization of our hypernetwork, testing knowledge propagation along\nrelations and entities unseen during hypernetwork training. PropMEND still\noutperforms existing approaches in unseen entity-relation pairs, yet the\nperformance gap decreases substantially, suggesting future work in propagating\nknowledge to a wide range of relations.", "AI": {"tldr": "The paper introduces PropMEND, a hypernetwork-based approach for knowledge propagation in large language models (LLMs), which enhances the ability to answer multi-hop questions using injected knowledge.", "motivation": "Existing knowledge editing techniques for LLMs can inject knowledge but fail to propagate it effectively, meaning models struggle with reasoning tasks involving the injected knowledge.", "method": "PropMEND uses a hypernetwork-based approach where gradients of a language modeling loss are modified through meta-learning. This method extends the meta-objective of MEND to transform gradient updates on knowledge, enabling answers to multi-hop questions that involve the injected knowledge.", "result": "PropMEND shows nearly 2x accuracy improvement on challenging multi-hop questions in the RippleEdit dataset. It also performs well on a new dataset, Controlled RippleEdit, though the performance gap decreases for unseen entity-relation pairs.", "conclusion": "PropMEND outperforms existing methods in knowledge propagation, yet there is room for improvement in generalizing to a wide range of relations."}}
{"id": "2506.08528", "pdf": "https://arxiv.org/pdf/2506.08528", "abs": "https://arxiv.org/abs/2506.08528", "authors": ["Yu Guan", "Zhiyu Yin", "Haoyu Chen", "Sheng Cheng", "Chaojie Yang", "Tianyin Xu", "Yang Zhang", "Hanyu Zhao", "Yong Li", "Dennis Cai", "Ennan Zhai"], "title": "PerfTracker: Online Performance Troubleshooting for Large-scale Model Training in Production", "categories": ["cs.DC", "cs.LG", "cs.OS"], "comment": null, "summary": "Troubleshooting performance problems of large model training (LMT) is\nimmensely challenging, due to unprecedented scales of modern GPU clusters, the\ncomplexity of software-hardware interactions, and the data intensity of the\ntraining process. Existing troubleshooting approaches designed for traditional\ndistributed systems or datacenter networks fall short and can hardly apply to\nreal-world training systems. In this paper, we present PerfTracker, the first\nonline troubleshooting system utilizing fine-grained profiling, to diagnose\nperformance issues of large-scale model training in production. PerfTracker can\ndiagnose performance issues rooted in both hardware (e.g., GPUs and their\ninterconnects) and software (e.g., Python functions and GPU operations). It\nscales to LMT on modern GPU clusters. PerfTracker effectively summarizes\nruntime behavior patterns of fine-grained LMT functions via online profiling,\nand leverages differential observability to localize the root cause with\nminimal production impact. PerfTracker has been deployed as a production\nservice for large-scale GPU clusters of O(10, 000) GPUs (product homepage\nhttps://help.aliyun.com/zh/pai/user-guide/perftracker-online-performance-analysis-diagnostic-tool).\nIt has been used to diagnose a variety of difficult performance issues.", "AI": {"tldr": "PerfTracker is an online troubleshooting system for diagnosing performance issues in large-scale model training on modern GPU clusters.", "motivation": "Troubleshooting performance problems of large model training is immensely challenging due to the unprecedented scales of modern GPU clusters, the complexity of software-hardware interactions, and the data intensity of the training process.", "method": "PerfTracker utilizes fine-grained profiling to diagnose performance issues rooted in both hardware (e.g., GPUs and their interconnects) and software (e.g., Python functions and GPU operations). It effectively summarizes runtime behavior patterns of fine-grained LMT functions via online profiling, and leverages differential observability to localize the root cause with minimal production impact.", "result": "PerfTracker has been deployed as a production service for large-scale GPU clusters of O(10, 000) GPUs. It has been used to diagnose a variety of difficult performance issues.", "conclusion": "PerfTracker is the first online troubleshooting system utilizing fine-grained profiling, to diagnose performance issues of large-scale model training in production."}}
{"id": "2506.08927", "pdf": "https://arxiv.org/pdf/2506.08927", "abs": "https://arxiv.org/abs/2506.08927", "authors": ["David Acuna", "Ximing Lu", "Jaehun Jung", "Hyunwoo Kim", "Amlan Kar", "Sanja Fidler", "Yejin Choi"], "title": "Socratic-MCTS: Test-Time Visual Reasoning by Asking the Right Questions", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent research in vision-language models (VLMs) has centered around the\npossibility of equipping them with implicit long-form chain-of-thought\nreasoning -- akin to the success observed in language models -- via\ndistillation and reinforcement learning. But what about the non-reasoning\nmodels already trained and deployed across the internet? Should we simply\nabandon them, or is there hope for a search mechanism that can elicit hidden\nknowledge and induce long reasoning traces -- without any additional training\nor supervision? In this paper, we explore this possibility using a Monte Carlo\nTree Search (MCTS)-inspired algorithm, which injects subquestion-subanswer\npairs into the model's output stream. We show that framing reasoning as a\nsearch process -- where subquestions act as latent decisions within a broader\ninference trajectory -- helps the model \"connect the dots\" between fragmented\nknowledge and produce extended reasoning traces in non-reasoning models. We\nevaluate our method across three benchmarks and observe consistent\nimprovements. Notably, our approach yields a 2% overall improvement on\nMMMU-PRO, including a significant 9% gain in Liberal Arts.", "AI": {"tldr": "\u901a\u8fc7\u53d7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u542f\u53d1\u7684\u7b97\u6cd5\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u76d1\u7763\u5373\u53ef\u4ece\u975e\u63a8\u7406\u6a21\u578b\u4e2d\u63d0\u53d6\u9690\u85cf\u77e5\u8bc6\u5e76\u8bf1\u5bfc\u957f\u63a8\u7406\u8f68\u8ff9\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728MMMU-PRO\u4e0a\u603b\u4f53\u63d0\u9ad8\u4e862%\uff0c\u5728\u6587\u79d1\u9886\u57df\u663e\u8457\u63d0\u9ad8\u4e869%\u3002", "motivation": "\u5f53\u524d\u5173\u4e8e\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u7684\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u901a\u8fc7\u84b8\u998f\u548c\u5f3a\u5316\u5b66\u4e60\u8d4b\u4e88\u5176\u9690\u5f0f\u7684\u957f\u7bc7\u94fe\u5f0f\u63a8\u7406\u80fd\u529b\u3002\u7136\u800c\uff0c\u5df2\u7ecf\u8bad\u7ec3\u548c\u90e8\u7f72\u5728\u4e92\u8054\u7f51\u4e0a\u7684\u975e\u63a8\u7406\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u88ab\u5229\u7528\uff1f\u662f\u5426\u6709\u529e\u6cd5\u901a\u8fc7\u641c\u7d22\u673a\u5236\u6765\u6fc0\u53d1\u8fd9\u4e9b\u6a21\u578b\u4e2d\u7684\u9690\u85cf\u77e5\u8bc6\uff0c\u800c\u4e0d\u9700\u8981\u989d\u5916\u7684\u8bad\u7ec3\u6216\u76d1\u7763\uff1f", "method": "\u7814\u7a76\u8005\u91c7\u7528\u4e86\u4e00\u79cd\u53d7\u8499\u7279\u5361\u6d1b\u6811\u641c\u7d22\uff08MCTS\uff09\u542f\u53d1\u7684\u7b97\u6cd5\uff0c\u5c06\u5b50\u95ee\u9898-\u5b50\u7b54\u6848\u5bf9\u6ce8\u5165\u5230\u6a21\u578b\u7684\u8f93\u51fa\u6d41\u4e2d\u3002\u901a\u8fc7\u5c06\u63a8\u7406\u89c6\u4e3a\u4e00\u4e2a\u641c\u7d22\u8fc7\u7a0b\uff0c\u5176\u4e2d\u5b50\u95ee\u9898\u4f5c\u4e3a\u66f4\u5e7f\u6cdb\u63a8\u7406\u8f68\u8ff9\u4e2d\u7684\u6f5c\u5728\u51b3\u7b56\u70b9\uff0c\u5e2e\u52a9\u6a21\u578b\u8fde\u63a5\u788e\u7247\u5316\u7684\u77e5\u8bc6\uff0c\u751f\u6210\u6269\u5c55\u7684\u63a8\u7406\u8f68\u8ff9\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u4e09\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u793a\u51fa\u4e00\u81f4\u7684\u6539\u8fdb\u3002\u7279\u522b\u5730\uff0c\u5728MMMU-PRO\u6570\u636e\u96c6\u4e0a\uff0c\u603b\u4f53\u6027\u80fd\u63d0\u9ad8\u4e862%\uff0c\u800c\u5728\u6587\u79d1\u9886\u57df\u4e2d\uff0c\u6027\u80fd\u63d0\u5347\u4e869%\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u4f7f\u7528MCTS\u542f\u53d1\u7684\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5728\u4e0d\u589e\u52a0\u989d\u5916\u8bad\u7ec3\u6216\u76d1\u7763\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u63d0\u5347\u975e\u63a8\u7406\u6a21\u578b\u7684\u77e5\u8bc6\u8fde\u63a5\u548c\u957f\u63a8\u7406\u80fd\u529b\u3002\u8fd9\u4e3a\u91cd\u65b0\u5229\u7528\u73b0\u6709\u7684\u975e\u63a8\u7406\u6a21\u578b\u63d0\u4f9b\u4e86\u4e00\u6761\u65b0\u7684\u9014\u5f84\u3002"}}
{"id": "2506.08535", "pdf": "https://arxiv.org/pdf/2506.08535", "abs": "https://arxiv.org/abs/2506.08535", "authors": ["Ronald Katende"], "title": "Structured Variational $D$-Decomposition for Accurate and Stable Low-Rank Approximation", "categories": ["math.NA", "cs.LG", "cs.NA"], "comment": null, "summary": "We introduce the $D$-decomposition, a non-orthogonal matrix factorization of\nthe form $A \\approx P D Q$, where $P \\in \\mathbb{R}^{n \\times k}$, $D \\in\n\\mathbb{R}^{k \\times k}$, and $Q \\in \\mathbb{R}^{k \\times n}$. The\ndecomposition is defined variationally by minimizing a regularized Frobenius\nloss, allowing control over rank, sparsity, and conditioning. Unlike algebraic\nfactorizations such as LU or SVD, it is computed by alternating minimization.\nWe establish existence and perturbation stability of the solution and show that\neach update has complexity $\\mathcal{O}(n^2k)$. Benchmarks against truncated\nSVD, CUR, and nonnegative matrix factorization show improved reconstruction\naccuracy on MovieLens, MNIST, Olivetti Faces, and gene expression matrices,\nparticularly under sparsity and noise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aD-decomposition\u7684\u975e\u6b63\u4ea4\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u6b63\u5219\u5316\u7684Frobenius\u635f\u5931\u6765\u8fdb\u884c\u53d8\u5206\u5b9a\u4e49\uff0c\u5141\u8bb8\u5bf9\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u8fdb\u884c\u63a7\u5236\u3002\u4e0e\u4ee3\u6570\u5206\u89e3\u4e0d\u540c\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u4ea4\u66ff\u6700\u5c0f\u5316\u8ba1\u7b97\uff0c\u5e76\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u91cd\u5efa\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff08\u5982LU\u6216SVD\uff09\u53ef\u80fd\u65e0\u6cd5\u5f88\u597d\u5730\u63a7\u5236\u79e9\u3001\u7a00\u758f\u6027\u548c\u6761\u4ef6\u6027\uff0c\u4e14\u8ba1\u7b97\u65b9\u5f0f\u53ef\u80fd\u4e0d\u591f\u7075\u6d3b\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\uff0c\u5e76\u5728\u5b9e\u9645\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "method": "\u5f15\u5165\u4e86D-decomposition\uff0c\u5f62\u5f0f\u4e3aA \u2248 P D Q\uff0c\u5176\u4e2dP\u3001D\u548cQ\u5206\u522b\u4e3an\u00d7k\u3001k\u00d7k\u548ck\u00d7n\u7684\u77e9\u9635\u3002\u8be5\u5206\u89e3\u901a\u8fc7\u6700\u5c0f\u5316\u6b63\u5219\u5316\u7684Frobenius\u635f\u5931\u8fdb\u884c\u53d8\u5206\u5b9a\u4e49\uff0c\u4f7f\u7528\u4ea4\u66ff\u6700\u5c0f\u5316\u7b97\u6cd5\u8fdb\u884c\u8ba1\u7b97\uff0c\u6bcf\u6b21\u66f4\u65b0\u7684\u590d\u6742\u5ea6\u4e3aO(n^2k)\u3002", "result": "\u5728MovieLens\u3001MNIST\u3001Olivetti Faces\u548c\u57fa\u56e0\u8868\u8fbe\u77e9\u9635\u7b49\u6570\u636e\u96c6\u4e0a\uff0c\u4e0e\u622a\u65adSVD\u3001CUR\u548c\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u76f8\u6bd4\uff0cD-decomposition\u5c55\u73b0\u51fa\u66f4\u9ad8\u7684\u91cd\u5efa\u7cbe\u5ea6\uff0c\u7279\u522b\u662f\u5728\u7a00\u758f\u6027\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u3002", "conclusion": "D-decomposition\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u77e9\u9635\u5206\u89e3\u65b9\u6cd5\uff0c\u5177\u6709\u7075\u6d3b\u6027\u548c\u7a33\u5b9a\u6027\uff0c\u9002\u7528\u4e8e\u591a\u79cd\u5e94\u7528\u573a\u666f\uff0c\u5c24\u5176\u5728\u7a00\u758f\u6027\u548c\u566a\u58f0\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2506.08935", "pdf": "https://arxiv.org/pdf/2506.08935", "abs": "https://arxiv.org/abs/2506.08935", "authors": ["Andrew Shin"], "title": "Can A Gamer Train A Mathematical Reasoning Model?", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) have achieved remarkable performance in\nvarious tasks including mathematical reasoning, their development typically\ndemands prohibitive computational resources. Recent advancements have reduced\ncosts for training capable models, yet even these approaches rely on high-end\nhardware clusters. In this paper, we demonstrate that a single average gaming\nGPU can train a solid mathematical reasoning model, by integrating\nreinforcement learning and memory optimization techniques. Specifically, we\ntrain a 1.5B parameter mathematical reasoning model on RTX 3080 Ti of 16GB\nmemory that achieves comparable or better performance on mathematical reasoning\nbenchmarks than models several times larger, in resource-constrained\nenvironments. Our results challenge the paradigm that state-of-the-art\nmathematical reasoning necessitates massive infrastructure, democratizing\naccess to high-performance AI research.\nhttps://github.com/shinandrew/YouronMath.", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u8bc1\u660e\u5355\u4e2a\u666e\u901a\u6e38\u620fGPU\u53ef\u4ee5\u8bad\u7ec3\u51fa\u5f3a\u5927\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u6311\u6218\u4e86\u9700\u8981\u5927\u91cf\u57fa\u7840\u8bbe\u65bd\u7684\u8303\u5f0f\uff0c\u4fc3\u8fdb\u4e86\u9ad8\u6027\u80fdAI\u7814\u7a76\u7684\u666e\u53ca\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u5b66\u63a8\u7406\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u5f00\u53d1\u901a\u5e38\u9700\u8981\u9ad8\u6602\u7684\u8ba1\u7b97\u8d44\u6e90\u3002\u5c3d\u7ba1\u6700\u8fd1\u7684\u8fdb\u5c55\u964d\u4f4e\u4e86\u8bad\u7ec3\u6709\u80fd\u529b\u6a21\u578b\u7684\u6210\u672c\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u7136\u4f9d\u8d56\u4e8e\u9ad8\u7aef\u786c\u4ef6\u96c6\u7fa4\u3002", "method": "\u5728RTX 3080 Ti\uff0816GB\u5185\u5b58\uff09\u4e0a\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u548c\u5185\u5b58\u4f18\u5316\u6280\u672f\uff0c\u8bad\u7ec3\u4e00\u4e2a15\u4ebf\u53c2\u6570\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\u3002", "result": "\u8be5\u6a21\u578b\u5728\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\uff0c\u5728\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u7684\u8868\u73b0\u4e0e\u5927\u51e0\u500d\u7684\u6a21\u578b\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "\u5355\u4e00\u5e73\u5747\u6e38\u620fGPU\u53ef\u4ee5\u8bad\u7ec3\u51fa\u5f3a\u5927\u7684\u6570\u5b66\u63a8\u7406\u6a21\u578b\uff0c\u4e0d\u5fc5\u4f9d\u8d56\u9ad8\u7aef\u786c\u4ef6\u96c6\u7fa4\u3002"}}
{"id": "2506.08548", "pdf": "https://arxiv.org/pdf/2506.08548", "abs": "https://arxiv.org/abs/2506.08548", "authors": ["Moria Mayala", "Erwan Scornet", "Charles Tillier", "Olivier Wintenberger"], "title": "Asymptotic Normality of Infinite Centered Random Forests -Application to Imbalanced Classification", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Many classification tasks involve imbalanced data, in which a class is\nlargely underrepresented. Several techniques consists in creating a rebalanced\ndataset on which a classifier is trained. In this paper, we study theoretically\nsuch a procedure, when the classifier is a Centered Random Forests (CRF). We\nestablish a Central Limit Theorem (CLT) on the infinite CRF with explicit rates\nand exact constant. We then prove that the CRF trained on the rebalanced\ndataset exhibits a bias, which can be removed with appropriate techniques.\nBased on an importance sampling (IS) approach, the resulting debiased\nestimator, called IS-ICRF, satisfies a CLT centered at the prediction function\nvalue. For high imbalance settings, we prove that the IS-ICRF estimator enjoys\na variance reduction compared to the ICRF trained on the original data.\nTherefore, our theoretical analysis highlights the benefits of training random\nforests on a rebalanced dataset (followed by a debiasing procedure) compared to\nusing the original data. Our theoretical results, especially the variance rates\nand the variance reduction, appear to be valid for Breiman's random forests in\nour experiments.", "AI": {"tldr": "This paper investigates the theoretical benefits of training Centered Random Forests (CRF) on rebalanced datasets for imbalanced classification tasks, proposing an importance sampling-based debiased estimator (IS-ICRF) that exhibits variance reduction in high imbalance settings.", "motivation": "Imbalanced data poses challenges for classification tasks where one class is largely underrepresented. The motivation is to explore the theoretical advantages of rebalancing datasets before training classifiers such as CRFs, and to develop techniques to remove potential bias introduced by this process.", "method": "The authors establish a Central Limit Theorem (CLT) for infinite CRFs with explicit rates and constants. They analyze the bias in CRFs trained on rebalanced data and propose a debiasing method based on importance sampling (IS), resulting in the IS-ICRF estimator. This estimator satisfies a CLT centered at the prediction function value and demonstrates variance reduction in high imbalance scenarios.", "result": "The IS-ICRF estimator shows variance reduction compared to the ICRF trained on original data in high imbalance settings. Experimental results suggest that these theoretical findings also apply to Breiman's random forests.", "conclusion": "Training random forests on rebalanced datasets followed by a debiasing procedure offers advantages over using original imbalanced data, particularly in terms of variance reduction."}}
{"id": "2506.08952", "pdf": "https://arxiv.org/pdf/2506.08952", "abs": "https://arxiv.org/abs/2506.08952", "authors": ["Clara Lachenmaier", "Judith Sieker", "Sina Zarrie\u00df"], "title": "Can LLMs Ground when they (Don't) Know: A Study on Direct and Loaded Political Questions", "categories": ["cs.CL", "cs.AI"], "comment": "Preprint accepted at ACL Main Conference 2025", "summary": "Communication among humans relies on conversational grounding, allowing\ninterlocutors to reach mutual understanding even when they do not have perfect\nknowledge and must resolve discrepancies in each other's beliefs. This paper\ninvestigates how large language models (LLMs) manage common ground in cases\nwhere they (don't) possess knowledge, focusing on facts in the political domain\nwhere the risk of misinformation and grounding failure is high. We examine the\nability of LLMs to answer direct knowledge questions and loaded questions that\npresuppose misinformation. We evaluate whether loaded questions lead LLMs to\nengage in active grounding and correct false user beliefs, in connection to\ntheir level of knowledge and their political bias. Our findings highlight\nsignificant challenges in LLMs' ability to engage in grounding and reject false\nuser beliefs, raising concerns about their role in mitigating misinformation in\npolitical discourse.", "AI": {"tldr": "This paper explores the ability of large language models (LLMs) to manage common ground in political conversations, especially when they lack knowledge or encounter misinformation.", "motivation": "To understand how LLMs handle conversational grounding and mutual understanding in situations where they may not have perfect knowledge, particularly in the political domain where misinformation is prevalent.", "method": "The study investigates LLMs' responses to direct knowledge questions and loaded questions that presuppose misinformation. It evaluates if these questions lead LLMs to engage in active grounding and correct false user beliefs, considering their level of knowledge and political bias.", "result": "LLMs face significant challenges in engaging in grounding and rejecting false user beliefs, indicating limitations in mitigating misinformation in political discourse.", "conclusion": "There are concerns regarding the role of LLMs in reducing misinformation due to their struggles with conversational grounding and managing discrepancies in beliefs."}}
{"id": "2506.08558", "pdf": "https://arxiv.org/pdf/2506.08558", "abs": "https://arxiv.org/abs/2506.08558", "authors": ["William de Vazelhes", "Xiao-Tong Yuan", "Bin Gu"], "title": "Optimization over Sparse Support-Preserving Sets: Two-Step Projection with Global Optimality Guarantees", "categories": ["math.OC", "cs.LG"], "comment": "Accepted for publication at ICML 2025", "summary": "In sparse optimization, enforcing hard constraints using the $\\ell_0$\npseudo-norm offers advantages like controlled sparsity compared to convex\nrelaxations. However, many real-world applications demand not only sparsity\nconstraints but also some extra constraints. While prior algorithms have been\ndeveloped to address this complex scenario with mixed combinatorial and convex\nconstraints, they typically require the closed form projection onto the mixed\nconstraints which might not exist, and/or only provide local guarantees of\nconvergence which is different from the global guarantees commonly sought in\nsparse optimization. To fill this gap, in this paper, we study the problem of\nsparse optimization with extra \\qw{\\textit{support-preserving}} constraints\ncommonly encountered in the literature. We present a new variant of iterative\nhard-thresholding algorithm equipped with a two-step consecutive projection\noperator customized for these mixed constraints, serving as a simple\nalternative to the Euclidean projection onto the mixed constraint. By\nintroducing a novel trade-off between sparsity relaxation and sub-optimality,\nwe provide global guarantees in objective value for the output of our\nalgorithm, in the deterministic, stochastic, and zeroth-order settings, under\nthe conventional restricted strong-convexity/smoothness assumptions. As a\nfundamental contribution in proof techniques, we develop a novel extension of\nthe classic three-point lemma to the considered two-step non-convex projection\noperator, which allows us to analyze the convergence in objective value in an\nelegant way that has not been possible with existing techniques. In the\nzeroth-order case, such technique also improves upon the state-of-the-art\nresult from de Vazelhes et. al. (2022), even in the case without additional\nconstraints, by allowing us to remove a non-vanishing system error present in\ntheir work.", "AI": {"tldr": "\u5728\u7a00\u758f\u4f18\u5316\u4e2d\uff0c\u4f7f\u7528\u2113\u2080\u4f2a\u8303\u6570\u5f3a\u5236\u786c\u7ea6\u675f\u6bd4\u51f8\u677e\u5f1b\u6709\u4f18\u52bf\uff0c\u4f46\u8bb8\u591a\u5b9e\u9645\u5e94\u7528\u9700\u8981\u989d\u5916\u7684\u7ea6\u675f\u6761\u4ef6\u3002\u672c\u6587\u7814\u7a76\u4e86\u5e26\u6709\u989d\u5916\u652f\u6301\u4fdd\u7559\u7ea6\u675f\u7684\u7a00\u758f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fed\u4ee3\u786c\u9608\u503c\u7b97\u6cd5\u53d8\u4f53\uff0c\u63d0\u4f9b\u5168\u5c40\u76ee\u6807\u503c\u4fdd\u8bc1\u5e76\u6539\u8fdb\u4e86\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u7b97\u6cd5\u5df2\u7ecf\u5f00\u53d1\u51fa\u6765\u4ee5\u89e3\u51b3\u5177\u6709\u6df7\u5408\u7ec4\u5408\u548c\u51f8\u7ea6\u675f\u7684\u590d\u6742\u573a\u666f\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u9700\u8981\u5c01\u95ed\u5f62\u5f0f\u7684\u6295\u5f71\u5230\u6df7\u5408\u7ea6\u675f\u4e0a\uff0c\u8fd9\u53ef\u80fd\u4e0d\u5b58\u5728\uff0c\u5e76\u4e14\u53ea\u63d0\u4f9b\u5c40\u90e8\u6536\u655b\u4fdd\u8bc1\uff0c\u4e0e\u7a00\u758f\u4f18\u5316\u4e2d\u5e38\u89c1\u7684\u5168\u5c40\u4fdd\u8bc1\u4e0d\u540c\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u8fed\u4ee3\u786c\u9608\u503c\u7b97\u6cd5\u53d8\u4f53\uff0c\u914d\u5907\u4e86\u4e3a\u8fd9\u4e9b\u6df7\u5408\u7ea6\u675f\u5b9a\u5236\u7684\u4e24\u6b65\u8fde\u7eed\u6295\u5f71\u7b97\u5b50\uff0c\u4f5c\u4e3a\u6b27\u51e0\u91cc\u5fb7\u6295\u5f71\u5230\u6df7\u5408\u7ea6\u675f\u4e0a\u7684\u7b80\u5355\u66ff\u4ee3\u65b9\u6848\u3002\u901a\u8fc7\u5f15\u5165\u7a00\u758f\u6027\u677e\u5f1b\u548c\u6b21\u4f18\u6027\u7684\u65b0\u6743\u8861\uff0c\u4f5c\u8005\u63d0\u4f9b\u4e86\u5728\u786e\u5b9a\u6027\u3001\u968f\u673a\u548c\u96f6\u9636\u8bbe\u7f6e\u4e0b\u7684\u76ee\u6807\u503c\u5168\u5c40\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u4f5c\u8005\u8fd8\u53d1\u5c55\u4e86\u7ecf\u5178\u4e09\u70b9\u5f15\u7406\u7684\u65b0\u6269\u5c55\u5230\u8003\u8651\u7684\u4e24\u6b65\u975e\u51f8\u6295\u5f71\u7b97\u5b50\uff0c\u5141\u8bb8\u4ee5\u4e00\u79cd\u4f18\u96c5\u7684\u65b9\u5f0f\u5206\u6790\u76ee\u6807\u503c\u7684\u6536\u655b\u6027\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u96f6\u9636\u60c5\u51b5\u4e0b\u6539\u8fdb\u4e86de Vazelhes\u7b49\u4eba\u7684\u6700\u65b0\u7ed3\u679c\uff082022\u5e74\uff09\uff0c\u5373\u4f7f\u5728\u6ca1\u6709\u989d\u5916\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\uff0c\u4e5f\u80fd\u53bb\u9664\u4ed6\u4eec\u5de5\u4f5c\u4e2d\u5b58\u5728\u7684\u975e\u6d88\u5931\u7cfb\u7edf\u8bef\u5dee\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u8fed\u4ee3\u786c\u9608\u503c\u7b97\u6cd5\u53d8\u4f53\uff0c\u9002\u7528\u4e8e\u5e26\u6709\u989d\u5916\u652f\u6301\u4fdd\u7559\u7ea6\u675f\u7684\u7a00\u758f\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u7a00\u758f\u6027\u677e\u5f1b\u548c\u6b21\u4f18\u6027\u7684\u6743\u8861\uff0c\u63d0\u4f9b\u4e86\u5168\u5c40\u76ee\u6807\u503c\u4fdd\u8bc1\u3002\u6b64\u5916\uff0c\u63d0\u51fa\u7684\u8bc1\u660e\u6280\u672f\u4e5f\u4e3a\u5206\u6790\u6b64\u7c7b\u95ee\u9898\u7684\u6536\u655b\u6027\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2506.08955", "pdf": "https://arxiv.org/pdf/2506.08955", "abs": "https://arxiv.org/abs/2506.08955", "authors": ["Chunming He", "Kai Li", "Yachao Zhang", "Ziyun Yang", "Youwei Pang", "Longxiang Tang", "Chengyu Fang", "Yulun Zhang", "Linghe Kong", "Xiu Li", "Sina Farsiu"], "title": "Segment Concealed Objects with Incomplete Supervision", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "IEEE TPAMI", "summary": "Incompletely-Supervised Concealed Object Segmentation (ISCOS) involves\nsegmenting objects that seamlessly blend into their surrounding environments,\nutilizing incompletely annotated data, such as weak and semi-annotations, for\nmodel training. This task remains highly challenging due to (1) the limited\nsupervision provided by the incompletely annotated training data, and (2) the\ndifficulty of distinguishing concealed objects from the background, which\narises from the intrinsic similarities in concealed scenarios. In this paper,\nwe introduce the first unified method for ISCOS to address these challenges. To\ntackle the issue of incomplete supervision, we propose a unified mean-teacher\nframework, SEE, that leverages the vision foundation model, ``\\emph{Segment\nAnything Model (SAM)}'', to generate pseudo-labels using coarse masks produced\nby the teacher model as prompts. To mitigate the effect of low-quality\nsegmentation masks, we introduce a series of strategies for pseudo-label\ngeneration, storage, and supervision. These strategies aim to produce\ninformative pseudo-labels, store the best pseudo-labels generated, and select\nthe most reliable components to guide the student model, thereby ensuring\nrobust network training. Additionally, to tackle the issue of intrinsic\nsimilarity, we design a hybrid-granularity feature grouping module that groups\nfeatures at different granularities and aggregates these results. By clustering\nsimilar features, this module promotes segmentation coherence, facilitating\nmore complete segmentation for both single-object and multiple-object images.\nWe validate the effectiveness of our approach across multiple ISCOS tasks, and\nexperimental results demonstrate that our method achieves state-of-the-art\nperformance. Furthermore, SEE can serve as a plug-and-play solution, enhancing\nthe performance of existing models.", "AI": {"tldr": "An unified method SEE is proposed for Incompletely-Supervised Concealed Object Segmentation (ISCOS). It uses a mean-teacher framework with the Segment Anything Model (SAM) to generate pseudo-labels and introduces strategies for pseudo-label handling and a hybrid-granularity feature grouping module. Experiments show state-of-the-art performance.", "motivation": "The task of Incompletely-Supervised Concealed Object Segmentation (ISCOS) remains highly challenging due to limited supervision from incompletely annotated training data and the difficulty of distinguishing concealed objects from the background because of intrinsic similarities in concealed scenarios.", "method": "A unified mean-teacher framework named SEE is proposed which leverages SAM to generate pseudo-labels using coarse masks produced by the teacher model as prompts. Strategies are introduced for pseudo-label generation, storage, and supervision to ensure robust network training. Additionally, a hybrid-granularity feature grouping module is designed to promote segmentation coherence by clustering similar features.", "result": "The experimental results demonstrate that the proposed method achieves state-of-the-art performance across multiple ISCOS tasks.", "conclusion": "SEE can serve as a plug-and-play solution enhancing the performance of existing models."}}
{"id": "2506.08591", "pdf": "https://arxiv.org/pdf/2506.08591", "abs": "https://arxiv.org/abs/2506.08591", "authors": ["Chengchao Shen", "Hourun Zhu", "Gongfan Fang", "Jianxin Wang", "Xinchao Wang"], "title": "Diversity-Guided MLP Reduction for Efficient Large Vision Transformers", "categories": ["cs.CV", "cs.LG", "cs.MM"], "comment": null, "summary": "Transformer models achieve excellent scaling property, where the performance\nis improved with the increment of model capacity. However, large-scale model\nparameters lead to an unaffordable cost of computing and memory. We analyze\npopular transformer architectures and find that multilayer perceptron (MLP)\nmodules take up the majority of model parameters. To this end, we focus on the\nrecoverability of the compressed models and propose a Diversity-Guided MLP\nReduction (DGMR) method to significantly reduce the parameters of large vision\ntransformers with only negligible performance degradation. Specifically, we\nconduct a Gram-Schmidt weight pruning strategy to eliminate redundant neurons\nof MLP hidden layer, while preserving weight diversity for better performance\nrecover during distillation. Compared to the model trained from scratch, our\npruned model only requires 0.06\\% data of LAION-2B (for the training of large\nvision transformers) without labels (ImageNet-1K) to recover the original\nperformance. Experimental results on several state-of-the-art large vision\ntransformers demonstrate that our method achieves a more than 57.0\\% parameter\nand FLOPs reduction in a near lossless manner. Notably, for EVA-CLIP-E (4.4B),\nour method accomplishes a 71.5\\% parameter and FLOPs reduction without\nperformance degradation. The source code and trained weights are available at\nhttps://github.com/visresearch/DGMR.", "AI": {"tldr": "Transformer\u6a21\u578b\u5c3d\u7ba1\u6027\u80fd\u968f\u89c4\u6a21\u589e\u52a0\u800c\u63d0\u5347\uff0c\u4f46\u53c2\u6570\u91cf\u8fc7\u5927\u5bfc\u81f4\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u9ad8\u6602\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cdDiversity-Guided MLP Reduction (DGMR)\u65b9\u6cd5\uff0c\u901a\u8fc7Gram-Schmidt\u6743\u91cd\u526a\u679d\u7b56\u7565\u51cf\u5c11\u5927\u578b\u89c6\u89c9Transformer\u4e2d\u7684MLP\u6a21\u5757\u53c2\u6570\uff0c\u540c\u65f6\u4fdd\u7559\u6743\u91cd\u591a\u6837\u6027\u4ee5\u5728\u84b8\u998f\u8fc7\u7a0b\u4e2d\u66f4\u597d\u5730\u6062\u590d\u6027\u80fd\u3002\u8be5\u65b9\u6cd5\u5728\u51e0\u4e4e\u4e0d\u635f\u5931\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u4e86\u53c2\u6570\u548cFLOPs\u3002", "motivation": "Transformer\u6a21\u578b\u7684\u6027\u80fd\u968f\u7740\u6a21\u578b\u5bb9\u91cf\u7684\u589e\u52a0\u800c\u63d0\u9ad8\uff0c\u4f46\u662f\u5927\u89c4\u6a21\u6a21\u578b\u53c2\u6570\u5e26\u6765\u4e86\u96be\u4ee5\u627f\u53d7\u7684\u8ba1\u7b97\u548c\u5185\u5b58\u6210\u672c\u3002\u5206\u6790\u53d1\u73b0MLP\u6a21\u5757\u5360\u636e\u4e86\u6a21\u578b\u53c2\u6570\u7684\u4e3b\u8981\u90e8\u5206\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u538b\u7f29\u8fd9\u4e9b\u6a21\u578b\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u63d0\u51faDGMR\u65b9\u6cd5\uff0c\u4f7f\u7528Gram-Schmidt\u6743\u91cd\u526a\u679d\u7b56\u7565\u6d88\u9664MLP\u9690\u85cf\u5c42\u4e2d\u7684\u5197\u4f59\u795e\u7ecf\u5143\uff0c\u540c\u65f6\u4fdd\u6301\u6743\u91cd\u591a\u6837\u6027\u4ee5\u4fbf\u5728\u84b8\u998f\u8fc7\u7a0b\u4e2d\u66f4\u597d\u5730\u6062\u590d\u6027\u80fd\u3002\u4e0e\u4ece\u5934\u5f00\u59cb\u8bad\u7ec3\u7684\u6a21\u578b\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u53ea\u9700\u8981LAION-2B\u6570\u636e\u96c60.06%\u7684\u6570\u636e\uff08\u65e0\u6807\u7b7e\uff09\u5373\u53ef\u6062\u590d\u539f\u59cb\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDGMR\u65b9\u6cd5\u53ef\u4ee5\u5728\u51e0\u4e4e\u4e0d\u5931\u6027\u80fd\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u8d85\u8fc757.0%\u7684\u53c2\u6570\u548cFLOPs\u51cf\u5c11\u3002\u5bf9\u4e8eEVA-CLIP-E\uff084.4B\uff09\uff0c\u5b9e\u73b0\u4e8671.5%\u7684\u53c2\u6570\u548cFLOPs\u51cf\u5c11\u4e14\u6ca1\u6709\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "DGMR\u65b9\u6cd5\u80fd\u591f\u663e\u8457\u51cf\u5c11\u5927\u578b\u89c6\u89c9Transformer\u7684\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u90e8\u7f72\u5927\u578b\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u80fd\u3002"}}
{"id": "2506.08962", "pdf": "https://arxiv.org/pdf/2506.08962", "abs": "https://arxiv.org/abs/2506.08962", "authors": ["Liangliang Chen", "Huiru Xie", "Jacqueline Rohde", "Ying Zhang"], "title": "WIP: Large Language Model-Enhanced Smart Tutor for Undergraduate Circuit Analysis", "categories": ["cs.CY", "cs.AI", "cs.HC"], "comment": "Accepted to 2025 Frontiers in Education (FIE) Conference", "summary": "This research-to-practice work-in-progress (WIP) paper presents an AI-enabled\nsmart tutor designed to provide homework assessment and feedback for students\nin an undergraduate circuit analysis course. We detail the tutor's design\nphilosophy and core components, including open-ended question answering and\nhomework feedback generation. The prompts are carefully crafted to optimize\nresponses across different problems. The smart tutor was deployed on the\nMicrosoft Azure platform and is currently in use in an undergraduate circuit\nanalysis course at the School of Electrical and Computer Engineering in a\nlarge, public, research-intensive institution in the Southeastern United\nStates. Beyond offering personalized instruction and feedback, the tutor\ncollects student interaction data, which is summarized and shared with the\ncourse instructor. To evaluate its effectiveness, we collected student\nfeedback, with 90.9% of responses indicating satisfaction with the tutor.\nAdditionally, we analyze a subset of collected data on preliminary circuit\nanalysis topics to assess tutor usage frequency for each problem and identify\nfrequently asked questions. These insights help instructors gain real-time\nawareness of student difficulties, enabling more targeted classroom\ninstruction. In future work, we will release a full analysis once the complete\ndataset is available after the Spring 2025 semester. We also explore the\npotential applications of this smart tutor across a broader range of\nengineering disciplines by developing improved prompts, diagram-recognition\nmethods, and database management strategies, which remain ongoing areas of\nresearch.", "AI": {"tldr": "This paper introduces an AI-enabled smart tutor designed for homework assessment and feedback in an undergraduate circuit analysis course. Deployed on Microsoft Azure, it offers personalized instruction, collects student interaction data, and provides instructors with insights into student difficulties. Student satisfaction is high (90.9%), and future work includes a full dataset analysis and exploring broader applications.", "motivation": "To provide effective homework assessment and feedback for students in an undergraduate circuit analysis course using AI technology, enhancing personalized learning experiences and improving teaching strategies based on real-time student data.", "method": "Design and implementation of an AI-enabled smart tutor that includes open-ended question answering and homework feedback generation. Carefully crafted prompts optimize responses across different problems, deployed on the Microsoft Azure platform.", "result": "90.9% of student feedback indicates satisfaction with the tutor. Data analysis reveals tutor usage frequency per problem and frequently asked questions, helping instructors understand student difficulties better.", "conclusion": "The AI-enabled smart tutor effectively supports personalized instruction and feedback in circuit analysis courses. Future work will involve comprehensive data analysis and expanding its application to other engineering disciplines."}}
{"id": "2506.08592", "pdf": "https://arxiv.org/pdf/2506.08592", "abs": "https://arxiv.org/abs/2506.08592", "authors": ["Liyan Xu", "Zhenlin Su", "Mo Yu", "Jiangnan Li", "Fandong Meng", "Jie Zhou"], "title": "Dense Retrievers Can Fail on Simple Queries: Revealing The Granularity Dilemma of Embeddings", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This work focuses on an observed limitation of text encoders: embeddings may\nnot be able to recognize fine-grained entities or events within the semantics,\nresulting in failed dense retrieval on even simple cases. To examine such\nbehaviors, we first introduce a new evaluation dataset in Chinese, named\nCapRetrieval, whose passages are image captions, and queries are phrases\ninquiring entities or events in various forms. Zero-shot evaluation suggests\nthat encoders may fail on these fine-grained matching, regardless of training\nsources or model sizes. Aiming for enhancement, we proceed to finetune encoders\nwith our proposed data generation strategies, which obtains the best\nperformance on CapRetrieval. Within this process, we further identify an issue\nof granularity dilemma, a challenge for embeddings to express fine-grained\nsalience while aligning with overall semantics. Our dataset, code and models in\nthis work are publicly released at https://github.com/lxucs/CapRetrieval.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u6587\u672c\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u6216\u4e8b\u4ef6\u8bc6\u522b\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5f15\u5165\u4e2d\u6587\u8bc4\u4f30\u6570\u636e\u96c6CapRetrieval\u8fdb\u884c\u9a8c\u8bc1\u3002\u5c3d\u7ba1\u4e0d\u540c\u6765\u6e90\u8bad\u7ec3\u548c\u6a21\u578b\u5927\u5c0f\u7684\u7f16\u7801\u5668\u90fd\u53ef\u80fd\u65e0\u6cd5\u5b8c\u6210\u8fd9\u4e9b\u5339\u914d\u4efb\u52a1\uff0c\u4f46\u901a\u8fc7\u5fae\u8c03\u7f16\u7801\u5668\u548c\u63d0\u51fa\u7684\u6570\u636e\u751f\u6210\u7b56\u7565\u53ef\u4ee5\u63d0\u5347\u6027\u80fd\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u63ed\u793a\u4e86\u5d4c\u5165\u8868\u793a\u5728\u8868\u8fbe\u7ec6\u7c92\u5ea6\u663e\u8457\u6027\u4e0e\u6574\u4f53\u8bed\u4e49\u5bf9\u9f50\u4e4b\u95f4\u7684\u7c92\u5ea6\u56f0\u5883\u3002", "motivation": "\u89c2\u5bdf\u5230\u6587\u672c\u7f16\u7801\u5668\u7684\u4e00\u4e2a\u5c40\u9650\u6027\uff1a\u5d4c\u5165\u53ef\u80fd\u65e0\u6cd5\u8bc6\u522b\u8bed\u4e49\u4e2d\u7684\u7ec6\u7c92\u5ea6\u5b9e\u4f53\u6216\u4e8b\u4ef6\uff0c\u5bfc\u81f4\u5373\u4f7f\u5728\u7b80\u5355\u60c5\u51b5\u4e0b\u5bc6\u96c6\u68c0\u7d22\u4e5f\u53ef\u80fd\u5931\u8d25\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u8bc4\u4f30\u6570\u636e\u96c6\u6765\u6df1\u5165\u7814\u7a76\u8fd9\u79cd\u884c\u4e3a\u3002", "method": "1. \u6784\u5efa\u4e86\u4e00\u4e2a\u65b0\u7684\u4e2d\u6587\u8bc4\u4f30\u6570\u636e\u96c6CapRetrieval\uff0c\u5176\u4e2d\u6bb5\u843d\u662f\u56fe\u50cf\u6807\u9898\uff0c\u67e5\u8be2\u662f\u8be2\u95ee\u5404\u79cd\u5f62\u5f0f\u7684\u5b9e\u4f53\u6216\u4e8b\u4ef6\u7684\u77ed\u8bed\u3002\n2. \u901a\u8fc7\u96f6\u6837\u672c\u8bc4\u4f30\u6d4b\u8bd5\u4e0d\u540c\u6765\u6e90\u8bad\u7ec3\u548c\u6a21\u578b\u5927\u5c0f\u7684\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u5339\u914d\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u3002\n3. \u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u751f\u6210\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u7f16\u7801\u5668\u6765\u589e\u5f3a\u5176\u6027\u80fd\u3002\n4. \u8bc6\u522b\u5e76\u8ba8\u8bba\u4e86\u5d4c\u5165\u8868\u793a\u4e2d\u5b58\u5728\u7684\u7c92\u5ea6\u56f0\u5883\u95ee\u9898\u3002", "result": "1. \u96f6\u6837\u672c\u8bc4\u4f30\u8868\u660e\uff0c\u73b0\u6709\u7684\u6587\u672c\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u5339\u914d\u4efb\u52a1\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\n2. \u5fae\u8c03\u540e\u7684\u7f16\u7801\u5668\u5728CapRetrieval\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u4e86\u6700\u4f73\u6027\u80fd\u3002\n3. \u53d1\u73b0\u4e86\u7c92\u5ea6\u56f0\u5883\u95ee\u9898\uff0c\u5373\u5d4c\u5165\u8868\u793a\u5728\u8868\u8fbe\u7ec6\u7c92\u5ea6\u663e\u8457\u6027\u65f6\u96be\u4ee5\u4e0e\u6574\u4f53\u8bed\u4e49\u5bf9\u9f50\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u6784\u5efaCapRetrieval\u6570\u636e\u96c6\u63ed\u793a\u4e86\u6587\u672c\u7f16\u7801\u5668\u5728\u7ec6\u7c92\u5ea6\u5339\u914d\u4efb\u52a1\u4e0a\u7684\u5c40\u9650\u6027\uff0c\u5e76\u901a\u8fc7\u5fae\u8c03\u548c\u6570\u636e\u751f\u6210\u7b56\u7565\u63d0\u5347\u4e86\u6027\u80fd\u3002\u540c\u65f6\u63d0\u51fa\u4e86\u7c92\u5ea6\u56f0\u5883\u95ee\u9898\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002\u6240\u6709\u8d44\u6e90\u5df2\u516c\u5f00\u53d1\u5e03\u3002"}}
{"id": "2506.08616", "pdf": "https://arxiv.org/pdf/2506.08616", "abs": "https://arxiv.org/abs/2506.08616", "authors": ["Julien Fageot", "Peva Blanchard", "Gilles Bareilles", "L\u00ea-Nguy\u00ean Hoang"], "title": "Generalizing while preserving monotonicity in comparison-based preference learning models", "categories": ["math.ST", "cs.LG", "stat.TH"], "comment": null, "summary": "If you tell a learning model that you prefer an alternative $a$ over another\nalternative $b$, then you probably expect the model to be monotone, that is,\nthe valuation of $a$ increases, and that of $b$ decreases. Yet, perhaps\nsurprisingly, many widely deployed comparison-based preference learning models,\nincluding large language models, fail to have this guarantee. Until now, the\nonly comparison-based preference learning algorithms that were proved to be\nmonotone are the Generalized Bradley-Terry models. Yet, these models are unable\nto generalize to uncompared data. In this paper, we advance the understanding\nof the set of models with generalization ability that are monotone. Namely, we\npropose a new class of Linear Generalized Bradley-Terry models with Diffusion\nPriors, and identify sufficient conditions on alternatives' embeddings that\nguarantee monotonicity. Our experiments show that this monotonicity is far from\nbeing a general guarantee, and that our new class of generalizing models\nimproves accuracy, especially when the dataset is limited.", "AI": {"tldr": "An analysis of preference learning models reveals that many lack the expected monotonicity guarantee. The paper proposes a new class of Linear Generalized Bradley-Terry models with Diffusion Priors, which ensures monotonicity and improves accuracy in limited datasets.", "motivation": "To address the issue where many comparison-based preference learning models, including large language models, do not guarantee monotonicity despite it being an expected property.", "method": "Propose a new class of Linear Generalized Bradley-Terry models with Diffusion Priors and identify sufficient conditions on alternatives' embeddings to ensure monotonicity.", "result": "Experiments demonstrate that monotonicity is not a common guarantee among models and that the proposed model class enhances accuracy, particularly with limited data.", "conclusion": "The advancement in understanding models with generalization ability that are monotone could lead to more reliable preference learning models."}}
{"id": "2506.08990", "pdf": "https://arxiv.org/pdf/2506.08990", "abs": "https://arxiv.org/abs/2506.08990", "authors": ["Chenyu Lian", "Hong-Yu Zhou", "Dongyun Liang", "Jing Qin", "Liansheng Wang"], "title": "Efficient Medical Vision-Language Alignment Through Adapting Masked Vision Models", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "TMI 2025", "summary": "Medical vision-language alignment through cross-modal contrastive learning\nshows promising performance in image-text matching tasks, such as retrieval and\nzero-shot classification. However, conventional cross-modal contrastive\nlearning (CLIP-based) methods suffer from suboptimal visual representation\ncapabilities, which also limits their effectiveness in vision-language\nalignment. In contrast, although the models pretrained via multimodal masked\nmodeling struggle with direct cross-modal matching, they excel in visual\nrepresentation. To address this contradiction, we propose ALTA (ALign Through\nAdapting), an efficient medical vision-language alignment method that utilizes\nonly about 8% of the trainable parameters and less than 1/5 of the\ncomputational consumption required for masked record modeling. ALTA achieves\nsuperior performance in vision-language matching tasks like retrieval and\nzero-shot classification by adapting the pretrained vision model from masked\nrecord modeling. Additionally, we integrate temporal-multiview radiograph\ninputs to enhance the information consistency between radiographs and their\ncorresponding descriptions in reports, further improving the vision-language\nalignment. Experimental evaluations show that ALTA outperforms the\nbest-performing counterpart by over 4% absolute points in text-to-image\naccuracy and approximately 6% absolute points in image-to-text retrieval\naccuracy. The adaptation of vision-language models during efficient alignment\nalso promotes better vision and language understanding. Code is publicly\navailable at https://github.com/DopamineLcy/ALTA.", "AI": {"tldr": "The paper proposes ALTA, an efficient medical vision-language alignment method that adapts pretrained vision models for superior performance in vision-language matching tasks.", "motivation": "Conventional cross-modal contrastive learning methods have suboptimal visual representation capabilities while multimodal masked modeling methods struggle with direct cross-modal matching despite excelling in visual representation.", "method": "ALTA utilizes only about 8% of the trainable parameters and less than 1/5 of the computational consumption required for masked record modeling. It adapts the pretrained vision model from masked record modeling and integrates temporal-multiview radiograph inputs to enhance information consistency between radiographs and their descriptions.", "result": "ALTA outperforms the best-performing counterpart by over 4% absolute points in text-to-image accuracy and approximately 6% absolute points in image-to-text retrieval accuracy.", "conclusion": "ALTA achieves superior performance in vision-language matching tasks and promotes better vision and language understanding."}}
{"id": "2506.08654", "pdf": "https://arxiv.org/pdf/2506.08654", "abs": "https://arxiv.org/abs/2506.08654", "authors": ["Ciro Benito Raggio", "Paolo Zaffino", "Maria Francesca Spadea"], "title": "A Privacy-Preserving Federated Learning Framework for Generalizable CBCT to Synthetic CT Translation in Head and Neck", "categories": ["physics.med-ph", "cs.LG"], "comment": null, "summary": "Shortened Abstract\n  Cone-beam computed tomography (CBCT) has become a widely adopted modality for\nimage-guided radiotherapy (IGRT). However, CBCT suffers from increased noise,\nlimited soft-tissue contrast, and artifacts, resulting in unreliable Hounsfield\nunit values and hindering direct dose calculation. Synthetic CT (sCT)\ngeneration from CBCT addresses these issues, especially using deep learning\n(DL) methods. Existing approaches are limited by institutional heterogeneity,\nscanner-dependent variations, and data privacy regulations that prevent\nmulti-center data sharing.\n  To overcome these challenges, we propose a cross-silo horizontal federated\nlearning (FL) approach for CBCT-to-sCT synthesis in the head and neck region,\nextending our FedSynthCT framework. A conditional generative adversarial\nnetwork was collaboratively trained on data from three European medical centers\nin the public SynthRAD2025 challenge dataset.\n  The federated model demonstrated effective generalization across centers,\nwith mean absolute error (MAE) ranging from $64.38\\pm13.63$ to $85.90\\pm7.10$\nHU, structural similarity index (SSIM) from $0.882\\pm0.022$ to $0.922\\pm0.039$,\nand peak signal-to-noise ratio (PSNR) from $32.86\\pm0.94$ to $34.91\\pm1.04$ dB.\nNotably, on an external validation dataset of 60 patients, comparable\nperformance was achieved (MAE: $75.22\\pm11.81$ HU, SSIM: $0.904\\pm0.034$, PSNR:\n$33.52\\pm2.06$ dB) without additional training, confirming robust\ngeneralization despite protocol, scanner differences and registration errors.\n  These findings demonstrate the technical feasibility of FL for CBCT-to-sCT\nsynthesis while preserving data privacy and offer a collaborative solution for\ndeveloping generalizable models across institutions without centralized data\nsharing or site-specific fine-tuning.", "AI": {"tldr": "Cone-beam computed tomography (CBCT) has issues with noise, contrast and artifacts that hinder direct dose calculation. Synthetic CT (sCT) generation from CBCT can address these problems but is limited by institutional heterogeneity and data privacy regulations. The authors propose a cross-silo horizontal federated learning approach for CBCT-to-sCT synthesis in the head and neck region, which they call FedSynthCT. This model was trained on data from three European medical centers and showed effective generalization across centers.", "motivation": "To overcome the limitations of existing approaches for synthetic CT generation from CBCT which are limited by institutional heterogeneity, scanner-dependent variations, and data privacy regulations that prevent multi-center data sharing.", "method": "The authors propose a cross-silo horizontal federated learning (FL) approach for CBCT-to-sCT synthesis in the head and neck region. They extend their FedSynthCT framework using a conditional generative adversarial network collaboratively trained on data from three European medical centers in the public SynthRAD2025 challenge dataset.", "result": "The federated model demonstrated effective generalization across centers, with mean absolute error (MAE) ranging from $64.38\\pm13.63$ to $85.90\\pm7.10$ HU, structural similarity index (SSIM) from $0.882\\pm0.022$ to $0.922\\pm0.039$, and peak signal-to-noise ratio (PSNR) from $32.86\\pm0.94$ to $34.91\\pm1.04$ dB. On an external validation dataset of 60 patients, comparable performance was achieved without additional training.", "conclusion": "The findings demonstrate the technical feasibility of federated learning for CBCT-to-sCT synthesis while preserving data privacy and offer a collaborative solution for developing generalizable models across institutions without centralized data sharing or site-specific fine-tuning."}}
{"id": "2506.08999", "pdf": "https://arxiv.org/pdf/2506.08999", "abs": "https://arxiv.org/abs/2506.08999", "authors": ["Theo Zhang", "Madurya Suresh", "Anne S. Warlaumont", "Kasia Hitczenko", "Alejandrina Cristia", "Margaret Cychosz"], "title": "Employing self-supervised learning models for cross-linguistic child speech maturity classification", "categories": ["cs.CL", "cs.AI"], "comment": "To be published in Interspeech 2025. 5 pages, 2 figures. For\n  associated Github repository, see\n  https://github.com/spoglab-stanford/w2v2-pro-sm/tree/main/speechbrain/recipes/W2V2-LL4300-Pro-SM", "summary": "Speech technology systems struggle with many downstream tasks for child\nspeech due to small training corpora and the difficulties that child speech\npose. We apply a novel dataset, SpeechMaturity, to state-of-the-art transformer\nmodels to address a fundamental classification task: identifying child\nvocalizations. Unlike previous corpora, our dataset captures maximally\necologically-valid child vocalizations across an unprecedented sample,\ncomprising children acquiring 25+ languages in the U.S., Bolivia, Vanuatu,\nPapua New Guinea, Solomon Islands, and France. The dataset contains 242,004\nlabeled vocalizations, magnitudes larger than previous work. Models were\ntrained to distinguish between cry, laughter, mature (consonant+vowel), and\nimmature speech (just consonant or vowel). Models trained on the dataset\noutperform state-of-the-art models trained on previous datasets, achieved\nclassification accuracy comparable to humans, and were robust across rural and\nurban settings.", "AI": {"tldr": "\u901a\u8fc7\u4f7f\u7528\u65b0\u9896\u7684SpeechMaturity\u6570\u636e\u96c6\uff0c\u7814\u7a76\u63d0\u9ad8\u4e86\u513f\u7ae5\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u7684\u6a21\u578b\u6027\u80fd\uff0c\u8d85\u8d8a\u4e86\u73b0\u6709\u6280\u672f\u6c34\u5e73\uff0c\u5e76\u5728\u591a\u79cd\u73af\u5883\u4e0b\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u513f\u7ae5\u8bed\u97f3\u6280\u672f\u7cfb\u7edf\u5728\u5904\u7406\u4e0b\u6e38\u4efb\u52a1\u65f6\u6548\u679c\u4e0d\u4f73\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8bad\u7ec3\u8bed\u6599\u5e93\u89c4\u6a21\u5c0f\u4ee5\u53ca\u513f\u7ae5\u8bed\u97f3\u672c\u8eab\u7684\u590d\u6742\u6027\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e00\u72b6\u51b5\uff0c\u672c\u7814\u7a76\u5f15\u5165\u4e86\u4e00\u4e2a\u5168\u65b0\u7684\u6570\u636e\u96c6SpeechMaturity\uff0c\u4ee5\u5e94\u5bf9\u57fa\u7840\u5206\u7c7b\u4efb\u52a1\uff1a\u8bc6\u522b\u513f\u7ae5\u53d1\u58f0\u3002", "method": "\u7814\u7a76\u4f7f\u7528\u4e86\u6700\u5148\u8fdb\u7684Transformer\u6a21\u578b\uff0c\u5e76\u5728\u4e00\u4e2a\u540d\u4e3aSpeechMaturity\u7684\u65b0\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u6570\u636e\u96c6\u5305\u542b\u4e86\u751f\u6001\u6548\u5ea6\u6781\u9ad8\u7684\u513f\u7ae5\u53d1\u58f0\u6837\u672c\uff0c\u8986\u76d6\u4e86\u7f8e\u56fd\u3001\u73bb\u5229\u7ef4\u4e9a\u3001\u74e6\u52aa\u963f\u56fe\u3001\u5df4\u5e03\u4e9a\u65b0\u51e0\u5185\u4e9a\u3001\u6240\u7f57\u95e8\u7fa4\u5c9b\u548c\u6cd5\u56fd\u7b49\u5730\u533a\uff0c\u6d89\u53ca25\u79cd\u4ee5\u4e0a\u8bed\u8a00\u7684\u513f\u7ae5\u3002\u6570\u636e\u96c6\u4e2d\u6709242,004\u4e2a\u6807\u6ce8\u7684\u53d1\u58f0\u6837\u672c\uff0c\u8fdc\u8d85\u4ee5\u5f80\u7684\u7814\u7a76\u89c4\u6a21\u3002\u6a21\u578b\u88ab\u8bad\u7ec3\u7528\u4e8e\u533a\u5206\u54ed\u58f0\u3001\u7b11\u58f0\u3001\u6210\u719f\u8bed\u97f3\uff08\u8f85\u97f3+\u5143\u97f3\uff09\u548c\u4e0d\u6210\u719f\u8bed\u97f3\uff08\u4ec5\u8f85\u97f3\u6216\u5143\u97f3\uff09\u3002", "result": "\u57fa\u4e8eSpeechMaturity\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u8868\u73b0\u4f18\u4e8e\u5148\u524d\u6570\u636e\u96c6\u4e0a\u8bad\u7ec3\u7684\u6700\u5148\u8fdb\u6a21\u578b\uff0c\u5176\u5206\u7c7b\u51c6\u786e\u7387\u4e0e\u4eba\u7c7b\u76f8\u5f53\uff0c\u5e76\u4e14\u5728\u57ce\u5e02\u548c\u519c\u6751\u73af\u5883\u4e2d\u90fd\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "SpeechMaturity\u6570\u636e\u96c6\u4e3a\u513f\u7ae5\u8bed\u97f3\u8bc6\u522b\u4efb\u52a1\u63d0\u4f9b\u4e86\u663e\u8457\u6539\u8fdb\uff0c\u63d0\u5347\u4e86\u6a21\u578b\u6027\u80fd\u5e76\u5c55\u793a\u4e86\u8de8\u73af\u5883\u7684\u9c81\u68d2\u6027\u3002\u8fd9\u4e3a\u672a\u6765\u513f\u7ae5\u8bed\u97f3\u6280\u672f\u7684\u53d1\u5c55\u5960\u5b9a\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2506.08670", "pdf": "https://arxiv.org/pdf/2506.08670", "abs": "https://arxiv.org/abs/2506.08670", "authors": ["Renjie Xu", "Chong Wu", "Maolin Che", "Zhuoheng Ran", "Yimin Wei", "Hong Yan"], "title": "sparseGeoHOPCA: A Geometric Solution to Sparse Higher-Order PCA Without Covariance Estimation", "categories": ["math.NA", "cs.LG", "cs.NA", "math.OC"], "comment": null, "summary": "We propose sparseGeoHOPCA, a novel framework for sparse higher-order\nprincipal component analysis (SHOPCA) that introduces a geometric perspective\nto high-dimensional tensor decomposition. By unfolding the input tensor along\neach mode and reformulating the resulting subproblems as structured binary\nlinear optimization problems, our method transforms the original nonconvex\nsparse objective into a tractable geometric form. This eliminates the need for\nexplicit covariance estimation and iterative deflation, enabling significant\ngains in both computational efficiency and interpretability, particularly in\nhigh-dimensional and unbalanced data scenarios. We theoretically establish the\nequivalence between the geometric subproblems and the original SHOPCA\nformulation, and derive worst-case approximation error bounds based on\nclassical PCA residuals, providing data-dependent performance guarantees. The\nproposed algorithm achieves a total computational complexity of\n$O\\left(\\sum_{n=1}^{N} (k_n^3 + J_n k_n^2)\\right)$, which scales linearly with\ntensor size. Extensive experiments demonstrate that sparseGeoHOPCA accurately\nrecovers sparse supports in synthetic settings, preserves classification\nperformance under 10$\\times$ compression, and achieves high-quality image\nreconstruction on ImageNet, highlighting its robustness and versatility.", "AI": {"tldr": "This paper presents sparseGeoHOPCA, a novel framework for SHOPCA that incorporates a geometric perspective to high-dimensional tensor decomposition. It transforms nonconvex sparse objectives into tractable geometric forms, enhancing computational efficiency and interpretability. Theoretical equivalence and error bounds are established, with experiments showing accurate recovery, preserved classification performance under compression, and high-quality image reconstruction.", "motivation": "To introduce a geometric perspective to high-dimensional tensor decomposition in the context of sparse higher-order principal component analysis (SHOPCA), improving computational efficiency and interpretability, particularly in high-dimensional and unbalanced data scenarios.", "method": "The method unfolds the input tensor along each mode, reformulating subproblems as structured binary linear optimization problems. This approach eliminates the need for explicit covariance estimation and iterative deflation, transforming the original nonconvex sparse objective into a tractable geometric form.", "result": "sparseGeoHOPCA accurately recovers sparse supports in synthetic settings, preserves classification performance under 10$\\times$ compression, and achieves high-quality image reconstruction on ImageNet, demonstrating its robustness and versatility.", "conclusion": "sparseGeoHOPCA offers significant gains in computational efficiency and interpretability for high-dimensional tensor decomposition, with theoretical guarantees and strong empirical results."}}
{"id": "2506.09027", "pdf": "https://arxiv.org/pdf/2506.09027", "abs": "https://arxiv.org/abs/2506.09027", "authors": ["Runqian Wang", "Kaiming He"], "title": "Diffuse and Disperse: Image Generation with Representation Regularization", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": null, "summary": "The development of diffusion-based generative models over the past decade has\nlargely proceeded independently of progress in representation learning. These\ndiffusion models typically rely on regression-based objectives and generally\nlack explicit regularization. In this work, we propose \\textit{Dispersive\nLoss}, a simple plug-and-play regularizer that effectively improves\ndiffusion-based generative models. Our loss function encourages internal\nrepresentations to disperse in the hidden space, analogous to contrastive\nself-supervised learning, with the key distinction that it requires no positive\nsample pairs and therefore does not interfere with the sampling process used\nfor regression. Compared to the recent method of representation alignment\n(REPA), our approach is self-contained and minimalist, requiring no\npre-training, no additional parameters, and no external data. We evaluate\nDispersive Loss on the ImageNet dataset across a range of models and report\nconsistent improvements over widely used and strong baselines. We hope our work\nwill help bridge the gap between generative modeling and representation\nlearning.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDispersive Loss\u7684\u65b0\u578b\u635f\u5931\u51fd\u6570\uff0c\u7528\u4e8e\u6539\u8fdb\u6269\u6563\u751f\u6210\u6a21\u578b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u9f13\u52b1\u9690\u85cf\u7a7a\u95f4\u4e2d\u7684\u8868\u793a\u5206\u6563\u6765\u5b9e\u73b0\u6b63\u5219\u5316\u6548\u679c\uff0c\u65e0\u9700\u6b63\u6837\u672c\u5bf9\u6216\u5e72\u6270\u56de\u5f52\u91c7\u6837\u8fc7\u7a0b\u3002\u4e0eREPA\u65b9\u6cd5\u76f8\u6bd4\uff0cDispersive Loss\u65e0\u9700\u9884\u8bad\u7ec3\u3001\u989d\u5916\u53c2\u6570\u6216\u5916\u90e8\u6570\u636e\u3002\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\u4e0a\u5747\u4f18\u4e8e\u5f3a\u5927\u57fa\u7ebf\u6a21\u578b\u3002", "motivation": "\u6269\u6563\u751f\u6210\u6a21\u578b\u5728\u8fc7\u53bb\u5341\u5e74\u4e2d\u72ec\u7acb\u4e8e\u8868\u5f81\u5b66\u4e60\u53d1\u5c55\uff0c\u901a\u5e38\u4f9d\u8d56\u56de\u5f52\u76ee\u6807\u4e14\u7f3a\u4e4f\u663e\u5f0f\u6b63\u5219\u5316\u3002\u4e3a\u4e86\u6539\u5584\u8fd9\u4e00\u60c5\u51b5\u5e76\u5f25\u5408\u751f\u6210\u5efa\u6a21\u548c\u8868\u5f81\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u6b63\u5219\u5316\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDispersive Loss\u7684\u635f\u5931\u51fd\u6570\uff0c\u5b83\u9f13\u52b1\u5185\u90e8\u8868\u793a\u5728\u9690\u85cf\u7a7a\u95f4\u4e2d\u5206\u6563\u3002\u8fd9\u79cd\u65b9\u6cd5\u7c7b\u4f3c\u4e8e\u5bf9\u6bd4\u81ea\u76d1\u7763\u5b66\u4e60\uff0c\u4f46\u4e0d\u9700\u8981\u6b63\u6837\u672c\u5bf9\uff0c\u56e0\u6b64\u4e0d\u4f1a\u5e72\u6270\u56de\u5f52\u91c7\u6837\u8fc7\u7a0b\u3002\u6b64\u5916\uff0cDispersive Loss\u662f\u81ea\u5305\u542b\u7684\uff0c\u4e0d\u9700\u8981\u9884\u8bad\u7ec3\u3001\u989d\u5916\u53c2\u6570\u6216\u5916\u90e8\u6570\u636e\u3002", "result": "\u5728ImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f7f\u7528Dispersive Loss\u53ef\u4ee5\u4e00\u81f4\u5730\u63d0\u9ad8\u591a\u4e2a\u6a21\u578b\u7684\u6027\u80fd\uff0c\u4f18\u4e8e\u5e7f\u6cdb\u4f7f\u7528\u7684\u5f3a\u5927\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "Dispersive Loss\u662f\u4e00\u79cd\u7b80\u5355\u6709\u6548\u7684\u63d2\u4ef6\u5f0f\u6b63\u5219\u5316\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6269\u6563\u751f\u6210\u6a21\u578b\u7684\u6027\u80fd\uff0c\u5e76\u6709\u671b\u5f25\u5408\u751f\u6210\u5efa\u6a21\u548c\u8868\u5f81\u5b66\u4e60\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002"}}
{"id": "2506.08725", "pdf": "https://arxiv.org/pdf/2506.08725", "abs": "https://arxiv.org/abs/2506.08725", "authors": ["Hyeon Jeon", "Jeongin Park", "Sungbok Shin", "Jinwook Seo"], "title": "Stop Misusing t-SNE and UMAP for Visual Analytics", "categories": ["cs.HC", "cs.LG"], "comment": "9 pages", "summary": "Misuses of t-SNE and UMAP in visual analytics have become increasingly\ncommon. For example, although t-SNE and UMAP projections often do not\nfaithfully reflect true distances between clusters, practitioners frequently\nuse them to investigate inter-cluster relationships. In this paper, we bring\nthis issue to the surface and comprehensively investigate why such misuse\noccurs and how to prevent it. We conduct a literature review of 114 papers to\nverify the prevalence of the misuse and analyze the reasonings behind it. We\nthen execute an interview study to uncover practitioners' implicit motivations\nfor using these techniques -- rationales often undisclosed in the literature.\nOur findings indicate that misuse of t-SNE and UMAP primarily stems from\nlimited discourse on their appropriate use in visual analytics. We conclude by\nproposing future directions and concrete action items to promote more\nreasonable use of DR.", "AI": {"tldr": "Misuses of t-SNE and UMAP in visual analytics are prevalent because of limited discourse on their appropriate use.", "motivation": "The motivation is to investigate why misuses of t-SNE and UMAP occur and how to prevent them as these misuses are increasingly common.", "method": "Conduct a literature review of 114 papers to verify the prevalence of misuse and analyze the reasonings, then execute an interview study to uncover practitioners' implicit motivations.", "result": "Findings indicate that misuse primarily stems from limited discourse on appropriate use in visual analytics.", "conclusion": "Propose future directions and concrete action items to promote more reasonable use of DR."}}
{"id": "2506.09033", "pdf": "https://arxiv.org/pdf/2506.09033", "abs": "https://arxiv.org/abs/2506.09033", "authors": ["Haozhen Zhang", "Tao Feng", "Jiaxuan You"], "title": "Router-R1: Teaching LLMs Multi-Round Routing and Aggregation via Reinforcement Learning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Code is available at https://github.com/ulab-uiuc/Router-R1", "summary": "The rapid emergence of diverse large language models (LLMs) has spurred the\ndevelopment of LLM routers that assign user queries to the most suitable model.\nHowever, existing LLM routers typically perform a single-round, one-to-one\nmapping (\\textit{i.e.}, assigning each query to a single model in isolation),\nwhich limits their capability to tackle complex tasks that demand the\ncomplementary strengths of multiple LLMs. In this paper, we present\n\\textbf{Router-R1}, a reinforcement learning (RL)-based framework that\nformulates multi-LLM routing and aggregation as a sequential decision process.\nRouter-R1 instantiates the router itself as a capable LLM, leveraging its\nreasoning ability to interleave \"think\" actions (internal deliberation) with\n\"route\" actions (dynamic model invocation), and integrates each response into\nits evolving context. To guide learning, we employ a lightweight rule-based\nreward comprising format rewards, final outcome rewards, and a novel cost\nreward for performance and cost trade-off optimization, opening a pathway\ntoward optimizing performance-cost tradeoffs via RL. Router-R1 also conditions\nonly on simple model descriptors such as pricing, latency, and example\nperformance, enabling strong generalization to unseen model selection.\nExperiments on seven general and multi-hop QA benchmarks show that Router-R1\noutperforms over several strong baselines, achieving superior performance while\nmaintaining robust generalization and cost management.Code is available at\nhttps://github.com/ulab-uiuc/Router-R1.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u591a\u8bed\u8a00\u6a21\u578b\u8def\u7531\u6846\u67b6Router-R1\uff0c\u901a\u8fc7\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\u5b9e\u73b0\u590d\u6742\u4efb\u52a1\u4e2d\u7684\u6a21\u578b\u5206\u914d\u4e0e\u96c6\u6210\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u5f53\u524d\u7684\u8bed\u8a00\u6a21\u578b\u8def\u7531\u5668\u901a\u5e38\u91c7\u7528\u5355\u8f6e\u4e00\u5bf9\u4e00\u6620\u5c04\u65b9\u5f0f\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\u6765\u89e3\u51b3\u590d\u6742\u4efb\u52a1\u3002", "method": "Router-R1\u5c06\u591a\u8bed\u8a00\u6a21\u578b\u8def\u7531\u548c\u805a\u5408\u89c6\u4e3a\u5e8f\u5217\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5229\u7528\u5f3a\u5316\u5b66\u4e60\u8fdb\u884c\u8bad\u7ec3\uff1b\u8def\u7531\u5668\u672c\u8eab\u88ab\u5b9e\u4f8b\u5316\u4e3a\u4e00\u4e2a\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u7ed3\u5408\u201c\u601d\u8003\u201d\u548c\u201c\u8def\u7531\u201d\u52a8\u4f5c\uff0c\u5e76\u6574\u5408\u6bcf\u4e2a\u54cd\u5e94\u5230\u5176\u4e0a\u4e0b\u6587\u4e2d\uff1b\u4f7f\u7528\u8f7b\u91cf\u7ea7\u89c4\u5219\u5956\u52b1\u6307\u5bfc\u5b66\u4e60\uff0c\u5305\u62ec\u683c\u5f0f\u5956\u52b1\u3001\u6700\u7ec8\u7ed3\u679c\u5956\u52b1\u548c\u6210\u672c\u5956\u52b1\u3002", "result": "\u5728\u4e03\u4e2a\u901a\u7528\u548c\u591a\u8df3\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cRouter-R1\u4f18\u4e8e\u591a\u4e2a\u5f3a\u57fa\u7ebf\uff0c\u5728\u4fdd\u6301\u7a33\u5065\u6cdb\u5316\u548c\u6210\u672c\u7ba1\u7406\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "Router-R1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u4f18\u5316\u4e86\u6027\u80fd-\u6210\u672c\u6743\u8861\uff0c\u4ec5\u9700\u7b80\u5355\u6a21\u578b\u63cf\u8ff0\u7b26\u5373\u53ef\u5b9e\u73b0\u5bf9\u672a\u89c1\u6a21\u578b\u9009\u62e9\u7684\u5f3a\u5927\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2506.08734", "pdf": "https://arxiv.org/pdf/2506.08734", "abs": "https://arxiv.org/abs/2506.08734", "authors": ["Nelvin Tan", "Yu-Ching Shih", "Dong Yang", "Amol Salunkhe"], "title": "Flexible and Efficient Drift Detection without Labels", "categories": ["stat.ML", "cs.LG", "stat.AP"], "comment": "9 pages, 4 figures", "summary": "Machine learning models are being increasingly used to automate decisions in\nalmost every domain, and ensuring the performance of these models is crucial\nfor ensuring high quality machine learning enabled services. Ensuring concept\ndrift is detected early is thus of the highest importance. A lot of research on\nconcept drift has focused on the supervised case that assumes the true labels\nof supervised tasks are available immediately after making predictions.\nControlling for false positives while monitoring the performance of predictive\nmodels used to make inference from extremely large datasets periodically, where\nthe true labels are not instantly available, becomes extremely challenging. We\npropose a flexible and efficient concept drift detection algorithm that uses\nclassical statistical process control in a label-less setting to accurately\ndetect concept drifts. We shown empirically that under computational\nconstraints, our approach has better statistical power than previous known\nmethods. Furthermore, we introduce a new drift detection framework to model the\nscenario of detecting drift (without labels) given prior detections, and show\nour how our drift detection algorithm can be incorporated effectively into this\nframework. We demonstrate promising performance via numerical simulations.", "AI": {"tldr": "The paper proposes a flexible and efficient label-less concept drift detection algorithm using classical statistical process control, demonstrating better statistical power under computational constraints and introducing a new drift detection framework.", "motivation": "There is a need for early detection of concept drift in machine learning models to ensure their performance. Current research mainly focuses on supervised cases where true labels are immediately available after predictions, but in scenarios with extremely large datasets where true labels are not instantly accessible, controlling false positives becomes challenging.", "method": "The authors propose an algorithm that uses classical statistical process control in a label-less setting to detect concept drifts. They also introduce a new drift detection framework to model the scenario of detecting drift without labels given prior detections.", "result": "Empirical results show that the proposed approach has better statistical power than previous methods under computational constraints. The algorithm performs promisingly in numerical simulations.", "conclusion": "The proposed concept drift detection algorithm is effective in a label-less setting and can be incorporated into a new drift detection framework, offering promising performance."}}
{"id": "2506.09040", "pdf": "https://arxiv.org/pdf/2506.09040", "abs": "https://arxiv.org/abs/2506.09040", "authors": ["Dianyi Wang", "Wei Song", "Yikun Wang", "Siyuan Wang", "Kaicheng Yu", "Zhongyu Wei", "Jiaqi Wang"], "title": "Autoregressive Semantic Visual Reconstruction Helps VLMs Understand Better", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Typical large vision-language models (LVLMs) apply autoregressive supervision\nsolely to textual sequences, without fully incorporating the visual modality\ninto the learning process. This results in three key limitations: (1) an\ninability to utilize images without accompanying captions, (2) the risk that\ncaptions omit critical visual details, and (3) the challenge that certain\nvision-centric content cannot be adequately conveyed through text. As a result,\ncurrent LVLMs often prioritize vision-to-language alignment while potentially\noverlooking fine-grained visual information. While some prior works have\nexplored autoregressive image generation, effectively leveraging autoregressive\nvisual supervision to enhance image understanding remains an open challenge. In\nthis paper, we introduce Autoregressive Semantic Visual Reconstruction (ASVR),\nwhich enables joint learning of visual and textual modalities within a unified\nautoregressive framework. We show that autoregressively reconstructing the raw\nvisual appearance of images does not enhance and may even impair multimodal\nunderstanding. In contrast, autoregressively reconstructing the semantic\nrepresentation of images consistently improves comprehension. Notably, we find\nthat even when models are given continuous image features as input, they can\neffectively reconstruct discrete semantic tokens, resulting in stable and\nconsistent improvements across a wide range of multimodal understanding\nbenchmarks. Our approach delivers significant performance gains across varying\ndata scales (556k-2M) and types of LLM bacbones. Specifically, ASVR improves\nLLaVA-1.5 by 5% in average scores across 14 multimodal benchmarks. The code is\navailable at https://github.com/AlenjandroWang/ASVR.", "AI": {"tldr": "The paper introduces Autoregressive Semantic Visual Reconstruction (ASVR) to address limitations in large vision-language models by enabling joint learning of visual and textual modalities, leading to significant performance gains.", "motivation": "Current large vision-language models primarily focus on text-based autoregressive supervision, potentially overlooking fine-grained visual details. This leads to challenges such as underutilization of images without captions, omission of critical visual details in captions, and difficulty conveying vision-centric content through text.", "method": "The authors propose ASVR, which involves autoregressively reconstructing the semantic representation of images within a unified framework. They demonstrate that this approach is more effective than raw visual appearance reconstruction, leading to consistent improvements in multimodal understanding.", "result": "ASVR results in stable and consistent improvements across various multimodal benchmarks. Specifically, it improves LLaVA-1.5 by 5% in average scores across 14 benchmarks, showcasing its effectiveness across different data scales and LLM backbones.", "conclusion": "ASVR successfully enhances multimodal understanding by effectively integrating visual and textual modalities through autoregressive semantic reconstruction, offering a promising direction for future advancements in LVLMs."}}
{"id": "2506.08746", "pdf": "https://arxiv.org/pdf/2506.08746", "abs": "https://arxiv.org/abs/2506.08746", "authors": ["Muhammad Anwar", "Mishca de Costa", "Issam Hammad", "Daniel Lau"], "title": "Towards Secure and Private Language Models for Nuclear Power Plants", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "This paper introduces a domain-specific Large Language Model for nuclear\napplications, built from the publicly accessible Essential CANDU textbook.\nDrawing on a compact Transformer-based architecture, the model is trained on a\nsingle GPU to protect the sensitive data inherent in nuclear operations.\nDespite relying on a relatively small dataset, it shows encouraging signs of\ncapturing specialized nuclear vocabulary, though the generated text sometimes\nlacks syntactic coherence. By focusing exclusively on nuclear content, this\napproach demonstrates the feasibility of in-house LLM solutions that align with\nrigorous cybersecurity and data confidentiality standards. Early successes in\ntext generation underscore the model's utility for specialized tasks, while\nalso revealing the need for richer corpora, more sophisticated preprocessing,\nand instruction fine-tuning to enhance domain accuracy. Future directions\ninclude extending the dataset to cover diverse nuclear subtopics, refining\ntokenization to reduce noise, and systematically evaluating the model's\nreadiness for real-world applications in nuclear domain.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u4e00\u79cd\u7528\u4e8e\u6838\u5e94\u7528\u7684\u9886\u57df\u4e13\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u8be5\u6a21\u578b\u57fa\u4e8e\u516c\u5f00\u53ef\u83b7\u53d6\u7684\u300aEssential CANDU\u300b\u6559\u79d1\u4e66\u6784\u5efa\u3002\u91c7\u7528\u7d27\u51d1\u7684Transformer\u67b6\u6784\uff0c\u5728\u5355\u4e2aGPU\u4e0a\u8bad\u7ec3\u4ee5\u4fdd\u62a4\u6838\u64cd\u4f5c\u4e2d\u7684\u654f\u611f\u6570\u636e\u3002\u5c3d\u7ba1\u6570\u636e\u96c6\u8f83\u5c0f\uff0c\u4f46\u6a21\u578b\u5c55\u793a\u4e86\u6355\u6349\u4e13\u4e1a\u6838\u8bcd\u6c47\u7684\u6f5c\u529b\uff0c\u5c3d\u7ba1\u751f\u6210\u7684\u6587\u672c\u6709\u65f6\u7f3a\u4e4f\u8bed\u6cd5\u8fde\u8d2f\u6027\u3002\u4e13\u6ce8\u4e8e\u6838\u5185\u5bb9\u7684\u65b9\u6cd5\u8bc1\u660e\u4e86\u7b26\u5408\u4e25\u683c\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u5bc6\u6807\u51c6\u7684\u5185\u90e8LLM\u89e3\u51b3\u65b9\u6848\u7684\u53ef\u884c\u6027\u3002\u65e9\u671f\u7684\u6587\u672c\u751f\u6210\u6210\u529f\u7a81\u663e\u4e86\u6a21\u578b\u5728\u7279\u5b9a\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\uff0c\u540c\u65f6\u4e5f\u63ed\u793a\u4e86\u9700\u8981\u66f4\u4e30\u5bcc\u7684\u8bed\u6599\u5e93\u3001\u66f4\u590d\u6742\u7684\u9884\u5904\u7406\u548c\u6307\u4ee4\u5fae\u8c03\u6765\u63d0\u9ad8\u9886\u57df\u51c6\u786e\u6027\u3002\u672a\u6765\u65b9\u5411\u5305\u62ec\u6269\u5c55\u6570\u636e\u96c6\u8986\u76d6\u66f4\u591a\u6838\u5b50\u4e3b\u9898\u3001\u6539\u8fdb\u5206\u8bcd\u4ee5\u51cf\u5c11\u566a\u97f3\u4ee5\u53ca\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5728\u6838\u9886\u57df\u7684\u5b9e\u9645\u5e94\u7528\u51c6\u5907\u60c5\u51b5\u3002", "motivation": "\u968f\u7740\u5bf9\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u5bc6\u7684\u8981\u6c42\u65e5\u76ca\u4e25\u683c\uff0c\u5f00\u53d1\u4e00\u79cd\u7b26\u5408\u8fd9\u4e9b\u6807\u51c6\u7684\u9886\u57df\u4e13\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u4e8e\u6838\u5de5\u4e1a\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7684\u901a\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u53ef\u80fd\u65e0\u6cd5\u6ee1\u8db3\u6838\u5e94\u7528\u7684\u7279\u6b8a\u9700\u6c42\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u4e13\u6ce8\u4e8e\u6838\u5185\u5bb9\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u6765\u81ea\u300aEssential CANDU\u300b\u6559\u79d1\u4e66\u7684\u6570\u636e\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u57fa\u4e8eTransformer\u67b6\u6784\u7684\u9886\u57df\u4e13\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u3002\u8be5\u6a21\u578b\u5728\u5355\u4e2aGPU\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u4ee5\u786e\u4fdd\u654f\u611f\u6570\u636e\u7684\u5b89\u5168\u6027\u3002\u901a\u8fc7\u4e13\u6ce8\u4e8e\u6838\u76f8\u5173\u5185\u5bb9\uff0c\u6a21\u578b\u8bd5\u56fe\u6355\u6349\u4e13\u4e1a\u7684\u6838\u8bcd\u6c47\u5e76\u751f\u6210\u76f8\u5173\u7684\u6587\u672c\u3002", "result": "\u5c3d\u7ba1\u6570\u636e\u96c6\u76f8\u5bf9\u8f83\u5c0f\uff0c\u6a21\u578b\u5728\u6355\u6349\u4e13\u4e1a\u6838\u8bcd\u6c47\u65b9\u9762\u663e\u793a\u51fa\u79ef\u6781\u7684\u8ff9\u8c61\u3002\u7136\u800c\uff0c\u751f\u6210\u7684\u6587\u672c\u6709\u65f6\u7f3a\u4e4f\u8bed\u6cd5\u8fde\u8d2f\u6027\u3002\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5b9e\u73b0\u7b26\u5408\u7f51\u7edc\u5b89\u5168\u548c\u6570\u636e\u4fdd\u5bc6\u6807\u51c6\u7684\u5185\u90e8LLM\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u867d\u7136\u5f53\u524d\u6a21\u578b\u5728\u8bed\u6cd5\u8fde\u8d2f\u6027\u548c\u9886\u57df\u51c6\u786e\u6027\u65b9\u9762\u8fd8\u6709\u63d0\u5347\u7a7a\u95f4\uff0c\u4f46\u5b83\u5c55\u793a\u4e86\u5728\u6838\u5e94\u7528\u4e2d\u4f7f\u7528\u9886\u57df\u4e13\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6f5c\u529b\u3002\u672a\u6765\u5de5\u4f5c\u5c06\u96c6\u4e2d\u5728\u6269\u5c55\u6570\u636e\u96c6\u3001\u6539\u8fdb\u9884\u5904\u7406\u548c\u5206\u8bcd\u6280\u672f\uff0c\u4ee5\u53ca\u8fdb\u4e00\u6b65\u8bc4\u4f30\u6a21\u578b\u7684\u5b9e\u9645\u5e94\u7528\u51c6\u5907\u60c5\u51b5\u3002"}}
{"id": "2506.08749", "pdf": "https://arxiv.org/pdf/2506.08749", "abs": "https://arxiv.org/abs/2506.08749", "authors": ["Viktoria Patapovich", "Mo Kordzanganeh", "Alexey Melnikov"], "title": "Superposed Parameterised Quantum Circuits", "categories": ["quant-ph", "cs.ET", "cs.LG", "cs.NE"], "comment": "20 pages, 6 figures, 3 tables", "summary": "Quantum machine learning has shown promise for high-dimensional data\nanalysis, yet many existing approaches rely on linear unitary operations and\nshared trainable parameters across outputs. These constraints limit\nexpressivity and scalability relative to the multi-layered, non-linear\narchitectures of classical deep networks. We introduce superposed parameterised\nquantum circuits to overcome these limitations. By combining flip-flop quantum\nrandom-access memory with repeat-until-success protocols, a superposed\nparameterised quantum circuit embeds an exponential number of parameterised\nsub-models in a single circuit and induces polynomial activation functions\nthrough amplitude transformations and post-selection. We provide an analytic\ndescription of the architecture, showing how multiple parameter sets are\ntrained in parallel while non-linear amplitude transformations broaden\nrepresentational power beyond conventional quantum kernels. Numerical\nexperiments underscore these advantages: on a 1D step-function regression a\ntwo-qubit superposed parameterised quantum circuit cuts the mean-squared error\nby three orders of magnitude versus a parameter-matched variational baseline;\non a 2D star-shaped two-dimensional classification task, introducing a\nquadratic activation lifts accuracy to 81.4% and reduces run-to-run variance\nthree-fold. These results position superposed parameterised quantum circuits as\na hardware-efficient route toward deeper, more versatile parameterised quantum\ncircuits capable of learning complex decision boundaries.", "AI": {"tldr": "Quantum machine learning uses superposed parameterised quantum circuits for high-dimensional data analysis, which can overcome the limitations of linear unitary operations and shared trainable parameters across outputs.", "motivation": "The motivation is to develop a more expressive and scalable quantum machine learning model that goes beyond the constraints of linear unitary operations and shared parameters.", "method": "By combining flip-flop quantum random-access memory with repeat-until-success protocols, a superposed parameterised quantum circuit embeds an exponential number of parameterised sub-models in a single circuit and induces polynomial activation functions through amplitude transformations and post-selection.", "result": "On a 1D step-function regression task, this method reduces mean-squared error by three orders of magnitude compared to a variational baseline. On a 2D star-shaped classification task, introducing a quadratic activation increases accuracy to 81.4% and reduces run-to-run variance three-fold.", "conclusion": "Superposed parameterised quantum circuits provide a hardware-efficient approach towards deeper and more versatile quantum circuits that can learn complex decision boundaries."}}
{"id": "2506.08757", "pdf": "https://arxiv.org/pdf/2506.08757", "abs": "https://arxiv.org/abs/2506.08757", "authors": ["Mishca de Costa", "Muhammad Anwar", "Dave Mercier", "Mark Randall", "Issam Hammad"], "title": "Enhancing Accuracy and Maintainability in Nuclear Plant Data Retrieval: A Function-Calling LLM Approach Over NL-to-SQL", "categories": ["cs.CL", "cs.LG"], "comment": "44th Annual CNS Conference and the 49th Annual CNS/CNA Student\n  Conference, Westin Harbour Castle Hotel, Toronto, ON, Canada, June 8-11, 2025", "summary": "Retrieving operational data from nuclear power plants requires exceptional\naccuracy and transparency due to the criticality of the decisions it supports.\nTraditionally, natural language to SQL (NL-to-SQL) approaches have been\nexplored for querying such data. While NL-to-SQL promises ease of use, it poses\nsignificant risks: end-users cannot easily validate generated SQL queries, and\nlegacy nuclear plant databases -- often complex and poorly structured --\ncomplicate query generation due to decades of incremental modifications. These\nchallenges increase the likelihood of inaccuracies and reduce trust in the\napproach. In this work, we propose an alternative paradigm: leveraging\nfunction-calling large language models (LLMs) to address these challenges.\nInstead of directly generating SQL queries, we define a set of pre-approved,\npurpose-specific functions representing common use cases. Queries are processed\nby invoking these functions, which encapsulate validated SQL logic. This hybrid\napproach mitigates the risks associated with direct NL-to-SQL translations by\nensuring that SQL queries are reviewed and optimized by experts before\ndeployment. While this strategy introduces the upfront cost of developing and\nmaintaining the function library, we demonstrate how NL-to-SQL tools can assist\nin the initial generation of function code, allowing experts to focus on\nvalidation rather than creation. Our study includes a performance comparison\nbetween direct NL-to-SQL generation and the proposed function-based approach,\nhighlighting improvements in accuracy and maintainability. This work\nunderscores the importance of balancing user accessibility with operational\nsafety and provides a novel, actionable framework for robust data retrieval in\ncritical systems.", "AI": {"tldr": "\u5728\u6838\u7535\u5382\u6570\u636e\u68c0\u7d22\u4e2d\uff0c\u4f20\u7edf\u7684\u81ea\u7136\u8bed\u8a00\u5230SQL\uff08NL-to-SQL\uff09\u65b9\u6cd5\u5b58\u5728\u98ce\u9669\u548c\u6311\u6218\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u51fd\u6570\u8c03\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u901a\u8fc7\u9884\u5b9a\u4e49\u529f\u80fd\u7279\u5b9a\u7684\u51fd\u6570\u6765\u5c01\u88c5\u9a8c\u8bc1\u8fc7\u7684SQL\u903b\u8f91\uff0c\u4ece\u800c\u63d0\u9ad8\u51c6\u786e\u6027\u548c\u53ef\u7ef4\u62a4\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u98ce\u9669\u3002", "motivation": "\u6838\u7535\u5382\u6570\u636e\u68c0\u7d22\u8981\u6c42\u6781\u9ad8\u7684\u51c6\u786e\u6027\u548c\u900f\u660e\u5ea6\uff0c\u4f46\u4f20\u7edf\u7684NL-to-SQL\u65b9\u6cd5\u5b58\u5728\u751f\u6210\u7684SQL\u67e5\u8be2\u96be\u4ee5\u9a8c\u8bc1\u3001\u4ee5\u53ca\u590d\u6742\u4e14\u7ed3\u6784\u4e0d\u826f\u7684\u6570\u636e\u5e93\u5e26\u6765\u7684\u6311\u6218\uff0c\u8fd9\u4e9b\u95ee\u9898\u589e\u52a0\u4e86\u4e0d\u51c6\u786e\u6027\u5e76\u964d\u4f4e\u4e86\u5bf9\u8be5\u65b9\u6cd5\u7684\u4fe1\u4efb\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u51fd\u6570\u8c03\u7528\u7684\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u5b9a\u4e49\u4e00\u7ec4\u9884\u6279\u51c6\u7684\u7279\u5b9a\u7528\u9014\u51fd\u6570\u4ee5\u4ee3\u8868\u5e38\u89c1\u4f7f\u7528\u6848\u4f8b\u3002\u8fd9\u4e9b\u51fd\u6570\u5c01\u88c5\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684SQL\u903b\u8f91\uff0c\u4ece\u800c\u907f\u514d\u76f4\u63a5\u751f\u6210SQL\u67e5\u8be2\uff0c\u5e76\u786e\u4fdd\u4e13\u5bb6\u5728\u90e8\u7f72\u524d\u5bf9SQL\u67e5\u8be2\u8fdb\u884c\u5ba1\u67e5\u548c\u4f18\u5316\u3002\u6b64\u5916\uff0c\u8fd8\u63a2\u8ba8\u4e86\u5982\u4f55\u5229\u7528NL-to-SQL\u5de5\u5177\u534f\u52a9\u751f\u6210\u521d\u59cb\u51fd\u6570\u4ee3\u7801\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u4e0e\u76f4\u63a5NL-to-SQL\u751f\u6210\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u51fd\u6570\u7684\u65b9\u6cd5\u63d0\u9ad8\u4e86\u51c6\u786e\u6027\u548c\u53ef\u7ef4\u62a4\u6027\u3002", "conclusion": "\u672c\u6587\u5f3a\u8c03\u4e86\u5728\u5173\u952e\u7cfb\u7edf\u4e2d\u5e73\u8861\u7528\u6237\u6613\u7528\u6027\u548c\u64cd\u4f5c\u5b89\u5168\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u3001\u53ef\u884c\u7684\u6846\u67b6\u7528\u4e8e\u7a33\u5065\u7684\u6570\u636e\u68c0\u7d22\u3002"}}
{"id": "2506.08762", "pdf": "https://arxiv.org/pdf/2506.08762", "abs": "https://arxiv.org/abs/2506.08762", "authors": ["Issa Sugiura", "Takashi Ishida", "Taro Makino", "Chieko Tazuke", "Takanori Nakagawa", "Kosuke Nakago", "David Ha"], "title": "EDINET-Bench: Evaluating LLMs on Complex Financial Tasks using Japanese Financial Statements", "categories": ["q-fin.ST", "cs.CE", "cs.CL", "cs.LG"], "comment": null, "summary": "Financial analysis presents complex challenges that could leverage large\nlanguage model (LLM) capabilities. However, the scarcity of challenging\nfinancial datasets, particularly for Japanese financial data, impedes academic\ninnovation in financial analytics. As LLMs advance, this lack of accessible\nresearch resources increasingly hinders their development and evaluation in\nthis specialized domain. To address this gap, we introduce EDINET-Bench, an\nopen-source Japanese financial benchmark designed to evaluate the performance\nof LLMs on challenging financial tasks including accounting fraud detection,\nearnings forecasting, and industry prediction. EDINET-Bench is constructed by\ndownloading annual reports from the past 10 years from Japan's Electronic\nDisclosure for Investors' NETwork (EDINET) and automatically assigning labels\ncorresponding to each evaluation task. Our experiments reveal that even\nstate-of-the-art LLMs struggle, performing only slightly better than logistic\nregression in binary classification for fraud detection and earnings\nforecasting. These results highlight significant challenges in applying LLMs to\nreal-world financial applications and underscore the need for domain-specific\nadaptation. Our dataset, benchmark construction code, and evaluation code is\npublicly available to facilitate future research in finance with LLMs.", "AI": {"tldr": "The paper introduces EDINET-Bench, an open-source Japanese financial benchmark to evaluate LLMs on tasks like fraud detection and earnings forecasting. Experiments show LLMs perform only slightly better than logistic regression in binary classification for these tasks. The dataset and code are publicly available.", "motivation": "The motivation of this paper is to address the gap in challenging financial datasets, particularly for Japanese financial data, which impedes academic innovation in financial analytics and hinders the development and evaluation of LLMs in this specialized domain.", "method": "The authors constructed EDINET-Bench by downloading annual reports from Japan's EDINET over the past 10 years and automatically assigning labels corresponding to evaluation tasks such as accounting fraud detection, earnings forecasting, and industry prediction.", "result": "Experiments reveal that state-of-the-art LLMs struggle with these tasks, performing only slightly better than logistic regression in binary classification for fraud detection and earnings forecasting.", "conclusion": "These results highlight significant challenges in applying LLMs to real-world financial applications and emphasize the need for domain-specific adaptation."}}
{"id": "2506.08780", "pdf": "https://arxiv.org/pdf/2506.08780", "abs": "https://arxiv.org/abs/2506.08780", "authors": ["Isaac Corley", "Lakshay Sharma", "Ruth Crasto"], "title": "Landsat-Bench: Datasets and Benchmarks for Landsat Foundation Models", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The Landsat program offers over 50 years of globally consistent Earth\nimagery. However, the lack of benchmarks for this data constrains progress\ntowards Landsat-based Geospatial Foundation Models (GFM). In this paper, we\nintroduce Landsat-Bench, a suite of three benchmarks with Landsat imagery that\nadapt from existing remote sensing datasets -- EuroSAT-L, BigEarthNet-L, and\nLC100-L. We establish baseline and standardized evaluation methods across both\ncommon architectures and Landsat foundation models pretrained on the SSL4EO-L\ndataset. Notably, we provide evidence that SSL4EO-L pretrained GFMs extract\nbetter representations for downstream tasks in comparison to ImageNet,\nincluding performance gains of +4% OA and +5.1% mAP on EuroSAT-L and\nBigEarthNet-L.", "AI": {"tldr": "The paper presents Landsat-Bench, a set of three benchmarks based on Landsat imagery, and shows that SSL4EO-L pretrained Geospatial Foundation Models (GFMs) offer better representations for downstream tasks compared to ImageNet.", "motivation": "The motivation is the lack of benchmarks for Landsat data which limits progress towards developing Landsat-based Geospatial Foundation Models (GFM).", "method": "The method involves introducing Landsat-Bench, consisting of three benchmarks adapted from existing remote sensing datasets (EuroSAT-L, BigEarthNet-L, and LC100-L), and establishing baseline and standardized evaluation methods across common architectures and Landsat foundation models pretrained on the SSL4EO-L dataset.", "result": "SSL4EO-L pretrained GFMs extract better representations for downstream tasks than ImageNet, with performance gains of +4% Overall Accuracy (OA) and +5.1% mean Average Precision (mAP) on EuroSAT-L and BigEarthNet-L.", "conclusion": "Landsat-Bench provides valuable benchmarks for Landsat imagery and demonstrates the effectiveness of SSL4EO-L pretrained GFMs for downstream tasks."}}
{"id": "2506.08783", "pdf": "https://arxiv.org/pdf/2506.08783", "abs": "https://arxiv.org/abs/2506.08783", "authors": ["Lukas Kammerer", "Deaglan J. Bartlett", "Gabriel Kronberger", "Harry Desmond", "Pedro G. Ferreira"], "title": "syren-baryon: Analytic emulators for the impact of baryons on the matter power spectrum", "categories": ["astro-ph.CO", "astro-ph.GA", "astro-ph.IM", "cs.LG", "cs.NE"], "comment": "14 pages, 6 figures. Submitted to A&A", "summary": "Baryonic physics has a considerable impact on the distribution of matter in\nour Universe on scales probed by current and future cosmological surveys,\nacting as a key systematic in such analyses. We seek simple symbolic\nparametrisations for the impact of baryonic physics on the matter power\nspectrum for a range of physically motivated models, as a function of\nwavenumber, redshift, cosmology, and parameters controlling the baryonic\nfeedback. We use symbolic regression to construct analytic approximations for\nthe ratio of the matter power spectrum in the presence of baryons to that\nwithout such effects. We obtain separate functions of each of four distinct\nsub-grid prescriptions of baryonic physics from the CAMELS suite of\nhydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as\nwell as for a baryonification algorithm. We also provide functions which\ndescribe the uncertainty on these predictions, due to both the stochastic\nnature of baryonic physics and the errors on our fits. The error on our\napproximations to the hydrodynamical simulations is comparable to the sample\nvariance estimated through varying initial conditions, and our baryonification\nexpression has a root mean squared error of better than one percent, although\nthis increases on small scales. These errors are comparable to those of\nprevious numerical emulators for these models. Our expressions are enforced to\nhave the physically correct behaviour on large scales and at high redshift. Due\nto their analytic form, we are able to directly interpret the impact of varying\ncosmology and feedback parameters, and we can identify parameters which have\nlittle to no effect. Each function is based on a different implementation of\nbaryonic physics, and can therefore be used to discriminate between these\nmodels when applied to real data. We provide publicly available code for all\nsymbolic approximations found.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u7b26\u53f7\u56de\u5f52\u65b9\u6cd5\u6784\u5efa\u4e86\u5206\u6790\u8fd1\u4f3c\u503c\uff0c\u4ee5\u8868\u793a\u6709\u65e0\u91cd\u5b50\u6548\u5e94\u4e0b\u7269\u8d28\u529f\u7387\u8c31\u7684\u6bd4\u7387\u3002\u8fd9\u4e9b\u8868\u8fbe\u5f0f\u9002\u7528\u4e8e\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u6a21\u578b\uff0c\u5e76\u80fd\u89e3\u91ca\u4e0d\u786e\u5b9a\u6027\u6765\u6e90\u3002\u8bef\u5dee\u4e0e\u5148\u524d\u6570\u503c\u6a21\u62df\u76f8\u5f53\uff0c\u4e14\u5728\u5927\u5c3a\u5ea6\u548c\u9ad8\u7ea2\u79fb\u65f6\u884c\u4e3a\u6b63\u786e\u3002\u6b64\u7814\u7a76\u6709\u52a9\u4e8e\u533a\u5206\u91cd\u5b50\u7269\u7406\u6a21\u578b\u5e76\u63d0\u4f9b\u516c\u5f00\u4ee3\u7801\u3002", "motivation": "\u91cd\u5b50\u7269\u7406\u5bf9\u5b87\u5b99\u4e2d\u7269\u8d28\u5206\u5e03\u6709\u7740\u663e\u8457\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5728\u5f53\u524d\u548c\u672a\u6765\u7684\u5b87\u5b99\u5b66\u8c03\u67e5\u6240\u6d89\u53ca\u7684\u5c3a\u5ea6\u4e0a\u3002\u8fd9\u79cd\u5f71\u54cd\u662f\u6b64\u7c7b\u5206\u6790\u4e2d\u7684\u5173\u952e\u7cfb\u7edf\u6027\u56e0\u7d20\uff0c\u56e0\u6b64\u9700\u8981\u7b80\u5355\u7684\u53c2\u6570\u5316\u65b9\u6cd5\u6765\u63cf\u8ff0\u91cd\u5b50\u7269\u7406\u5bf9\u7269\u8d28\u529f\u7387\u8c31\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u7b26\u53f7\u56de\u5f52\u6280\u672f\u6784\u5efa\u89e3\u6790\u8fd1\u4f3c\u503c\uff0c\u8868\u793a\u5305\u542b\u91cd\u5b50\u6548\u5e94\u548c\u4e0d\u5305\u542b\u91cd\u5b50\u6548\u5e94\u4e0b\u7684\u7269\u8d28\u529f\u7387\u8c31\u4e4b\u6bd4\u3002\u57fa\u4e8eCAMELS\u6a21\u62df\u5957\u4ef6\u4e2d\u7684\u56db\u79cd\u4e0d\u540c\u91cd\u5b50\u7269\u7406\u4e9a\u7f51\u683c\u6a21\u578b\uff08Astrid, IllustrisTNG, SIMBA \u548c Swift-EAGLE\uff09\u4ee5\u53ca\u4e00\u79cd\u91cd\u5b50\u5316\u7b97\u6cd5\uff0c\u5206\u522b\u83b7\u5f97\u5bf9\u5e94\u7684\u51fd\u6570\u3002\u540c\u65f6\u63d0\u4f9b\u4e86\u63cf\u8ff0\u8fd9\u4e9b\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u7684\u51fd\u6570\uff0c\u8003\u8651\u4e86\u91cd\u5b50\u7269\u7406\u7684\u968f\u673a\u6027\u8d28\u548c\u62df\u5408\u8bef\u5dee\u3002", "result": "\u5bf9\u4e8e\u6c34\u52a8\u529b\u5b66\u6a21\u62df\uff0c\u8fd1\u4f3c\u8bef\u5dee\u4e0e\u901a\u8fc7\u53d8\u5316\u521d\u59cb\u6761\u4ef6\u4f30\u8ba1\u7684\u6837\u672c\u65b9\u5dee\u76f8\u5f53\uff1b\u91cd\u5b50\u5316\u8868\u8fbe\u5f0f\u7684\u5747\u65b9\u6839\u8bef\u5dee\u4f18\u4e8e1%\uff0c\u5c3d\u7ba1\u5728\u5c0f\u5c3a\u5ea6\u4e0a\u6709\u6240\u589e\u52a0\u3002\u8fd9\u4e9b\u8bef\u5dee\u4e0e\u4e4b\u524d\u8fd9\u4e9b\u6a21\u578b\u7684\u6570\u503c\u4eff\u771f\u5668\u8bef\u5dee\u76f8\u5f53\u3002\u8868\u8fbe\u5f0f\u5728\u5927\u5c3a\u5ea6\u548c\u9ad8\u7ea2\u79fb\u65f6\u5177\u6709\u6b63\u786e\u7684\u7269\u7406\u884c\u4e3a\u3002\u53ef\u4ee5\u89e3\u6790\u5730\u89e3\u91ca\u5b87\u5b99\u5b66\u548c\u53cd\u9988\u53c2\u6570\u7684\u53d8\u5316\u5f71\u54cd\uff0c\u5e76\u8bc6\u522b\u51fa\u51e0\u4e4e\u65e0\u5f71\u54cd\u7684\u53c2\u6570\u3002", "conclusion": "\u5f97\u5230\u7684\u6bcf\u4e2a\u51fd\u6570\u57fa\u4e8e\u4e0d\u540c\u7684\u91cd\u5b50\u7269\u7406\u5b9e\u73b0\u65b9\u5f0f\uff0c\u53ef\u5e94\u7528\u4e8e\u771f\u5b9e\u6570\u636e\u4ee5\u533a\u5206\u8fd9\u4e9b\u6a21\u578b\u3002\u6240\u6709\u7b26\u53f7\u8fd1\u4f3c\u503c\u7684\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2506.08862", "pdf": "https://arxiv.org/pdf/2506.08862", "abs": "https://arxiv.org/abs/2506.08862", "authors": ["Zike Wu", "Qi Yan", "Xuanyu Yi", "Lele Wang", "Renjie Liao"], "title": "StreamSplat: Towards Online Dynamic 3D Reconstruction from Uncalibrated Video Streams", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams\nis crucial for numerous real-world applications. However, existing methods\nstruggle to jointly address three key challenges: 1) processing uncalibrated\ninputs in real time, 2) accurately modeling dynamic scene evolution, and 3)\nmaintaining long-term stability and computational efficiency. To this end, we\nintroduce StreamSplat, the first fully feed-forward framework that transforms\nuncalibrated video streams of arbitrary length into dynamic 3D Gaussian\nSplatting (3DGS) representations in an online manner, capable of recovering\nscene dynamics from temporally local observations. We propose two key technical\ninnovations: a probabilistic sampling mechanism in the static encoder for 3DGS\nposition prediction, and a bidirectional deformation field in the dynamic\ndecoder that enables robust and efficient dynamic modeling. Extensive\nexperiments on static and dynamic benchmarks demonstrate that StreamSplat\nconsistently outperforms prior works in both reconstruction quality and dynamic\nscene modeling, while uniquely supporting online reconstruction of arbitrarily\nlong video streams. Code and models are available at\nhttps://github.com/nickwzk/StreamSplat.", "AI": {"tldr": "StreamSplat is a novel framework that transforms uncalibrated video streams into 3D Gaussian Splatting representations in real time, excelling in reconstruction quality and dynamic scene modeling.", "motivation": "Real-time reconstruction of dynamic 3D scenes from uncalibrated video streams is essential for many applications, yet existing methods face challenges in processing inputs efficiently, modeling scene dynamics accurately, and maintaining long-term stability.", "method": "The paper introduces StreamSplat, a fully feed-forward framework that converts uncalibrated video streams into dynamic 3D Gaussian Splatting representations online. It includes a probabilistic sampling mechanism in the static encoder for position prediction and a bidirectional deformation field in the dynamic decoder for robust dynamic modeling.", "result": "Extensive experiments show that StreamSplat surpasses previous methods in reconstruction quality and dynamic scene modeling, while uniquely supporting online reconstruction of arbitrarily long video streams.", "conclusion": "StreamSplat addresses key challenges in real-time 3D scene reconstruction from uncalibrated video streams, offering superior performance and unique capabilities for handling long video sequences."}}
{"id": "2506.08885", "pdf": "https://arxiv.org/pdf/2506.08885", "abs": "https://arxiv.org/abs/2506.08885", "authors": ["Danush Khanna", "Krishna Kumar", "Basab Ghosh", "Vinija Jain", "Vasu Sharma", "Aman Chadha", "Amitava Das"], "title": "AdversariaL attacK sAfety aLIgnment(ALKALI): Safeguarding LLMs through GRACE: Geometric Representation-Aware Contrastive Enhancement- Introducing Adversarial Vulnerability Quality Index (AVQI)", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Adversarial threats against LLMs are escalating faster than current defenses\ncan adapt. We expose a critical geometric blind spot in alignment: adversarial\nprompts exploit latent camouflage, embedding perilously close to the safe\nrepresentation manifold while encoding unsafe intent thereby evading surface\nlevel defenses like Direct Preference Optimization (DPO), which remain blind to\nthe latent geometry. We introduce ALKALI, the first rigorously curated\nadversarial benchmark and the most comprehensive to date spanning 9,000 prompts\nacross three macro categories, six subtypes, and fifteen attack families.\nEvaluation of 21 leading LLMs reveals alarmingly high Attack Success Rates\n(ASRs) across both open and closed source models, exposing an underlying\nvulnerability we term latent camouflage, a structural blind spot where\nadversarial completions mimic the latent geometry of safe ones. To mitigate\nthis vulnerability, we introduce GRACE - Geometric Representation Aware\nContrastive Enhancement, an alignment framework coupling preference learning\nwith latent space regularization. GRACE enforces two constraints: latent\nseparation between safe and adversarial completions, and adversarial cohesion\namong unsafe and jailbreak behaviors. These operate over layerwise pooled\nembeddings guided by a learned attention profile, reshaping internal geometry\nwithout modifying the base model, and achieve up to 39% ASR reduction.\nMoreover, we introduce AVQI, a geometry aware metric that quantifies latent\nalignment failure via cluster separation and compactness. AVQI reveals when\nunsafe completions mimic the geometry of safe ones, offering a principled lens\ninto how models internally encode safety. We make the code publicly available\nat https://anonymous.4open.science/r/alkali-B416/README.md.", "AI": {"tldr": "Adversarial threats against LLMs are increasing faster than defenses can adapt. The paper exposes a critical geometric blind spot in alignment and introduces ALKALI, an adversarial benchmark, and GRACE, an alignment framework to mitigate this vulnerability.", "motivation": "The motivation is the escalating adversarial threats against LLMs that current defenses cannot adapt fast enough to counteract.", "method": "ALKALI is introduced as an adversarial benchmark spanning 9,000 prompts across multiple categories and subtypes. GRACE, an alignment framework coupling preference learning with latent space regularization, enforces constraints for latent separation and adversarial cohesion.", "result": "Evaluation of 21 leading LLMs revealed high Attack Success Rates (ASRs) exposing the vulnerability termed latent camouflage. GRACE achieved up to 39% ASR reduction. AVQI, a geometry aware metric, quantifies latent alignment failure.", "conclusion": "The paper concludes by making the code publicly available and introducing methods to reshape internal geometry of models without modifying the base model."}}
{"id": "2506.08893", "pdf": "https://arxiv.org/pdf/2506.08893", "abs": "https://arxiv.org/abs/2506.08893", "authors": ["Kai Zhou", "Youbiao He", "Chong Zhong", "Yifu Wu"], "title": "Real-Time Cascade Mitigation in Power Systems Using Influence Graph Improved by Reinforcement Learning", "categories": ["physics.soc-ph", "cs.LG", "physics.data-an"], "comment": null, "summary": "Despite high reliability, modern power systems with growing renewable\npenetration face an increasing risk of cascading outages. Real-time cascade\nmitigation requires fast, complex operational decisions under uncertainty. In\nthis work, we extend the influence graph into a Markov decision process model\n(MDP) for real-time mitigation of cascading outages in power transmission\nsystems, accounting for uncertainties in generation, load, and initial\ncontingencies. The MDP includes a do-nothing action to allow for conservative\ndecision-making and is solved using reinforcement learning. We present a policy\ngradient learning algorithm initialized with a policy corresponding to the\nunmitigated case and designed to handle invalid actions. The proposed learning\nmethod converges faster than the conventional algorithm. Through careful reward\ndesign, we learn a policy that takes conservative actions without deteriorating\nsystem conditions. The model is validated on the IEEE 14-bus and IEEE 118-bus\nsystems. The results show that proactive line disconnections can effectively\nreduce cascading risk, and certain lines consistently emerge as critical in\nmitigating cascade propagation.", "AI": {"tldr": "The paper proposes a Markov decision process model (MDP) extended from the influence graph for real-time mitigation of cascading outages in power transmission systems under uncertainties, solved using reinforcement learning. It validates the model on IEEE 14-bus and IEEE 118-bus systems.", "motivation": "Modern power systems with increasing renewable energy penetration face higher risks of cascading outages. Real-time mitigation requires fast and complex operational decisions under uncertainty.", "method": "The influence graph is extended into an MDP model for real-time cascade mitigation in power transmission systems. The MDP includes uncertainties in generation, load, and initial contingencies and incorporates a do-nothing action for conservative decision-making. Reinforcement learning is used to solve the MDP, and a policy gradient learning algorithm initialized with a policy corresponding to the unmitigated case is presented to handle invalid actions.", "result": "Proactive line disconnections can effectively reduce cascading risk in power transmission systems. Certain lines consistently emerge as critical in mitigating cascade propagation. The proposed learning method converges faster than conventional algorithms.", "conclusion": "A Markov decision process model extended from the influence graph can be effectively used for real-time mitigation of cascading outages in power transmission systems under uncertainties, with validation on IEEE test systems."}}
{"id": "2506.08911", "pdf": "https://arxiv.org/pdf/2506.08911", "abs": "https://arxiv.org/abs/2506.08911", "authors": ["Petar Jaku\u0161", "Hrvoje D\u017eapo"], "title": "Implementing Keyword Spotting on the MCUX947 Microcontroller with Integrated NPU", "categories": ["cs.HC", "cs.LG", "cs.SD", "eess.AS"], "comment": "4 pages", "summary": "This paper presents a keyword spotting (KWS) system implemented on the NXP\nMCXN947 microcontroller with an integrated Neural Processing Unit (NPU),\nenabling real-time voice interaction on resource-constrained devices. The\nsystem combines MFCC feature extraction with a CNN classifier, optimized using\nQuantization Aware Training to reduce model size with minimal accuracy drop.\nExperimental results demonstrate a 59x speedup in inference time when\nleveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy\nwith a model size of 30.58 KB, demonstrating the feasibility of efficient,\nlow-power voice interfaces on embedded platforms.", "AI": {"tldr": "This paper presents a keyword spotting (KWS) system on NXP MCXN947 microcontroller with an integrated Neural Processing Unit (NPU), which enables real-time voice interaction. The system combines MFCC feature extraction with a CNN classifier, optimized using Quantization Aware Training. Experimental results demonstrate a 59x speedup in inference time when leveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy with a model size of 30.58 KB.", "motivation": "To enable real-time voice interaction on resource-constrained devices by implementing an efficient, low-power KWS system.", "method": "The KWS system combines MFCC feature extraction with a CNN classifier and is optimized using Quantization Aware Training to reduce model size with minimal accuracy drop.", "result": "A 59x speedup in inference time when leveraging the NPU compared to CPU-only execution, achieving 97.06% accuracy with a model size of 30.58 KB.", "conclusion": "The implementation demonstrates the feasibility of efficient, low-power voice interfaces on embedded platforms."}}
{"id": "2506.08954", "pdf": "https://arxiv.org/pdf/2506.08954", "abs": "https://arxiv.org/abs/2506.08954", "authors": ["Ruben Weitzman", "Peter M\u00f8rch Groth", "Lood Van Niekerk", "Aoi Otani", "Yarin Gal", "Debora Marks", "Pascal Notin"], "title": "Protriever: End-to-End Differentiable Protein Homology Search for Fitness Prediction", "categories": ["q-bio.QM", "cs.LG", "q-bio.BM"], "comment": "Accepted at ICML 2025", "summary": "Retrieving homologous protein sequences is essential for a broad range of\nprotein modeling tasks such as fitness prediction, protein design, structure\nmodeling, and protein-protein interactions. Traditional workflows have relied\non a two-step process: first retrieving homologs via Multiple Sequence\nAlignments (MSA), then training models on one or more of these alignments.\nHowever, MSA-based retrieval is computationally expensive, struggles with\nhighly divergent sequences or complex insertions & deletions patterns, and\noperates independently of the downstream modeling objective. We introduce\nProtriever, an end-to-end differentiable framework that learns to retrieve\nrelevant homologs while simultaneously training for the target task. When\napplied to protein fitness prediction, Protriever achieves state-of-the-art\nperformance compared to sequence-based models that rely on MSA-based homolog\nretrieval, while being two orders of magnitude faster through efficient vector\nsearch. Protriever is both architecture- and task-agnostic, and can flexibly\nadapt to different retrieval strategies and protein databases at inference time\n-- offering a scalable alternative to alignment-centric approaches.", "AI": {"tldr": "Protriever is a new framework that retrieves homologous protein sequences more efficiently and accurately than traditional methods, achieving state-of-the-art performance in protein fitness prediction while being significantly faster.", "motivation": "Traditional methods for retrieving homologous protein sequences using Multiple Sequence Alignments (MSA) are computationally expensive, struggle with highly divergent sequences or complex patterns, and are independent of downstream modeling objectives.", "method": "Protriever is an end-to-end differentiable framework that learns to retrieve relevant homologs while simultaneously training for the target task. It uses efficient vector search instead of MSA-based retrieval.", "result": "Protriever achieves state-of-the-art performance in protein fitness prediction compared to sequence-based models that rely on MSA-based homolog retrieval, while being two orders of magnitude faster.", "conclusion": "Protriever offers a scalable alternative to alignment-centric approaches and can flexibly adapt to different retrieval strategies and protein databases at inference time."}}
{"id": "2506.08956", "pdf": "https://arxiv.org/pdf/2506.08956", "abs": "https://arxiv.org/abs/2506.08956", "authors": ["DaeEun Yoon", "Semin Kim", "SangWook Yoo", "Jongha Lee"], "title": "Data Augmentation For Small Object using Fast AutoAugment", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted and published in the USB Proceedings of the 20th\n  International Conference on Modeling Decisions for Artificial Intelligence\n  (MDAI 2023), Ume{\\aa}, Sweden, June 19--22, 2023, ISBN 978-91-527-7293-5,\n  pp.\\ 12--21", "summary": "In recent years, there has been tremendous progress in object detection\nperformance. However, despite these advances, the detection performance for\nsmall objects is significantly inferior to that of large objects. Detecting\nsmall objects is one of the most challenging and important problems in computer\nvision. To improve the detection performance for small objects, we propose an\noptimal data augmentation method using Fast AutoAugment. Through our proposed\nmethod, we can quickly find optimal augmentation policies that can overcome\ndegradation when detecting small objects, and we achieve a 20% performance\nimprovement on the DOTA dataset.", "AI": {"tldr": "\u4e3a\u4e86\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eFast AutoAugment\u7684\u6700\u4f18\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5feb\u901f\u627e\u5230\u514b\u670d\u5c0f\u76ee\u6807\u68c0\u6d4b\u9000\u5316\u7684\u6700\u4f18\u589e\u5f3a\u7b56\u7565\uff0c\u5728DOTA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8620%\u7684\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u5c3d\u7ba1\u8fd1\u5e74\u6765\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u53d6\u5f97\u4e86\u5de8\u5927\u8fdb\u5c55\uff0c\u4f46\u5c0f\u76ee\u6807\u7684\u68c0\u6d4b\u6027\u80fd\u8fdc\u4e0d\u5982\u5927\u76ee\u6807\uff0c\u56e0\u6b64\u63d0\u5347\u5c0f\u76ee\u6807\u68c0\u6d4b\u6027\u80fd\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u4e14\u91cd\u8981\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f7f\u7528Fast AutoAugment\u7684\u6700\u4f18\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5feb\u901f\u627e\u5230\u80fd\u591f\u514b\u670d\u5c0f\u76ee\u6807\u68c0\u6d4b\u9000\u5316\u7684\u6700\u4f18\u589e\u5f3a\u7b56\u7565\u3002", "result": "\u5728DOTA\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e8620%\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u6709\u6548\u5730\u63d0\u9ad8\u4e86\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u6027\u80fd\u3002"}}
{"id": "2506.08966", "pdf": "https://arxiv.org/pdf/2506.08966", "abs": "https://arxiv.org/abs/2506.08966", "authors": ["Marek Kadl\u010d\u00edk", "Michal \u0160tef\u00e1nik", "Timothee Mickus", "Michal Spiegel", "Josef Kucha\u0159"], "title": "Pre-trained Language Models Learn Remarkably Accurate Representations of Numbers", "categories": ["cs.CL", "cs.LG", "cs.NE"], "comment": null, "summary": "Pretrained language models (LMs) are prone to arithmetic errors. Existing\nwork showed limited success in probing numeric values from models'\nrepresentations, indicating that these errors can be attributed to the inherent\nunreliability of distributionally learned embeddings in representing exact\nquantities. However, we observe that previous probing methods are inadequate\nfor the emergent structure of learned number embeddings with sinusoidal\npatterns.\n  In response, we propose a novel probing technique that decodes numeric values\nfrom input embeddings with near-perfect accuracy across a range of open-source\nLMs. This proves that after the sole pre-training, LMs represent numbers with\nremarkable precision. Finally, we find that the embeddings' preciseness judged\nby our probe's accuracy explains a large portion of LM's errors in elementary\narithmetic, and show that aligning the embeddings with the pattern discovered\nby our probe can mitigate these errors.", "AI": {"tldr": "Pretrained language models often make arithmetic errors due to unreliable embeddings for exact quantities. The existing probing methods are inadequate for the learned number embeddings with sinusoidal patterns. This paper proposes a new probing technique that decodes numeric values from input embeddings with high accuracy, proving that LMs can represent numbers precisely after pre-training. The probe's accuracy explains many of the LMs' arithmetic errors, and aligning embeddings with the discovered pattern reduces these errors.", "motivation": "The motivation is to address the issue of arithmetic errors in pretrained language models and improve the understanding of how these models represent numeric values.", "method": "The authors propose a novel probing technique that decodes numeric values from input embeddings, which works with near-perfect accuracy across various open-source LMs.", "result": "The proposed probing method successfully decodes numeric values with remarkable precision, explaining a significant portion of arithmetic errors in LMs. Aligning embeddings with the discovered pattern mitigates these errors.", "conclusion": "LMs can represent numbers with great precision after pre-training, and the proposed probing technique effectively identifies this ability. Improving the alignment of embeddings with the discovered pattern can reduce arithmetic errors."}}
{"id": "2506.09024", "pdf": "https://arxiv.org/pdf/2506.09024", "abs": "https://arxiv.org/abs/2506.09024", "authors": ["Felix Wagner", "Pramit Saha", "Harry Anthony", "J. Alison Noble", "Konstantinos Kamnitsas"], "title": "DIsoN: Decentralized Isolation Networks for Out-of-Distribution Detection in Medical Imaging", "categories": ["cs.CV", "cs.LG", "I.2.11; I.4.9; I.4.9; J.3; I.2.0"], "comment": null, "summary": "Safe deployment of machine learning (ML) models in safety-critical domains\nsuch as medical imaging requires detecting inputs with characteristics not seen\nduring training, known as out-of-distribution (OOD) detection, to prevent\nunreliable predictions. Effective OOD detection after deployment could benefit\nfrom access to the training data, enabling direct comparison between test\nsamples and the training data distribution to identify differences.\nState-of-the-art OOD detection methods, however, either discard training data\nafter deployment or assume that test samples and training data are centrally\nstored together, an assumption that rarely holds in real-world settings. This\nis because shipping training data with the deployed model is usually impossible\ndue to the size of training databases, as well as proprietary or privacy\nconstraints. We introduce the Isolation Network, an OOD detection framework\nthat quantifies the difficulty of separating a target test sample from the\ntraining data by solving a binary classification task. We then propose\nDecentralized Isolation Networks (DIsoN), which enables the comparison of\ntraining and test data when data-sharing is impossible, by exchanging only\nmodel parameters between the remote computational nodes of training and\ndeployment. We further extend DIsoN with class-conditioning, comparing a target\nsample solely with training data of its predicted class. We evaluate DIsoN on\nfour medical imaging datasets (dermatology, chest X-ray, breast ultrasound,\nhistopathology) across 12 OOD detection tasks. DIsoN performs favorably against\nexisting methods while respecting data-privacy. This decentralized OOD\ndetection framework opens the way for a new type of service that ML developers\ncould provide along with their models: providing remote, secure utilization of\ntheir training data for OOD detection services. Code will be available upon\nacceptance at: *****", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDecentralized Isolation Networks\uff08DIsoN\uff09\u7684\u65b0\u578b\u6846\u67b6\uff0c\u7528\u4e8e\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u90e8\u7f72\u540e\u65e0\u6cd5\u6709\u6548\u68c0\u6d4b\u51fa\u5206\u5e03\u5916\u6570\u636e\u7684\u95ee\u9898\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6bd4\u8f83\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\uff0c\u91cf\u5316\u5c06\u76ee\u6807\u6d4b\u8bd5\u6837\u672c\u4e0e\u8bad\u7ec3\u6570\u636e\u5206\u79bb\u7684\u96be\u5ea6\uff0c\u5e76\u4e14\u65e0\u9700\u5171\u4eab\u539f\u59cb\u6570\u636e\uff0c\u4ec5\u9700\u4ea4\u6362\u6a21\u578b\u53c2\u6570\u5373\u53ef\u5b9e\u73b0\u8de8\u8282\u70b9\u7684\u6570\u636e\u6bd4\u8f83\u3002\u8fdb\u4e00\u6b65\u5730\uff0c\u7814\u7a76\u8fd8\u63d0\u51fa\u4e86\u57fa\u4e8e\u7c7b\u522b\u6761\u4ef6\u7684\u6269\u5c55\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDIsoN\u5728\u56db\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\u4e0a\u7684\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u540c\u65f6\u786e\u4fdd\u4e86\u6570\u636e\u9690\u79c1\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684OOD\u68c0\u6d4b\u65b9\u6cd5\u8981\u4e48\u5728\u90e8\u7f72\u540e\u4e22\u5f03\u8bad\u7ec3\u6570\u636e\uff0c\u8981\u4e48\u5047\u8bbe\u6d4b\u8bd5\u6570\u636e\u548c\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u5b58\u50a8\u5728\u4e00\u8d77\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u96be\u4ee5\u6ee1\u8db3\u3002\u7279\u522b\u662f\u5728\u533b\u7597\u5f71\u50cf\u9886\u57df\uff0c\u7531\u4e8e\u6570\u636e\u89c4\u6a21\u5e9e\u5927\u4ee5\u53ca\u9690\u79c1\u548c\u4e13\u6709\u6743\u7684\u9650\u5236\uff0c\u901a\u5e38\u65e0\u6cd5\u968f\u6a21\u578b\u4e00\u8d77\u4f20\u8f93\u8bad\u7ec3\u6570\u636e\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u4e0d\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6709\u6548OOD\u68c0\u6d4b\u7684\u65b9\u6cd5\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u5f15\u5165\u4e86Isolation Network\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u51b3\u4e8c\u5206\u7c7b\u4efb\u52a1\u6765\u91cf\u5316\u5c06\u76ee\u6807\u6d4b\u8bd5\u6837\u672c\u4ece\u8bad\u7ec3\u6570\u636e\u4e2d\u5206\u79bb\u7684\u96be\u5ea6\u3002\u63a5\u7740\uff0c\u4ed6\u4eec\u63d0\u51fa\u4e86Decentralized Isolation Networks\uff08DIsoN\uff09\uff0c\u5141\u8bb8\u5728\u65e0\u6cd5\u5171\u4eab\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u901a\u8fc7\u4ea4\u6362\u6a21\u578b\u53c2\u6570\u5728\u8fdc\u7a0b\u8ba1\u7b97\u8282\u70b9\u4e4b\u95f4\u6bd4\u8f83\u8bad\u7ec3\u548c\u6d4b\u8bd5\u6570\u636e\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8fd8\u6269\u5c55\u4e86DIsoN\uff0c\u52a0\u5165\u4e86\u7c7b\u522b\u6761\u4ef6\uff0c\u4f7f\u76ee\u6807\u6837\u672c\u4ec5\u4e0e\u5176\u9884\u6d4b\u7c7b\u522b\u7684\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "DIsoN\u5728\u56db\u4e2a\u533b\u5b66\u5f71\u50cf\u6570\u636e\u96c6\uff08\u76ae\u80a4\u79d1\u3001\u80f8\u90e8X\u5149\u3001\u4e73\u817a\u8d85\u58f0\u3001\u7ec4\u7ec7\u75c5\u7406\u5b66\uff09\u4e0a\u768412\u4e2aOOD\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u76f8\u8f83\u4e8e\u73b0\u6709\u65b9\u6cd5\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u540c\u65f6\u5c0a\u91cd\u4e86\u6570\u636e\u9690\u79c1\u3002", "conclusion": "DIsoN\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u7684\u53bb\u4e2d\u5fc3\u5316OOD\u68c0\u6d4b\u6846\u67b6\uff0c\u4e3a\u673a\u5668\u5b66\u4e60\u5f00\u53d1\u8005\u63d0\u4f9b\u4e86\u4e00\u79cd\u65b0\u670d\u52a1\uff1a\u5728\u4e0d\u5171\u4eab\u6570\u636e\u7684\u524d\u63d0\u4e0b\uff0c\u5229\u7528\u8bad\u7ec3\u6570\u636e\u8fdb\u884c\u5b89\u5168\u7684OOD\u68c0\u6d4b\u670d\u52a1\u3002"}}
