{"id": "2505.23881", "pdf": "https://arxiv.org/pdf/2505.23881", "abs": "https://arxiv.org/abs/2505.23881", "authors": ["Christopher D. Rosin"], "title": "Using Reasoning Models to Generate Search Heuristics that Solve Open Instances of Combinatorial Design Problems", "categories": ["cs.AI", "cs.CL", "math.CO"], "comment": "arXiv admin note: text overlap with arXiv:2501.17725", "summary": "Large Language Models (LLMs) with reasoning are trained to iteratively\ngenerate and refine their answers before finalizing them, which can help with\napplications to mathematics and code generation. We apply code generation with\nreasoning LLMs to a specific task in the mathematical field of combinatorial\ndesign. This field studies diverse types of combinatorial designs, many of\nwhich have lists of open instances for which existence has not yet been\ndetermined. The Constructive Protocol CPro1 uses LLMs to generate search\nheuristics that have the potential to construct solutions to small open\ninstances. Starting with a textual definition and a validity verifier for a\nparticular type of design, CPro1 guides LLMs to select and implement\nstrategies, while providing automated hyperparameter tuning and execution\nfeedback. CPro1 with reasoning LLMs successfully solves long-standing open\ninstances for 7 of 16 combinatorial design problems selected from the 2006\nHandbook of Combinatorial Designs, including new solved instances for 3 of\nthese (Bhaskar Rao Designs, Symmetric Weighing Matrices, Balanced Ternary\nDesigns) that were unsolved by CPro1 with non-reasoning LLMs. It also solves\nopen instances for several problems from recent (2025) literature, generating\nnew Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform\nNested Steiner Quadruple System.", "AI": {"tldr": "Large Language Models (LLMs) with reasoning capabilities can generate search heuristics to solve combinatorial design problems, successfully solving longstanding open instances and generating new solutions.", "motivation": "To apply code generation with reasoning LLMs to solve open instances in the mathematical field of combinatorial design, where many problems have yet to be solved.", "method": "Using Constructive Protocol CPro1, which guides LLMs to select and implement strategies for constructing solutions to small open instances, while providing automated hyperparameter tuning and execution feedback.", "result": "CPro1 with reasoning LLMs solved longstanding open instances for 7 of 16 combinatorial design problems from the 2006 Handbook of Combinatorial Designs, including new solved instances for Bhaskar Rao Designs, Symmetric Weighing Matrices, and Balanced Ternary Designs. It also solved open instances for several problems from recent literature, generating new Covering Sequences, Johnson Clique Covers, Deletion Codes, and a Uniform Nested Steiner Quadruple System.", "conclusion": "Reasoning LLMs integrated with CPro1 show promise in advancing the field of combinatorial design by solving previously unsolved problems."}}
{"id": "2505.23885", "pdf": "https://arxiv.org/pdf/2505.23885", "abs": "https://arxiv.org/abs/2505.23885", "authors": ["Mengkang Hu", "Yuhang Zhou", "Wendong Fan", "Yuzhou Nie", "Bowei Xia", "Tao Sun", "Ziyu Ye", "Zhaoxuan Jin", "Yingru Li", "Qiguang Chen", "Zeyu Zhang", "Yifeng Wang", "Qianshuo Ye", "Bernard Ghanem", "Ping Luo", "Guohao Li"], "title": "OWL: Optimized Workforce Learning for General Multi-Agent Assistance in Real-World Task Automation", "categories": ["cs.AI", "cs.CL"], "comment": "Project Page: https://github.com/camel-ai/owl", "summary": "Large Language Model (LLM)-based multi-agent systems show promise for\nautomating real-world tasks but struggle to transfer across domains due to\ntheir domain-specific nature. Current approaches face two critical\nshortcomings: they require complete architectural redesign and full retraining\nof all components when applied to new domains. We introduce Workforce, a\nhierarchical multi-agent framework that decouples strategic planning from\nspecialized execution through a modular architecture comprising: (i) a\ndomain-agnostic Planner for task decomposition, (ii) a Coordinator for subtask\nmanagement, and (iii) specialized Workers with domain-specific tool-calling\ncapabilities. This decoupling enables cross-domain transferability during both\ninference and training phases: During inference, Workforce seamlessly adapts to\nnew domains by adding or modifying worker agents; For training, we introduce\nOptimized Workforce Learning (OWL), which improves generalization across\ndomains by optimizing a domain-agnostic planner with reinforcement learning\nfrom real-world feedback. To validate our approach, we evaluate Workforce on\nthe GAIA benchmark, covering various realistic, multi-domain agentic tasks.\nExperimental results demonstrate Workforce achieves open-source\nstate-of-the-art performance (69.70%), outperforming commercial systems like\nOpenAI's Deep Research by 2.34%. More notably, our OWL-trained 32B model\nachieves 52.73% accuracy (+16.37%) and demonstrates performance comparable to\nGPT-4o on challenging tasks. To summarize, by enabling scalable generalization\nand modular domain transfer, our work establishes a foundation for the next\ngeneration of general-purpose AI assistants.", "AI": {"tldr": "Workforce is a hierarchical multi-agent framework that decouples strategic planning from specialized execution, enabling cross-domain transferability. It comprises a domain-agnostic Planner, a Coordinator, and specialized Workers. OWL optimizes the planner with reinforcement learning for better generalization. Workforce achieves state-of-the-art performance on the GAIA benchmark.", "motivation": "Current LLM-based multi-agent systems struggle to transfer across domains due to their domain-specific nature, requiring complete architectural redesign and full retraining when applied to new domains.", "method": "Workforce includes a domain-agnostic Planner for task decomposition, a Coordinator for subtask management, and specialized Workers with domain-specific tool-calling capabilities. OWL optimizes the Planner with reinforcement learning from real-world feedback.", "result": "Workforce achieves open-source state-of-the-art performance (69.70%) on the GAIA benchmark, outperforming commercial systems like OpenAI's Deep Research by 2.34%. The OWL-trained 32B model achieves 52.73% accuracy (+16.37%) and performs comparably to GPT-4o on challenging tasks.", "conclusion": "Workforce establishes a foundation for the next generation of general-purpose AI assistants by enabling scalable generalization and modular domain transfer."}}
{"id": "2505.23946", "pdf": "https://arxiv.org/pdf/2505.23946", "abs": "https://arxiv.org/abs/2505.23946", "authors": ["Yuanzhe Liu", "Ryan Deng", "Tim Kaler", "Xuhao Chen", "Charles E. Leiserson", "Yao Ma", "Jie Chen"], "title": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "categories": ["cs.AI", "cs.LG", "cs.MA", "cs.SE"], "comment": null, "summary": "Recent studies show that LLMs possess different skills and specialize in\ndifferent tasks. In fact, we observe that their varied performance occur in\nseveral levels of granularity. For example, in the code optimization task, code\nLLMs excel at different optimization categories and no one dominates others.\nThis observation prompts the question of how one leverages multiple LLM agents\nto solve a coding problem without knowing their complementary strengths a\npriori. We argue that a team of agents can learn from each other's successes\nand failures so as to improve their own performance. Thus, a lesson is the\nknowledge produced by an agent and passed on to other agents in the collective\nsolution process. We propose a lesson-based collaboration framework, design the\nlesson solicitation--banking--selection mechanism, and demonstrate that a team\nof small LLMs with lessons learned can outperform a much larger LLM and other\nmulti-LLM collaboration methods.", "AI": {"tldr": "\u901a\u8fc7\u4e00\u4e2a\u57fa\u4e8elesson\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u591a\u4e2a\u5c0f\u578bLLM\u53ef\u4ee5\u901a\u8fc7\u76f8\u4e92\u5b66\u4e60\u6210\u529f\u4e0e\u5931\u8d25\u7684\u7ecf\u9a8c\u6765\u63d0\u5347\u81ea\u8eab\u6027\u80fd\uff0c\u5728\u89e3\u51b3\u7f16\u7801\u95ee\u9898\u65f6\uff0c\u5176\u8868\u73b0\u53ef\u4ee5\u4f18\u4e8e\u5927\u578bLLM\u548c\u5176\u4ed6\u591aLLM\u534f\u4f5c\u65b9\u6cd5\uff0c\u5373\u4f7f\u5728\u4e8b\u5148\u4e0d\u77e5\u9053\u5b83\u4eec\u4e92\u8865\u4f18\u52bf\u7684\u60c5\u51b5\u4e0b\u3002", "motivation": "\u7814\u7a76\u8005\u89c2\u5bdf\u5230\u4e0d\u540cLLM\u5728\u5404\u79cd\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5b58\u5728\u591a\u7c92\u5ea6\u5dee\u5f02\uff0c\u4f8b\u5982\u5728\u4ee3\u7801\u4f18\u5316\u4efb\u52a1\u4e2d\uff0c\u4e0d\u540c\u7684code LLM\u64c5\u957f\u4e0d\u540c\u7684\u4f18\u5316\u7c7b\u522b\u4e14\u6ca1\u6709\u4e00\u4e2a\u80fd\u5168\u9762\u8d85\u8d8a\u5176\u4ed6\u6a21\u578b\u3002\u8fd9\u5f15\u53d1\u4e86\u5982\u4f55\u5728\u4e0d\u9884\u5148\u4e86\u89e3\u5404\u81ea\u4f18\u52bf\u7684\u60c5\u51b5\u4e0b\uff0c\u5229\u7528\u591a\u4e2aLLM\u4ee3\u7406\u89e3\u51b3\u7f16\u7801\u95ee\u9898\u7684\u601d\u8003\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8elesson\u7684\u534f\u4f5c\u6846\u67b6\uff0c\u8bbe\u8ba1\u4e86lesson\u7684\u5f81\u96c6-\u5b58\u50a8-\u9009\u62e9\u673a\u5236\uff0c\u4f7f\u4e00\u7ec4\u4ee3\u7406\u80fd\u591f\u5728\u96c6\u4f53\u89e3\u51b3\u95ee\u9898\u7684\u8fc7\u7a0b\u4e2d\u76f8\u4e92\u5b66\u4e60\u6210\u529f\u548c\u5931\u8d25\u7684\u77e5\u8bc6\u4ee5\u63d0\u9ad8\u5404\u81ea\u7684\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u6240\u63d0\u51fa\u7684\u6846\u67b6\uff0c\u4e00\u7ec4\u5c0f\u578bLLM\u80fd\u591f\u8d85\u8d8a\u5927\u578bLLM\u4ee5\u53ca\u5176\u4ed6\u591aLLM\u534f\u4f5c\u65b9\u6cd5\u3002", "conclusion": "\u57fa\u4e8elesson\u7684\u534f\u4f5c\u6846\u67b6\u4e3a\u63d0\u5347\u591aLLM\u56e2\u961f\u89e3\u51b3\u95ee\u9898\u7684\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\uff0c\u5c55\u793a\u4e86\u901a\u8fc7\u76f8\u4e92\u5b66\u4e60\u6539\u8fdb\u6027\u80fd\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2505.23950", "pdf": "https://arxiv.org/pdf/2505.23950", "abs": "https://arxiv.org/abs/2505.23950", "authors": ["Boyuan Chen", "Donghai Hong", "Jiaming Ji", "Jiacheng Zheng", "Bowen Dong", "Jiayi Zhou", "Kaile Wang", "Juntao Dai", "Xuyao Wang", "Wenqi Chen", "Qirui Zheng", "Wenxin Li", "Sirui Han", "Yike Guo", "Yaodong Yang"], "title": "InterMT: Multi-Turn Interleaved Preference Alignment with Human Feedback", "categories": ["cs.AI"], "comment": null, "summary": "As multimodal large models (MLLMs) continue to advance across challenging\ntasks, a key question emerges: What essential capabilities are still missing? A\ncritical aspect of human learning is continuous interaction with the\nenvironment -- not limited to language, but also involving multimodal\nunderstanding and generation. To move closer to human-level intelligence,\nmodels must similarly support multi-turn, multimodal interaction. In\nparticular, they should comprehend interleaved multimodal contexts and respond\ncoherently in ongoing exchanges. In this work, we present an initial\nexploration through the InterMT -- the first preference dataset for multi-turn\nmultimodal interaction, grounded in real human feedback. In this exploration,\nwe particularly emphasize the importance of human oversight, introducing expert\nannotations to guide the process, motivated by the fact that current MLLMs lack\nsuch complex interactive capabilities. InterMT captures human preferences at\nboth global and local levels into nine sub-dimensions, consists of 15.6k\nprompts, 52.6k multi-turn dialogue instances, and 32.4k human-labeled\npreference pairs. To compensate for the lack of capability for multi-modal\nunderstanding and generation, we introduce an agentic workflow that leverages\ntool-augmented MLLMs to construct multi-turn QA instances. To further this\ngoal, we introduce InterMT-Bench to assess the ability of MLLMs in assisting\njudges with multi-turn, multimodal tasks. We demonstrate the utility of\n\\InterMT through applications such as judge moderation and further reveal the\nmulti-turn scaling law of judge model. We hope the open-source of our data can\nhelp facilitate further research on aligning current MLLMs to the next step.\nOur project website can be found at https://pku-intermt.github.io .", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u591a\u6a21\u6001\u5927\u6a21\u578b\uff08MLLMs\uff09\u5728\u4ea4\u4e92\u80fd\u529b\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86InterMT\u6570\u636e\u96c6\u548cInterMT-Bench\u57fa\u51c6\u6765\u6539\u8fdb\u548c\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u591a\u8f6e\u3001\u591a\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\u3002", "motivation": "\u5c3d\u7ba1MLLMs\u5728\u8bb8\u591a\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u4ecd\u7f3a\u4e4f\u7c7b\u4f3c\u4e8e\u4eba\u7c7b\u7684\u590d\u6742\u4ea4\u4e92\u80fd\u529b\uff0c\u7279\u522b\u662f\u591a\u8f6e\u3001\u591a\u6a21\u6001\u7684\u4ea4\u4e92\u3002\u4e3a\u4e86\u5411\u4eba\u7c7b\u667a\u80fd\u9760\u8fd1\uff0c\u6a21\u578b\u9700\u8981\u5177\u5907\u7406\u89e3\u4ea4\u7ec7\u7684\u591a\u6a21\u6001\u4e0a\u4e0b\u6587\u5e76\u8fde\u8d2f\u56de\u5e94\u7684\u80fd\u529b\u3002", "method": "\u4f5c\u8005\u521b\u5efa\u4e86\u9996\u4e2a\u57fa\u4e8e\u771f\u5b9e\u4eba\u7c7b\u53cd\u9988\u7684\u591a\u8f6e\u591a\u6a21\u6001\u4ea4\u4e92\u504f\u597d\u6570\u636e\u96c6InterMT\uff0c\u5305\u542b15.6k\u63d0\u793a\u300152.6k\u5bf9\u8bdd\u5b9e\u4f8b\u548c32.4k\u4eba\u5de5\u6807\u6ce8\u7684\u504f\u597d\u5bf9\u3002\u6b64\u5916\uff0c\u8fd8\u5f15\u5165\u4e86\u4e00\u79cd\u4ee3\u7406\u589e\u5f3a\u7684\u5de5\u4f5c\u6d41\u7a0b\uff0c\u4ee5\u5f25\u8865\u5f53\u524dMLLMs\u5728\u591a\u6a21\u6001\u7406\u89e3\u548c\u751f\u6210\u65b9\u9762\u7684\u80fd\u529b\u4e0d\u8db3\u3002\u6700\u540e\uff0c\u63d0\u51fa\u4e86InterMT-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30MLLMs\u5728\u591a\u8f6e\u591a\u6a21\u6001\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "result": "\u901a\u8fc7\u5e94\u7528\u5982\u88c1\u5224\u8c03\u8282\u7b49\u4efb\u52a1\uff0c\u63ed\u793a\u4e86\u88c1\u5224\u6a21\u578b\u7684\u591a\u8f6e\u6269\u5c55\u89c4\u5f8b\uff0c\u5e76\u5c55\u793a\u4e86InterMT\u6570\u636e\u96c6\u7684\u5b9e\u7528\u6027\u3002\u8fd9\u6709\u52a9\u4e8e\u63a8\u52a8MLLMs\u5728\u591a\u6a21\u6001\u4ea4\u4e92\u65b9\u9762\u7684\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u3002", "conclusion": "\u4f5c\u8005\u5e0c\u671b\u5f00\u6e90\u7684InterMT\u6570\u636e\u96c6\u80fd\u591f\u4fc3\u8fdb\u5bf9\u5f53\u524dMLLMs\u7684\u7814\u7a76\uff0c\u4f7f\u5176\u66f4\u63a5\u8fd1\u4eba\u7c7b\u6c34\u5e73\u7684\u591a\u6a21\u6001\u4ea4\u4e92\u80fd\u529b\u3002\u9879\u76ee\u7f51\u7ad9\u4e3ahttps://pku-intermt.github.io\u3002"}}
{"id": "2505.23770", "pdf": "https://arxiv.org/pdf/2505.23770", "abs": "https://arxiv.org/abs/2505.23770", "authors": ["Sudhanshu Sekhar Tripathy"], "title": "A comprehensive survey of cybercrimes in India over the last decade", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Since the 1990s, the integration of technology into daily life has led to the\ncreation of an extensive network of interconnected devices, transforming how\nindividuals and organizations operate. However, this digital transformation has\nalso spurred the rise of cybercrime, criminal activities perpetrated through\nnetworks or computer systems. Cybercrime has become a global concern,\npresenting significant challenges to security systems. Although advancements in\ndigital technology have enhanced efficiency, they have also opened new avenues\nfor exploitation by cybercriminals, highlighting the urgent need for advanced\ncybersecurity measures. The escalating number of cyberattacks and associated\nrisks in the past decade highlights the critical importance of protecting\nsensitive data and safeguarding information systems. Cybercrimes range from\nfinancial fraud and phishing scams to identity theft and online harassment,\nposing substantial risks to both individuals and organizations. In response,\ngovernments, law enforcement agencies, and cybersecurity units have intensified\ntheir efforts to address these threats. In recent years, India has experienced\na significant surge in cybercrime incidents, with a notable increase in cases\ninvolving ransomware, data breaches, and social engineering attacks. The\ngrowing penetration of internet services, the expansion of e-commerce, and the\nrapid adoption of digital payment systems have made individuals and\norganizations more vulnerable to cyber threats. Key areas affected include\nbanking, healthcare, and government sectors, which are frequently targeted due\nto the sensitive nature of the data they handle. To combat these risks, there\nis an increasing focus on public awareness, cybersecurity education, and robust\nregulatory frameworks. This paper examines cybercrime, prevention strategies,\nsecurity protocols, and terminology to safeguard digital infrastructure.", "AI": {"tldr": "Since the 1990s, digital transformation has spurred cybercrime growth. This paper examines cybercrime, prevention strategies, security protocols, and terminology to safeguard digital infrastructure in India.", "motivation": "To address the increasing risks of cybercrime due to digital transformation and technology integration.", "method": "Analysis of cybercrime, prevention strategies, security protocols, and terminology related to safeguarding digital infrastructure.", "result": "Highlights the surge in cybercrime incidents in India, particularly involving ransomware, data breaches, and social engineering attacks, affecting sectors like banking, healthcare, and government.", "conclusion": "There is a need for public awareness, cybersecurity education, and robust regulatory frameworks to combat cyber threats."}}
{"id": "2505.23857", "pdf": "https://arxiv.org/pdf/2505.23857", "abs": "https://arxiv.org/abs/2505.23857", "authors": ["Wuhao Wang", "Zhiyong Chen"], "title": "DATD3: Depthwise Attention Twin Delayed Deep Deterministic Policy Gradient For Model Free Reinforcement Learning Under Output Feedback Control", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning in real-world applications often involves\noutput-feedback settings, where the agent receives only partial state\ninformation. To address this challenge, we propose the Output-Feedback Markov\nDecision Process (OPMDP), which extends the standard MDP formulation to\naccommodate decision-making based on observation histories. Building on this\nframework, we introduce Depthwise Attention Twin Delayed Deep Deterministic\nPolicy Gradient (DATD3), a novel actor-critic algorithm that employs depthwise\nseparable convolution and multi-head attention to encode historical\nobservations. DATD3 maintains policy expressiveness while avoiding the\ninstability of recurrent models. Extensive experiments on continuous control\ntasks demonstrate that DATD3 outperforms existing memory-based and recurrent\nbaselines under both partial and full observability.", "AI": {"tldr": "DATD3 is a new actor-critic algorithm which uses depthwise separable convolution and multi-head attention to encode historical observations, outperforming existing models in continuous control tasks with partial or full observability.", "motivation": "Reinforcement learning often faces challenges in real-world applications due to receiving only partial state information. To tackle this issue, there's a need for an approach that can accommodate decision-making based on observation histories.", "method": "The paper proposes the Output-Feedback Markov Decision Process (OPMDP) and DATD3, a novel actor-critic algorithm. DATD3 employs depthwise separable convolution and multi-head attention to encode historical observations, maintaining policy expressiveness while avoiding instability of recurrent models.", "result": "Extensive experiments on continuous control tasks show that DATD3 outperforms existing memory-based and recurrent baselines under both partial and full observability.", "conclusion": "DATD3 provides a superior alternative for reinforcement learning in output-feedback settings, enhancing performance in both partially and fully observable environments."}}
{"id": "2505.23982", "pdf": "https://arxiv.org/pdf/2505.23982", "abs": "https://arxiv.org/abs/2505.23982", "authors": ["Jerry Junyang Cheung", "Shiyao Shen", "Yuchen Zhuang", "Yinghao Li", "Rampi Ramprasad", "Chao Zhang"], "title": "MSQA: Benchmarking LLMs on Graduate-Level Materials Science Reasoning and Knowledge", "categories": ["cs.AI"], "comment": null, "summary": "Despite recent advances in large language models (LLMs) for materials\nscience, there is a lack of benchmarks for evaluating their domain-specific\nknowledge and complex reasoning abilities. To bridge this gap, we introduce\nMSQA, a comprehensive evaluation benchmark of 1,757 graduate-level materials\nscience questions in two formats: detailed explanatory responses and binary\nTrue/False assessments. MSQA distinctively challenges LLMs by requiring both\nprecise factual knowledge and multi-step reasoning across seven materials\nscience sub-fields, such as structure-property relationships, synthesis\nprocesses, and computational modeling. Through experiments with 10\nstate-of-the-art LLMs, we identify significant gaps in current LLM performance.\nWhile API-based proprietary LLMs achieve up to 84.5% accuracy, open-source\n(OSS) LLMs peak around 60.5%, and domain-specific LLMs often underperform\nsignificantly due to overfitting and distributional shifts. MSQA represents the\nfirst benchmark to jointly evaluate the factual and reasoning capabilities of\nLLMs crucial for LLMs in advanced materials science.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7f3a\u4e4f\u8bc4\u4f30\u5176\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\u3002\u4e3a\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7814\u7a76\u8005\u5f15\u5165\u4e86MSQA\uff0c\u8fd9\u662f\u4e00\u4e2a\u5305\u542b1757\u4e2a\u7814\u7a76\u751f\u6c34\u5e73\u6750\u6599\u79d1\u5b66\u95ee\u9898\u7684\u7efc\u5408\u8bc4\u4f30\u57fa\u51c6\uff0c\u6db5\u76d6\u8be6\u7ec6\u89e3\u91ca\u6027\u56de\u7b54\u548c\u4e8c\u5143\u662f\u975e\u5224\u65ad\u4e24\u79cd\u5f62\u5f0f\u3002\u901a\u8fc7\u5b9e\u9a8c\u53d1\u73b0\uff0c\u5f53\u524dLLMs\u6027\u80fd\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff1a\u57fa\u4e8eAPI\u7684\u4e13\u6709LLMs\u51c6\u786e\u7387\u53ef\u8fbe84.5%\uff0c\u800c\u5f00\u6e90LLMs\u7ea6\u4e3a60.5%\uff0c\u9886\u57df\u4e13\u7528LLMs\u56e0\u8fc7\u62df\u5408\u548c\u5206\u5e03\u504f\u79fb\u8868\u73b0\u8f83\u5dee\u3002MSQA\u662f\u9996\u4e2a\u540c\u65f6\u8bc4\u4f30LLMs\u4e8b\u5b9e\u548c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5bf9\u63a8\u52a8\u6750\u6599\u79d1\u5b66\u9886\u57dfLLMs\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6750\u6599\u79d1\u5b66\u9886\u57df\u7684\u5e94\u7528\u4e2d\uff0c\u7f3a\u4e4f\u5bf9\u5176\u9886\u57df\u7279\u5b9a\u77e5\u8bc6\u548c\u590d\u6742\u63a8\u7406\u80fd\u529b\u7684\u6709\u6548\u8bc4\u4f30\u6807\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aMSQA\u7684\u7efc\u5408\u8bc4\u4f30\u57fa\u51c6\uff0c\u5305\u542b1757\u4e2a\u7814\u7a76\u751f\u6c34\u5e73\u7684\u6750\u6599\u79d1\u5b66\u95ee\u9898\uff0c\u6db5\u76d6\u8be6\u7ec6\u89e3\u91ca\u6027\u56de\u7b54\u548c\u4e8c\u5143\u662f\u975e\u5224\u65ad\u4e24\u79cd\u5f62\u5f0f\uff0c\u6d89\u53ca\u6750\u6599\u79d1\u5b66\u7684\u4e03\u4e2a\u5b50\u9886\u57df\u3002\u4f7f\u7528\u8be5\u57fa\u51c6\u5bf910\u79cd\u6700\u5148\u8fdb\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8fdb\u884c\u5b9e\u9a8c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u57fa\u4e8eAPI\u7684\u4e13\u6709LLMs\u8868\u73b0\u6700\u4f73\uff0c\u51c6\u786e\u7387\u53ef\u8fbe84.5%\uff1b\u5f00\u6e90LLMs\u6b21\u4e4b\uff0c\u51c6\u786e\u7387\u7ea6\u4e3a60.5%\uff1b\u9886\u57df\u4e13\u7528LLMs\u7531\u4e8e\u8fc7\u62df\u5408\u548c\u5206\u5e03\u504f\u79fb\uff0c\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "MSQA\u662f\u9996\u4e2a\u80fd\u591f\u540c\u65f6\u8bc4\u4f30\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e8b\u5b9e\u77e5\u8bc6\u548c\u63a8\u7406\u80fd\u529b\u7684\u57fa\u51c6\uff0c\u5bf9\u4e8e\u63a8\u52a8\u6750\u6599\u79d1\u5b66\u9886\u57df\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\u5177\u6709\u91cd\u8981\u4f5c\u7528\u3002"}}
{"id": "2505.23771", "pdf": "https://arxiv.org/pdf/2505.23771", "abs": "https://arxiv.org/abs/2505.23771", "authors": ["Ankush Soni", "Sanjay K. Sahay", "Parit Mehta"], "title": "AESHA3: Efficient and Secure Sub-Key Generation for AES Using SHA-3", "categories": ["cs.CR"], "comment": "13 Pages, 7 figures", "summary": "Advanced Encryption Standard (AES) is one of the most widely used symmetric\ncipher for the confidentiality of data. Also it is used for other security\nservices, viz. integrity, authentication and key establishment. However,\nrecently, authors have shown some weakness in the generation of sub-keys in\nAES, e.g. bit leakage attack, etc. Also, AES sub-keys are generated\nsequentially, which is an overhead, especially for resource-constrained\ndevices. Therefore, we propose and investigate a novel encryption AESHA3, which\nuses sub-keys generated by Secure Hash Algorithm-3 (SHA3). The output of SHA3\nis one-way and highly non-linear, and random. The experimental analysis shows\nthat the average time taken for generating the sub-keys to be used for\nencrypting the data using our approach i.e. AESHA3 is ~1300 times faster than\nthe sub-key generated by the standard AES. Accordingly, we find that AESHA3\nwill be very relevant not only in terms of security but also it will save the\nresources in IoT devices. We investigated AESHA3 in Intel Core i7, 6th\nGeneration processor and Raspberry Pi 4B and found that up to two MB data\nencryption is very significant, and lesser the data size, more the resource\nsaving compared to AES.", "AI": {"tldr": "A new encryption method AESHA3 is proposed, which uses SHA3 to generate sub-keys. It is faster and more resource-saving than the standard AES, especially suitable for IoT devices.", "motivation": "The motivation of this paper is to address the weaknesses in the generation of sub-keys in AES and the overhead caused by sequential sub-key generation, particularly for resource-constrained devices.", "method": "The method involves proposing a novel encryption method called AESHA3, which utilizes Secure Hash Algorithm-3 (SHA3) to generate sub-keys. The output of SHA3 is described as one-way, highly non-linear, and random.", "result": "Experimental analysis indicates that the average time taken for generating sub-keys using AESHA3 is approximately 1300 times faster than with standard AES. The investigation also shows significant data encryption up to two MB and more resource saving with smaller data sizes compared to AES.", "conclusion": "AESHA3 is found to be very relevant not only in terms of security but also in saving resources in IoT devices."}}
{"id": "2505.23859", "pdf": "https://arxiv.org/pdf/2505.23859", "abs": "https://arxiv.org/abs/2505.23859", "authors": ["Wenju Sun", "Qingyong Li", "Wen Wang", "Yang Liu", "Yangli-ao Geng", "Boyang Li"], "title": "Towards Minimizing Feature Drift in Model Merging: Layer-wise Task Vector Fusion for Adaptive Knowledge Integration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Multi-task model merging aims to consolidate knowledge from multiple\nfine-tuned task-specific experts into a unified model while minimizing\nperformance degradation. Existing methods primarily approach this by minimizing\ndifferences between task-specific experts and the unified model, either from a\nparameter-level or a task-loss perspective. However, parameter-level methods\nexhibit a significant performance gap compared to the upper bound, while\ntask-loss approaches entail costly secondary training procedures. In contrast,\nwe observe that performance degradation closely correlates with feature drift,\ni.e., differences in feature representations of the same sample caused by model\nmerging. Motivated by this observation, we propose Layer-wise Optimal Task\nVector Merging (LOT Merging), a technique that explicitly minimizes feature\ndrift between task-specific experts and the unified model in a layer-by-layer\nmanner. LOT Merging can be formulated as a convex quadratic optimization\nproblem, enabling us to analytically derive closed-form solutions for the\nparameters of linear and normalization layers. Consequently, LOT Merging\nachieves efficient model consolidation through basic matrix operations.\nExtensive experiments across vision and vision-language benchmarks demonstrate\nthat LOT Merging significantly outperforms baseline methods, achieving\nimprovements of up to 4.4% (ViT-B/32) over state-of-the-art approaches.", "AI": {"tldr": "The paper introduces LOT Merging, a method to minimize feature drift during multi-task model merging, outperforming existing techniques.", "motivation": "Existing methods for multi-task model merging either have a significant performance gap or require costly secondary training procedures. The authors observe that performance degradation correlates with feature drift.", "method": "LOT Merging is proposed, which minimizes feature drift between task-specific experts and the unified model in a layer-by-layer manner, formulated as a convex quadratic optimization problem.", "result": "Experiments show that LOT Merging significantly outperforms baseline methods, achieving up to 4.4% improvements over state-of-the-art approaches on vision and vision-language benchmarks.", "conclusion": "LOT Merging provides an efficient way to consolidate knowledge from multiple task-specific models into a unified model with minimal performance degradation."}}
{"id": "2505.23990", "pdf": "https://arxiv.org/pdf/2505.23990", "abs": "https://arxiv.org/abs/2505.23990", "authors": ["Mingyang Mao", "Mariela M. Perez-Cabarcas", "Utteja Kallakuri", "Nicholas R. Waytowich", "Xiaomin Lin", "Tinoosh Mohsenin"], "title": "Multi-RAG: A Multimodal Retrieval-Augmented Generation System for Adaptive Video Understanding", "categories": ["cs.AI"], "comment": null, "summary": "To effectively engage in human society, the ability to adapt, filter\ninformation, and make informed decisions in ever-changing situations is\ncritical. As robots and intelligent agents become more integrated into human\nlife, there is a growing opportunity-and need-to offload the cognitive burden\non humans to these systems, particularly in dynamic, information-rich\nscenarios.\n  To fill this critical need, we present Multi-RAG, a multimodal\nretrieval-augmented generation system designed to provide adaptive assistance\nto humans in information-intensive circumstances. Our system aims to improve\nsituational understanding and reduce cognitive load by integrating and\nreasoning over multi-source information streams, including video, audio, and\ntext. As an enabling step toward long-term human-robot partnerships, Multi-RAG\nexplores how multimodal information understanding can serve as a foundation for\nadaptive robotic assistance in dynamic, human-centered situations. To evaluate\nits capability in a realistic human-assistance proxy task, we benchmarked\nMulti-RAG on the MMBench-Video dataset, a challenging multimodal video\nunderstanding benchmark. Our system achieves superior performance compared to\nexisting open-source video large language models (Video-LLMs) and large\nvision-language models (LVLMs), while utilizing fewer resources and less input\ndata. The results demonstrate Multi- RAG's potential as a practical and\nefficient foundation for future human-robot adaptive assistance systems in\ndynamic, real-world contexts.", "AI": {"tldr": "Multi-RAG is a multimodal retrieval-augmented generation system that provides adaptive assistance in information-intensive circumstances, integrating video, audio, and text to reduce cognitive load. Evaluated on MMBench-Video, it outperforms existing models while using fewer resources.", "motivation": "As robots and intelligent agents become more integrated into human life, there is a growing need to offload the cognitive burden on humans to these systems, especially in dynamic, information-rich scenarios.", "method": "The Multi-RAG system integrates and reasons over multi-source information streams including video, audio, and text to improve situational understanding and reduce cognitive load.", "result": "Multi-RAG achieves superior performance compared to existing open-source Video-LLMs and LVLMs while utilizing fewer resources and less input data when benchmarked on the MMBench-Video dataset.", "conclusion": "The results demonstrate Multi-RAG's potential as a practical and efficient foundation for future human-robot adaptive assistance systems in dynamic, real-world contexts."}}
{"id": "2505.23772", "pdf": "https://arxiv.org/pdf/2505.23772", "abs": "https://arxiv.org/abs/2505.23772", "authors": ["William J Buchanan"], "title": "Anamorphic Cryptography with Elliptic Curve Methods", "categories": ["cs.CR"], "comment": null, "summary": "In 2022, Persianom, Phan and Yung outlined the creation of Anamorphic\nCryptography. With this, we can create a public key to encrypt data, and then\nhave two secret keys. These secret keys are used to decrypt the cipher into\ndifferent messages. So, one secret key is given to the Dictator (who must be\nable to decrypt all the messages), and the other is given to Alice. Alice can\nthen decrypt the ciphertext to a secret message that the Dictator cannot see.\nThis paper outlines the implementation of Anamorphic Cryptography using ECC\n(Elliptic Curve Cryptography), such as with the secp256k1 curve. This gives\nconsiderable performance improvements over discrete logarithm-based methods.\nOverall, it outlines how the secret message sent to Alice is hidden within the\nrandom nonce value, which is used within the encryption process, and which is\ncancelled out when the Dictator decrypts the ciphertext.", "AI": {"tldr": "In 2022, Persianom, Phan and Yung created Anamorphic Cryptography which allows for a public key to encrypt data with two secret keys decrypting it into different messages. This paper implements this using ECC (Elliptic Curve Cryptography) such as secp256k1 curve providing better performance than discrete logarithm-based methods. The secret message to Alice is hidden within the random nonce value used in encryption.", "motivation": "To provide a method where one party (Alice) can receive a secret message that another party (the Dictator) cannot see despite both being able to decrypt the same ciphertext into different messages.", "method": "Implementation of Anamorphic Cryptography using Elliptic Curve Cryptography (ECC), specifically utilizing the secp256k1 curve. This involves creating a public key for encryption and two secret keys for decryption leading to different messages. The secret message intended for Alice is embedded within the random nonce value used in encryption.", "result": "Provides significant performance improvements over discrete logarithm-based methods while successfully enabling the Dictator to decrypt all messages and Alice to decrypt her unique secret message.", "conclusion": "Anamorphic Cryptography implemented via ECC offers an effective solution for secure communications where multiple parties can decrypt the same ciphertext into distinct messages."}}
{"id": "2505.23861", "pdf": "https://arxiv.org/pdf/2505.23861", "abs": "https://arxiv.org/abs/2505.23861", "authors": ["Renye Zhang", "Mengyun Yang", "Qichang Zhao", "Jianxin Wang"], "title": "BiBLDR: Bidirectional Behavior Learning for Drug Repositioning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Drug repositioning aims to identify potential new indications for existing\ndrugs to reduce the time and financial costs associated with developing new\ndrugs. Most existing deep learning-based drug repositioning methods\npredominantly utilize graph-based representations. However, graph-based drug\nrepositioning methods struggle to perform effective inference in cold-start\nscenarios involving novel drugs because of the lack of association information\nwith the diseases. Unlike traditional graph-based approaches, we propose a\nbidirectional behavior learning strategy for drug repositioning, known as\nBiBLDR. This innovative framework redefines drug repositioning as a behavior\nsequential learning task to capture drug-disease interaction patterns. First,\nwe construct bidirectional behavioral sequences based on drug and disease\nsides. The consideration of bidirectional information ensures a more meticulous\nand rigorous characterization of the behavioral sequences. Subsequently, we\npropose a two-stage strategy for drug repositioning. In the first stage, we\nconstruct prototype spaces to characterize the representational attributes of\ndrugs and diseases. In the second stage, these refined prototypes and\nbidirectional behavior sequence data are leveraged to predict potential\ndrug-disease associations. Based on this learning approach, the model can more\nrobustly and precisely capture the interactive relationships between drug and\ndisease features from bidirectional behavioral sequences. Extensive experiments\ndemonstrate that our method achieves state-of-the-art performance on benchmark\ndatasets. Meanwhile, BiBLDR demonstrates significantly superior performance\ncompared to previous methods in cold-start scenarios. Our code is published in\nhttps://github.com/Renyeeah/BiBLDR.", "AI": {"tldr": "Drug repositioning using a bidirectional behavior learning strategy (BiBLDR) for better performance in cold-start scenarios.", "motivation": "Existing deep learning-based drug repositioning methods predominantly utilize graph-based representations which struggle to perform effective inference in cold-start scenarios involving novel drugs because of the lack of association information with the diseases.", "method": "The innovative framework, BiBLDR, redefines drug repositioning as a behavior sequential learning task. It constructs bidirectional behavioral sequences based on drug and disease sides and proposes a two-stage strategy for drug repositioning. In the first stage, prototype spaces are constructed to characterize the representational attributes of drugs and diseases. In the second stage, these refined prototypes and bidirectional behavior sequence data are leveraged to predict potential drug-disease associations.", "result": "Extensive experiments demonstrate that the method achieves state-of-the-art performance on benchmark datasets and significantly superior performance compared to previous methods in cold-start scenarios.", "conclusion": "BiBLDR is a robust and precise model for capturing interactive relationships between drug and disease features from bidirectional behavioral sequences, especially excelling in cold-start scenarios."}}
{"id": "2505.24036", "pdf": "https://arxiv.org/pdf/2505.24036", "abs": "https://arxiv.org/abs/2505.24036", "authors": ["Amel Gader", "Alsayed Algergawy"], "title": "GenIC: An LLM-Based Framework for Instance Completion in Knowledge Graphs", "categories": ["cs.AI", "cs.IR"], "comment": null, "summary": "Knowledge graph completion aims to address the gaps of knowledge bases by\nadding new triples that represent facts. The complexity of this task depends on\nhow many parts of a triple are already known. Instance completion involves\npredicting the relation-tail pair when only the head is given (h, ?, ?).\nNotably, modern knowledge bases often contain entity descriptions and types,\nwhich can provide valuable context for inferring missing facts. By leveraging\nthese textual descriptions and the ability of large language models to extract\nfacts from them and recognize patterns within the knowledge graph schema, we\npropose an LLM-powered, end-to-end instance completion approach. Specifically,\nwe introduce GenIC: a two-step Generative Instance Completion framework. The\nfirst step focuses on property prediction, treated as a multi-label\nclassification task. The second step is link prediction, framed as a generative\nsequence-to-sequence task. Experimental results on three datasets show that our\nmethod outperforms existing baselines. Our code is available at\nhttps://github.com/amal-gader/genic.", "AI": {"tldr": "The paper introduces GenIC, a two-step generative framework leveraging large language models for knowledge graph instance completion. It consists of property prediction and link prediction steps, outperforming existing methods in experiments.", "motivation": "Knowledge graph completion is crucial for enhancing knowledge bases, yet predicting missing triples remains challenging. Modern knowledge bases with entity descriptions and types offer potential contextual clues for inferring missing facts.", "method": "Proposes GenIC, a two-step framework: 1) Property Prediction as multi-label classification to predict possible relations for an entity; 2) Link Prediction as a generative sequence-to-sequence task to predict the tail entity given head and relation.", "result": "GenIC shows superior performance compared to existing baselines across three datasets.", "conclusion": "GenIC effectively leverages textual descriptions and schema patterns through large language models for improved knowledge graph instance completion."}}
{"id": "2505.23773", "pdf": "https://arxiv.org/pdf/2505.23773", "abs": "https://arxiv.org/abs/2505.23773", "authors": ["Sefik Serengil", "Alper Ozpinar"], "title": "LightDSA: A Python-Based Hybrid Digital Signature Library and Performance Analysis of RSA, DSA, ECDSA and EdDSA in Variable Configurations, Elliptic Curve Forms and Curves", "categories": ["cs.CR"], "comment": null, "summary": "Digital signature algorithms (DSAs) are fundamental to cryptographic\nsecurity, ensuring data integrity and authentication. While RSA, DSA, ECDSA,\nand EdDSA are widely used, their performance varies significantly depending on\nkey sizes, hash functions, and elliptic curve configurations. In this paper, we\nintroduce LightDSA, a hybrid and configurable digital signature library that\nsupports RSA, DSA, ECDSA, and EdDSA with flexible form and curve selection,\nopen sourced at https://github.com/serengil/LightDSA. Unlike conventional\nimplementations that impose strict curve-form mappings - such as Weierstrass\nfor ECDSA and Edwards for EdDSA LightDSA - allows arbitrary combinations,\nenabling a broader performance evaluation. We analyze the computational\nefficiency of these algorithms across various configurations, comparing key\ngeneration, signing, and verification times. Our results provide insights into\nthe trade-offs between security and efficiency, guiding the selection of\noptimal configurations for different cryptographic needs.", "AI": {"tldr": "The paper introduces LightDSA, a configurable digital signature library supporting RSA, DSA, ECDSA, and EdDSA with flexible curve and form selection. It allows arbitrary combinations of curves and forms, unlike traditional implementations. The authors analyze the computational efficiency of these algorithms across various configurations to provide insights into security-efficiency trade-offs.", "motivation": "To create a more flexible and hybrid digital signature library that supports multiple algorithms (RSA, DSA, ECDSA, EdDSA) with arbitrary curve-form combinations, enabling broader performance evaluation beyond conventional strict mappings.", "method": "Development of LightDSA, a digital signature library allowing flexible form and curve selection for different DSAs. The method involves implementing and analyzing key generation, signing, and verification times across various configurations and comparing the performance of different algorithms.", "result": "LightDSA enables a comprehensive analysis of the trade-offs between security and efficiency in digital signatures, offering guidance on selecting optimal configurations for specific cryptographic needs.", "conclusion": "LightDSA provides a flexible platform for evaluating digital signature algorithms, demonstrating significant variability in performance depending on configuration choices. This can help users choose the best algorithm and settings based on their security and efficiency requirements."}}
{"id": "2505.23863", "pdf": "https://arxiv.org/pdf/2505.23863", "abs": "https://arxiv.org/abs/2505.23863", "authors": ["Chang Liu", "Bohao Zhao", "Jingtao Ding", "Huandong Wang", "Yong Li"], "title": "Mamba Integrated with Physics Principles Masters Long-term Chaotic System Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Long-term forecasting of chaotic systems from short-term observations remains\na fundamental and underexplored challenge due to the intrinsic sensitivity to\ninitial conditions and the complex geometry of strange attractors. Existing\napproaches often rely on long-term training data or focus on short-term\nsequence correlations, struggling to maintain predictive stability and\ndynamical coherence over extended horizons. We propose PhyxMamba, a novel\nframework that integrates a Mamba-based state-space model with physics-informed\nprinciples to capture the underlying dynamics of chaotic systems. By\nreconstructing the attractor manifold from brief observations using time-delay\nembeddings, PhyxMamba extracts global dynamical features essential for accurate\nforecasting. Our generative training scheme enables Mamba to replicate the\nphysical process, augmented by multi-token prediction and attractor geometry\nregularization for physical constraints, enhancing prediction accuracy and\npreserving key statistical invariants. Extensive evaluations on diverse\nsimulated and real-world chaotic systems demonstrate that PhyxMamba delivers\nsuperior long-term forecasting and faithfully captures essential dynamical\ninvariants from short-term data. This framework opens new avenues for reliably\npredicting chaotic systems under observation-scarce conditions, with broad\nimplications across climate science, neuroscience, epidemiology, and beyond.\nOur code is open-source at https://github.com/tsinghua-fib-lab/PhyxMamba.", "AI": {"tldr": "PhyxMamba is a novel framework integrating Mamba-based state-space model with physics-informed principles for long-term forecasting of chaotic systems from short-term observations.", "motivation": "Long-term forecasting of chaotic systems remains a challenge due to sensitivity to initial conditions and complex geometry. Existing methods struggle with maintaining predictive stability and dynamical coherence over extended horizons.", "method": "PhyxMamba reconstructs the attractor manifold from brief observations using time-delay embeddings, extracts global dynamical features, and uses a generative training scheme with multi-token prediction and attractor geometry regularization to replicate the physical process and preserve key statistical invariants.", "result": "Extensive evaluations show that PhyxMamba delivers superior long-term forecasting and captures essential dynamical invariants from short-term data.", "conclusion": "PhyxMamba opens new avenues for reliably predicting chaotic systems under observation-scarce conditions, with implications across various fields."}}
{"id": "2505.24037", "pdf": "https://arxiv.org/pdf/2505.24037", "abs": "https://arxiv.org/abs/2505.24037", "authors": ["Qiao Xiao", "Alan Ansell", "Boqian Wu", "Lu Yin", "Mykola Pechenizkiy", "Shiwei Liu", "Decebal Constantin Mocanu"], "title": "Leave it to the Specialist: Repair Sparse LLMs with Sparse Fine-Tuning via Sparsity Evolution", "categories": ["cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable success across various\ntasks but face deployment challenges due to their massive computational\ndemands. While post-training pruning methods like SparseGPT and Wanda can\neffectively reduce the model size, but struggle to maintain model performance\nat high sparsity levels, limiting their utility for downstream tasks. Existing\nfine-tuning methods, such as full fine-tuning and LoRA, fail to preserve\nsparsity as they require updating the whole dense metrics, not well-suited for\nsparse LLMs. In this paper, we propose Sparsity Evolution Fine-Tuning (SEFT), a\nnovel method designed specifically for sparse LLMs. SEFT dynamically evolves\nthe sparse topology of pruned models during fine-tuning, while preserving the\noverall sparsity throughout the process. The strengths of SEFT lie in its\nability to perform task-specific adaptation through a weight drop-and-grow\nstrategy, enabling the pruned model to self-adapt its sparse connectivity\npattern based on the target dataset. Furthermore, a sensitivity-driven pruning\ncriterion is employed to ensure that the desired sparsity level is consistently\nmaintained throughout fine-tuning. Our experiments on various LLMs, including\nLLaMA families, DeepSeek, and Mistral, across a diverse set of benchmarks\ndemonstrate that SEFT achieves stronger performance while offering superior\nmemory and time efficiency compared to existing baselines. Our code is publicly\navailable at: https://github.com/QiaoXiao7282/SEFT.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u56e0\u8ba1\u7b97\u9700\u6c42\u5de8\u5927\u800c\u9762\u4e34\u90e8\u7f72\u6311\u6218\u3002\u5c3d\u7ba1\u540e\u8bad\u7ec3\u4fee\u526a\u65b9\u6cd5\u5982SparseGPT\u548cWanda\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u6a21\u578b\u5927\u5c0f\uff0c\u4f46\u5728\u9ad8\u7a00\u758f\u5ea6\u6c34\u5e73\u4e0b\u96be\u4ee5\u7ef4\u6301\u6a21\u578b\u6027\u80fd\u3002\u73b0\u6709\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u5982\u5168\u5fae\u8c03\u548cLoRA\uff0c\u65e0\u6cd5\u4fdd\u7559\u7a00\u758f\u6027\uff0c\u56e0\u4e3a\u5b83\u4eec\u9700\u8981\u66f4\u65b0\u6574\u4e2a\u5bc6\u96c6\u77e9\u9635\uff0c\u4e0d\u9002\u5408\u7a00\u758fLLMs\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSparsity Evolution Fine-Tuning (SEFT)\u7684\u65b0\u65b9\u6cd5\uff0c\u4e13\u4e3a\u7a00\u758fLLMs\u8bbe\u8ba1\u3002SEFT\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6f14\u5316\u4fee\u526a\u6a21\u578b\u7684\u7a00\u758f\u62d3\u6251\u7ed3\u6784\uff0c\u540c\u65f6\u5728\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u6574\u4f53\u7a00\u758f\u6027\u3002SEFT\u901a\u8fc7\u6743\u91cd\u964d-\u589e\u7b56\u7565\u8fdb\u884c\u7279\u5b9a\u4efb\u52a1\u7684\u9002\u5e94\uff0c\u4f7f\u4fee\u526a\u540e\u7684\u6a21\u578b\u80fd\u591f\u6839\u636e\u76ee\u6807\u6570\u636e\u96c6\u81ea\u9002\u5e94\u5176\u7a00\u758f\u8fde\u63a5\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u91c7\u7528\u654f\u611f\u6027\u9a71\u52a8\u7684\u4fee\u526a\u6807\u51c6\uff0c\u4ee5\u786e\u4fdd\u5728\u6574\u4e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u59cb\u7ec8\u4fdd\u6301\u6240\u9700\u7684\u7a00\u758f\u5ea6\u6c34\u5e73\u3002\u6211\u4eec\u5728\u5305\u62ecLLaMA\u7cfb\u5217\u3001DeepSeek\u548cMistral\u5728\u5185\u7684\u5404\u79cdLLMs\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u8de8\u8d8a\u591a\u6837\u5316\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7ed3\u679c\u8868\u660eSEFT\u5728\u63d0\u4f9b\u6bd4\u73b0\u6709\u57fa\u7ebf\u66f4\u4f18\u7684\u5185\u5b58\u548c\u65f6\u95f4\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u66f4\u5f3a\u7684\u6027\u80fd\u3002\u6211\u4eec\u7684\u4ee3\u7801\u5df2\u516c\u5f00\u53d1\u5e03\uff1ahttps://github.com/QiaoXiao7282/SEFT\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u867d\u7136\u529f\u80fd\u5f3a\u5927\uff0c\u4f46\u56e0\u5176\u5de8\u5927\u7684\u8ba1\u7b97\u9700\u6c42\u800c\u5728\u90e8\u7f72\u65b9\u9762\u9047\u5230\u56f0\u96be\u3002\u73b0\u6709\u7684\u4fee\u526a\u548c\u5fae\u8c03\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u4fdd\u6301\u6027\u80fd\uff0c\u8981\u4e48\u65e0\u6cd5\u4fdd\u7559\u7a00\u758f\u6027\uff0c\u56e0\u6b64\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4e0b\u6e38\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u3002", "method": "\u63d0\u51fa\u4e86Sparsity Evolution Fine-Tuning (SEFT)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u52a8\u6001\u6f14\u5316\u4fee\u526a\u6a21\u578b\u7684\u7a00\u758f\u62d3\u6251\u7ed3\u6784\uff0c\u540c\u65f6\u4fdd\u6301\u6574\u4f53\u7a00\u758f\u6027\u3002\u5b83\u4f7f\u7528\u4e00\u79cd\u6743\u91cd\u964d-\u589e\u7b56\u7565\u6765\u5b9e\u73b0\u7279\u5b9a\u4efb\u52a1\u7684\u9002\u5e94\uff0c\u5e76\u91c7\u7528\u654f\u611f\u6027\u9a71\u52a8\u7684\u4fee\u526a\u6807\u51c6\u4ee5\u786e\u4fdd\u5728\u6574\u4e2a\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u7ef4\u6301\u6240\u9700\u7684\u7a00\u758f\u5ea6\u6c34\u5e73\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSEFT\u5728\u591a\u79cd\u5927\u578b\u8bed\u8a00\u6a21\u578b\u548c\u591a\u6837\u5316\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u6027\u80fd\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709\u57fa\u7ebf\u66f4\u4f18\u7684\u5185\u5b58\u548c\u65f6\u95f4\u6548\u7387\u3002", "conclusion": "SEFT\u662f\u4e00\u79cd\u4e13\u4e3a\u7a00\u758fLLMs\u8bbe\u8ba1\u7684\u6709\u6548\u5fae\u8c03\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u4fdd\u6301\u7a00\u758f\u6027\u7684\u540c\u65f6\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4e14\u5728\u8d44\u6e90\u5229\u7528\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2505.23786", "pdf": "https://arxiv.org/pdf/2505.23786", "abs": "https://arxiv.org/abs/2505.23786", "authors": ["Kazuki Egashira", "Robin Staab", "Mark Vero", "Jingxuan He", "Martin Vechev"], "title": "Mind the Gap: A Practical Attack on GGUF Quantization", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "ICML 2025", "summary": "With the increasing size of frontier LLMs, post-training quantization has\nbecome the standard for memory-efficient deployment. Recent work has shown that\nbasic rounding-based quantization schemes pose security risks, as they can be\nexploited to inject malicious behaviors into quantized models that remain\nhidden in full precision. However, existing attacks cannot be applied to more\ncomplex quantization methods, such as the GGUF family used in the popular\nollama and llama.cpp frameworks. In this work, we address this gap by\nintroducing the first attack on GGUF. Our key insight is that the quantization\nerror -- the difference between the full-precision weights and their\n(de-)quantized version -- provides sufficient flexibility to construct\nmalicious quantized models that appear benign in full precision. Leveraging\nthis, we develop an attack that trains the target malicious LLM while\nconstraining its weights based on quantization errors. We demonstrate the\neffectiveness of our attack on three popular LLMs across nine GGUF quantization\ndata types on three diverse attack scenarios: insecure code generation\n($\\Delta$=$88.7\\%$), targeted content injection ($\\Delta$=$85.0\\%$), and benign\ninstruction refusal ($\\Delta$=$30.1\\%$). Our attack highlights that (1) the\nmost widely used post-training quantization method is susceptible to\nadversarial interferences, and (2) the complexity of quantization schemes alone\nis insufficient as a defense.", "AI": {"tldr": "\u5728\u524d\u6cbfLLM\u7684\u89c4\u6a21\u65e5\u76ca\u589e\u5927\u7684\u80cc\u666f\u4e0b\uff0c\u4e3a\u4e86\u5b9e\u73b0\u5185\u5b58\u9ad8\u6548\u7684\u90e8\u7f72\uff0c\u540e\u8bad\u7ec3\u91cf\u5316\u5df2\u6210\u4e3a\u6807\u51c6\u3002\u7136\u800c\uff0c\u57fa\u672c\u7684\u57fa\u4e8e\u820d\u5165\u7684\u91cf\u5316\u65b9\u6848\u5b58\u5728\u5b89\u5168\u98ce\u9669\uff0c\u56e0\u4e3a\u5b83\u4eec\u53ef\u80fd\u88ab\u5229\u7528\u5411\u91cf\u5316\u6a21\u578b\u6ce8\u5165\u6076\u610f\u884c\u4e3a\uff0c\u800c\u8fd9\u4e9b\u884c\u4e3a\u5728\u5168\u7cbe\u5ea6\u4e0b\u4ecd\u7136\u9690\u85cf\u3002\u73b0\u6709\u7684\u653b\u51fb\u65e0\u6cd5\u5e94\u7528\u4e8e\u66f4\u590d\u6742\u7684\u91cf\u5316\u65b9\u6cd5\uff08\u5982GGUF\uff09\u3002\u672c\u6587\u901a\u8fc7\u5f15\u5165\u9996\u4e2a\u9488\u5bf9GGUF\u7684\u653b\u51fb\u586b\u8865\u4e86\u8fd9\u4e00\u7a7a\u767d\u3002\u7814\u7a76\u8868\u660e\uff0c\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u5e72\u6270\uff0c\u4e14\u4ec5\u4f9d\u9760\u91cf\u5316\u65b9\u6848\u7684\u590d\u6742\u6027\u4e0d\u8db3\u4ee5\u4f5c\u4e3a\u9632\u5fa1\u624b\u6bb5\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u6280\u672f\u867d\u7136\u63d0\u9ad8\u4e86\u5185\u5b58\u6548\u7387\uff0c\u4f46\u5176\u5b89\u5168\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002\u5c3d\u7ba1\u5df2\u77e5\u57fa\u7840\u7684\u91cf\u5316\u65b9\u6cd5\u5b58\u5728\u5b89\u5168\u9690\u60a3\uff0c\u4f46\u66f4\u590d\u6742\u7684\u91cf\u5316\u65b9\u6cd5\uff08\u5982GGUF\uff09\u7684\u5b89\u5168\u6027\u4ecd\u662f\u4e00\u4e2a\u5f00\u653e\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5e76\u63ed\u793aGGUF\u7b49\u590d\u6742\u91cf\u5316\u65b9\u6cd5\u662f\u5426\u4e5f\u5b58\u5728\u6f5c\u5728\u7684\u5b89\u5168\u5a01\u80c1\u3002", "method": "\u7814\u7a76\u8005\u9996\u5148\u53d1\u73b0\u91cf\u5316\u8bef\u5dee\uff08\u5168\u7cbe\u5ea6\u6743\u91cd\u4e0e\u91cf\u5316\u7248\u672c\u4e4b\u95f4\u7684\u5dee\u5f02\uff09\u63d0\u4f9b\u4e86\u8db3\u591f\u7684\u7075\u6d3b\u6027\u6765\u6784\u5efa\u6076\u610f\u7684\u91cf\u5316\u6a21\u578b\uff0c\u8fd9\u4e9b\u6a21\u578b\u5728\u5168\u7cbe\u5ea6\u4e0b\u8868\u73b0\u6b63\u5e38\u3002\u57fa\u4e8e\u6b64\uff0c\u4ed6\u4eec\u5f00\u53d1\u4e86\u4e00\u79cd\u653b\u51fb\u65b9\u6cd5\uff0c\u5728\u8bad\u7ec3\u76ee\u6807\u6076\u610fLLM\u65f6\u7ea6\u675f\u5176\u6743\u91cd\u4ee5\u9002\u5e94\u91cf\u5316\u8bef\u5dee\u3002\u8be5\u65b9\u6cd5\u9002\u7528\u4e8e\u591a\u79cdGGUF\u91cf\u5316\u6570\u636e\u7c7b\u578b\uff0c\u5e76\u80fd\u5728\u4e0d\u540c\u653b\u51fb\u573a\u666f\u4e2d\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "\u8be5\u653b\u51fb\u65b9\u6cd5\u5728\u4e09\u4e2a\u6d41\u884c\u7684LLM\u4e0a\u8fdb\u884c\u4e86\u6d4b\u8bd5\uff0c\u6db5\u76d6\u4e86\u4e5d\u79cdGGUF\u91cf\u5316\u6570\u636e\u7c7b\u578b\u548c\u4e09\u79cd\u4e0d\u540c\u7684\u653b\u51fb\u573a\u666f\uff1a\u4e0d\u5b89\u5168\u4ee3\u7801\u751f\u6210\uff08\u63d0\u534788.7%\uff09\u3001\u76ee\u6807\u5185\u5bb9\u6ce8\u5165\uff08\u63d0\u534785.0%\uff09\u548c\u826f\u6027\u6307\u4ee4\u62d2\u7edd\uff08\u63d0\u534730.1%\uff09\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5e38\u7528\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u5e72\u6270\uff0c\u800c\u4ec5\u4ec5\u4f9d\u8d56\u91cf\u5316\u65b9\u6848\u7684\u590d\u6742\u6027\u5e76\u4e0d\u8db3\u4ee5\u9632\u6b62\u6b64\u7c7b\u653b\u51fb\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u540e\u8bad\u7ec3\u91cf\u5316\u65b9\u6cd5\u4e5f\u53ef\u80fd\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u5e72\u6270\u3002\u6b64\u5916\uff0c\u4ec5\u4ec5\u589e\u52a0\u91cf\u5316\u65b9\u6848\u7684\u590d\u6742\u6027\u5e76\u4e0d\u80fd\u6709\u6548\u9632\u5fa1\u6076\u610f\u653b\u51fb\u3002\u8fd9\u63d0\u793a\u7814\u7a76\u8005\u548c\u4ece\u4e1a\u8005\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u91cf\u5316\u6280\u672f\u7684\u5b89\u5168\u6027\uff0c\u5e76\u63a2\u7d22\u66f4\u52a0\u5065\u58ee\u7684\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2505.23864", "pdf": "https://arxiv.org/pdf/2505.23864", "abs": "https://arxiv.org/abs/2505.23864", "authors": ["Wei Zhuo", "Zhaohuan Zhan", "Ziduo Yang", "Han Yu"], "title": "Personalized Subgraph Federated Learning with Differentiable Auxiliary Projections", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Federated learning (FL) on graph-structured data typically faces non-IID\nchallenges, particularly in scenarios where each client holds a distinct\nsubgraph sampled from a global graph. In this paper, we introduce Federated\nlearning with Auxiliary projections (FedAux), a personalized subgraph FL\nframework that learns to align, compare, and aggregate heterogeneously\ndistributed local models without sharing raw data or node embeddings. In\nFedAux, each client jointly trains (i) a local GNN and (ii) a learnable\nauxiliary projection vector (APV) that differentiably projects node embeddings\nonto a 1D space. A soft-sorting operation followed by a lightweight 1D\nconvolution refines these embeddings in the ordered space, enabling the APV to\neffectively capture client-specific information. After local training, these\nAPVs serve as compact signatures that the server uses to compute inter-client\nsimilarities and perform similarity-weighted parameter mixing, yielding\npersonalized models while preserving cross-client knowledge transfer. Moreover,\nwe provide rigorous theoretical analysis to establish the convergence and\nrationality of our design. Empirical evaluations across diverse graph\nbenchmarks demonstrate that FedAux substantially outperforms existing baselines\nin both accuracy and personalization performance.", "AI": {"tldr": "This paper introduces Federated learning with Auxiliary projections (FedAux), a personalized subgraph FL framework for non-IID graph-structured data, which learns to align, compare, and aggregate heterogeneously distributed local models without sharing raw data or node embeddings. Empirical evaluations show that FedAux outperforms existing baselines in both accuracy and personalization performance.", "motivation": "Federated learning on graph-structured data typically faces non-IID challenges, particularly in scenarios where each client holds a distinct subgraph sampled from a global graph.", "method": "FedAux is a personalized subgraph FL framework that jointly trains a local GNN and a learnable auxiliary projection vector (APV) that projects node embeddings onto a 1D space. A soft-sorting operation followed by a lightweight 1D convolution refines these embeddings in the ordered space, enabling the APV to effectively capture client-specific information. After local training, these APVs serve as compact signatures that the server uses to compute inter-client similarities and perform similarity-weighted parameter mixing, yielding personalized models while preserving cross-client knowledge transfer.", "result": "Empirical evaluations across diverse graph benchmarks demonstrate that FedAux substantially outperforms existing baselines in both accuracy and personalization performance.", "conclusion": "The authors introduce FedAux, a personalized subgraph FL framework for non-IID graph-structured data, which learns to align, compare, and aggregate heterogeneously distributed local models without sharing raw data or node embeddings. The method substantially outperforms existing baselines in both accuracy and personalization performance."}}
{"id": "2505.24073", "pdf": "https://arxiv.org/pdf/2505.24073", "abs": "https://arxiv.org/abs/2505.24073", "authors": ["Chan-Wei Hu", "Yueqi Wang", "Shuo Xing", "Chia-Ju Chen", "Zhengzhong Tu"], "title": "mRAG: Elucidating the Design Space of Multi-modal Retrieval-Augmented Generation", "categories": ["cs.AI"], "comment": "16 pages, 11 figures", "summary": "Large Vision-Language Models (LVLMs) have made remarkable strides in\nmultimodal tasks such as visual question answering, visual grounding, and\ncomplex reasoning. However, they remain limited by static training data,\nsusceptibility to hallucinations, and inability to verify claims against\nup-to-date, external evidence, compromising their performance in dynamic\nreal-world applications. Retrieval-Augmented Generation (RAG) offers a\npractical solution to mitigate these challenges by allowing the LVLMs to access\nlarge-scale knowledge databases via retrieval mechanisms, thereby grounding\nmodel outputs in factual, contextually relevant information. Here in this\npaper, we conduct the first systematic dissection of the multimodal RAG\npipeline for LVLMs, explicitly investigating (1) the retrieval phase: on the\nmodality configurations and retrieval strategies, (2) the re-ranking stage: on\nstrategies to mitigate positional biases and improve the relevance of retrieved\nevidence, and (3) the generation phase: we further investigate how to best\nintegrate retrieved candidates into the final generation process. Finally, we\nextend to explore a unified agentic framework that integrates re-ranking and\ngeneration through self-reflection, enabling LVLMs to select relevant evidence\nand suppress irrelevant context dynamically. Our full-stack exploration of RAG\nfor LVLMs yields substantial insights, resulting in an average performance\nboost of 5% without any fine-tuning.", "AI": {"tldr": "Large Vision-Language Models (LVLMs) have made great progress in multimodal tasks, but they still have limitations. Retrieval-Augmented Generation (RAG) provides a solution to these problems by enabling LVLMs to access large-scale knowledge databases through retrieval mechanisms. In this paper, we dissect the multimodal RAG pipeline for LVLMs and explore a unified agentic framework that integrates re-ranking and generation through self-reflection. Our exploration of RAG for LVLMs yields substantial insights.", "motivation": "LVLMs are limited by static training data, susceptibility to hallucinations, and inability to verify claims against up-to-date, external evidence. RAG offers a practical solution to mitigate these challenges.", "method": "Systematic dissection of the multimodal RAG pipeline for LVLMs, including the retrieval phase, the re-ranking stage, and the generation phase. Exploration of a unified agentic framework that integrates re-ranking and generation through self-reflection.", "result": "An average performance boost of 5% without any fine-tuning.", "conclusion": "The full-stack exploration of RAG for LVLMs yields substantial insights."}}
{"id": "2505.23791", "pdf": "https://arxiv.org/pdf/2505.23791", "abs": "https://arxiv.org/abs/2505.23791", "authors": ["Sayyed Farid Ahamed", "Sandip Roy", "Soumya Banerjee", "Marc Vucovich", "Kevin Choi", "Abdul Rahman", "Alison Hu", "Edward Bowen", "Sachin Shetty"], "title": "Evaluating Query Efficiency and Accuracy of Transfer Learning-based Model Extraction Attack in Federated Learning", "categories": ["cs.CR", "cs.AI", "cs.LG", "I.2.6; D.4.6"], "comment": "Accepted at IEEE IWCMC. 6 pages, 4 Figures, 3 tables", "summary": "Federated Learning (FL) is a collaborative learning framework designed to\nprotect client data, yet it remains highly vulnerable to Intellectual Property\n(IP) threats. Model extraction (ME) attacks pose a significant risk to Machine\nLearning as a Service (MLaaS) platforms, enabling attackers to replicate\nconfidential models by querying black-box (without internal insight) APIs.\nDespite FL's privacy-preserving goals, its distributed nature makes it\nparticularly susceptible to such attacks. This paper examines the vulnerability\nof FL-based victim models to two types of model extraction attacks. For various\nfederated clients built under the NVFlare platform, we implemented ME attacks\nacross two deep learning architectures and three image datasets. We evaluate\nthe proposed ME attack performance using various metrics, including accuracy,\nfidelity, and KL divergence. The experiments show that for different FL\nclients, the accuracy and fidelity of the extracted model are closely related\nto the size of the attack query set. Additionally, we explore a transfer\nlearning based approach where pretrained models serve as the starting point for\nthe extraction process. The results indicate that the accuracy and fidelity of\nthe fine-tuned pretrained extraction models are notably higher, particularly\nwith smaller query sets, highlighting potential advantages for attackers.", "AI": {"tldr": "Federated Learning, despite its privacy-preserving goals, is highly vulnerable to model extraction attacks. This paper explores two types of such attacks on FL-based models using various deep learning architectures and datasets. The study finds that the success of these attacks depends heavily on the size of the attack query set. Additionally, a transfer learning approach increases the accuracy and fidelity of the extracted models, especially with smaller query sets.", "motivation": "The motivation behind this research is the need to address the vulnerabilities in Federated Learning (FL) systems against Intellectual Property (IP) threats, particularly model extraction (ME) attacks. While FL aims to protect client data, its distributed nature makes it susceptible to ME attacks, which can replicate confidential models by querying black-box APIs.", "method": "The researchers implemented ME attacks on various federated clients built under the NVFlare platform across two deep learning architectures and three image datasets. They evaluated the performance of these attacks using metrics like accuracy, fidelity, and KL divergence. Furthermore, they explored a transfer learning based approach where pretrained models were fine-tuned to serve as the starting point for the extraction process.", "result": "The experiments demonstrated that the accuracy and fidelity of the extracted models are closely related to the size of the attack query set. Using transfer learning significantly improved the accuracy and fidelity of the extracted models, particularly when the query sets were small.", "conclusion": "Federated Learning systems are highly vulnerable to model extraction attacks. The effectiveness of these attacks can be enhanced through the use of transfer learning, which poses additional risks to the confidentiality of models in FL-based systems."}}
{"id": "2505.23865", "pdf": "https://arxiv.org/pdf/2505.23865", "abs": "https://arxiv.org/abs/2505.23865", "authors": ["Emanuele Masiero", "Vito Trianni", "Giuseppe Vizzari", "Dimitri Ognibene"], "title": "Combining Deep Architectures for Information Gain estimation and Reinforcement Learning for multiagent field exploration", "categories": ["cs.LG", "cs.AI"], "comment": "4 pages, presented at RLDM 2025", "summary": "Precision agriculture requires efficient autonomous systems for crop\nmonitoring, where agents must explore large-scale environments while minimizing\nresource consumption. This work addresses the problem as an active exploration\ntask in a grid environment representing an agricultural field. Each cell may\ncontain targets (e.g., damaged crops) observable from nine predefined points of\nview (POVs). Agents must infer the number of targets per cell using partial,\nsequential observations.\n  We propose a two-stage deep learning framework. A pre-trained LSTM serves as\na belief model, updating a probabilistic map of the environment and its\nassociated entropy, which defines the expected information gain (IG). This\nallows agents to prioritize informative regions. A key contribution is the\ninclusion of a POV visibility mask in the input, preserving the Markov property\nunder partial observability and avoiding revisits to already explored views.\n  Three agent architectures were compared: an untrained IG-based agent\nselecting actions to maximize entropy reduction; a DQN agent using CNNs over\nlocal 3x3 inputs with belief, entropy, and POV mask; and a Double-CNN DQN agent\nwith wider spatial context. Simulations on 20x20 maps showed that the untrained\nagent performs well despite its simplicity. The DQN agent matches this\nperformance when the POV mask is included, while the Double-CNN agent\nconsistently achieves superior exploration efficiency, especially in larger\nenvironments.\n  Results show that uncertainty-aware policies leveraging entropy, belief\nstates, and visibility tracking lead to robust and scalable exploration. Future\nwork includes curriculum learning, multi-agent cooperation with shared rewards,\ntransformer-based models, and intrinsic motivation mechanisms to further\nenhance learning efficiency and policy generalization.", "AI": {"tldr": "\u5728\u7cbe\u51c6\u519c\u4e1a\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f5c\u7269\u76d1\u6d4b\u7684\u4e3b\u52a8\u63a2\u7d22\u4efb\u52a1\u3002\u8be5\u6846\u67b6\u901a\u8fc7\u71b5\u548c\u53ef\u89c1\u6027\u63a9\u7801\u6765\u6307\u5bfc\u667a\u80fd\u4f53\u4f18\u5148\u63a2\u7d22\u4fe1\u606f\u4e30\u5bcc\u7684\u533a\u57df\uff0c\u5e76\u901a\u8fc7\u6a21\u62df\u9a8c\u8bc1\u4e86\u4e0d\u540c\u667a\u80fd\u4f53\u67b6\u6784\u7684\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u5229\u7528\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7b56\u7565\u53ef\u4ee5\u5b9e\u73b0\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u63a2\u7d22\u3002", "motivation": "\u7cbe\u51c6\u519c\u4e1a\u9700\u8981\u9ad8\u6548\u7684\u81ea\u4e3b\u7cfb\u7edf\u6765\u8fdb\u884c\u4f5c\u7269\u76d1\u6d4b\uff0c\u8fd9\u4e9b\u7cfb\u7edf\u5fc5\u987b\u5728\u5927\u89c4\u6a21\u73af\u5883\u4e2d\u8fdb\u884c\u63a2\u7d22\uff0c\u540c\u65f6\u5c3d\u91cf\u51cf\u5c11\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff1a1. \u4f7f\u7528\u9884\u8bad\u7ec3\u7684LSTM\u4f5c\u4e3a\u4fe1\u5ff5\u6a21\u578b\uff0c\u66f4\u65b0\u73af\u5883\u7684\u6982\u7387\u56fe\u53ca\u5176\u71b5\uff1b2. \u5728\u8f93\u5165\u4e2d\u52a0\u5165POV\u53ef\u89c1\u6027\u63a9\u7801\uff0c\u4ee5\u4fdd\u6301\u90e8\u5206\u53ef\u89c2\u6d4b\u6027\u4e0b\u7684\u9a6c\u5c14\u53ef\u592b\u6027\u8d28\u3002\u6bd4\u8f83\u4e86\u4e09\u79cd\u667a\u80fd\u4f53\u67b6\u6784\uff1a\u57fa\u4e8eIG\u7684\u672a\u8bad\u7ec3\u667a\u80fd\u4f53\u3001\u4f7f\u7528CNN\u7684DQN\u667a\u80fd\u4f53\u4ee5\u53ca\u5177\u6709\u66f4\u5bbd\u7a7a\u95f4\u4e0a\u4e0b\u6587\u7684Double-CNN DQN\u667a\u80fd\u4f53\u3002", "result": "\u572820x20\u5730\u56fe\u4e0a\u7684\u6a21\u62df\u663e\u793a\uff0c\u672a\u8bad\u7ec3\u667a\u80fd\u4f53\u8868\u73b0\u826f\u597d\uff0cDQN\u667a\u80fd\u4f53\u5728\u5305\u542bPOV\u63a9\u7801\u65f6\u5339\u914d\u5176\u6027\u80fd\uff0c\u800cDouble-CNN DQN\u667a\u80fd\u4f53\u5728\u66f4\u5927\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u63a2\u7d22\u6548\u7387\u3002", "conclusion": "\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u7b56\u7565\uff08\u5229\u7528\u71b5\u3001\u4fe1\u5ff5\u72b6\u6001\u548c\u53ef\u89c1\u6027\u8ddf\u8e2a\uff09\u80fd\u591f\u5b9e\u73b0\u7a33\u5065\u4e14\u53ef\u6269\u5c55\u7684\u63a2\u7d22\u3002\u672a\u6765\u5de5\u4f5c\u5305\u62ec\u8bfe\u7a0b\u5b66\u4e60\u3001\u591a\u667a\u80fd\u4f53\u5408\u4f5c\u3001\u57fa\u4e8e\u53d8\u538b\u5668\u7684\u6a21\u578b\u4ee5\u53ca\u5185\u5728\u52a8\u673a\u673a\u5236\u7b49\u3002"}}
{"id": "2505.24181", "pdf": "https://arxiv.org/pdf/2505.24181", "abs": "https://arxiv.org/abs/2505.24181", "authors": ["Guanghao Li", "Wenhao Jiang", "Mingfeng Chen", "Yan Li", "Hao Yu", "Shuting Dong", "Tao Ren", "Ming Tang", "Chun Yuan"], "title": "SCOUT: Teaching Pre-trained Language Models to Enhance Reasoning via Flow Chain-of-Thought", "categories": ["cs.AI"], "comment": null, "summary": "Chain of Thought (CoT) prompting improves the reasoning performance of large\nlanguage models (LLMs) by encouraging step by step thinking. However, CoT-based\nmethods depend on intermediate reasoning steps, which limits scalability and\ngeneralization. Recent work explores recursive reasoning, where LLMs reuse\ninternal layers across iterations to refine latent representations without\nexplicit CoT supervision. While promising, these approaches often require\ncostly pretraining and lack a principled framework for how reasoning should\nevolve across iterations. We address this gap by introducing Flow Chain of\nThought (Flow CoT), a reasoning paradigm that models recursive inference as a\nprogressive trajectory of latent cognitive states. Flow CoT frames each\niteration as a distinct cognitive stage deepening reasoning across iterations\nwithout relying on manual supervision. To realize this, we propose SCOUT\n(Stepwise Cognitive Optimization Using Teachers), a lightweight fine tuning\nframework that enables Flow CoT style reasoning without the need for\npretraining. SCOUT uses progressive distillation to align each iteration with a\nteacher of appropriate capacity, and a cross attention based retrospective\nmodule that integrates outputs from previous iterations while preserving the\nmodels original computation flow. Experiments across eight reasoning benchmarks\nshow that SCOUT consistently improves both accuracy and explanation quality,\nachieving up to 1.8% gains under fine tuning. Qualitative analyses further\nreveal that SCOUT enables progressively deeper reasoning across iterations\nrefining both belief formation and explanation granularity. These results not\nonly validate the effectiveness of SCOUT, but also demonstrate the practical\nviability of Flow CoT as a scalable framework for enhancing reasoning in LLMs.", "AI": {"tldr": "SCOUT is a framework that improves reasoning in large language models by modeling recursive inference as progressive cognitive stages without requiring pretraining, showing gains in accuracy and explanation quality.", "motivation": "Current Chain of Thought methods for improving reasoning in large language models are limited by their reliance on intermediate steps and lack a principled framework for evolving reasoning across iterations.", "method": "Introduced Flow Chain of Thought (Flow CoT) which models recursive inference as a trajectory of latent cognitive states. Proposed SCOUT, a fine-tuning framework that uses progressive distillation and a cross attention based retrospective module to enable Flow CoT style reasoning without pretraining.", "result": "Experiments on eight reasoning benchmarks showed consistent improvements in accuracy and explanation quality with up to 1.8% gains under fine tuning. Qualitative analyses revealed deeper reasoning across iterations.", "conclusion": "SCOUT effectively enhances reasoning in LLMs and demonstrates the practical viability of Flow CoT as a scalable framework."}}
{"id": "2505.23792", "pdf": "https://arxiv.org/pdf/2505.23792", "abs": "https://arxiv.org/abs/2505.23792", "authors": ["Kai Li", "Conggai Li", "Xin Yuan", "Shenghong Li", "Sai Zou", "Syed Sohail Ahmed", "Wei Ni", "Dusit Niyato", "Abbas Jamalipour", "Falko Dressler", "Ozgur B. Akan"], "title": "Zero-Trust Foundation Models: A New Paradigm for Secure and Collaborative Artificial Intelligence for Internet of Things", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper focuses on Zero-Trust Foundation Models (ZTFMs), a novel paradigm\nthat embeds zero-trust security principles into the lifecycle of foundation\nmodels (FMs) for Internet of Things (IoT) systems. By integrating core tenets,\nsuch as continuous verification, least privilege access (LPA), data\nconfidentiality, and behavioral analytics into the design, training, and\ndeployment of FMs, ZTFMs can enable secure, privacy-preserving AI across\ndistributed, heterogeneous, and potentially adversarial IoT environments. We\npresent the first structured synthesis of ZTFMs, identifying their potential to\ntransform conventional trust-based IoT architectures into resilient,\nself-defending ecosystems. Moreover, we propose a comprehensive technical\nframework, incorporating federated learning (FL), blockchain-based identity\nmanagement, micro-segmentation, and trusted execution environments (TEEs) to\nsupport decentralized, verifiable intelligence at the network edge. In\naddition, we investigate emerging security threats unique to ZTFM-enabled\nsystems and evaluate countermeasures, such as anomaly detection, adversarial\ntraining, and secure aggregation. Through this analysis, we highlight key open\nresearch challenges in terms of scalability, secure orchestration,\ninterpretable threat attribution, and dynamic trust calibration. This survey\nlays a foundational roadmap for secure, intelligent, and trustworthy IoT\ninfrastructures powered by FMs.", "AI": {"tldr": "This paper introduces Zero-Trust Foundation Models (ZTFMs) for IoT systems, integrating zero-trust security principles into foundation models through a technical framework including federated learning and blockchain-based identity management. It addresses emerging security threats and outlines research challenges.", "motivation": "To enhance security and privacy in AI-driven IoT systems by embedding zero-trust security principles into the lifecycle of foundation models.", "method": "Integrating continuous verification, least privilege access, data confidentiality, and behavioral analytics into the design, training, and deployment of foundation models using a framework that includes federated learning, blockchain-based identity management, micro-segmentation, and trusted execution environments.", "result": "Identifies ZTFMs' potential to transform conventional IoT architectures into resilient ecosystems, evaluates countermeasures for security threats, and highlights open research challenges.", "conclusion": "The paper provides a roadmap for secure, intelligent, and trustworthy IoT infrastructures powered by foundation models."}}
{"id": "2505.23866", "pdf": "https://arxiv.org/pdf/2505.23866", "abs": "https://arxiv.org/abs/2505.23866", "authors": ["Chengli Tan", "Yubo Zhou", "Haishan Ye", "Guang Dai", "Junmin Liu", "Zengjie Song", "Jiangshe Zhang", "Zixiang Zhao", "Yunda Hao", "Yong Xu"], "title": "Towards Understanding The Calibration Benefits of Sharpness-Aware Minimization", "categories": ["cs.LG", "cs.AI"], "comment": "16 pages", "summary": "Deep neural networks have been increasingly used in safety-critical\napplications such as medical diagnosis and autonomous driving. However, many\nstudies suggest that they are prone to being poorly calibrated and have a\npropensity for overconfidence, which may have disastrous consequences. In this\npaper, unlike standard training such as stochastic gradient descent, we show\nthat the recently proposed sharpness-aware minimization (SAM) counteracts this\ntendency towards overconfidence. The theoretical analysis suggests that SAM\nallows us to learn models that are already well-calibrated by implicitly\nmaximizing the entropy of the predictive distribution. Inspired by this\nfinding, we further propose a variant of SAM, coined as CSAM, to ameliorate\nmodel calibration. Extensive experiments on various datasets, including\nImageNet-1K, demonstrate the benefits of SAM in reducing calibration error.\nMeanwhile, CSAM performs even better than SAM and consistently achieves lower\ncalibration error than other approaches", "AI": {"tldr": "Deep neural networks are often overconfident in safety-critical applications. This paper shows that sharpness-aware minimization (SAM) reduces this overconfidence and improves model calibration. A variant, CSAM, further enhances calibration.", "motivation": "Deep neural networks used in critical areas like medical diagnosis and autonomous driving tend to be poorly calibrated and overly confident, which can lead to serious issues.", "method": "The authors use sharpness-aware minimization (SAM) instead of standard training methods. They find SAM counteracts overconfidence by implicitly maximizing the entropy of the predictive distribution. They also propose a variant called CSAM for better calibration.", "result": "Experiments on datasets including ImageNet-1K show SAM reduces calibration error. CSAM performs even better than SAM and achieves lower calibration error consistently compared to other methods.", "conclusion": "SAM and its variant CSAM effectively improve the calibration of deep neural networks, reducing their overconfidence in safety-critical applications."}}
{"id": "2505.24197", "pdf": "https://arxiv.org/pdf/2505.24197", "abs": "https://arxiv.org/abs/2505.24197", "authors": ["Bhrij Patel", "Ashish Jagmohan", "Aditya Vempaty"], "title": "Learning API Functionality from Demonstrations for Tool-based Agents", "categories": ["cs.AI"], "comment": "18 Pages, 13 Figures, 5 Tables", "summary": "Digital tool-based agents that invoke external Application Programming\nInterfaces (APIs) often rely on documentation to understand API functionality.\nHowever, such documentation is frequently missing, outdated, privatized, or\ninconsistent-hindering the development of reliable, general-purpose agents. In\nthis work, we propose learning API functionality directly from demonstrations\nas a new paradigm applicable in scenarios without documentation. Using existing\nAPI benchmarks, we collect demonstrations from both expert API-based agents and\nfrom self-exploration. To understand what information demonstrations must\nconvey for successful task completion, we extensively study how the number of\ndemonstrations and the use of LLM-generated summaries and evaluations affect\nthe task success rate of the API-based agent. Our experiments across 3 datasets\nand 5 models show that learning functionality from demonstrations remains a\nnon-trivial challenge, even for state-of-the-art LLMs. We find that providing\nexplicit function calls and natural language critiques significantly improves\nthe agent's task success rate due to more accurate parameter filling. We\nanalyze failure modes, identify sources of error, and highlight key open\nchallenges for future work in documentation-free, self-improving, API-based\nagents.", "AI": {"tldr": "The paper proposes learning API functionality directly from demonstrations as a new paradigm, studies factors affecting task success rate, and analyzes failure modes.", "motivation": "Digital tool-based agents often rely on documentation to understand API functionality, but such documentation is frequently missing, outdated, privatized, or inconsistent.", "method": "Propose learning API functionality directly from demonstrations; collect demonstrations from expert API-based agents and self-exploration; study how number of demonstrations, LLM-generated summaries, and evaluations affect task success rate.", "result": "Experiments across 3 datasets and 5 models show that learning functionality from demonstrations remains challenging even for state-of-the-art LLMs. Providing explicit function calls and natural language critiques significantly improves task success rate.", "conclusion": "Learning API functionality from demonstrations is a non-trivial challenge. The paper analyzes failure modes, identifies sources of error, and highlights key open challenges for future work in documentation-free, self-improving, API-based agents."}}
{"id": "2505.23793", "pdf": "https://arxiv.org/pdf/2505.23793", "abs": "https://arxiv.org/abs/2505.23793", "authors": ["Baolin Zheng", "Guanlin Chen", "Hongqiong Zhong", "Qingyang Teng", "Yingshui Tan", "Zhendong Liu", "Weixun Wang", "Jiaheng Liu", "Jian Yang", "Huiyun Jing", "Jincheng Wei", "Wenbo Su", "Xiaoyong Zhu", "Bo Zheng", "Kaifu Zhang"], "title": "USB: A Comprehensive and Unified Safety Evaluation Benchmark for Multimodal Large Language Models", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Despite their remarkable achievements and widespread adoption, Multimodal\nLarge Language Models (MLLMs) have revealed significant security\nvulnerabilities, highlighting the urgent need for robust safety evaluation\nbenchmarks. Existing MLLM safety benchmarks, however, fall short in terms of\ndata quality and coverge, and modal risk combinations, resulting in inflated\nand contradictory evaluation results, which hinders the discovery and\ngovernance of security concerns. Besides, we argue that vulnerabilities to\nharmful queries and oversensitivity to harmless ones should be considered\nsimultaneously in MLLMs safety evaluation, whereas these were previously\nconsidered separately. In this paper, to address these shortcomings, we\nintroduce Unified Safety Benchmarks (USB), which is one of the most\ncomprehensive evaluation benchmarks in MLLM safety. Our benchmark features\nhigh-quality queries, extensive risk categories, comprehensive modal\ncombinations, and encompasses both vulnerability and oversensitivity\nevaluations. From the perspective of two key dimensions: risk categories and\nmodality combinations, we demonstrate that the available benchmarks -- even the\nunion of the vast majority of them -- are far from being truly comprehensive.\nTo bridge this gap, we design a sophisticated data synthesis pipeline that\ngenerates extensive, high-quality complementary data addressing previously\nunexplored aspects. By combining open-source datasets with our synthetic data,\nour benchmark provides 4 distinct modality combinations for each of the 61 risk\nsub-categories, covering both English and Chinese across both vulnerability and\noversensitivity dimensions.", "AI": {"tldr": "\u5c3d\u7ba1\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLMs\uff09\u53d6\u5f97\u4e86\u663e\u8457\u6210\u5c31\u5e76\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5176\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u65e5\u76ca\u51f8\u663e\uff0c\u4e9f\u9700\u53ef\u9760\u7684\u8bc4\u4f30\u57fa\u51c6\u3002\u73b0\u6709\u7684MLLM\u5b89\u5168\u57fa\u51c6\u5728\u6570\u636e\u8d28\u91cf\u548c\u8986\u76d6\u8303\u56f4\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5e76\u4e14\u901a\u5e38\u5355\u72ec\u8003\u8651\u5bf9\u6709\u5bb3\u67e5\u8be2\u7684\u8106\u5f31\u6027\u548c\u5bf9\u65e0\u5bb3\u67e5\u8be2\u7684\u8fc7\u5ea6\u654f\u611f\u6027\u3002\u672c\u6587\u63d0\u51fa\u4e86\u7edf\u4e00\u5b89\u5168\u57fa\u51c6\uff08USB\uff09\uff0c\u4f5c\u4e3a\u6700\u5168\u9762\u7684MLLM\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u4e4b\u4e00\uff0c\u6db5\u76d6\u4e86\u9ad8\u8d28\u91cf\u67e5\u8be2\u3001\u5e7f\u6cdb\u7684\u98ce\u9669\u7c7b\u522b\u3001\u7efc\u5408\u7684\u6a21\u6001\u7ec4\u5408\u4ee5\u53ca\u8106\u5f31\u6027\u548c\u8fc7\u5ea6\u654f\u611f\u6027\u7684\u8bc4\u4f30\u3002\u901a\u8fc7\u7ed3\u5408\u5f00\u6e90\u6570\u636e\u96c6\u4e0e\u5408\u6210\u6570\u636e\uff0cUSB\u4e3a61\u4e2a\u98ce\u9669\u5b50\u7c7b\u522b\u63d0\u4f9b\u4e864\u79cd\u4e0d\u540c\u7684\u6a21\u6001\u7ec4\u5408\uff0c\u6db5\u76d6\u82f1\u6c49\u53cc\u8bed\u53ca\u8106\u5f31\u6027\u548c\u8fc7\u5ea6\u654f\u611f\u6027\u4e24\u4e2a\u7ef4\u5ea6\u3002", "motivation": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u6f0f\u6d1e\u95ee\u9898\u65e5\u76ca\u4e25\u91cd\uff0c\u800c\u73b0\u6709\u5b89\u5168\u57fa\u51c6\u5b58\u5728\u6570\u636e\u8d28\u91cf\u5dee\u3001\u8986\u76d6\u8303\u56f4\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u4e14\u672a\u80fd\u540c\u65f6\u8003\u8651\u5bf9\u6709\u5bb3\u67e5\u8be2\u7684\u8106\u5f31\u6027\u548c\u5bf9\u65e0\u5bb3\u67e5\u8be2\u7684\u8fc7\u5ea6\u654f\u611f\u6027\u3002\u8fd9\u963b\u788d\u4e86\u5bf9\u5b89\u5168\u95ee\u9898\u7684\u53d1\u73b0\u548c\u6cbb\u7406\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u9ad8\u8d28\u91cf\u7684\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u7edf\u4e00\u5b89\u5168\u57fa\u51c6\uff08USB\uff09\u7684\u8bc4\u4f30\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5177\u6709\u9ad8\u8d28\u91cf\u67e5\u8be2\u3001\u5e7f\u6cdb\u7684\u98ce\u9669\u7c7b\u522b\u3001\u7efc\u5408\u7684\u6a21\u6001\u7ec4\u5408\uff0c\u5e76\u540c\u65f6\u8bc4\u4f30\u8106\u5f31\u6027\u548c\u8fc7\u5ea6\u654f\u611f\u6027\u3002\u901a\u8fc7\u8bbe\u8ba1\u590d\u6742\u7684\u6570\u636e\u5408\u6210\u7ba1\u9053\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u8865\u5145\u6570\u636e\uff0c\u586b\u8865\u4e86\u5148\u524d\u672a\u63a2\u7d22\u7684\u9886\u57df\u3002USB\u7ed3\u5408\u4e86\u5f00\u6e90\u6570\u636e\u96c6\u548c\u5408\u6210\u6570\u636e\uff0c\u4e3a\u6bcf\u4e2a\u98ce\u9669\u5b50\u7c7b\u522b\u63d0\u4f9b4\u79cd\u4e0d\u540c\u7684\u6a21\u6001\u7ec4\u5408\uff0c\u6db5\u76d6\u82f1\u8bed\u548c\u4e2d\u6587\u4e24\u79cd\u8bed\u8a00\u3002", "result": "USB\u6210\u4e3a\u76ee\u524d\u6700\u5168\u9762\u7684MLLM\u5b89\u5168\u8bc4\u4f30\u57fa\u51c6\u4e4b\u4e00\uff0c\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u6a21\u578b\u5728\u4e0d\u540c\u98ce\u9669\u7c7b\u522b\u548c\u6a21\u6001\u7ec4\u5408\u4e0b\u7684\u8868\u73b0\uff0c\u540c\u65f6\u8003\u8651\u4e86\u8106\u5f31\u6027\u548c\u8fc7\u5ea6\u654f\u611f\u6027\u3002\u901a\u8fc7\u5bf9\u6bd4\u73b0\u6709\u57fa\u51c6\uff0c\u8bc1\u660e\u4e86USB\u5728\u8986\u76d6\u8303\u56f4\u548c\u6570\u636e\u8d28\u91cf\u4e0a\u7684\u4f18\u8d8a\u6027\u3002", "conclusion": "\u7edf\u4e00\u5b89\u5168\u57fa\u51c6\uff08USB\uff09\u4e3a\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u5b89\u5168\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u5168\u9762\u3001\u66f4\u9ad8\u8d28\u91cf\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u53d1\u73b0\u548c\u6cbb\u7406\u5b89\u5168\u95ee\u9898\u3002"}}
{"id": "2505.23868", "pdf": "https://arxiv.org/pdf/2505.23868", "abs": "https://arxiv.org/abs/2505.23868", "authors": ["Zhaokun Wang", "Jinyu Guo", "Jingwen Pu", "Lingfeng Chen", "Hongli Pu", "Jie Ou. Libo Qin", "Wenhong Tian"], "title": "Noise-Robustness Through Noise: Asymmetric LoRA Adaption with Poisoning Expert", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Current parameter-efficient fine-tuning methods for adapting pre-trained\nlanguage models to downstream tasks are susceptible to interference from noisy\ndata. Conventional noise-handling approaches either rely on laborious data\npre-processing or employ model architecture modifications prone to error\naccumulation. In contrast to existing noise-process paradigms, we propose a\nnoise-robust adaptation method via asymmetric LoRA poisoning experts (LoPE), a\nnovel framework that enhances model robustness to noise only with generated\nnoisy data. Drawing inspiration from the mixture-of-experts architecture, LoPE\nstrategically integrates a dedicated poisoning expert in an asymmetric LoRA\nconfiguration. Through a two-stage paradigm, LoPE performs noise injection on\nthe poisoning expert during fine-tuning to enhance its noise discrimination and\nprocessing ability. During inference, we selectively mask the dedicated\npoisoning expert to leverage purified knowledge acquired by normal experts for\nnoise-robust output. Extensive experiments demonstrate that LoPE achieves\nstrong performance and robustness purely through the low-cost noise injection,\nwhich completely eliminates the requirement of data cleaning.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6LoPE\uff0c\u901a\u8fc7\u4e0d\u5bf9\u79f0LoRA\u914d\u7f6e\u548c\u751f\u6210\u7684\u566a\u58f0\u6570\u636e\u63d0\u9ad8\u6a21\u578b\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u6570\u636e\u6e05\u7406\u3002", "motivation": "\u5f53\u524d\u53c2\u6570\u9ad8\u6548\u7684\u5fae\u8c03\u65b9\u6cd5\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u6570\u636e\u7684\u5e72\u6270\uff0c\u800c\u4f20\u7edf\u7684\u566a\u58f0\u5904\u7406\u65b9\u6cd5\u8981\u4e48\u4f9d\u8d56\u7e41\u7410\u7684\u6570\u636e\u9884\u5904\u7406\uff0c\u8981\u4e48\u5bb9\u6613\u79ef\u7d2f\u9519\u8bef\u3002", "method": "LoPE\u4ece\u4e13\u5bb6\u6df7\u5408\u67b6\u6784\u4e2d\u6c72\u53d6\u7075\u611f\uff0c\u5728\u4e0d\u5bf9\u79f0LoRA\u914d\u7f6e\u4e2d\u6218\u7565\u6027\u5730\u6574\u5408\u4e86\u4e00\u4e2a\u4e13\u95e8\u7684\u4e2d\u6bd2\u4e13\u5bb6\u3002\u901a\u8fc7\u4e24\u9636\u6bb5\u8303\u5f0f\uff0cLoPE\u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\u5bf9\u4e2d\u6bd2\u4e13\u5bb6\u8fdb\u884c\u566a\u58f0\u6ce8\u5165\u4ee5\u589e\u5f3a\u5176\u566a\u58f0\u8fa8\u522b\u548c\u5904\u7406\u80fd\u529b\uff1b\u5728\u63a8\u7406\u65f6\uff0c\u9009\u62e9\u6027\u5730\u5c4f\u853d\u4e13\u95e8\u7684\u4e2d\u6bd2\u4e13\u5bb6\uff0c\u5229\u7528\u6b63\u5e38\u4e13\u5bb6\u83b7\u5f97\u7684\u51c0\u5316\u77e5\u8bc6\u5b9e\u73b0\u5bf9\u566a\u58f0\u9c81\u68d2\u7684\u8f93\u51fa\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8bc1\u660e\uff0cLoPE\u4ec5\u901a\u8fc7\u4f4e\u6210\u672c\u7684\u566a\u58f0\u6ce8\u5165\u5c31\u80fd\u8fbe\u5230\u5f3a\u5927\u7684\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u5b8c\u5168\u6d88\u9664\u4e86\u6570\u636e\u6e05\u7406\u7684\u9700\u6c42\u3002", "conclusion": "LoPE\u662f\u4e00\u79cd\u65b0\u9896\u4e14\u6709\u6548\u7684\u6846\u67b6\uff0c\u80fd\u591f\u901a\u8fc7\u751f\u6210\u7684\u566a\u58f0\u6570\u636e\u589e\u5f3a\u6a21\u578b\u5bf9\u566a\u58f0\u7684\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u6570\u636e\u6e05\u7406\u6b65\u9aa4\u3002"}}
{"id": "2505.24201", "pdf": "https://arxiv.org/pdf/2505.24201", "abs": "https://arxiv.org/abs/2505.24201", "authors": ["Xu He", "Di Wu", "Yan Zhai", "Kun Sun"], "title": "SentinelAgent: Graph-based Anomaly Detection in Multi-Agent Systems", "categories": ["cs.AI"], "comment": null, "summary": "The rise of large language model (LLM)-based multi-agent systems (MAS)\nintroduces new security and reliability challenges. While these systems show\ngreat promise in decomposing and coordinating complex tasks, they also face\nmulti-faceted risks across prompt manipulation, unsafe tool usage, and emergent\nagent miscoordination. Existing guardrail mechanisms offer only partial\nprotection, primarily at the input-output level, and fall short in addressing\nsystemic or multi-point failures in MAS. In this work, we present a\nsystem-level anomaly detection framework tailored for MAS, integrating\nstructural modeling with runtime behavioral oversight. Our approach consists of\ntwo components. First, we propose a graph-based framework that models agent\ninteractions as dynamic execution graphs, enabling semantic anomaly detection\nat node, edge, and path levels. Second, we introduce a pluggable SentinelAgent,\nan LLM-powered oversight agent that observes, analyzes, and intervenes in MAS\nexecution based on security policies and contextual reasoning. By bridging\nabstract detection logic with actionable enforcement, our method detects not\nonly single-point faults and prompt injections but also multi-agent collusion\nand latent exploit paths. We validate our framework through two case studies,\nincluding an email assistant and Microsoft's Magentic-One system, demonstrating\nits ability to detect covert risks and provide explainable root-cause\nattribution. Our work lays the foundation for more trustworthy, monitorable,\nand secure agent-based AI ecosystems.", "AI": {"tldr": "This paper addresses the security and reliability challenges in LLM-based multi-agent systems (MAS) by presenting a system-level anomaly detection framework. The framework integrates structural modeling with runtime behavioral oversight through two components: a graph-based framework for semantic anomaly detection and a SentinelAgent for observing, analyzing, and intervening based on security policies.", "motivation": "The motivation of this paper is to address the security and reliability challenges in LLM-based multi-agent systems, which face risks such as prompt manipulation, unsafe tool usage, and emergent agent miscoordination. Existing guardrail mechanisms offer only partial protection and do not fully address systemic or multi-point failures in MAS.", "method": "The method consists of two components: 1) A graph-based framework that models agent interactions as dynamic execution graphs, enabling semantic anomaly detection at node, edge, and path levels; 2) A pluggable SentinelAgent, an LLM-powered oversight agent that observes, analyzes, and intervenes in MAS execution based on security policies and contextual reasoning.", "result": "The framework was validated through two case studies, including an email assistant and Microsoft's Magentic-One system. It demonstrated the ability to detect covert risks and provide explainable root-cause attribution.", "conclusion": "This work lays the foundation for more trustworthy, monitorable, and secure agent-based AI ecosystems by providing a system-level anomaly detection framework tailored for multi-agent systems."}}
{"id": "2505.23800", "pdf": "https://arxiv.org/pdf/2505.23800", "abs": "https://arxiv.org/abs/2505.23800", "authors": ["George Grispos", "Logan Mears", "Larry Loucks"], "title": "Strengthening Cybersecurity Resilience in Agriculture Through Educational Interventions: A Case Study of the Ponca Tribe of Nebraska", "categories": ["cs.CR", "cs.CY"], "comment": "Preprint of paper presented at 24th European Conference on Cyber\n  Warfare and Security (ECCWS 2025)", "summary": "The increasing digitization of agricultural operations has introduced new\ncybersecurity challenges for the farming community. This paper introduces an\neducational intervention called Cybersecurity Improvement Initiative for\nAgriculture (CIIA), which aims to strengthen cybersecurity awareness and\nresilience among farmers and food producers. Using a case study that focuses on\nfarmers from the Ponca Tribe of Nebraska, the research evaluates pre- and post-\nintervention survey data to assess participants' cybersecurity knowledge and\nawareness before and after exposure to the CIIA. The findings reveal a\nsubstantial baseline deficiency in cybersecurity education among participants,\nhowever, post-intervention assessments demonstrate improvements in the\ncomprehension of cybersecurity concepts, such as password hygiene, multi-factor\nauthentication, and the necessity of routine data backups. These initial\nfindings highlight the need for a continued and sustained, community-specific\ncybersecurity education effort to help mitigate emerging cyber threats in the\nagricultural sector.", "AI": {"tldr": "The paper discusses the Cybersecurity Improvement Initiative for Agriculture (CIIA), an educational intervention aimed at enhancing cybersecurity awareness among farmers, particularly those from the Ponca Tribe of Nebraska. Through pre- and post-intervention surveys, it was found that while there was a significant lack of cybersecurity knowledge initially, the intervention led to improvements in understanding key concepts such as password hygiene, multi-factor authentication, and data backups.", "motivation": "To address the growing cybersecurity challenges faced by the agricultural community due to increasing digitization, and to strengthen cybersecurity awareness and resilience among farmers and food producers.", "method": "The research employed a case study approach focusing on farmers from the Ponca Tribe of Nebraska. Pre- and post-intervention surveys were used to evaluate participants' cybersecurity knowledge and awareness before and after exposure to the CIIA.", "result": "Findings revealed a substantial baseline deficiency in cybersecurity education among participants, but post-intervention assessments showed improvements in the understanding of cybersecurity concepts like password hygiene, multi-factor authentication, and routine data backups.", "conclusion": "There is a need for continued and sustained, community-specific cybersecurity education efforts to mitigate emerging cyber threats in the agricultural sector."}}
{"id": "2505.23870", "pdf": "https://arxiv.org/pdf/2505.23870", "abs": "https://arxiv.org/abs/2505.23870", "authors": ["Yixian Shen", "Qi Bi", "Jia-Hong Huang", "Hongyi Zhu", "Andy D. Pimentel", "Anuj Pathania"], "title": "MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection", "categories": ["cs.LG", "cs.AI"], "comment": "arXiv admin note: substantial text overlap with arXiv:2410.09103", "summary": "We present a new adaptation method MaCP, Minimal yet Mighty adaptive Cosine\nProjection, that achieves exceptional performance while requiring minimal\nparameters and memory for fine-tuning large foundation models. Its general idea\nis to exploit the superior energy compaction and decorrelation properties of\ncosine projection to improve both model efficiency and accuracy. Specifically,\nit projects the weight change from the low-rank adaptation into the discrete\ncosine space. Then, the weight change is partitioned over different levels of\nthe discrete cosine spectrum, and each partition's most critical frequency\ncomponents are selected. Extensive experiments demonstrate the effectiveness of\nMaCP across a wide range of single-modality tasks, including natural language\nunderstanding, natural language generation, text summarization, as well as\nmulti-modality tasks such as image classification and video understanding. MaCP\nconsistently delivers superior accuracy, significantly reduced computational\ncomplexity, and lower memory requirements compared to existing alternatives.", "AI": {"tldr": "A new adaptation method MaCP is presented, which achieves exceptional performance with minimal parameters and memory for fine-tuning large models. It exploits cosine projection to improve model efficiency and accuracy. Extensive experiments demonstrate its effectiveness across a wide range of tasks.", "motivation": "To develop an adaptation method that achieves high performance while requiring minimal parameters and memory for fine-tuning large foundation models.", "method": "The method projects the weight change from the low-rank adaptation into the discrete cosine space, partitions the weight change over different levels of the discrete cosine spectrum, and selects each partition's most critical frequency components.", "result": "MaCP delivers superior accuracy, significantly reduced computational complexity, and lower memory requirements compared to existing alternatives in single-modality and multi-modality tasks.", "conclusion": "MaCP is an effective adaptation method for improving both model efficiency and accuracy with minimal resource consumption."}}
{"id": "2505.24208", "pdf": "https://arxiv.org/pdf/2505.24208", "abs": "https://arxiv.org/abs/2505.24208", "authors": ["Wenhan Yang", "Spencer Stice", "Ali Payani", "Baharan Mirzasoleiman"], "title": "Bootstrapping LLM Robustness for VLM Safety via Reducing the Pretraining Modality Gap", "categories": ["cs.AI"], "comment": null, "summary": "Ensuring Vision-Language Models (VLMs) generate safe outputs is crucial for\ntheir reliable deployment. However, LVLMs suffer from drastic safety\ndegradation compared to their LLM backbone. Even blank or irrelevant images can\ntrigger LVLMs to generate harmful responses to prompts that would otherwise be\nrefused in text-only contexts. The modality gap between image and text\nrepresentations has been recently hypothesized to contribute to safety\ndegradation of LVLMs. However, if and how the amount of modality gap affects\nLVLMs' safety is not studied. In this work, we show that the amount of modality\ngap is highly inversely correlated with VLMs' safety. Then, we show that this\nmodality gap is introduced during pretraining LVLMs and persists through\nfine-tuning. Inspired by this observation, we propose a regularization to\nreduce the modality gap during pretraining. Our extensive experiments on LLaVA\nv1.5, ShareGPT4V, and MiniGPT-4 show that our method substantially improves\nsafety alignment of LVLMs, reducing unsafe rate by up to 16.3% without\ncompromising performance, and can further boost existing defenses by up to\n18.2%.", "AI": {"tldr": "To ensure the safe deployment of Vision-Language Models (VLMs), this paper addresses the issue of safety degradation in LVLMs compared to their LLM backbone. The authors find that the modality gap between image and text representations is highly inversely correlated with VLMs' safety. They propose a regularization method during pretraining to reduce this gap, which significantly improves safety alignment without sacrificing performance.", "motivation": "The motivation of this work is to address the safety degradation problem in LVLMs compared to their LLM backbone, particularly focusing on how the modality gap between image and text representations affects the safety of LVLMs.", "method": "The authors first demonstrate the inverse correlation between the modality gap and VLMs' safety. Then, they identify that the modality gap is introduced during the pretraining phase and persists through fine-tuning. Based on these findings, they propose a regularization technique applied during pretraining to reduce the modality gap.", "result": "Extensive experiments conducted on LLaVA v1.5, ShareGPT4V, and MiniGPT-4 show that the proposed method reduces the unsafe rate by up to 16.3% without affecting performance, and can enhance existing defense mechanisms by up to 18.2%.", "conclusion": "This study concludes that reducing the modality gap during pretraining significantly improves the safety alignment of LVLMs, offering a promising direction for enhancing the reliability of these models."}}
{"id": "2505.23803", "pdf": "https://arxiv.org/pdf/2505.23803", "abs": "https://arxiv.org/abs/2505.23803", "authors": ["Yinuo Xue", "Eric Spero", "Yun Sing Koh", "Giovanni Russello"], "title": "MultiPhishGuard: An LLM-based Multi-Agent System for Phishing Email Detection", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Phishing email detection faces critical challenges from evolving adversarial\ntactics and heterogeneous attack patterns. Traditional detection methods, such\nas rule-based filters and denylists, often struggle to keep pace with these\nevolving tactics, leading to false negatives and compromised security. While\nmachine learning approaches have improved detection accuracy, they still face\nchallenges adapting to novel phishing strategies. We present MultiPhishGuard, a\ndynamic LLM-based multi-agent detection system that synergizes specialized\nexpertise with adversarial-aware reinforcement learning. Our framework employs\nfive cooperative agents (text, URL, metadata, explanation simplifier, and\nadversarial agents) with automatically adjusted decision weights powered by a\nProximal Policy Optimization reinforcement learning algorithm. To address\nemerging threats, we introduce an adversarial training loop featuring an\nadversarial agent that generates subtle context-aware email variants, creating\na self-improving defense ecosystem and enhancing system robustness.\nExperimental evaluations on public datasets demonstrate that MultiPhishGuard\nsignificantly outperforms Chain-of-Thoughts, single-agent baselines and\nstate-of-the-art detectors, as validated by ablation studies and comparative\nanalyses. Experiments demonstrate that MultiPhishGuard achieves high accuracy\n(97.89\\%) with low false positive (2.73\\%) and false negative rates (0.20\\%).\nAdditionally, we incorporate an explanation simplifier agent, which provides\nusers with clear and easily understandable explanations for why an email is\nclassified as phishing or legitimate. This work advances phishing defense\nthrough dynamic multi-agent collaboration and generative adversarial\nresilience.", "AI": {"tldr": "MultiPhishGuard is a dynamic LLM-based multi-agent detection system that significantly outperforms existing phishing detectors with high accuracy and low false positive/negative rates.", "motivation": "Phishing email detection faces challenges from evolving adversarial tactics and heterogeneous attack patterns. Traditional methods struggle to keep pace, while machine learning approaches face challenges adapting to novel phishing strategies.", "method": "A framework with five cooperative agents (text, URL, metadata, explanation simplifier, and adversarial agents) is employed, with automatically adjusted decision weights powered by a Proximal Policy Optimization reinforcement learning algorithm. An adversarial training loop featuring an adversarial agent that generates subtle context-aware email variants is introduced.", "result": "Experimental evaluations on public datasets demonstrate that MultiPhishGuard significantly outperforms Chain-of-Thoughts, single-agent baselines and state-of-the-art detectors, achieving high accuracy (97.89%) with low false positive (2.73%) and false negative rates (0.20%).", "conclusion": "This work advances phishing defense through dynamic multi-agent collaboration and generative adversarial resilience."}}
{"id": "2505.23871", "pdf": "https://arxiv.org/pdf/2505.23871", "abs": "https://arxiv.org/abs/2505.23871", "authors": ["Zeyuan Liu", "Zhihe Yang", "Jiawei Xu", "Rui Yang", "Jiafei Lyu", "Baoxiang Wang", "Yunjian Xu", "Xiu Li"], "title": "ADG: Ambient Diffusion-Guided Dataset Recovery for Corruption-Robust Offline Reinforcement Learning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Real-world datasets collected from sensors or human inputs are prone to noise\nand errors, posing significant challenges for applying offline reinforcement\nlearning (RL). While existing methods have made progress in addressing\ncorrupted actions and rewards, they remain insufficient for handling corruption\nin high-dimensional state spaces and for cases where multiple elements in the\ndataset are corrupted simultaneously. Diffusion models, known for their strong\ndenoising capabilities, offer a promising direction for this problem-but their\ntendency to overfit noisy samples limits their direct applicability. To\novercome this, we propose Ambient Diffusion-Guided Dataset Recovery (ADG), a\nnovel approach that pioneers the use of diffusion models to tackle data\ncorruption in offline RL. First, we introduce Ambient Denoising Diffusion\nProbabilistic Models (DDPM) from approximated distributions, which enable\nlearning on partially corrupted datasets with theoretical guarantees. Second,\nwe use the noise-prediction property of Ambient DDPM to distinguish between\nclean and corrupted data, and then use the clean subset to train a standard\nDDPM. Third, we employ the trained standard DDPM to refine the previously\nidentified corrupted data, enhancing data quality for subsequent offline RL\ntraining. A notable strength of ADG is its versatility-it can be seamlessly\nintegrated with any offline RL algorithm. Experiments on a range of benchmarks,\nincluding MuJoCo, Kitchen, and Adroit, demonstrate that ADG effectively\nmitigates the impact of corrupted data and improves the robustness of offline\nRL under various noise settings, achieving state-of-the-art results.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5ADG\uff0c\u5229\u7528\u6269\u6563\u6a21\u578b\u89e3\u51b3\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u95ee\u9898\uff0c\u901a\u8fc7\u533a\u5206\u5e72\u51c0\u548c\u6c61\u67d3\u6570\u636e\u5e76\u8fdb\u884c\u4f18\u5316\uff0c\u63d0\u9ad8\u4e86\u5728\u591a\u79cd\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u8fbe\u5230\u4e1a\u5185\u9886\u5148\u6c34\u5e73\u3002", "motivation": "\u5b9e\u9645\u6536\u96c6\u7684\u6570\u636e\u96c6\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u548c\u9519\u8bef\u7684\u5f71\u54cd\uff0c\u800c\u73b0\u6709\u7684\u65b9\u6cd5\u5728\u5904\u7406\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\u4e2d\u7684\u6570\u636e\u6c61\u67d3\u4ee5\u53ca\u540c\u65f6\u591a\u4e2a\u5143\u7d20\u88ab\u6c61\u67d3\u7684\u60c5\u51b5\u65f6\u4ecd\u663e\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86Ambient Diffusion-Guided Dataset Recovery (ADG)\uff0c\u5305\u62ec\uff1a1) \u4f7f\u7528Ambient Denoising Diffusion Probabilistic Models (DDPM) \u4ece\u8fd1\u4f3c\u5206\u5e03\u4e2d\u5b66\u4e60\u90e8\u5206\u6c61\u67d3\u6570\u636e\u96c6\uff1b2) \u5229\u7528Ambient DDPM\u7684\u566a\u58f0\u9884\u6d4b\u5c5e\u6027\u533a\u5206\u5e72\u51c0\u548c\u6c61\u67d3\u6570\u636e\uff0c\u5e76\u7528\u5e72\u51c0\u5b50\u96c6\u8bad\u7ec3\u6807\u51c6DDPM\uff1b3) \u4f7f\u7528\u8bad\u7ec3\u597d\u7684\u6807\u51c6DDPM\u4f18\u5316\u4e4b\u524d\u8bc6\u522b\u51fa\u7684\u6c61\u67d3\u6570\u636e\u4ee5\u63d0\u9ad8\u6570\u636e\u8d28\u91cf\u3002", "result": "\u5b9e\u9a8c\u8868\u660eADG\u6709\u6548\u7f13\u89e3\u4e86\u6c61\u67d3\u6570\u636e\u7684\u5f71\u54cd\uff0c\u5728\u5404\u79cd\u566a\u58f0\u73af\u5883\u4e0b\u63d0\u9ad8\u4e86\u79bb\u7ebf\u5f3a\u5316\u5b66\u4e60\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u5728MuJoCo\u3001Kitchen\u548cAdroit\u7b49\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u4e86\u4e1a\u5185\u9886\u5148\u7684\u6027\u80fd\u3002", "conclusion": "ADG\u65b9\u6cd5\u5177\u6709\u9ad8\u5ea6\u7684\u901a\u7528\u6027\uff0c\u53ef\u4ee5\u4e0e\u4efb\u4f55\u79bb\u7ebfRL\u7b97\u6cd5\u65e0\u7f1d\u96c6\u6210\uff0c\u663e\u8457\u63d0\u5347\u4e86\u79bb\u7ebfRL\u5728\u4e0d\u540c\u566a\u58f0\u8bbe\u7f6e\u4e0b\u7684\u6027\u80fd\u3002"}}
{"id": "2505.24226", "pdf": "https://arxiv.org/pdf/2505.24226", "abs": "https://arxiv.org/abs/2505.24226", "authors": ["Yibo Zhao", "Jiapeng Zhu", "Ye Guo", "Kangkang He", "Xiang Li"], "title": "E^2GraphRAG: Streamlining Graph-based RAG for High Efficiency and Effectiveness", "categories": ["cs.AI"], "comment": "16 pages", "summary": "Graph-based RAG methods like GraphRAG have shown promising global\nunderstanding of the knowledge base by constructing hierarchical entity graphs.\nHowever, they often suffer from inefficiency and rely on manually pre-defined\nquery modes, limiting practical use. In this paper, we propose E^2GraphRAG, a\nstreamlined graph-based RAG framework that improves both Efficiency and\nEffectiveness. During the indexing stage, E^2GraphRAG constructs a summary tree\nwith large language models and an entity graph with SpaCy based on document\nchunks. We then construct bidirectional indexes between entities and chunks to\ncapture their many-to-many relationships, enabling fast lookup during both\nlocal and global retrieval. For the retrieval stage, we design an adaptive\nretrieval strategy that leverages the graph structure to retrieve and select\nbetween local and global modes. Experiments show that E^2GraphRAG achieves up\nto 10 times faster indexing than GraphRAG and 100 times speedup over LightRAG\nin retrieval while maintaining competitive QA performance.", "AI": {"tldr": "The paper introduces E^2GraphRAG, an improved graph-based RAG framework that enhances efficiency and effectiveness through a summary tree and entity graph with bidirectional indexes. It features adaptive retrieval and shows significant speed improvements over existing methods while maintaining QA performance.", "motivation": "Graph-based RAG methods provide global understanding of knowledge bases but are inefficient and rely on pre-defined query modes, restricting practical application.", "method": "E^2GraphRAG constructs a summary tree using large language models and an entity graph with SpaCy during indexing. Bidirectional indexes capture relationships between entities and chunks for fast lookup. An adaptive retrieval strategy is used to select between local and global retrieval modes.", "result": "E^2GraphRAG achieves up to 10 times faster indexing than GraphRAG and 100 times speedup in retrieval compared to LightRAG, while maintaining competitive QA performance.", "conclusion": "E^2GraphRAG offers a more efficient and effective streamlined graph-based RAG framework."}}
{"id": "2505.23805", "pdf": "https://arxiv.org/pdf/2505.23805", "abs": "https://arxiv.org/abs/2505.23805", "authors": ["Akram Sheriff", "Ken Huang", "Zsolt Nemeth", "Madjid Nakhjiri"], "title": "ADA: Automated Moving Target Defense for AI Workloads via Ephemeral Infrastructure-Native Rotation in Kubernetes", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "This paper introduces the Adaptive Defense Agent (ADA), an innovative\nAutomated Moving Target Defense (AMTD) system designed to fundamentally enhance\nthe security posture of AI workloads. ADA operates by continuously and\nautomatically rotating these workloads at the infrastructure level, leveraging\nthe inherent ephemerality of Kubernetes pods. This constant managed churn\nsystematically invalidates attacker assumptions and disrupts potential kill\nchains by regularly destroying and respawning AI service instances. This\nmethodology, applying principles of chaos engineering as a continuous,\nproactive defense, offers a paradigm shift from traditional static defenses\nthat rely on complex and expensive confidential or trusted computing solutions\nto secure the underlying compute platforms, while at the same time agnostically\nsupporting the latest advancements in agentic and nonagentic AI ecosystems and\nsolutions such as agent-to-agent (A2A) communication frameworks or model\ncontext protocols (MCP). This AI-native infrastructure design, relying on the\nwidely proliferated cloud-native Kubernetes technologies, facilitates easier\ndeployment, simplifies maintenance through an inherent zero trust posture\nachieved by rotation, and promotes faster adoption. We posit that ADA's novel\napproach to AMTD provides a more robust, agile, and operationally efficient\nzero-trust model for AI services, achieving security through proactive\nenvironmental manipulation rather than reactive patching.", "AI": {"tldr": "The paper introduces Adaptive Defense Agent (ADA), an Automated Moving Target Defense (AMTD) system enhancing AI workload security by continuously rotating workloads at the infrastructure level using Kubernetes pods ephemerality. This invalidates attacker assumptions and disrupts kill chains, applying chaos engineering principles as a proactive defense. ADA supports advancements in AI ecosystems, uses cloud-native Kubernetes technologies for easier deployment and maintenance, and promotes faster adoption with a robust zero-trust model.", "motivation": "To fundamentally enhance the security posture of AI workloads by introducing a new approach to Automated Moving Target Defense (AMTD). Traditional static defenses are complex and expensive, relying on confidential or trusted computing solutions, while ADA aims to provide a more robust, agile, and operationally efficient zero-trust model through proactive environmental manipulation.", "method": "ADA operates by continuously and automatically rotating AI workloads at the infrastructure level using the ephemerality of Kubernetes pods. It regularly destroys and respawns AI service instances, thus systematically invalidating attacker assumptions and disrupting potential kill chains. The methodology applies principles of chaos engineering as a continuous, proactive defense mechanism.", "result": "ADA's novel approach offers a paradigm shift from traditional static defenses. It supports the latest advancements in agentic and nonagentic AI ecosystems, facilitates easier deployment and maintenance, and achieves security through proactive environmental manipulation rather than reactive patching.", "conclusion": "ADA provides a more robust, agile, and operationally efficient zero-trust model for AI services. By leveraging widely proliferated cloud-native Kubernetes technologies and achieving an inherent zero trust posture through rotation, it enhances the security posture of AI workloads significantly."}}
{"id": "2505.23875", "pdf": "https://arxiv.org/pdf/2505.23875", "abs": "https://arxiv.org/abs/2505.23875", "authors": ["Peter Samoaa", "Marcus Vukojevic", "Morteza Haghir Chehreghani", "Antonio Longa"], "title": "A Benchmark Dataset for Graph Regression with Homogeneous and Multi-Relational Variants", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph-level regression underpins many real-world applications, yet public\nbenchmarks remain heavily skewed toward molecular graphs and citation networks.\nThis limited diversity hinders progress on models that must generalize across\nboth homogeneous and heterogeneous graph structures. We introduce RelSC, a new\ngraph-regression dataset built from program graphs that combine syntactic and\nsemantic information extracted from source code. Each graph is labelled with\nthe execution-time cost of the corresponding program, providing a continuous\ntarget variable that differs markedly from those found in existing benchmarks.\nRelSC is released in two complementary variants. RelSC-H supplies rich node\nfeatures under a single (homogeneous) edge type, while RelSC-M preserves the\noriginal multi-relational structure, connecting nodes through multiple edge\ntypes that encode distinct semantic relationships. Together, these variants let\nresearchers probe how representation choice influences model behaviour. We\nevaluate a diverse set of graph neural network architectures on both variants\nof RelSC. The results reveal consistent performance differences between the\nhomogeneous and multi-relational settings, emphasising the importance of\nstructural representation. These findings demonstrate RelSC's value as a\nchallenging and versatile benchmark for advancing graph regression methods.", "AI": {"tldr": "A new graph-regression dataset named RelSC is introduced, which is built from program graphs combining syntactic and semantic information. It provides a continuous target variable for execution-time cost and comes in two variants: homogeneous (RelSC-H) and multi-relational (RelSC-M). Evaluations on various GNN architectures reveal significant performance differences based on structural representation.", "motivation": "Public benchmarks for graph-level regression are heavily focused on molecular graphs and citation networks, limiting the diversity needed to develop models that generalize across different graph structures.", "method": "The authors created RelSC, a dataset derived from program graphs with labels indicating execution-time cost. This dataset exists in two forms: RelSC-H with rich node features under a single edge type, and RelSC-M preserving the original multi-relational structure. Both variants allow researchers to explore how different representations affect model behavior.", "result": "Evaluation of several graph neural network architectures on both RelSC-H and RelSC-M showed consistent performance differences between the homogeneous and multi-relational settings, highlighting the importance of structural representation in model performance.", "conclusion": "RelSC serves as a valuable and challenging benchmark for advancing graph regression methods by providing diverse graph structures not found in existing datasets."}}
{"id": "2505.24230", "pdf": "https://arxiv.org/pdf/2505.24230", "abs": "https://arxiv.org/abs/2505.24230", "authors": ["Murari Ambati"], "title": "ProofNet++: A Neuro-Symbolic System for Formal Proof Verification with Self-Correction", "categories": ["cs.AI"], "comment": "6 pages, 2 figures", "summary": "We propose ProofNet++, a neuro-symbolic framework that enhances automated\ntheorem proving by combining large language models (LLMs) with formal proof\nverification and self-correction mechanisms. Current LLM-based systems suffer\nfrom hallucinated logical steps and unverifiable reasoning. ProofNet++\nmitigates these limitations by integrating symbolic proof tree supervision, a\nreinforcement learning loop using verifiers as reward functions, and an\niterative self-correction module. Our experiments on miniF2F, Lean's mathlib,\nand HOL Light show that ProofNet++ significantly improves proof accuracy,\ncorrectness, and formal verifiability over prior models. We provide theoretical\nanalysis of the convergence and stability of the verifier-guided RL framework\nand release our datasets and codebase for future research.", "AI": {"tldr": "ProofNet++ is a neuro-symbolic framework that enhances automated theorem proving by combining LLMs with formal proof verification and self-correction mechanisms.", "motivation": "Current LLM-based systems suffer from hallucinated logical steps and unverifiable reasoning.", "method": "Integrating symbolic proof tree supervision, reinforcement learning loop using verifiers as reward functions, and iterative self-correction module.", "result": "Experiments on miniF2F, Lean's mathlib, and HOL Light show significant improvements in proof accuracy, correctness, and formal verifiability over prior models.", "conclusion": "Theoretical analysis of the convergence and stability of the verifier-guided RL framework was provided and datasets and codebase were released for future research."}}
{"id": "2505.23813", "pdf": "https://arxiv.org/pdf/2505.23813", "abs": "https://arxiv.org/abs/2505.23813", "authors": ["Abhijit Talluri"], "title": "DP-RTFL: Differentially Private Resilient Temporal Federated Learning for Trustworthy AI in Regulated Industries", "categories": ["cs.CR", "cs.AI", "Computing methodologies~Machine learning~Machine learning\n  paradigms~Federated learning", "I.2.6; K.6.5; C.4"], "comment": "6 pages (IEEE conference format), 10 figures. Source code available\n  at https://github.com/abhitall/federated-credit-risk-rtfl.git", "summary": "Federated Learning (FL) has emerged as a critical paradigm for enabling\nprivacy-preserving machine learning, particularly in regulated sectors such as\nfinance and healthcare. However, standard FL strategies often encounter\nsignificant operational challenges related to fault tolerance, system\nresilience against concurrent client and server failures, and the provision of\nrobust, verifiable privacy guarantees essential for handling sensitive data.\nThese deficiencies can lead to training disruptions, data loss, compromised\nmodel integrity, and non-compliance with data protection regulations (e.g.,\nGDPR, CCPA). This paper introduces Differentially Private Resilient Temporal\nFederated Learning (DP-RTFL), an advanced FL framework designed to ensure\ntraining continuity, precise state recovery, and strong data privacy. DP-RTFL\nintegrates local Differential Privacy (LDP) at the client level with resilient\ntemporal state management and integrity verification mechanisms, such as\nhash-based commitments (referred to as Zero-Knowledge Integrity Proofs or ZKIPs\nin this context). The framework is particularly suited for critical\napplications like credit risk assessment using sensitive financial data, aiming\nto be operationally robust, auditable, and scalable for enterprise AI\ndeployments. The implementation of the DP-RTFL framework is available as\nopen-source.", "AI": {"tldr": "The paper introduces DP-RTFL, an advanced FL framework integrating local Differential Privacy (LDP) with resilient temporal state management and integrity verification mechanisms for ensuring training continuity, precise state recovery, and strong data privacy.", "motivation": "Standard FL strategies encounter significant operational challenges related to fault tolerance, system resilience against concurrent client and server failures, and the provision of robust, verifiable privacy guarantees.", "method": "DP-RTFL integrates local Differential Privacy (LDP) at the client level with resilient temporal state management and integrity verification mechanisms, such as hash-based commitments (referred to as Zero-Knowledge Integrity Proofs or ZKIPs in this context).", "result": "This framework is particularly suited for critical applications like credit risk assessment using sensitive financial data, aiming to be operationally robust, auditable, and scalable for enterprise AI deployments.", "conclusion": "The implementation of the DP-RTFL framework is available as open-source."}}
{"id": "2505.23876", "pdf": "https://arxiv.org/pdf/2505.23876", "abs": "https://arxiv.org/abs/2505.23876", "authors": ["Polad Geidarov"], "title": "A comparative analysis of a neural network with calculated weights and a neural network with random generation of weights based on the training dataset size", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The paper discusses the capabilities of multilayer perceptron neural networks\nimplementing metric recognition methods, for which the values of the weights\nare calculated analytically by formulas. Comparative experiments in training a\nneural network with pre-calculated weights and with random initialization of\nweights on different sizes of the MNIST training dataset are carried out. The\nresults of the experiments show that a multilayer perceptron with\npre-calculated weights can be trained much faster and is much more robust to\nthe reduction of the training dataset.", "AI": {"tldr": "This paper explores the use of multilayer perceptron neural networks with analytically calculated weights for metric recognition, demonstrating faster training and greater robustness to dataset reduction compared to random weight initialization through experiments on the MNIST dataset.", "motivation": "To investigate the effectiveness and efficiency of using analytically pre-calculated weights in multilayer perceptron neural networks for metric recognition methods as opposed to traditional random weight initialization.", "method": "Conduct comparative experiments by training multilayer perceptron neural networks on the MNIST dataset using both pre-calculated weights (via formulas) and random weight initialization, across different sizes of the training dataset.", "result": "The experiments indicate that multilayer perceptrons with pre-calculated weights can be trained significantly faster and are more resilient when the size of the training dataset is reduced.", "conclusion": "Using analytically derived weights for initializing a multilayer perceptron leads to more efficient training processes and better performance stability, especially when dealing with smaller training datasets."}}
{"id": "2505.24258", "pdf": "https://arxiv.org/pdf/2505.24258", "abs": "https://arxiv.org/abs/2505.24258", "authors": ["Vishal Pallagani", "Nitin Gupta", "John Aydin", "Biplav Srivastava"], "title": "FABLE: A Novel Data-Flow Analysis Benchmark on Procedural Text for Large Language Model Evaluation", "categories": ["cs.AI"], "comment": null, "summary": "Understanding how data moves, transforms, and persists, known as data flow,\nis fundamental to reasoning in procedural tasks. Despite their fluency in\nnatural and programming languages, large language models (LLMs), although\nincreasingly being applied to decisions with procedural tasks, have not been\nsystematically evaluated for their ability to perform data-flow reasoning. We\nintroduce FABLE, an extensible benchmark designed to assess LLMs' understanding\nof data flow using structured, procedural text. FABLE adapts eight classical\ndata-flow analyses from software engineering: reaching definitions, very busy\nexpressions, available expressions, live variable analysis, interval analysis,\ntype-state analysis, taint analysis, and concurrency analysis. These analyses\nare instantiated across three real-world domains: cooking recipes, travel\nroutes, and automated plans. The benchmark includes 2,400 question-answer\npairs, with 100 examples for each domain-analysis combination. We evaluate\nthree types of LLMs: a reasoning-focused model (DeepSeek-R1 8B), a\ngeneral-purpose model (LLaMA 3.1 8B), and a code-specific model (Granite Code\n8B). Each model is tested using majority voting over five sampled completions\nper prompt. Results show that the reasoning model achieves higher accuracy, but\nat the cost of over 20 times slower inference compared to the other models. In\ncontrast, the general-purpose and code-specific models perform close to random\nchance. FABLE provides the first diagnostic benchmark to systematically\nevaluate data-flow reasoning and offers insights for developing models with\nstronger procedural understanding.", "AI": {"tldr": "FABLE is a benchmark that evaluates large language models' ability to understand data flow in procedural text. It uses eight classical data-flow analyses across three domains and tests three types of LLMs. The reasoning-focused model performs best but is much slower, while other models perform poorly.", "motivation": "To systematically evaluate the ability of large language models (LLMs) to perform data-flow reasoning, which is fundamental to procedural tasks but has not been thoroughly assessed before.", "method": "Introduced FABLE, an extensible benchmark with 2,400 question-answer pairs assessing LLMs' understanding of data flow using structured, procedural text across three real-world domains and eight classical data-flow analyses. Evaluated three types of LLMs using majority voting over five sampled completions per prompt.", "result": "The reasoning-focused model achieved higher accuracy at the cost of significantly slower inference, while general-purpose and code-specific models performed close to random chance.", "conclusion": "FABLE provides the first diagnostic benchmark for evaluating data-flow reasoning in LLMs and offers insights into developing models with stronger procedural understanding."}}
{"id": "2505.23814", "pdf": "https://arxiv.org/pdf/2505.23814", "abs": "https://arxiv.org/abs/2505.23814", "authors": ["Alexander Nemecek", "Yuzhou Jiang", "Erman Ayday"], "title": "Watermarking Without Standards Is Not AI Governance", "categories": ["cs.CR"], "comment": "9 pages", "summary": "Watermarking has emerged as a leading technical proposal for attributing\ngenerative AI content and is increasingly cited in global governance\nframeworks. This paper argues that current implementations risk serving as\nsymbolic compliance rather than delivering effective oversight. We identify a\ngrowing gap between regulatory expectations and the technical limitations of\nexisting watermarking schemes. Through analysis of policy proposals and\nindustry practices, we show how incentive structures disincentivize robust,\nauditable deployments. To realign watermarking with governance goals, we\npropose a three-layer framework encompassing technical standards, audit\ninfrastructure, and enforcement mechanisms. Without enforceable requirements\nand independent verification, watermarking will remain inadequate for\naccountability and ultimately undermine broader efforts in AI safety and\nregulation.", "AI": {"tldr": "Watermarking for generative AI content faces challenges due to technical limitations and misaligned incentives. This paper proposes a three-layer framework to enhance its effectiveness in governance.", "motivation": "Current watermarking implementations may only provide an illusion of compliance rather than effective oversight, with a gap between regulatory expectations and technical capabilities.", "method": "Analyze policy proposals and industry practices to identify issues in incentive structures and propose a three-layer framework including technical standards, audit infrastructure, and enforcement mechanisms.", "result": "A proposed framework that could realign watermarking with governance goals by addressing technical, audit, and enforcement needs.", "conclusion": "Without enforceable requirements and independent verification, watermarking remains insufficient for accountability, potentially undermining AI safety and regulation efforts."}}
{"id": "2505.23878", "pdf": "https://arxiv.org/pdf/2505.23878", "abs": "https://arxiv.org/abs/2505.23878", "authors": ["Jing Ma", "Chenhao Dang", "Mingjie Liao"], "title": "Actor-Critic based Online Data Mixing For Language Model Pre-Training", "categories": ["cs.LG", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "The coverage and composition of pretraining data significantly impacts the\ngeneralization ability of Large Language Models (LLMs). To reduce the carbon\nfootprint and financial costs of training, some data mixing methods, which\napplied the optimized domain weights of a small proxy model to train a larger\none, were proposed. However, these methods did not evolute with the training\ndynamics. The existing online data mixing (ODM) method addressed this\nlimitation by applying the multi-armed bandit algorithm as data sampling\nstrategy. Yet, it did not consider the intra-domain interactions. In this\npaper, we develop an actor-critic based online data mixing (AC-ODM) method,\nwhich captures the varying domain weights by auxiliary actor-critic networks\nand consider the intra-domain interactions with the reward function. While\nconstructing the dataset to pretrain a large target LLM, we directly apply the\nactor, which is trained with a small proxy LLM as the environment, as the\nsampling strategy. The transfer of sampling strategy can not only ensure the\nefficiency of dynamical data mixing, but also expedite the convergence of\npretraining the target LLM. Numerical results demonstrate that AC-ODM-410M,\nwhich invokes the sampling strategy obtained by a proxy LLM with 410M\nparameters, reaching the optimal validation perplexity of ODM 71% faster, and\nimproves performance on the zero-shot MMLU benchmark by 27.5% of accuracy,\nabout 2.23x better on pass@1 of HumanEval benchmark.", "AI": {"tldr": "The paper presents an actor-critic based online data mixing (AC-ODM) method to improve the pretraining of large language models (LLMs). It uses auxiliary actor-critic networks and considers intra-domain interactions with a reward function. The method accelerates convergence and improves performance on benchmarks.", "motivation": "To address the limitations of existing data mixing methods that do not evolve with training dynamics or consider intra-domain interactions, thereby improving the generalization ability of LLMs while reducing carbon footprint and financial costs.", "method": "Developed an actor-critic based online data mixing (AC-ODM) method which captures varying domain weights using auxiliary actor-critic networks and considers intra-domain interactions via a reward function. The sampling strategy is transferred from a small proxy LLM to a larger target LLM during pretraining.", "result": "AC-ODM-410M reaches optimal validation perplexity 71% faster than ODM, improves zero-shot MMLU benchmark accuracy by 27.5%, and enhances HumanEval pass@1 performance by about 2.23 times.", "conclusion": "AC-ODM effectively improves the efficiency of dynamical data mixing and expedites the convergence of pretraining for target LLMs, leading to better performance on various benchmarks."}}
{"id": "2505.24260", "pdf": "https://arxiv.org/pdf/2505.24260", "abs": "https://arxiv.org/abs/2505.24260", "authors": ["Mingyi He", "Yuebing Liang", "Shenhao Wang", "Yunhan Zheng", "Qingyi Wang", "Dingyi Zhuang", "Li Tian", "Jinhua Zhao"], "title": "Generative AI for Urban Design: A Stepwise Approach Integrating Human Expertise with Multimodal Diffusion Models", "categories": ["cs.AI"], "comment": null, "summary": "Urban design is a multifaceted process that demands careful consideration of\nsite-specific constraints and collaboration among diverse professionals and\nstakeholders. The advent of generative artificial intelligence (GenAI) offers\ntransformative potential by improving the efficiency of design generation and\nfacilitating the communication of design ideas. However, most existing\napproaches are not well integrated with human design workflows. They often\nfollow end-to-end pipelines with limited control, overlooking the iterative\nnature of real-world design. This study proposes a stepwise generative urban\ndesign framework that integrates multimodal diffusion models with human\nexpertise to enable more adaptive and controllable design processes. Instead of\ngenerating design outcomes in a single end-to-end process, the framework\ndivides the process into three key stages aligned with established urban design\nworkflows: (1) road network and land use planning, (2) building layout\nplanning, and (3) detailed planning and rendering. At each stage, multimodal\ndiffusion models generate preliminary designs based on textual prompts and\nimage-based constraints, which can then be reviewed and refined by human\ndesigners. We design an evaluation framework to assess the fidelity,\ncompliance, and diversity of the generated designs. Experiments using data from\nChicago and New York City demonstrate that our framework outperforms baseline\nmodels and end-to-end approaches across all three dimensions. This study\nunderscores the benefits of multimodal diffusion models and stepwise generation\nin preserving human control and facilitating iterative refinements, laying the\ngroundwork for human-AI interaction in urban design solutions.", "AI": {"tldr": "Urban design aided by generative AI (GenAI) is explored in this study. A stepwise generative urban design framework integrating multimodal diffusion models with human expertise for more adaptive and controllable processes is proposed.", "motivation": "The motivation behind the paper lies in the limitations of current GenAI approaches that lack integration with human design workflows, have limited control, and do not account for the iterative nature of real-world design.", "method": "A stepwise generative urban design framework is proposed which integrates multimodal diffusion models with human expertise. The process is divided into three key stages aligned with established urban design workflows: road network and land use planning, building layout planning, and detailed planning and rendering. At each stage, preliminary designs are generated based on textual prompts and image-based constraints, then reviewed and refined by human designers.", "result": "Experiments using data from Chicago and New York City show that the proposed framework outperforms baseline models and end-to-end approaches in terms of fidelity, compliance, and diversity of the generated designs.", "conclusion": "This study highlights the benefits of multimodal diffusion models and stepwise generation in maintaining human control and allowing iterative refinements, providing a foundation for human-AI interaction in urban design."}}
{"id": "2505.23817", "pdf": "https://arxiv.org/pdf/2505.23817", "abs": "https://arxiv.org/abs/2505.23817", "authors": ["Badhan Chandra Das", "M. Hadi Amini", "Yanzhao Wu"], "title": "System Prompt Extraction Attacks and Defenses in Large Language Models", "categories": ["cs.CR"], "comment": null, "summary": "The system prompt in Large Language Models (LLMs) plays a pivotal role in\nguiding model behavior and response generation. Often containing private\nconfiguration details, user roles, and operational instructions, the system\nprompt has become an emerging attack target. Recent studies have shown that LLM\nsystem prompts are highly susceptible to extraction attacks through\nmeticulously designed queries, raising significant privacy and security\nconcerns. Despite the growing threat, there is a lack of systematic studies of\nsystem prompt extraction attacks and defenses. In this paper, we present a\ncomprehensive framework, SPE-LLM, to systematically evaluate System Prompt\nExtraction attacks and defenses in LLMs. First, we design a set of novel\nadversarial queries that effectively extract system prompts in state-of-the-art\n(SOTA) LLMs, demonstrating the severe risks of LLM system prompt extraction\nattacks. Second, we propose three defense techniques to mitigate system prompt\nextraction attacks in LLMs, providing practical solutions for secure LLM\ndeployments. Third, we introduce a set of rigorous evaluation metrics to\naccurately quantify the severity of system prompt extraction attacks in LLMs\nand conduct comprehensive experiments across multiple benchmark datasets, which\nvalidates the efficacy of our proposed SPE-LLM framework.", "AI": {"tldr": "The paper presents SPE-LLM, a framework for evaluating and defending against system prompt extraction attacks in LLMs.", "motivation": "System prompts in LLMs are crucial for guiding model behavior but are vulnerable to extraction attacks, posing privacy and security risks.", "method": "1) Design novel adversarial queries to extract system prompts. 2) Propose three defense techniques against extraction attacks. 3) Introduce rigorous evaluation metrics and conduct experiments on benchmark datasets.", "result": "Demonstrates severe risks of system prompt extraction and validates the effectiveness of the SPE-LLM framework through comprehensive experiments.", "conclusion": "SPE-LLM provides a systematic approach to evaluate and defend against system prompt extraction attacks in LLMs."}}
{"id": "2505.23879", "pdf": "https://arxiv.org/pdf/2505.23879", "abs": "https://arxiv.org/abs/2505.23879", "authors": ["Caio Cheohen", "Vinn\u00edcius M. S. Gomes", "Manuela L. da Silva"], "title": "CNN-LSTM Hybrid Model for AI-Driven Prediction of COVID-19 Severity from Spike Sequences and Clinical Data", "categories": ["cs.LG", "cs.AI", "68T07, 62P10, 92C50, 68T05", "I.2.6; I.5.1; J.3"], "comment": "12 pages, 4 figures, 4 tables", "summary": "The COVID-19 pandemic, caused by SARS-CoV-2, highlighted the critical need\nfor accurate prediction of disease severity to optimize healthcare resource\nallocation and patient management. The spike protein, which facilitates viral\nentry into host cells, exhibits high mutation rates, particularly in the\nreceptor-binding domain, influencing viral pathogenicity. Artificial\nintelligence approaches, such as deep learning, offer promising solutions for\nleveraging genomic and clinical data to predict disease outcomes. Objective:\nThis study aimed to develop a hybrid CNN-LSTM deep learning model to predict\nCOVID-19 severity using spike protein sequences and associated clinical\nmetadata from South American patients. Methods: We retrieved 9,570 spike\nprotein sequences from the GISAID database, of which 3,467 met inclusion\ncriteria after standardization. The dataset included 2,313 severe and 1,154\nmild cases. A feature engineering pipeline extracted features from sequences,\nwhile demographic and clinical variables were one-hot encoded. A hybrid\nCNN-LSTM architecture was trained, combining CNN layers for local pattern\nextraction and an LSTM layer for long-term dependency modeling. Results: The\nmodel achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%,\nand recall of 82.85%, demonstrating robust classification performance. Training\nstabilized at 85% accuracy with minimal overfitting. The most prevalent\nlineages (P.1, AY.99.2) and clades (GR, GK) aligned with regional\nepidemiological trends, suggesting potential associations between viral\ngenetics and clinical outcomes. Conclusion: The CNN-LSTM hybrid model\neffectively predicted COVID-19 severity using spike protein sequences and\nclinical data, highlighting the utility of AI in genomic surveillance and\nprecision public health. Despite limitations, this approach provides a\nframework for early severity prediction in future outbreaks.", "AI": {"tldr": "The study developed a hybrid CNN-LSTM model using spike protein sequences and clinical data to predict COVID-19 severity with high accuracy, showing AI's potential in genomic surveillance.", "motivation": "To address the critical need for accurate prediction of disease severity in managing healthcare resources during the pandemic caused by SARS-CoV-2.", "method": "Retrieved and processed 3,467 spike protein sequences from GISAID, extracted features through a feature engineering pipeline, one-hot encoded clinical variables, and trained a hybrid CNN-LSTM model.", "result": "The model achieved an F1 score of 82.92%, ROC-AUC of 0.9084, precision of 83.56%, recall of 82.85%, and stabilized training at 85% accuracy with minimal overfitting.", "conclusion": "The CNN-LSTM hybrid model effectively predicted COVID-19 severity, demonstrating the utility of AI in genomic surveillance and precision public health."}}
{"id": "2505.24273", "pdf": "https://arxiv.org/pdf/2505.24273", "abs": "https://arxiv.org/abs/2505.24273", "authors": ["Hongyi James Cai", "Junlin Wang", "Xiaoyin Chen", "Bhuwan Dhingra"], "title": "How Much Backtracking is Enough? Exploring the Interplay of SFT and RL in Enhancing LLM Reasoning", "categories": ["cs.AI"], "comment": null, "summary": "Recent breakthroughs in large language models (LLMs) have effectively\nimproved their reasoning abilities, particularly on mathematical and logical\nproblems that have verifiable answers, through techniques such as supervised\nfinetuning (SFT) and reinforcement learning (RL). Prior research indicates that\nRL effectively internalizes search strategies, enabling long chain-of-thought\n(CoT) reasoning, with backtracking emerging naturally as a learned capability.\nHowever, the precise benefits of backtracking, specifically, how significantly\nit contributes to reasoning improvements and the optimal extent of its use,\nremain poorly understood. In this work, we systematically investigate the\ndynamics between SFT and RL on eight reasoning tasks: Countdown, Sudoku, Arc\n1D, Geometry, Color Cube Rotation, List Functions, Zebra Puzzles, and Self\nReference. Our findings highlight that short CoT sequences used in SFT as a\nwarm-up do have moderate contribution to RL training, compared with cold-start\nRL; however such contribution diminishes when tasks become increasingly\ndifficult. Motivated by this observation, we construct synthetic datasets\nvarying systematically in the number of backtracking steps and conduct\ncontrolled experiments to isolate the influence of either the correctness\n(content) or the structure (i.e., backtrack frequency). We find that (1) longer\nCoT with backtracks generally induce better and more stable RL training, (2)\nmore challenging problems with larger search space tend to need higher numbers\nof backtracks during the SFT stage. Additionally, we demonstrate through\nexperiments on distilled data that RL training is largely unaffected by the\ncorrectness of long CoT sequences, suggesting that RL prioritizes structural\npatterns over content correctness. Collectively, our results offer practical\ninsights into designing optimal training strategies to effectively scale\nreasoning in LLMs.", "AI": {"tldr": "Recent breakthroughs in LLMs have improved reasoning abilities, especially in mathematical and logical problems through SFT and RL techniques. This paper investigates the dynamics between SFT and RL on various reasoning tasks.", "motivation": "To understand the precise benefits of backtracking in reasoning improvements and the optimal extent of its use in LLMs.", "method": "Systematically investigate the dynamics between SFT and RL on eight reasoning tasks; construct synthetic datasets varying in backtracking steps for controlled experiments.", "result": "Short CoT sequences used in SFT moderately contribute to RL training, but this contribution diminishes with task difficulty. Longer CoT with backtracks generally induce better and more stable RL training. More challenging problems need higher numbers of backtracks during SFT. RL training is largely unaffected by the correctness of long CoT sequences, prioritizing structural patterns over content correctness.", "conclusion": "The results offer practical insights into designing optimal training strategies for effectively scaling reasoning in LLMs."}}
{"id": "2505.23821", "pdf": "https://arxiv.org/pdf/2505.23821", "abs": "https://arxiv.org/abs/2505.23821", "authors": ["Lingfeng Yao", "Chenpei Huang", "Shengyao Wang", "Junpei Xue", "Hanqing Guo", "Jiang Liu", "Xun Chen", "Miao Pan"], "title": "SpeechVerifier: Robust Acoustic Fingerprint against Tampering Attacks via Watermarking", "categories": ["cs.CR", "cs.SD", "eess.AS"], "comment": null, "summary": "With the surge of social media, maliciously tampered public speeches,\nespecially those from influential figures, have seriously affected social\nstability and public trust. Existing speech tampering detection methods remain\ninsufficient: they either rely on external reference data or fail to be both\nsensitive to attacks and robust to benign operations, such as compression and\nresampling. To tackle these challenges, we introduce SpeechVerifer to\nproactively verify speech integrity using only the published speech itself,\ni.e., without requiring any external references. Inspired by audio\nfingerprinting and watermarking, SpeechVerifier can (i) effectively detect\ntampering attacks, (ii) be robust to benign operations and (iii) verify the\nintegrity only based on published speeches. Briefly, SpeechVerifier utilizes\nmultiscale feature extraction to capture speech features across different\ntemporal resolutions. Then, it employs contrastive learning to generate\nfingerprints that can detect modifications at varying granularities. These\nfingerprints are designed to be robust to benign operations, but exhibit\nsignificant changes when malicious tampering occurs. To enable speech\nverification in a self-contained manner, the generated fingerprints are then\nembedded into the speech signal by segment-wise watermarking. Without external\nreferences, SpeechVerifier can retrieve the fingerprint from the published\naudio and check it with the embedded watermark to verify the integrity of the\nspeech. Extensive experimental results demonstrate that the proposed\nSpeechVerifier is effective in detecting tampering attacks and robust to benign\noperations.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86SpeechVerifier\uff0c\u4e00\u79cd\u4e0d\u4f9d\u8d56\u5916\u90e8\u53c2\u8003\u6570\u636e\u7684\u8bed\u97f3\u5b8c\u6574\u6027\u9a8c\u8bc1\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u3001\u5bf9\u6bd4\u5b66\u4e60\u751f\u6210\u6307\u7eb9\u4ee5\u53ca\u5206\u6bb5\u6c34\u5370\u6280\u672f\uff0c\u5b9e\u73b0\u4e86\u5bf9\u6076\u610f\u7be1\u6539\u7684\u6709\u6548\u68c0\u6d4b\u548c\u5bf9\u826f\u6027\u64cd\u4f5c\u7684\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u8bc1\u660e\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u793e\u4ea4\u5a92\u4f53\u7684\u5174\u8d77\uff0c\u6709\u5f71\u54cd\u529b\u7684\u516c\u4f17\u4eba\u7269\u7684\u6f14\u8bb2\u88ab\u6076\u610f\u7be1\u6539\uff0c\u4e25\u91cd\u5f71\u54cd\u4e86\u793e\u4f1a\u7a33\u5b9a\u548c\u516c\u4f17\u4fe1\u4efb\u3002\u73b0\u6709\u7684\u8bed\u97f3\u7be1\u6539\u68c0\u6d4b\u65b9\u6cd5\u5b58\u5728\u4e0d\u8db3\uff1a\u5b83\u4eec\u8981\u4e48\u4f9d\u8d56\u5916\u90e8\u53c2\u8003\u6570\u636e\uff0c\u8981\u4e48\u65e0\u6cd5\u540c\u65f6\u5bf9\u653b\u51fb\u654f\u611f\u5e76\u5bf9\u826f\u6027\u64cd\u4f5c\uff08\u5982\u538b\u7f29\u548c\u91cd\u91c7\u6837\uff09\u5177\u6709\u9c81\u68d2\u6027\u3002", "method": "\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\uff0c\u5f15\u5165\u4e86SpeechVerifier\uff0c\u5b83\u4ec5\u4f7f\u7528\u5df2\u53d1\u5e03\u7684\u8bed\u97f3\u672c\u8eab\u6765\u4e3b\u52a8\u9a8c\u8bc1\u8bed\u97f3\u5b8c\u6574\u6027\uff0c\u800c\u65e0\u9700\u4efb\u4f55\u5916\u90e8\u53c2\u8003\u3002\u53d7\u97f3\u9891\u6307\u7eb9\u548c\u6c34\u5370\u6280\u672f\u7684\u542f\u53d1\uff0cSpeechVerifier\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u6765\u6355\u6349\u4e0d\u540c\u65f6\u95f4\u5206\u8fa8\u7387\u4e0b\u7684\u8bed\u97f3\u7279\u5f81\uff0c\u7136\u540e\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u751f\u6210\u53ef\u4ee5\u68c0\u6d4b\u5404\u79cd\u7c92\u5ea6\u4fee\u6539\u7684\u6307\u7eb9\u3002\u8fd9\u4e9b\u6307\u7eb9\u5bf9\u826f\u6027\u64cd\u4f5c\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4f46\u5728\u53d1\u751f\u6076\u610f\u7be1\u6539\u65f6\u4f1a\u8868\u73b0\u51fa\u663e\u8457\u53d8\u5316\u3002\u4e3a\u4e86\u5b9e\u73b0\u81ea\u6211\u5305\u542b\u7684\u8bed\u97f3\u9a8c\u8bc1\uff0c\u751f\u6210\u7684\u6307\u7eb9\u901a\u8fc7\u5206\u6bb5\u6c34\u5370\u5d4c\u5165\u5230\u8bed\u97f3\u4fe1\u53f7\u4e2d\u3002\u5728\u6ca1\u6709\u5916\u90e8\u53c2\u8003\u7684\u60c5\u51b5\u4e0b\uff0cSpeechVerifier\u53ef\u4ee5\u4ece\u5df2\u53d1\u5e03\u7684\u97f3\u9891\u4e2d\u68c0\u7d22\u6307\u7eb9\uff0c\u5e76\u5c06\u5176\u4e0e\u5d4c\u5165\u7684\u6c34\u5370\u8fdb\u884c\u6bd4\u8f83\u4ee5\u9a8c\u8bc1\u8bed\u97f3\u7684\u5b8c\u6574\u6027\u3002", "result": "\u5927\u91cf\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684SpeechVerifier\u5728\u68c0\u6d4b\u7be1\u6539\u653b\u51fb\u65b9\u9762\u662f\u6709\u6548\u7684\uff0c\u5e76\u4e14\u5bf9\u826f\u6027\u64cd\u4f5c\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSpeechVerifier\u7684\u65b0\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u5916\u90e8\u53c2\u8003\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u6548\u68c0\u6d4b\u8bed\u97f3\u7be1\u6539\u5e76\u62b5\u6297\u826f\u6027\u64cd\u4f5c\u7684\u5f71\u54cd\u3002\u8fd9\u4e3a\u89e3\u51b3\u73b0\u6709\u8bed\u97f3\u7be1\u6539\u68c0\u6d4b\u65b9\u6cd5\u7684\u4e0d\u8db3\u63d0\u4f9b\u4e86\u4e00\u4e2a\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2505.23884", "pdf": "https://arxiv.org/pdf/2505.23884", "abs": "https://arxiv.org/abs/2505.23884", "authors": ["Tianyuan Zhang", "Sai Bi", "Yicong Hong", "Kai Zhang", "Fujun Luan", "Songlin Yang", "Kalyan Sunkavalli", "William T. Freeman", "Hao Tan"], "title": "Test-Time Training Done Right", "categories": ["cs.LG", "cs.CL", "cs.CV"], "comment": "32 pages, 11 figures", "summary": "Test-Time Training (TTT) models context dependencies by adapting part of the\nmodel's weights (referred to as fast weights) during inference. This fast\nweight, akin to recurrent states in RNNs, stores temporary memories of past\ntokens in the current sequence. Existing TTT methods struggled to show\neffectiveness in handling long-context data, due to their inefficiency on\nmodern GPUs. The TTT layers in many of these approaches operate with extremely\nlow FLOPs utilization (often <5%) because they deliberately apply small online\nminibatch sizes (e.g., updating fast weights every 16 or 64 tokens). Moreover,\na small minibatch implies fine-grained block-wise causal dependencies in the\ndata, unsuitable for data beyond 1D ordered sequences, like sets or\nN-dimensional grids such as images or videos. In contrast, we pursue the\nopposite direction by using an extremely large chunk update, ranging from 2K to\n1M tokens across tasks of varying modalities, which we refer to as Large Chunk\nTest-Time Training (LaCT). It improves hardware utilization by orders of\nmagnitude, and more importantly, facilitates scaling of nonlinear state size\n(up to 40% of model parameters), hence substantially improving state capacity,\nall without requiring cumbersome and error-prone kernel implementations. It\nalso allows easy integration of sophisticated optimizers, e.g. Muon for online\nupdates. We validate our approach across diverse modalities and tasks,\nincluding novel view synthesis with image set, language models, and\nauto-regressive video diffusion. Our approach can scale up to 14B-parameter AR\nvideo diffusion model on sequences up to 56K tokens. In our longest sequence\nexperiment, we perform novel view synthesis with 1 million context length. We\nhope this work will inspire and accelerate new research in the field of\nlong-context modeling and test-time training. Website:\nhttps://tianyuanzhang.com/projects/ttt-done-right", "AI": {"tldr": "The paper introduces Large Chunk Test-Time Training (LaCT), an advancement over traditional Test-Time Training (TTT) methods, that uses large chunk updates to improve hardware utilization and state capacity. It allows for efficient processing of long-context data across diverse modalities and tasks.", "motivation": "Existing TTT methods are inefficient on modern GPUs due to their use of small online minibatch sizes which lead to extremely low FLOPs utilization. This limits their ability to handle long-context data effectively.", "method": "LaCT employs extremely large chunk updates (2K to 1M tokens) across various tasks, improving hardware utilization by orders of magnitude and facilitating scaling of nonlinear state size up to 40% of model parameters. It also integrates sophisticated optimizers like Muon for online updates.", "result": "Validated across diverse modalities and tasks such as novel view synthesis with image set, language models, and auto-regressive video diffusion. Successfully scaled a 14B-parameter AR video diffusion model on sequences up to 56K tokens and performed novel view synthesis with 1 million context length.", "conclusion": "LaCT significantly enhances the capabilities of TTT in handling long-context data and inspires further research in this field."}}
{"id": "2505.24292", "pdf": "https://arxiv.org/pdf/2505.24292", "abs": "https://arxiv.org/abs/2505.24292", "authors": ["Yueqi Zhang", "Peiwen Yuan", "Shaoxiong Feng", "Yiwei Li", "Xinglin Wang", "Jiayi Shi", "Chuyi Tan", "Boyuan Pan", "Yao Hu", "Kan Li"], "title": "Mind the Quote: Enabling Quotation-Aware Dialogue in LLMs via Plug-and-Play Modules", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Human-AI conversation frequently relies on quoting earlier text-\"check it\nwith the formula I just highlighted\"-yet today's large language models (LLMs)\nlack an explicit mechanism for locating and exploiting such spans. We formalise\nthe challenge as span-conditioned generation, decomposing each turn into the\ndialogue history, a set of token-offset quotation spans, and an intent\nutterance. Building on this abstraction, we introduce a quotation-centric data\npipeline that automatically synthesises task-specific dialogues, verifies\nanswer correctness through multi-stage consistency checks, and yields both a\nheterogeneous training corpus and the first benchmark covering five\nrepresentative scenarios. To meet the benchmark's zero-overhead and\nparameter-efficiency requirements, we propose QuAda, a lightweight\ntraining-based method that attaches two bottleneck projections to every\nattention head, dynamically amplifying or suppressing attention to quoted spans\nat inference time while leaving the prompt unchanged and updating < 2.8% of\nbackbone weights. Experiments across models show that QuAda is suitable for all\nscenarios and generalises to unseen topics, offering an effective,\nplug-and-play solution for quotation-aware dialogue.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aQuAda\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u4eba\u7c7b-AI\u5bf9\u8bdd\u4e2d\u7f3a\u4e4f\u6709\u6548\u5229\u7528\u5f15\u7528\u6587\u672c\u7684\u95ee\u9898\u3002\u901a\u8fc7\u5f15\u5165\u4e00\u79cd\u65b0\u7684\u6570\u636e\u7ba1\u9053\u548c\u8bad\u7ec3\u65b9\u6cd5\uff0cQuAda\u80fd\u591f\u5728\u4e0d\u6539\u53d8\u63d0\u793a\u7684\u60c5\u51b5\u4e0b\u52a8\u6001\u8c03\u6574\u5bf9\u5f15\u7528\u6587\u672c\u7684\u5173\u6ce8\u5ea6\uff0c\u5e76\u4e14\u5728\u591a\u4e2a\u6a21\u578b\u548c\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5bf9\u8bdd\u8fc7\u7a0b\u4e2d\u65e0\u6cd5\u6709\u6548\u5730\u5b9a\u4f4d\u548c\u5229\u7528\u4e4b\u524d\u63d0\u5230\u7684\u6587\u672c\u7247\u6bb5\uff08\u5982\u516c\u5f0f\u3001\u5f15\u6587\u7b49\uff09\uff0c\u8fd9\u9650\u5236\u4e86\u5b83\u4eec\u5728\u4eba\u7c7b-AI\u5bf9\u8bdd\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u63d0\u51fa\u4e86\u4e00\u4e2a\u79f0\u4e3aQuAda\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u901a\u8fc7\u5728\u6bcf\u4e2a\u6ce8\u610f\u529b\u5934\u9644\u52a0\u4e24\u4e2a\u74f6\u9888\u6295\u5f71\uff0c\u52a8\u6001\u5730\u589e\u5f3a\u6216\u6291\u5236\u5bf9\u5f15\u7528\u7247\u6bb5\u7684\u5173\u6ce8\uff0c\u540c\u65f6\u4e0d\u5f71\u54cd\u539f\u59cb\u63d0\u793a\u5e76\u53ea\u66f4\u65b0\u5c11\u91cf\u4e3b\u5e72\u6743\u91cd\u3002\u6b64\u5916\uff0c\u8fd8\u6784\u5efa\u4e86\u4e00\u4e2a\u4ee5\u5f15\u7528\u4e3a\u4e2d\u5fc3\u7684\u6570\u636e\u7ba1\u9053\uff0c\u7528\u4e8e\u5408\u6210\u7279\u5b9a\u4efb\u52a1\u7684\u5bf9\u8bdd\u5e76\u9a8c\u8bc1\u7b54\u6848\u7684\u6b63\u786e\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cQuAda\u65b9\u6cd5\u9002\u7528\u4e8e\u6240\u6709\u4ee3\u8868\u6027\u7684\u5bf9\u8bdd\u573a\u666f\uff0c\u5e76\u80fd\u591f\u63a8\u5e7f\u5230\u672a\u89c1\u8fc7\u7684\u4e3b\u9898\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5373\u63d2\u5373\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "QuAda\u4e3a\u5f15\u7528\u611f\u77e5\u5bf9\u8bdd\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u8f7b\u91cf\u7ea7\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u989d\u5916\u5f00\u9500\u7684\u60c5\u51b5\u4e0b\u63d0\u9ad8\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5bf9\u5f15\u7528\u6587\u672c\u7684\u5229\u7528\u80fd\u529b\u3002"}}
{"id": "2505.23825", "pdf": "https://arxiv.org/pdf/2505.23825", "abs": "https://arxiv.org/abs/2505.23825", "authors": ["Carl Corea", "Timotheus Kampik", "Nico Potyka"], "title": "Privacy-Preserving Inconsistency Measurement", "categories": ["cs.CR"], "comment": null, "summary": "We investigate a new form of (privacy-preserving) inconsistency measurement\nfor multi-party communication. Intuitively, for two knowledge bases K_A, K_B\n(of two agents A, B), our results allow to quantitatively assess the degree of\ninconsistency for K_A U K_B without having to reveal the actual contents of the\nknowledge bases. Using secure multi-party computation (SMPC) and cryptographic\nprotocols, we develop two concrete methods for this use-case and show that they\nsatisfy important properties of SMPC protocols -- notably, input privacy, i.e.,\njointly computing the inconsistency degree without revealing the inputs.", "AI": {"tldr": "This paper explores a new method of privacy-preserving inconsistency measurement for multi-party communication, developing two concrete methods using secure multi-party computation and cryptographic protocols that satisfy important properties such as input privacy.", "motivation": "The motivation is to quantitatively assess the degree of inconsistency between knowledge bases in multi-party communication without revealing their actual contents.", "method": "By using secure multi-party computation (SMPC) and cryptographic protocols, the authors develop two concrete methods for inconsistency measurement.", "result": "The developed methods successfully satisfy important properties of SMPC protocols, including input privacy.", "conclusion": "A new form of privacy-preserving inconsistency measurement has been investigated and shown to be effective via two developed methods."}}
{"id": "2505.23913", "pdf": "https://arxiv.org/pdf/2505.23913", "abs": "https://arxiv.org/abs/2505.23913", "authors": ["Gustavo Sutter Pessurno de Carvalho", "Mohammed Abdulrahman", "Hao Wang", "Sriram Ganapathi Subramanian", "Marc St-Aubin", "Sharon O'Sullivan", "Lawrence Wan", "Luis Ricardez-Sandoval", "Pascal Poupart", "Agustinus Kristiadi"], "title": "Simplifying Bayesian Optimization Via In-Context Direct Optimum Sampling", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "The optimization of expensive black-box functions is ubiquitous in science\nand engineering. A common solution to this problem is Bayesian optimization\n(BO), which is generally comprised of two components: (i) a surrogate model and\n(ii) an acquisition function, which generally require expensive re-training and\noptimization steps at each iteration, respectively. Although recent work\nenabled in-context surrogate models that do not require re-training, virtually\nall existing BO methods still require acquisition function maximization to\nselect the next observation, which introduces many knobs to tune, such as Monte\nCarlo samplers and multi-start optimizers. In this work, we propose a\ncompletely in-context, zero-shot solution for BO that does not require\nsurrogate fitting or acquisition function optimization. This is done by using a\npre-trained deep generative model to directly sample from the posterior over\nthe optimum point. We show that this process is equivalent to Thompson sampling\nand demonstrate the capabilities and cost-effectiveness of our foundation model\non a suite of real-world benchmarks. We achieve an efficiency gain of more than\n35x in terms of wall-clock time when compared with Gaussian process-based BO,\nenabling efficient parallel and distributed BO, e.g., for high-throughput\noptimization.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u65e0\u9700\u4ee3\u7406\u6a21\u578b\u62df\u5408\u6216\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u7684\u96f6\u6837\u672c\u8d1d\u53f6\u65af\u4f18\u5316\u65b9\u6cd5\uff0c\u5229\u7528\u9884\u8bad\u7ec3\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u76f4\u63a5\u4ece\u6700\u4f18\u89e3\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u76f8\u6bd4\u9ad8\u65af\u8fc7\u7a0bBO\u6548\u7387\u63d0\u534735\u500d\u4ee5\u4e0a\u3002", "motivation": "\u5f53\u524d\u8d1d\u53f6\u65af\u4f18\u5316\uff08BO\uff09\u867d\u7136\u6709\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u7684\u4e0a\u4e0b\u6587\u4ee3\u7406\u6a21\u578b\uff0c\u4f46\u5927\u591a\u6570\u4ecd\u9700\u8981\u901a\u8fc7\u83b7\u53d6\u51fd\u6570\u6700\u5927\u5316\u9009\u62e9\u4e0b\u4e00\u6b21\u89c2\u6d4b\uff0c\u5f15\u5165\u8bb8\u591a\u8c03\u53c2\u9700\u6c42\uff0c\u5982\u8499\u7279\u5361\u6d1b\u91c7\u6837\u5668\u548c\u591a\u542f\u52a8\u4f18\u5316\u5668\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u3002", "method": "\u4f7f\u7528\u9884\u8bad\u7ec3\u7684\u6df1\u5ea6\u751f\u6210\u6a21\u578b\u76f4\u63a5\u4ece\u6700\u4f18\u89e3\u70b9\u7684\u540e\u9a8c\u5206\u5e03\u4e2d\u91c7\u6837\uff0c\u4ece\u800c\u5b8c\u5168\u5728\u4e0a\u4e0b\u6587\u4e2d\u5b8c\u6210\u8d1d\u53f6\u65af\u4f18\u5316\uff0c\u907f\u514d\u4e86\u4ee3\u7406\u6a21\u578b\u62df\u5408\u548c\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u7684\u9700\u6c42\uff0c\u7b49\u4ef7\u4e8e\u6c64\u666e\u68ee\u91c7\u6837\u3002", "result": "\u5728\u4e00\u7cfb\u5217\u771f\u5b9e\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u5c55\u793a\u4e86\u8be5\u57fa\u7840\u6a21\u578b\u7684\u80fd\u529b\u548c\u6210\u672c\u6548\u76ca\uff0c\u4e0e\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684BO\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u8d85\u8fc735\u500d\u7684\u5899\u949f\u65f6\u95f4\u6548\u7387\u589e\u76ca\uff0c\u652f\u6301\u9ad8\u6548\u7684\u5e76\u884c\u548c\u5206\u5e03\u5f0fBO\uff0c\u9002\u7528\u4e8e\u9ad8\u541e\u5410\u91cf\u4f18\u5316\u573a\u666f\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u3001\u65e0\u9700\u4ee3\u7406\u6a21\u578b\u62df\u5408\u6216\u83b7\u53d6\u51fd\u6570\u4f18\u5316\u7684\u96f6\u6837\u672c\u8d1d\u53f6\u65af\u4f18\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u5927\u5e45\u63d0\u5347\u4e86\u4f18\u5316\u6548\u7387\uff0c\u5e76\u7b80\u5316\u4e86\u64cd\u4f5c\u6d41\u7a0b\u3002"}}
{"id": "2505.24306", "pdf": "https://arxiv.org/pdf/2505.24306", "abs": "https://arxiv.org/abs/2505.24306", "authors": ["Kechen Li", "Yaotian Tao", "Ximing Wen", "Quanwei Sun", "Zifei Gong", "Chang Xu", "Xizhe Zhang", "Tianbo Ji"], "title": "GridRoute: A Benchmark for LLM-Based Route Planning with Cardinal Movement in Grid Environments", "categories": ["cs.AI"], "comment": "8 pages", "summary": "Recent advancements in Large Language Models (LLMs) have demonstrated their\npotential in planning and reasoning tasks, offering a flexible alternative to\nclassical pathfinding algorithms. However, most existing studies focus on LLMs'\nindependent reasoning capabilities and overlook the potential synergy between\nLLMs and traditional algorithms. To fill this gap, we propose a comprehensive\nevaluation benchmark GridRoute to assess how LLMs can take advantage of\ntraditional algorithms. We also propose a novel hybrid prompting technique\ncalled Algorithm of Thought (AoT), which introduces traditional algorithms'\nguidance into prompting. Our benchmark evaluates six LLMs ranging from 7B to\n72B parameters across various map sizes, assessing their performance in\ncorrectness, optimality, and efficiency in grid environments with varying\nsizes. Our results show that AoT significantly boosts performance across all\nmodel sizes, particularly in larger or more complex environments, suggesting a\npromising approach to addressing path planning challenges. Our code is\nopen-sourced at https://github.com/LinChance/GridRoute.", "AI": {"tldr": "Recent advancements in LLMs show potential in planning and reasoning tasks. However, the synergy between LLMs and traditional algorithms is often overlooked. This paper proposes GridRoute, a benchmark for evaluating LLMs' ability to leverage traditional algorithms, and AoT, a hybrid prompting technique that integrates traditional algorithm guidance. Results indicate AoT significantly improves LLM performance, especially in complex environments.", "motivation": "To explore the potential synergy between LLMs and traditional algorithms in path planning and reasoning tasks, addressing the gap in existing studies that primarily focus on LLMs' independent capabilities.", "method": "Propose GridRoute, a comprehensive evaluation benchmark, and Algorithm of Thought (AoT), a novel hybrid prompting technique that incorporates traditional algorithm guidance into LLM prompts. Evaluate six LLMs with parameters ranging from 7B to 72B across various map sizes.", "result": "AoT significantly enhances LLM performance across all model sizes, particularly noticeable in larger or more complex grid environments.", "conclusion": "The proposed AoT method demonstrates promise in improving path planning challenges by integrating traditional algorithms with LLMs."}}
{"id": "2505.23828", "pdf": "https://arxiv.org/pdf/2505.23828", "abs": "https://arxiv.org/abs/2505.23828", "authors": ["Lei Yu", "Yechao Zhang", "Ziqi Zhou", "Yang Wu", "Wei Wan", "Minghui Li", "Shengshan Hu", "Pei Xiaobing", "Jing Wang"], "title": "Spa-VLM: Stealthy Poisoning Attacks on RAG-based VLM", "categories": ["cs.CR"], "comment": null, "summary": "With the rapid development of the Vision-Language Model (VLM), significant\nprogress has been made in Visual Question Answering (VQA) tasks. However,\nexisting VLM often generate inaccurate answers due to a lack of up-to-date\nknowledge. To address this issue, recent research has introduced\nRetrieval-Augmented Generation (RAG) techniques, commonly used in Large\nLanguage Models (LLM), into VLM, incorporating external multi-modal knowledge\nto enhance the accuracy and practicality of VLM systems. Nevertheless, the RAG\nin LLM may be susceptible to data poisoning attacks. RAG-based VLM may also\nface the threat of this attack. This paper first reveals the vulnerabilities of\nthe RAG-based large model under poisoning attack, showing that existing\nsingle-modal RAG poisoning attacks have a 100\\% failure rate in multi-modal RAG\nscenarios. To address this gap, we propose Spa-VLM (Stealthy Poisoning Attack\non RAG-based VLM), a new paradigm for poisoning attacks on large models. We\ncarefully craft malicious multi-modal knowledge entries, including adversarial\nimages and misleading text, which are then injected into the RAG's knowledge\nbase. When users access the VLM service, the system may generate misleading\noutputs. We evaluate Spa-VLM on two Wikipedia datasets and across two different\nRAGs. Results demonstrate that our method achieves highly stealthy poisoning,\nwith the attack success rate exceeding 0.8 after injecting just 5 malicious\nentries into knowledge bases with 100K and 2M entries, outperforming\nstate-of-the-art poisoning attacks designed for RAG-based LLMs. Additionally,\nwe evaluated several defense mechanisms, all of which ultimately proved\nineffective against Spa-VLM, underscoring the effectiveness and robustness of\nour attack.", "AI": {"tldr": "This paper addresses the vulnerability of Retrieval-Augmented Generation (RAG) in Vision-Language Models (VLMs) under poisoning attacks. It proposes a new attack method, Spa-VLM, which crafts malicious multi-modal knowledge to mislead VLM outputs. Evaluated on Wikipedia datasets and different RAGs, Spa-VLM shows high stealthiness and effectiveness, with an attack success rate exceeding 0.8 after injecting only 5 malicious entries into large knowledge bases.", "motivation": "Existing single-modal RAG poisoning attacks fail completely in multi-modal RAG scenarios for VLMs, highlighting a need for effective multi-modal RAG poisoning techniques.", "method": "The authors propose Spa-VLM, a method that creates malicious multi-modal knowledge entries (adversarial images and misleading text) and injects them into the RAG's knowledge base. This leads to misleading outputs when users access the VLM service.", "result": "Spa-VLM achieves highly stealthy poisoning with an attack success rate exceeding 0.8 after injecting just 5 malicious entries into knowledge bases with 100K and 2M entries. Several defense mechanisms were ineffective against Spa-VLM.", "conclusion": "The proposed Spa-VLM demonstrates significant vulnerabilities in RAG-based VLMs under poisoning attacks, showing its effectiveness and robustness compared to existing methods."}}
{"id": "2505.23927", "pdf": "https://arxiv.org/pdf/2505.23927", "abs": "https://arxiv.org/abs/2505.23927", "authors": ["Songtao Feng", "Jie Fu"], "title": "Thompson Sampling in Online RLHF with General Function Approximation", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning from human feedback (RLHF) has achieved great\nempirical success in aligning large language models (LLMs) with human\npreference, and it is of great importance to study the statistical efficiency\nof RLHF algorithms from a theoretical perspective. In this work, we consider\nthe online RLHF setting where the preference data is revealed during the\nlearning process and study action value function approximation. We design a\nmodel-free posterior sampling algorithm for online RLHF inspired by Thompson\nsampling and provide its theoretical guarantee. Specifically, we adopt Bellman\neluder (BE) dimension as the complexity measure of the function class and\nestablish $O(\\sqrt{T})$ regret bound for the proposed algorithm with other\nmultiplicative factor depending on the horizon, BE dimension and the\n$log$-bracketing number of the function class. Further, in the analysis, we\nfirst establish the concentration-type inequality of the squared Bellman error\nbound based on the maximum likelihood estimator (MLE) generalization bound,\nwhich plays the crucial rules in obtaining the eluder-type regret bound and may\nbe of independent interest.", "AI": {"tldr": "This paper explores the online reinforcement learning from human feedback (RLHF) setting, proposing a model-free posterior sampling algorithm inspired by Thompson sampling. It establishes a regret bound and introduces a concentration-type inequality for squared Bellman error.", "motivation": "To study the statistical efficiency of RLHF algorithms theoretically, particularly in aligning large language models with human preferences.", "method": "Design a model-free posterior sampling algorithm for online RLHF using Bellman eluder dimension as the complexity measure and establish O(\u221aT) regret bound.", "result": "Achieved O(\u221aT) regret bound with multiplicative factors depending on horizon, BE dimension, and log-bracketing number. Also established a concentration-type inequality for squared Bellman error.", "conclusion": "The proposed algorithm has strong theoretical guarantees and contributes to understanding the statistical efficiency of RLHF algorithms."}}
{"id": "2505.24422", "pdf": "https://arxiv.org/pdf/2505.24422", "abs": "https://arxiv.org/abs/2505.24422", "authors": ["Zhenghua Pan", "Yong Wang"], "title": "Three Kinds of Negation in Knowledge and Their Mathematical Foundations", "categories": ["cs.AI"], "comment": "32 pages,13 figures", "summary": "In the field of artificial intelligence, understanding, distinguishing,\nexpressing, and computing the negation in knowledge is a fundamental issue in\nknowledge processing and research. In this paper, we examine and analyze the\nunderstanding and characteristics of negation in various fields such as\nphilosophy, logic, and linguistics etc. Based on the distinction between the\nconcepts of contradiction and opposition, we propose that there are three\ndifferent types of negation in knowledge from a conceptual perspective:\ncontradictory negation, opposite negation, and intermediary negation. To\nestablish a mathematical foundation that fully reflects the intrinsic\nconnections, properties, and laws of these different forms of negation, we\nintroduce SCOI: sets with contradictory negation, opposite negation and\nintermediary negation, and LCOI: logic with contradictory negation, opposite\nnegation and intermediary negation, and we proved the main operational\nproperties of SCOI as well as the formal inference relations in LCOI.", "AI": {"tldr": "The paper explores negation in AI knowledge processing by examining its understanding and characteristics across philosophy, logic, and linguistics. It proposes three types of negation (contradictory, opposite, intermediary) and establishes a mathematical foundation through SCOI and LCOI.", "motivation": "To address the fundamental issue of negation in AI knowledge processing and research by understanding its nature across multiple disciplines.", "method": "Analysis of negation concepts from philosophy, logic, and linguistics leading to the proposition of three types of negation. Introduction of SCOI and LCOI to establish a mathematical foundation for these negations.", "result": "Three types of negation identified; SCOI and LCOI introduced with main operational properties proved.", "conclusion": "Negation in knowledge can be categorized into three types with a mathematical framework established to reflect their intrinsic connections, properties, and laws."}}
{"id": "2505.23839", "pdf": "https://arxiv.org/pdf/2505.23839", "abs": "https://arxiv.org/abs/2505.23839", "authors": ["Zaixi Zhang", "Zhenghong Zhou", "Ruofan Jin", "Le Cong", "Mengdi Wang"], "title": "GeneBreaker: Jailbreak Attacks against DNA Language Models with Pathogenicity Guidance", "categories": ["cs.CR", "q-bio.GN"], "comment": null, "summary": "DNA, encoding genetic instructions for almost all living organisms, fuels\ngroundbreaking advances in genomics and synthetic biology. Recently, DNA\nFoundation Models have achieved success in designing synthetic functional DNA\nsequences, even whole genomes, but their susceptibility to jailbreaking remains\nunderexplored, leading to potential concern of generating harmful sequences\nsuch as pathogens or toxin-producing genes. In this paper, we introduce\nGeneBreaker, the first framework to systematically evaluate jailbreak\nvulnerabilities of DNA foundation models. GeneBreaker employs (1) an LLM agent\nwith customized bioinformatic tools to design high-homology, non-pathogenic\njailbreaking prompts, (2) beam search guided by PathoLM and log-probability\nheuristics to steer generation toward pathogen-like sequences, and (3) a\nBLAST-based evaluation pipeline against a curated Human Pathogen Database\n(JailbreakDNABench) to detect successful jailbreaks. Evaluated on our\nJailbreakDNABench, GeneBreaker successfully jailbreaks the latest Evo series\nmodels across 6 viral categories consistently (up to 60\\% Attack Success Rate\nfor Evo2-40B). Further case studies on SARS-CoV-2 spike protein and HIV-1\nenvelope protein demonstrate the sequence and structural fidelity of jailbreak\noutput, while evolutionary modeling of SARS-CoV-2 underscores biosecurity\nrisks. Our findings also reveal that scaling DNA foundation models amplifies\ndual-use risks, motivating enhanced safety alignment and tracing mechanisms.\nOur code is at https://github.com/zaixizhang/GeneBreaker.", "AI": {"tldr": "This paper introduces GeneBreaker, a framework to evaluate vulnerabilities of DNA foundation models. It successfully jailbreaks the latest Evo series models across 6 viral categories and demonstrates biosecurity risks.", "motivation": "DNA Foundation Models have achieved success in designing synthetic functional DNA sequences but their susceptibility to jailbreaking remains underexplored, leading to potential concern of generating harmful sequences such as pathogens or toxin-producing genes.", "method": "GeneBreaker employs an LLM agent with customized bioinformatic tools, beam search guided by PathoLM and log-probability heuristics, and a BLAST-based evaluation pipeline against a curated Human Pathogen Database (JailbreakDNABench).", "result": "Evaluated on JailbreakDNABench, GeneBreaker successfully jailbreaks the latest Evo series models across 6 viral categories consistently (up to 60% Attack Success Rate for Evo2-40B). Further case studies on SARS-CoV-2 spike protein and HIV-1 envelope protein demonstrate the sequence and structural fidelity of jailbreak output.", "conclusion": "Our findings reveal that scaling DNA foundation models amplifies dual-use risks, motivating enhanced safety alignment and tracing mechanisms."}}
{"id": "2505.23933", "pdf": "https://arxiv.org/pdf/2505.23933", "abs": "https://arxiv.org/abs/2505.23933", "authors": ["Galen Pogoncheff", "Michael Beyeler"], "title": "BIRD: Behavior Induction via Representation-structure Distillation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Human-aligned deep learning models exhibit behaviors consistent with human\nvalues, such as robustness, fairness, and honesty. Transferring these\nbehavioral properties to models trained on different tasks or data\ndistributions remains challenging: aligned behavior is easily forgotten during\nfine-tuning, and collecting task-specific data that preserves this behavior can\nbe prohibitively costly. We introduce BIRD (Behavior Induction via\nRepresentation-structure Distillation), a flexible framework for transferring\naligned behavior by matching the internal representation structure of a student\nmodel to that of a teacher. Applied to out-of-distribution robustness in image\nclassification, BIRD outperforms fine-tuning, transfer learning, and continual\nlearning methods, improving robust accuracy by up to 16% over the next\nstrongest baseline. It remains effective even when the teacher is trained on a\nmuch simpler dataset and is $25 \\times$ smaller than the student. In a\nlarge-scale study of over 400 teacher-student pairs, we show that three\ninterpretable and computable properties of the teacher's representations (i.e.,\ntask relevance, behavioral relevance, and complementary knowledge) explain up\nto 85% of the variance in transfer success. These insights offer practical\nguidance for teacher selection and design. BIRD turns small, well-aligned\nmodels into scalable alignment seeds, removing a key bottleneck in deploying\nsafe AI systems in the wild.", "AI": {"tldr": "BIRD is a framework that transfers aligned behavior by matching the internal representation structure of a student model to that of a teacher, improving robust accuracy and offering practical guidance for teacher selection and design.", "motivation": "Transferring behavioral properties like robustness, fairness, and honesty to models trained on different tasks or data distributions is challenging as aligned behavior is easily forgotten during fine-tuning and collecting task-specific data can be costly.", "method": "BIRD matches the internal representation structure of a student model to that of a teacher. It focuses on three interpretable and computable properties of the teacher's representations: task relevance, behavioral relevance, and complementary knowledge.", "result": "BIRD outperforms fine-tuning, transfer learning, and continual learning methods, improving robust accuracy by up to 16% over the next strongest baseline. It remains effective even when the teacher is trained on a much simpler dataset and is 25 times smaller than the student.", "conclusion": "BIRD turns small, well-aligned models into scalable alignment seeds, removing a key bottleneck in deploying safe AI systems in the wild."}}
{"id": "2505.24426", "pdf": "https://arxiv.org/pdf/2505.24426", "abs": "https://arxiv.org/abs/2505.24426", "authors": ["David Gamez"], "title": "P: A Universal Measure of Predictive Intelligence", "categories": ["cs.AI"], "comment": null, "summary": "Over the last thirty years, considerable progress has been made with the\ndevelopment of systems that can drive cars, play games, predict protein folding\nand generate natural language. These systems are described as intelligent and\nthere has been a great deal of talk about the rapid increase in artificial\nintelligence and its potential dangers. However, our theoretical understanding\nof intelligence and ability to measure it lag far behind our capacity for\nbuilding systems that mimic intelligent human behaviour. There is no commonly\nagreed definition of the intelligence that AI systems are said to possess.\nNo-one has developed a practical measure that would enable us to compare the\nintelligence of humans, animals and AIs on a single ratio scale.\n  This paper sets out a new universal measure of intelligence that is based on\nthe hypothesis that prediction is the most important component of intelligence.\nAs an agent interacts with its normal environment, the accuracy of its\npredictions is summed up and the complexity of its predictions and perceived\nenvironment is accounted for using Kolmogorov complexity. Two experiments were\ncarried out to evaluate the practical feasibility of the algorithm. These\ndemonstrated that it could measure the intelligence of an agent embodied in a\nvirtual maze and an agent that makes predictions about time-series data. This\nuniversal measure could be the starting point for a new comparative science of\nintelligence that ranks humans, animals and AIs on a single ratio scale.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u80fd\u529b\u7684\u667a\u80fd\u901a\u7528\u5ea6\u91cf\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u53ef\u884c\u6027\uff0c\u53ef\u4e3a\u4eba\u7c7b\u3001\u52a8\u7269\u548cAI\u63d0\u4f9b\u5355\u4e00\u6bd4\u4f8b\u5c3a\u4e0a\u7684\u667a\u80fd\u6392\u540d\u3002", "motivation": "\u5f53\u524d\u5bf9\u667a\u80fd\u7684\u7406\u89e3\u548c\u6d4b\u91cf\u8fdc\u8fdc\u843d\u540e\u4e8e\u6784\u5efa\u6a21\u4eff\u4eba\u7c7b\u667a\u80fd\u884c\u4e3a\u7cfb\u7edf\u7684\u5b9e\u9645\u80fd\u529b\uff0c\u7f3a\u4e4f\u7edf\u4e00\u5b9a\u4e49\u548c\u5b9e\u7528\u6d4b\u91cf\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u9884\u6d4b\u662f\u667a\u80fd\u6700\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u7684\u5047\u8bbe\uff0c\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u901a\u7528\u667a\u80fd\u5ea6\u91cf\u65b9\u6cd5\uff1a\u901a\u8fc7\u4e0e\u73af\u5883\u4ea4\u4e92\u65f6\u9884\u6d4b\u51c6\u786e\u6027\u603b\u548c\uff0c\u7ed3\u5408\u67ef\u5c14\u83ab\u54e5\u6d1b\u592b\u590d\u6742\u6027\u8861\u91cf\u9884\u6d4b\u548c\u611f\u77e5\u73af\u5883\u590d\u6742\u5ea6\u3002", "result": "\u4e24\u4e2a\u5b9e\u9a8c\u8868\u660e\u8be5\u7b97\u6cd5\u53ef\u884c\uff0c\u80fd\u591f\u5ea6\u91cf\u865a\u62df\u8ff7\u5bab\u4e2d\u4ee3\u7406\u548c\u65f6\u95f4\u5e8f\u5217\u6570\u636e\u9884\u6d4b\u4ee3\u7406\u7684\u667a\u80fd\u3002", "conclusion": "\u8fd9\u79cd\u65b0\u901a\u7528\u667a\u80fd\u5ea6\u91cf\u53ef\u80fd\u662f\u65b0\u6bd4\u8f83\u667a\u80fd\u79d1\u5b66\u7684\u8d77\u70b9\uff0c\u53ef\u5728\u5355\u4e00\u6bd4\u4f8b\u5c3a\u4e0a\u5bf9\u4eba\u7c7b\u3001\u52a8\u7269\u548cAI\u8fdb\u884c\u6392\u540d\u3002"}}
{"id": "2505.23847", "pdf": "https://arxiv.org/pdf/2505.23847", "abs": "https://arxiv.org/abs/2505.23847", "authors": ["Ronny Ko", "Jiseong Jeong", "Shuyuan Zheng", "Chuan Xiao", "Taewan Kim", "Makoto Onizuka", "Wonyong Shin"], "title": "Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are rapidly evolving into autonomous agents that\ncooperate across organizational boundaries, enabling joint disaster response,\nsupply-chain optimization, and other tasks that demand decentralized expertise\nwithout surrendering data ownership. Yet, cross-domain collaboration shatters\nthe unified trust assumptions behind current alignment and containment\ntechniques. An agent benign in isolation may, when receiving messages from an\nuntrusted peer, leak secrets or violate policy, producing risks driven by\nemergent multi-agent dynamics rather than classical software bugs. This\nposition paper maps the security agenda for cross-domain multi-agent LLM\nsystems. We introduce seven categories of novel security challenges, for each\nof which we also present plausible attacks, security evaluation metrics, and\nfuture research guidelines.", "AI": {"tldr": "This position paper maps the security agenda for cross-domain multi-agent LLM systems, introducing seven categories of novel security challenges with plausible attacks, security evaluation metrics, and future research guidelines.", "motivation": "Large language models are evolving into autonomous agents that can collaborate across organizational boundaries for tasks like disaster response and supply-chain optimization. However, cross-domain collaboration breaks the unified trust assumptions behind current alignment and containment techniques, leading to potential risks from emergent multi-agent dynamics.", "method": "The paper identifies and categorizes seven novel security challenges for cross-domain multi-agent LLM systems, providing plausible attacks, security evaluation metrics, and future research guidelines for each category.", "result": "The paper successfully outlines a security agenda by defining the challenges, potential attacks, and necessary security measures for cross-domain multi-agent LLM systems.", "conclusion": "Cross-domain multi-agent LLM systems present new security challenges that require further research and development of appropriate security measures and evaluation metrics."}}
{"id": "2505.23939", "pdf": "https://arxiv.org/pdf/2505.23939", "abs": "https://arxiv.org/abs/2505.23939", "authors": ["Andrea Mattia Garavagno", "Edoardo Ragusa", "Antonio Frisoli", "Paolo Gastaldo"], "title": "Searching Neural Architectures for Sensor Nodes on IoT Gateways", "categories": ["cs.LG", "cs.NI"], "comment": null, "summary": "This paper presents an automatic method for the design of Neural Networks\n(NNs) at the edge, enabling Machine Learning (ML) access even in\nprivacy-sensitive Internet of Things (IoT) applications. The proposed method\nruns on IoT gateways and designs NNs for connected sensor nodes without sharing\nthe collected data outside the local network, keeping the data in the site of\ncollection. This approach has the potential to enable ML for Healthcare\nInternet of Things (HIoT) and Industrial Internet of Things (IIoT), designing\nhardware-friendly and custom NNs at the edge for personalized healthcare and\nadvanced industrial services such as quality control, predictive maintenance,\nor fault diagnosis. By preventing data from being disclosed to cloud services,\nthis method safeguards sensitive information, including industrial secrets and\npersonal data. The outcomes of a thorough experimental session confirm that --\non the Visual Wake Words dataset -- the proposed approach can achieve\nstate-of-the-art results by exploiting a search procedure that runs in less\nthan 10 hours on the Raspberry Pi Zero 2.", "AI": {"tldr": "This paper proposes an automatic method for designing Neural Networks at the edge, enabling Machine Learning access in privacy-sensitive IoT applications without sharing collected data outside the local network. The experimental results on Visual Wake Words dataset show that this method can achieve state-of-the-art results by running a search procedure within 10 hours on Raspberry Pi Zero 2.", "motivation": "To enable Machine Learning access in privacy-sensitive Internet of Things applications while safeguarding sensitive information including industrial secrets and personal data.", "method": "The proposed method runs on IoT gateways and designs Neural Networks for connected sensor nodes without sharing the collected data outside the local network, keeping the data in the site of collection.", "result": "The outcomes of a thorough experimental session confirm that -- on the Visual Wake Words dataset -- the proposed approach can achieve state-of-the-art results by exploiting a search procedure that runs in less than 10 hours on the Raspberry Pi Zero 2.", "conclusion": "This method has the potential to enable ML for Healthcare Internet of Things and Industrial Internet of Things, designing hardware-friendly and custom NNs at the edge for personalized healthcare and advanced industrial services such as quality control, predictive maintenance, or fault diagnosis."}}
{"id": "2505.24442", "pdf": "https://arxiv.org/pdf/2505.24442", "abs": "https://arxiv.org/abs/2505.24442", "authors": ["Zhentao Xie", "Chengcheng Han", "Jinxin Shi", "Wenjun Cui", "Xin Zhao", "Xingjiao Wu", "Jiabao Zhao"], "title": "RMoA: Optimizing Mixture-of-Agents through Diversity Maximization and Residual Compensation", "categories": ["cs.AI"], "comment": "Accepted by ACL 2025 (Findings)", "summary": "Although multi-agent systems based on large language models show strong\ncapabilities on multiple tasks, they are still limited by high computational\noverhead, information loss, and robustness. Inspired by ResNet's residual\nlearning, we propose Residual Mixture-of-Agents (RMoA), integrating residual\nconnections to optimize efficiency and reliability. To maximize information\nutilization from model responses while minimizing computational costs, we\ninnovatively design an embedding-based diversity selection mechanism that\ngreedily selects responses via vector similarity. Furthermore, to mitigate\niterative information degradation, we introduce a Residual Extraction Agent to\npreserve cross-layer incremental information by capturing inter-layer response\ndifferences, coupled with a Residual Aggregation Agent for hierarchical\ninformation integration. Additionally, we propose an adaptive termination\nmechanism that dynamically halts processing based on residual convergence,\nfurther improving inference efficiency. RMoA achieves state-of-the-art\nperformance on the benchmarks of across alignment, mathematical reasoning, code\ngeneration, and multitasking understanding, while significantly reducing\ncomputational overhead. Code is available at\nhttps://github.com/mindhunter01/RMoA.", "AI": {"tldr": "A new multi-agent system called Residual Mixture-of-Agents (RMoA) is proposed, which uses residual connections, a diversity selection mechanism, residual agents and an adaptive termination mechanism to improve efficiency, reliability and performance while reducing computational overhead.", "motivation": "Existing multi-agent systems based on large language models have limitations such as high computational overhead, information loss and lack of robustness.", "method": "The RMoA integrates residual connections inspired by ResNet's residual learning. It includes an embedding-based diversity selection mechanism for selecting responses via vector similarity, a Residual Extraction Agent for preserving cross-layer incremental information and a Residual Aggregation Agent for hierarchical information integration. There is also an adaptive termination mechanism that halts processing based on residual convergence.", "result": "RMoA achieves state-of-the-art performance on benchmarks across alignment, mathematical reasoning, code generation and multitasking understanding, with significantly reduced computational overhead.", "conclusion": "The proposed RMoA system improves efficiency, reliability and performance in multi-agent systems while reducing computational costs."}}
{"id": "2505.23849", "pdf": "https://arxiv.org/pdf/2505.23849", "abs": "https://arxiv.org/abs/2505.23849", "authors": ["Kaveen Hiniduma", "Zilinghan Li", "Aditya Sinha", "Ravi Madduri", "Suren Byna"], "title": "CADRE: Customizable Assurance of Data Readiness in Privacy-Preserving Federated Learning", "categories": ["cs.CR", "cs.AI", "cs.LG"], "comment": "10 pages, 7 figures, 2 tables", "summary": "Privacy-Preserving Federated Learning (PPFL) is a decentralized machine\nlearning approach where multiple clients train a model collaboratively. PPFL\npreserves privacy and security of the client's data by not exchanging it.\nHowever, ensuring that data at each client is of high quality and ready for\nfederated learning (FL) is a challenge due to restricted data access. In this\npaper, we introduce CADRE (Customizable Assurance of Data REadiness) for FL, a\nnovel framework that allows users to define custom data readiness (DR)\nstandards, metrics, rules, and remedies tailored to specific FL tasks. Our\nframework generates comprehensive DR reports based on the user-defined metrics,\nrules, and remedies to ensure datasets are optimally prepared for FL while\npreserving privacy. We demonstrate the framework's practical application by\nintegrating it into an existing PPFL framework. We conducted experiments across\nsix diverse datasets, addressing seven different DR issues. The results\nillustrate the framework's versatility and effectiveness in ensuring DR across\nvarious dimensions, including data quality, privacy, and fairness. This\napproach enhances the performance and reliability of FL models as well as\nutilizes valuable resources by identifying and addressing data-related issues\nbefore the training phase.", "AI": {"tldr": "CADRE is a novel framework introduced in this paper for ensuring data readiness in privacy-preserving federated learning. It allows users to define custom standards, metrics, rules, and remedies tailored to specific tasks. The framework generates comprehensive reports to ensure datasets are optimally prepared while preserving privacy.", "motivation": "The motivation behind this paper is the challenge of ensuring high-quality data at each client in privacy-preserving federated learning (PPFL), especially given the restricted access to data. This can hinder the performance and reliability of FL models.", "method": "The method involves introducing CADRE, a framework that enables users to define custom data readiness standards, metrics, rules, and remedies. Comprehensive DR reports are generated based on these user-defined parameters to prepare datasets optimally for federated learning while maintaining privacy.", "result": "Experiments conducted across six diverse datasets addressing seven different DR issues demonstrated the versatility and effectiveness of the framework in ensuring data readiness across various dimensions such as quality, privacy, and fairness.", "conclusion": "CADRE enhances the performance and reliability of federated learning models by identifying and addressing data-related issues before the training phase, making valuable resources more efficient."}}
{"id": "2505.23941", "pdf": "https://arxiv.org/pdf/2505.23941", "abs": "https://arxiv.org/abs/2505.23941", "authors": ["An Vo", "Khai-Nguyen Nguyen", "Mohammad Reza Taesiri", "Vy Tuong Dang", "Anh Totti Nguyen", "Daeyoung Kim"], "title": "Vision Language Models are Biased", "categories": ["cs.LG", "cs.CV"], "comment": "Code and qualitative examples are available at:\n  vlmsarebiased.github.io", "summary": "Large language models (LLMs) memorize a vast amount of prior knowledge from\nthe Internet that help them on downstream tasks but also may notoriously sway\ntheir outputs towards wrong or biased answers. In this work, we test how the\nknowledge about popular subjects hurt the accuracy of vision language models\n(VLMs) on standard, objective visual tasks of counting and identification. We\nfind that state-of-the-art VLMs are strongly biased (e.g, unable to recognize a\nfourth stripe has been added to a 3-stripe Adidas logo) scoring an average of\n17.05% accuracy in counting (e.g., counting stripes in an Adidas-like logo)\nacross 7 diverse domains from animals, logos, chess, board games, optical\nillusions, to patterned grids. Insert text (e.g., \"Adidas\") describing the\nsubject name into the counterfactual image further decreases VLM accuracy. The\nbiases in VLMs are so strong that instructing them to double-check their\nresults or rely exclusively on image details to answer improves counting\naccuracy by only +2 points, on average. Our work presents an interesting\nfailure mode in VLMs and an automated framework for testing VLM biases. Code\nand data are available at: vlmsarebiased.github.io.", "AI": {"tldr": "Large language models (LLMs) can memorize knowledge that may lead to wrong or biased answers. This study examines how such knowledge negatively impacts the accuracy of vision language models (VLMs) in counting and identification tasks.", "motivation": "To understand how prior knowledge affects the performance of VLMs in objective visual tasks.", "method": "Testing VLMs on counting and identification tasks across diverse domains, analyzing the impact of inserting subject-related text into images, and evaluating the effect of instructing VLMs to double-check their results or rely on image details.", "result": "State-of-the-art VLMs show strong biases, scoring 17.05% accuracy in counting tasks across 7 domains. Inserting subject-related text decreases accuracy further. Instructing VLMs to double-check or focus on image details improves accuracy by only +2 points on average.", "conclusion": "The study reveals a significant failure mode in VLMs due to strong biases and presents an automated framework for testing these biases."}}
{"id": "2505.24458", "pdf": "https://arxiv.org/pdf/2505.24458", "abs": "https://arxiv.org/abs/2505.24458", "authors": ["Tianlong Yu", "Chenghang Ye", "Zheyu Yang", "Ziyi Zhou", "Cui Tang", "Zui Tao", "Jun Zhang", "Kailong Wang", "Liting Zhou", "Yang Yang", "Ting Bi"], "title": "SEAR: A Multimodal Dataset for Analyzing AR-LLM-Driven Social Engineering Behaviors", "categories": ["cs.AI"], "comment": null, "summary": "The SEAR Dataset is a novel multimodal resource designed to study the\nemerging threat of social engineering (SE) attacks orchestrated through\naugmented reality (AR) and multimodal large language models (LLMs). This\ndataset captures 180 annotated conversations across 60 participants in\nsimulated adversarial scenarios, including meetings, classes and networking\nevents. It comprises synchronized AR-captured visual/audio cues (e.g., facial\nexpressions, vocal tones), environmental context, and curated social media\nprofiles, alongside subjective metrics such as trust ratings and susceptibility\nassessments. Key findings reveal SEAR's alarming efficacy in eliciting\ncompliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and\nhijacking trust (76.7% post-interaction trust surge). The dataset supports\nresearch in detecting AR-driven SE attacks, designing defensive frameworks, and\nunderstanding multimodal adversarial manipulation. Rigorous ethical safeguards,\nincluding anonymization and IRB compliance, ensure responsible use. The SEAR\ndataset is available at https://github.com/INSLabCN/SEAR-Dataset.", "AI": {"tldr": "The SEAR Dataset is a multimodal resource for studying social engineering attacks in AR and LLMs environments, revealing high efficacy in eliciting compliance and hijacking trust.", "motivation": "To address the emerging threat of social engineering attacks orchestrated through augmented reality and multimodal large language models.", "method": "Capturing 180 annotated conversations across 60 participants in simulated adversarial scenarios, including meetings, classes, and networking events. The dataset includes AR-captured visual/audio cues, environmental context, curated social media profiles, and subjective metrics such as trust ratings and susceptibility assessments.", "result": "Key findings reveal alarming efficacy in eliciting compliance (e.g., 93.3% phishing link clicks, 85% call acceptance) and hijacking trust (76.7% post-interaction trust surge).", "conclusion": "The dataset supports research in detecting AR-driven SE attacks, designing defensive frameworks, and understanding multimodal adversarial manipulation, with rigorous ethical safeguards ensuring responsible use."}}
{"id": "2505.23873", "pdf": "https://arxiv.org/pdf/2505.23873", "abs": "https://arxiv.org/abs/2505.23873", "authors": ["Hongrui Peng", "Haolang Lu", "Yuanlong Yu", "Weiye Fu", "Kun Wang", "Guoshun Nan"], "title": "KGMark: A Diffusion Watermark for Knowledge Graphs", "categories": ["cs.CR", "cs.AI", "68T07", "I.2.8"], "comment": "20pages, 6figures", "summary": "Knowledge graphs (KGs) are ubiquitous in numerous real-world applications,\nand watermarking facilitates protecting intellectual property and preventing\npotential harm from AI-generated content. Existing watermarking methods mainly\nfocus on static plain text or image data, while they can hardly be applied to\ndynamic graphs due to spatial and temporal variations of structured data. This\nmotivates us to propose KGMARK, the first graph watermarking framework that\naims to generate robust, detectable, and transparent diffusion fingerprints for\ndynamic KG data. Specifically, we propose a novel clustering-based alignment\nmethod to adapt the watermark to spatial variations. Meanwhile, we present a\nredundant embedding strategy to harden the diffusion watermark against various\nattacks, facilitating the robustness of the watermark to the temporal\nvariations. Additionally, we introduce a novel learnable mask matrix to improve\nthe transparency of diffusion fingerprints. By doing so, our KGMARK properly\ntackles the variation challenges of structured data. Experiments on various\npublic benchmarks show the effectiveness of our proposed KGMARK.", "AI": {"tldr": "This paper introduces KGMARK, the first graph watermarking framework for dynamic knowledge graph data, which generates robust, detectable, and transparent diffusion fingerprints through novel methods and strategies.", "motivation": "Existing watermarking methods are mainly designed for static plain text or image data, but they struggle to be applied to dynamic graphs due to spatial and temporal variations of structured data.", "method": "The authors propose a clustering-based alignment method to adapt watermarks to spatial variations, a redundant embedding strategy to strengthen robustness against attacks and temporal variations, and a learnable mask matrix to enhance transparency of the diffusion fingerprints.", "result": "Experiments on various public benchmarks demonstrate the effectiveness of the proposed KGMARK framework.", "conclusion": "KGMARK successfully addresses the challenges posed by variations in structured data and provides an effective solution for watermarking dynamic knowledge graph data."}}
{"id": "2505.23942", "pdf": "https://arxiv.org/pdf/2505.23942", "abs": "https://arxiv.org/abs/2505.23942", "authors": ["Gaurav Sarkar", "Jay Gala", "Subarna Tripathi"], "title": "SG-Blend: Learning an Interpolation Between Improved Swish and GELU for Robust Neural Representations", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "The design of activation functions remains a pivotal component in optimizing\ndeep neural networks. While prevailing choices like Swish and GELU demonstrate\nconsiderable efficacy, they often exhibit domain-specific optima. This work\nintroduces SG-Blend, a novel activation function that blends our proposed\nSSwish, a first-order symmetric variant of Swish and the established GELU\nthrough dynamic interpolation. By adaptively blending these constituent\nfunctions via learnable parameters, SG-Blend aims to harness their\ncomplementary strengths: SSwish's controlled non-monotonicity and symmetry, and\nGELU's smooth, probabilistic profile, to achieve a more universally robust\nbalance between model expressivity and gradient stability. We conduct\ncomprehensive empirical evaluations across diverse modalities and\narchitectures, showing performance improvements across all considered natural\nlanguage and computer vision tasks and models. These results, achieved with\nnegligible computational overhead, underscore SG-Blend's potential as a\nversatile, drop-in replacement that consistently outperforms strong\ncontemporary baselines. The code is available at\nhttps://anonymous.4open.science/r/SGBlend-6CBC.", "AI": {"tldr": "The paper proposes SG-Blend, a novel activation function combining SSwish and GELU through dynamic interpolation. It offers improvements in model expressivity and gradient stability across diverse tasks with minimal computational overhead.", "motivation": "Current activation functions like Swish and GELU are effective but often domain-specific. The authors aim to create a more universally robust activation function by blending complementary strengths of different functions.", "method": "SG-Blend blends SSwish (a first-order symmetric variant of Swish) and GELU via learnable parameters for dynamic interpolation. This approach leverages SSwish's controlled non-monotonicity and symmetry, and GELU's smooth probabilistic profile.", "result": "SG-Blend demonstrates performance improvements across all considered natural language and computer vision tasks and models, with negligible computational overhead.", "conclusion": "SG-Blend is presented as a versatile, drop-in replacement for existing activation functions, consistently outperforming strong contemporary baselines."}}
{"id": "2505.24478", "pdf": "https://arxiv.org/pdf/2505.24478", "abs": "https://arxiv.org/abs/2505.24478", "authors": ["Vasilije Markovic", "Lazar Obradovic", "Laszlo Hajdu", "Jovan Pavlovic"], "title": "Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning", "categories": ["cs.AI", "cs.CL"], "comment": "This is a preliminary version. A revised and expanded version is in\n  preparation", "summary": "Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) results\nin complex systems with numerous hyperparameters that directly affect\nperformance. While such systems are increasingly common in retrieval-augmented\ngeneration, the role of systematic hyperparameter optimization remains\nunderexplored. In this paper, we study this problem in the context of Cognee, a\nmodular framework for end-to-end KG construction and retrieval. Using three\nmulti-hop QA benchmarks (HotPotQA, TwoWikiMultiHop, and MuSiQue) we optimize\nparameters related to chunking, graph construction, retrieval, and prompting.\nEach configuration is scored using established metrics (exact match, F1, and\nDeepEval's LLM-based correctness metric). Our results demonstrate that\nmeaningful gains can be achieved through targeted tuning. While the gains are\nconsistent, they are not uniform, with performance varying across datasets and\nmetrics. This variability highlights both the value of tuning and the\nlimitations of standard evaluation measures. While demonstrating the immediate\npotential of hyperparameter tuning, we argue that future progress will depend\nnot only on architectural advances but also on clearer frameworks for\noptimization and evaluation in complex, modular systems.", "AI": {"tldr": "Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) leads to complex systems with numerous hyperparameters that directly affect performance. This paper explores the role of systematic hyperparameter optimization in such systems, using Cognee framework and three multi-hop QA benchmarks.", "motivation": "While integrating LLMs with KGs is common in retrieval-augmented generation, the role of systematic hyperparameter optimization remains underexplored.", "method": "The paper optimizes parameters related to chunking, graph construction, retrieval, and prompting using Cognee, a modular framework for end-to-end KG construction and retrieval. Each configuration is scored using established metrics.", "result": "Meaningful gains can be achieved through targeted tuning, but these gains are not uniform across datasets and metrics.", "conclusion": "Hyperparameter tuning shows immediate potential, but future progress will depend on clearer frameworks for optimization and evaluation in complex, modular systems."}}
{"id": "2505.23880", "pdf": "https://arxiv.org/pdf/2505.23880", "abs": "https://arxiv.org/abs/2505.23880", "authors": ["Madelyne Xiao", "Palak Jain", "Micha Gorelick", "Sarah Scheffler"], "title": "Synopsis: Secure and private trend inference from encrypted semantic embeddings", "categories": ["cs.CR"], "comment": null, "summary": "WhatsApp and many other commonly used communication platforms guarantee\nend-to-end encryption (E2EE), which requires that service providers lack the\ncryptographic keys to read communications on their own platforms. WhatsApp's\nprivacy-preserving design makes it difficult to study important phenomena like\nthe spread of misinformation or political messaging, as users have a clear\nexpectation and desire for privacy and little incentive to forfeit that privacy\nin the process of handing over raw data to researchers, journalists, or other\nparties.\n  We introduce Synopsis, a secure architecture for analyzing messaging trends\nin consensually-donated E2EE messages using message embeddings. Since the goal\nof this system is investigative journalism workflows, Synopsis must facilitate\nboth exploratory and targeted analyses -- a challenge for systems using\ndifferential privacy (DP), and, for different reasons, a challenge for private\ncomputation approaches based on cryptography. To meet these challenges, we\ncombine techniques from the local and central DP models and wrap the system in\nmalicious-secure multi-party computation to ensure the DP query architecture is\nthe only way to access messages, preventing any party from directly viewing\nstored message embeddings.\n  Evaluations on a dataset of Hindi-language WhatsApp messages (34,024 messages\nrepresented as 500-dimensional embeddings) demonstrate the efficiency and\naccuracy of our approach. Queries on this data run in about 30 seconds, and the\naccuracy of the fine-grained interface exceeds 94% on benchmark tasks.", "AI": {"tldr": "This paper introduces Synopsis, a secure architecture for analyzing messaging trends in consensually-donated E2EE messages using message embeddings. It combines techniques from the local and central DP models and wraps the system in malicious-secure multi-party computation to ensure privacy.", "motivation": "The motivation of this paper is to study important phenomena like the spread of misinformation or political messaging on platforms with end-to-end encryption (E2EE), while preserving user privacy.", "method": "Synopsis uses message embeddings to analyze messaging trends in consensually-donated E2EE messages. It combines techniques from the local and central differential privacy (DP) models and wraps the system in malicious-secure multi-party computation to ensure the DP query architecture is the only way to access messages.", "result": "Evaluations on a dataset of Hindi-language WhatsApp messages demonstrate the efficiency and accuracy of Synopsis. Queries run in about 30 seconds, and the accuracy of the fine-grained interface exceeds 94% on benchmark tasks.", "conclusion": "Synopsis provides a secure and efficient method for analyzing messaging trends in consensually-donated E2EE messages while preserving privacy."}}
{"id": "2505.23947", "pdf": "https://arxiv.org/pdf/2505.23947", "abs": "https://arxiv.org/abs/2505.23947", "authors": ["Samuel M\u00fcller", "Arik Reuter", "Noah Hollmann", "David R\u00fcgamer", "Frank Hutter"], "title": "Position: The Future of Bayesian Prediction Is Prior-Fitted", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted as position paper at ICML 2025", "summary": "Training neural networks on randomly generated artificial datasets yields\nBayesian models that capture the prior defined by the dataset-generating\ndistribution. Prior-data Fitted Networks (PFNs) are a class of methods designed\nto leverage this insight. In an era of rapidly increasing computational\nresources for pre-training and a near stagnation in the generation of new\nreal-world data in many applications, PFNs are poised to play a more important\nrole across a wide range of applications. They enable the efficient allocation\nof pre-training compute to low-data scenarios. Originally applied to small\nBayesian modeling tasks, the field of PFNs has significantly expanded to\naddress more complex domains and larger datasets. This position paper argues\nthat PFNs and other amortized inference approaches represent the future of\nBayesian inference, leveraging amortized learning to tackle data-scarce\nproblems. We thus believe they are a fruitful area of research. In this\nposition paper, we explore their potential and directions to address their\ncurrent limitations.", "AI": {"tldr": "Prior-data Fitted Networks (PFNs) use artificial datasets for training neural networks, leading to Bayesian models capturing the prior of the dataset-generating distribution. With increasing computational resources and limited real-world data in many applications, PFNs can efficiently allocate pre-training compute to low-data scenarios. Originally applied to small Bayesian modeling tasks, PFNs have expanded to more complex domains. This position paper argues that PFNs and other amortized inference approaches represent the future of Bayesian inference.", "motivation": "To explore the potential of Prior-data Fitted Networks (PFNs) and other amortized inference approaches as the future of Bayesian inference, especially in data-scarce problems.", "method": "Training neural networks on randomly generated artificial datasets to create Bayesian models that capture the prior defined by the dataset-generating distribution.", "result": "PFN's application has significantly expanded from small Bayesian modeling tasks to more complex domains and larger datasets.", "conclusion": "PFNs and other amortized inference approaches are believed to represent the future of Bayesian inference, and are considered a fruitful area of research."}}
{"id": "2505.24479", "pdf": "https://arxiv.org/pdf/2505.24479", "abs": "https://arxiv.org/abs/2505.24479", "authors": ["Sania Nayab", "Marco Simoni", "Giulio Rossolini"], "title": "Leveraging Knowledge Graphs and LLMs for Structured Generation of Misinformation", "categories": ["cs.AI", "cs.CL", "cs.SI"], "comment": null, "summary": "The rapid spread of misinformation, further amplified by recent advances in\ngenerative AI, poses significant threats to society, impacting public opinion,\ndemocratic stability, and national security. Understanding and proactively\nassessing these threats requires exploring methodologies that enable structured\nand scalable misinformation generation. In this paper, we propose a novel\napproach that leverages knowledge graphs (KGs) as structured semantic resources\nto systematically generate fake triplets. By analyzing the structural\nproperties of KGs, such as the distance between entities and their predicates,\nwe identify plausibly false relationships. These triplets are then used to\nguide large language models (LLMs) in generating misinformation statements with\nvarying degrees of credibility. By utilizing structured semantic relationships,\nour deterministic approach produces misinformation inherently challenging for\nhumans to detect, drawing exclusively upon publicly available KGs (e.g.,\nWikiGraphs).\n  Additionally, we investigate the effectiveness of LLMs in distinguishing\nbetween genuine and artificially generated misinformation. Our analysis\nhighlights significant limitations in current LLM-based detection methods,\nunderscoring the necessity for enhanced detection strategies and a deeper\nexploration of inherent biases in generative models.", "AI": {"tldr": "The paper proposes a novel approach leveraging knowledge graphs (KGs) to generate fake triplets that guide large language models (LLMs) in producing misinformation statements. It also investigates LLMs' effectiveness in distinguishing genuine and artificial misinformation.", "motivation": "To understand and assess the threats of misinformation amplified by generative AI, requiring methodologies for structured and scalable misinformation generation.", "method": "Proposes using knowledge graphs to identify plausibly false relationships and generate fake triplets, which then guide LLMs in creating misinformation statements with varying credibility degrees.", "result": "Demonstrates that the deterministic approach produces challenging misinformation for humans to detect, solely using publicly available KGs. Also finds significant limitations in current LLM-based detection methods.", "conclusion": "Highlights the necessity for improved detection strategies and further exploration of biases in generative models."}}
{"id": "2505.23938", "pdf": "https://arxiv.org/pdf/2505.23938", "abs": "https://arxiv.org/abs/2505.23938", "authors": ["Malithi Wanniarachchi Kankanamge", "Nick McKenna", "Santiago Carmona", "Syed Mhamudul Hasan", "Abdur R. Shahid", "Ahmed Imteaj"], "title": "Digital Forensic Investigation of the ChatGPT Windows Application", "categories": ["cs.CR"], "comment": null, "summary": "The ChatGPT Windows application offers better user interaction in the Windows\noperating system (OS) by enhancing productivity and streamlining the workflow\nof ChatGPT's utilization. However, there are potential misuses associated with\nthis application that require rigorous forensic analysis. This study presents a\nholistic forensic analysis of the ChatGPT Windows application, focusing on\nidentifying and recovering digital artifacts for investigative purposes. With\nthe use of widely popular and openly available digital forensics tools such as\nAutopsy, FTK Imager, Magnet RAM Capture, Wireshark, and Hex Workshop, this\nresearch explores different methods to extract and analyze cache, chat logs,\nmetadata, and network traffic from the application. Our key findings also\ndemonstrate the history of the application's chat, user interactions, and\nsystem-level traces that can be recovered even after deletion, providing\ncritical insights into the crime investigation and, thus, documenting and\noutlining a potential misuse report for digital forensics.", "AI": {"tldr": "The study conducts a forensic analysis of the ChatGPT Windows application, identifying methods to recover digital artifacts like cache, chat logs, metadata, and network traffic using various forensics tools. Critical insights are provided for crime investigation and misuse reporting even after data deletion.", "motivation": "To address the potential misuses of the ChatGPT Windows application by providing a comprehensive forensic analysis that can aid in crime investigation and digital forensics.", "method": "Using widely popular and openly available digital forensics tools such as Autopsy, FTK Imager, Magnet RAM Capture, Wireshark, and Hex Workshop to extract and analyze digital artifacts including cache, chat logs, metadata, and network traffic from the ChatGPT Windows application.", "result": "Successfully identified and recovered the history of the application's chat, user interactions, and system-level traces, even after they were deleted.", "conclusion": "This forensic analysis provides critical insights into investigating crimes involving the ChatGPT Windows application and outlines a potential misuse report for digital forensics."}}
{"id": "2505.23949", "pdf": "https://arxiv.org/pdf/2505.23949", "abs": "https://arxiv.org/abs/2505.23949", "authors": ["Xiang Meng", "Mehdi Makni", "Rahul Mazumder"], "title": "TSENOR: Highly-Efficient Algorithm for Finding Transposable N:M Sparse Masks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Network pruning reduces the computational requirements of large neural\nnetworks, with N:M sparsity -- retaining only N out of every M consecutive\nweights -- offering a compelling balance between compressed model quality and\nhardware acceleration. However, N:M sparsity only accelerates forward-pass\ncomputations, as N:M patterns are not preserved during matrix transposition,\nlimiting efficiency during training where both passes are computationally\nintensive. While transposable N:M sparsity has been proposed to address this\nlimitation, existing methods for finding transposable N:M sparse masks either\nfail to scale to large models or are restricted to M=4 which results in\nsuboptimal compression-accuracy trade-off. We introduce an efficient solver for\ntransposable N:M masks that scales to billion-parameter models. We formulate\nmask generation as optimal transport problems and solve through entropy\nregularization and Dykstra's algorithm, followed by a rounding procedure. Our\ntensor-based implementation exploits GPU parallelism, achieving up to 100x\nspeedup with only 1-10% error compared to existing methods. Our approach can be\nintegrated with layer-wise N:M pruning frameworks including Wanda, SparseGPT\nand ALPS to produce transposable N:M sparse models with arbitrary N:M values.\nExperiments show that LLaMA3.2-8B with transposable 16:32 sparsity maintains\nperformance close to its standard N:M counterpart and outperforms standard 2:4\nsparse model, showing the practical value of our approach.", "AI": {"tldr": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53ef\u8f6c\u7f6eN:M\u7a00\u758f\u6027\u63a9\u7801\u6c42\u89e3\u5668\uff0c\u80fd\u591f\u6269\u5c55\u5230\u5341\u4ebf\u53c2\u6570\u6a21\u578b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728LLaMA3.2-8B\u6a21\u578b\u4e0a\u7684\u6027\u80fd\u4f18\u52bf\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u8f6c\u7f6eN:M\u7a00\u758f\u6027\u63a9\u7801\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u6269\u5c55\u5230\u5927\u578b\u6a21\u578b\uff0c\u8981\u4e48\u53d7\u9650\u4e8eM=4\u7684\u60c5\u51b5\uff0c\u5bfc\u81f4\u538b\u7f29\u4e0e\u7cbe\u5ea6\u7684\u6743\u8861\u4e0d\u4f73\u3002", "method": "\u5c06\u63a9\u7801\u751f\u6210\u95ee\u9898\u8f6c\u5316\u4e3a\u6700\u4f18\u4f20\u8f93\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u71b5\u6b63\u5219\u5316\u3001Dykstra\u7b97\u6cd5\u548c\u820d\u5165\u8fc7\u7a0b\u89e3\u51b3\uff1b\u5229\u7528\u57fa\u4e8e\u5f20\u91cf\u7684\u5b9e\u73b0\u65b9\u5f0f\u5229\u7528GPU\u5e76\u884c\u6027\uff0c\u52a0\u901f\u8ba1\u7b97\u3002", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe100\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u4e14\u8bef\u5dee\u4ec5\u4e3a1-10%\uff1b\u5728LLaMA3.2-8B\u6a21\u578b\u4e0a\uff0c\u4f7f\u7528\u53ef\u8f6c\u7f6e16:32\u7a00\u758f\u6027\u65f6\u6027\u80fd\u63a5\u8fd1\u6807\u51c6N:M\u6a21\u578b\uff0c\u4f18\u4e8e\u6807\u51c62:4\u7a00\u758f\u6a21\u578b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6c42\u89e3\u5668\u80fd\u591f\u6709\u6548\u751f\u6210\u53ef\u8f6c\u7f6eN:M\u7a00\u758f\u6027\u63a9\u7801\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u6a21\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u4ef7\u503c\u3002"}}
{"id": "2505.24493", "pdf": "https://arxiv.org/pdf/2505.24493", "abs": "https://arxiv.org/abs/2505.24493", "authors": ["Xin Jing", "Jiadong Wang", "Iosif Tsangko", "Andreas Triantafyllopoulos", "Bj\u00f6rn W. Schuller"], "title": "MELT: Towards Automated Multimodal Emotion Data Annotation by Leveraging LLM Embedded Knowledge", "categories": ["cs.AI", "cs.SD", "eess.AS"], "comment": null, "summary": "Although speech emotion recognition (SER) has advanced significantly with\ndeep learning, annotation remains a major hurdle. Human annotation is not only\ncostly but also subject to inconsistencies annotators often have different\npreferences and may lack the necessary contextual knowledge, which can lead to\nvaried and inaccurate labels. Meanwhile, Large Language Models (LLMs) have\nemerged as a scalable alternative for annotating text data. However, the\npotential of LLMs to perform emotional speech data annotation without human\nsupervision has yet to be thoroughly investigated. To address these problems,\nwe apply GPT-4o to annotate a multimodal dataset collected from the sitcom\nFriends, using only textual cues as inputs. By crafting structured text\nprompts, our methodology capitalizes on the knowledge GPT-4o has accumulated\nduring its training, showcasing that it can generate accurate and contextually\nrelevant annotations without direct access to multimodal inputs. Therefore, we\npropose MELT, a multimodal emotion dataset fully annotated by GPT-4o. We\ndemonstrate the effectiveness of MELT by fine-tuning four self-supervised\nlearning (SSL) backbones and assessing speech emotion recognition performance\nacross emotion datasets. Additionally, our subjective experiments\\' results\ndemonstrate a consistence performance improvement on SER.", "AI": {"tldr": "The paper explores the use of GPT-4o for annotating a multimodal dataset derived from the sitcom Friends, using only textual cues as inputs. It proposes MELT, a multimodal emotion dataset fully annotated by GPT-4o, and demonstrates its effectiveness by fine-tuning SSL backbones and assessing SER performance.", "motivation": "To address the challenges of costly and inconsistent human annotation in speech emotion recognition (SER), and to investigate the potential of Large Language Models (LLMs) like GPT-4o to perform emotional speech data annotation without human supervision.", "method": "Apply GPT-4o to annotate a multimodal dataset collected from the sitcom Friends using structured text prompts with only textual cues as inputs. Propose MELT, a multimodal emotion dataset fully annotated by GPT-4o.", "result": "MELT demonstrates effectiveness in improving SER performance when used to fine-tune four self-supervised learning (SSL) backbones. Subjective experiments also show consistent performance improvement on SER.", "conclusion": "GPT-4o can generate accurate and contextually relevant annotations for emotional speech data without direct access to multimodal inputs, showcasing the potential of LLMs for scalable annotation in SER."}}
{"id": "2505.23968", "pdf": "https://arxiv.org/pdf/2505.23968", "abs": "https://arxiv.org/abs/2505.23968", "authors": ["Stephan Rabanser", "Ali Shahin Shamsabadi", "Olive Franzese", "Xiao Wang", "Adrian Weller", "Nicolas Papernot"], "title": "Confidential Guardian: Cryptographically Prohibiting the Abuse of Model Abstention", "categories": ["cs.CR", "cs.AI", "cs.CY", "cs.LG", "stat.ML"], "comment": "Proceedings of the 42nd International Conference on Machine Learning", "summary": "Cautious predictions -- where a machine learning model abstains when\nuncertain -- are crucial for limiting harmful errors in safety-critical\napplications. In this work, we identify a novel threat: a dishonest institution\ncan exploit these mechanisms to discriminate or unjustly deny services under\nthe guise of uncertainty. We demonstrate the practicality of this threat by\nintroducing an uncertainty-inducing attack called Mirage, which deliberately\nreduces confidence in targeted input regions, thereby covertly disadvantaging\nspecific individuals. At the same time, Mirage maintains high predictive\nperformance across all data points. To counter this threat, we propose\nConfidential Guardian, a framework that analyzes calibration metrics on a\nreference dataset to detect artificially suppressed confidence. Additionally,\nit employs zero-knowledge proofs of verified inference to ensure that reported\nconfidence scores genuinely originate from the deployed model. This prevents\nthe provider from fabricating arbitrary model confidence values while\nprotecting the model's proprietary details. Our results confirm that\nConfidential Guardian effectively prevents the misuse of cautious predictions,\nproviding verifiable assurances that abstention reflects genuine model\nuncertainty rather than malicious intent.", "AI": {"tldr": "This paper addresses the potential misuse of cautious predictions in machine learning models by introducing an uncertainty-inducing attack named Mirage that can be exploited to unjustly deny services. To counteract this, the authors propose Confidential Guardian, a framework that detects artificially suppressed confidence and uses zero-knowledge proofs to ensure genuine model confidence.", "motivation": "The motivation is to address the novel threat where cautious prediction mechanisms in machine learning models could be exploited by dishonest institutions to covertly disadvantage specific individuals under the guise of uncertainty.", "method": "The method involves two main components: 1) Introducing an uncertainty-inducing attack called Mirage which reduces confidence in targeted input regions while maintaining high predictive performance across all data points; 2) Proposing Confidential Guardian, a framework that analyzes calibration metrics on a reference dataset to detect artificially suppressed confidence and employs zero-knowledge proofs of verified inference to ensure reported confidence scores are genuine.", "result": "The results confirm that Confidential Guardian effectively prevents the misuse of cautious predictions, providing verifiable assurances that abstention reflects genuine model uncertainty rather than malicious intent.", "conclusion": "Confidential Guardian is concluded to be an effective solution for preventing the misuse of cautious predictions in machine learning models, ensuring that abstention decisions are based on genuine model uncertainty."}}
{"id": "2505.23954", "pdf": "https://arxiv.org/pdf/2505.23954", "abs": "https://arxiv.org/abs/2505.23954", "authors": ["Dylan Zapzalka", "Trenton Chang", "Lindsay Warrenburg", "Sae-Hwan Park", "Daniel K. Shenfeld", "Ravi B. Parikh", "Jenna Wiens", "Maggie Makar"], "title": "Estimating Misreporting in the Presence of Genuine Modification: A Causal Perspective", "categories": ["cs.LG"], "comment": null, "summary": "In settings where ML models are used to inform the allocation of resources,\nagents affected by the allocation decisions might have an incentive to\nstrategically change their features to secure better outcomes. While prior work\nhas studied strategic responses broadly, disentangling misreporting from\ngenuine modification remains a fundamental challenge. In this paper, we propose\na causally-motivated approach to identify and quantify how much an agent\nmisreports on average by distinguishing deceptive changes in their features\nfrom genuine modification. Our key insight is that, unlike genuine\nmodification, misreported features do not causally affect downstream variables\n(i.e., causal descendants). We exploit this asymmetry by comparing the causal\neffect of misreported features on their causal descendants as derived from\nmanipulated datasets against those from unmanipulated datasets. We formally\nprove identifiability of the misreporting rate and characterize the variance of\nour estimator. We empirically validate our theoretical results using a\nsemi-synthetic and real Medicare dataset with misreported data, demonstrating\nthat our approach can be employed to identify misreporting in real-world\nscenarios.", "AI": {"tldr": "This paper proposes a causally-motivated approach to identify and quantify agents' misreporting by distinguishing deceptive changes in their features from genuine modification.", "motivation": "In settings where ML models are used to inform the allocation of resources, agents might have an incentive to strategically change their features for better outcomes. Disentangling misreporting from genuine modification is a fundamental challenge.", "method": "The method involves exploiting the asymmetry between misreported features and genuine modification. Misreported features do not causally affect downstream variables (i.e., causal descendants). By comparing the causal effect of misreported features on their causal descendants as derived from manipulated datasets against those from unmanipulated datasets, the approach identifies and quantifies misreporting.", "result": "The authors formally prove identifiability of the misreporting rate and characterize the variance of their estimator. Empirical validation using semi-synthetic and real Medicare dataset shows that the approach can be employed to identify misreporting in real-world scenarios.", "conclusion": "The proposed causally-motivated approach successfully distinguishes between misreporting and genuine modification, providing a method to quantify misreporting in resource allocation informed by ML models."}}
{"id": "2505.24597", "pdf": "https://arxiv.org/pdf/2505.24597", "abs": "https://arxiv.org/abs/2505.24597", "authors": ["Shuai Liu", "Ning Cao", "Yile Chen", "Yue Jiang", "Gao Cong"], "title": "Mixture-of-Experts for Personalized and Semantic-Aware Next Location Prediction", "categories": ["cs.AI"], "comment": null, "summary": "Next location prediction plays a critical role in understanding human\nmobility patterns. However, existing approaches face two core limitations: (1)\nthey fall short in capturing the complex, multi-functional semantics of\nreal-world locations; and (2) they lack the capacity to model heterogeneous\nbehavioral dynamics across diverse user groups. To tackle these challenges, we\nintroduce NextLocMoE, a novel framework built upon large language models (LLMs)\nand structured around a dual-level Mixture-of-Experts (MoE) design. Our\narchitecture comprises two specialized modules: a Location Semantics MoE that\noperates at the embedding level to encode rich functional semantics of\nlocations, and a Personalized MoE embedded within the Transformer backbone to\ndynamically adapt to individual user mobility patterns. In addition, we\nincorporate a history-aware routing mechanism that leverages long-term\ntrajectory data to enhance expert selection and ensure prediction stability.\nEmpirical evaluations across several real-world urban datasets show that\nNextLocMoE achieves superior performance in terms of predictive accuracy,\ncross-domain generalization, and interpretability", "AI": {"tldr": "NextLocMoE is a new framework that improves next location prediction by using large language models and a dual-level Mixture-of-Experts design, which captures complex location semantics and heterogeneous behavioral dynamics.", "motivation": "Existing approaches for next location prediction do not adequately capture the complex semantics of real-world locations or model the diverse behavioral dynamics across different user groups.", "method": "The framework NextLocMoE is introduced, which uses large language models (LLMs) and has a dual-level Mixture-of-Experts design. It includes a Location Semantics MoE for encoding location functional semantics at the embedding level and a Personalized MoE within the Transformer backbone for adapting to individual user mobility patterns. Additionally, a history-aware routing mechanism is incorporated to enhance expert selection and ensure prediction stability.", "result": "Empirical evaluations on real-world urban datasets indicate that NextLocMoE achieves superior performance in predictive accuracy, cross-domain generalization, and interpretability compared to existing methods.", "conclusion": "NextLocMoE addresses the limitations of current next location prediction methods by better capturing location semantics and modeling heterogeneous behavioral dynamics, leading to improved performance."}}
{"id": "2505.24008", "pdf": "https://arxiv.org/pdf/2505.24008", "abs": "https://arxiv.org/abs/2505.24008", "authors": ["Efr\u00e9n L\u00f3pez-Morales", "Ulysse Planta", "Gabriele Marra", "Carlos Gonz\u00e1lez", "Jacob Hopkins", "Majid Garoosi", "El\u00edas Obreque", "Carlos Rubio-Medrano", "Ali Abbasi"], "title": "HoneySat: A Network-based Satellite Honeypot Framework", "categories": ["cs.CR"], "comment": "Efr\\'en L\\'opez-Morales and Ulysse Planta contributed equally to this\n  work", "summary": "Satellites are the backbone of several mission-critical services, such as GPS\nthat enable our modern society to function. For many years, satellites were\nassumed to be secure because of their indecipherable architectures and the\nreliance on security by obscurity. However, technological advancements have\nmade these assumptions obsolete, paving the way for potential attacks, and\nsparking a renewed interest in satellite security. Unfortunately, to this day,\nthere is no efficient way to collect data on adversarial techniques for\nsatellites, which severely hurts the generation of security intelligence. In\nthis paper, we present HoneySat, the first high-interaction satellite honeypot\nframework, which is fully capable of convincingly simulating a real-world\nCubeSat, a type of Small Satellite (SmallSat) widely used in practice. To\nprovide evidence of the effectiveness of HoneySat, we surveyed experienced\nSmallSat operators currently in charge of active in-orbit satellite missions.\nResults revealed that the majority of satellite operators (71.4%) agreed that\nHoneySat provides realistic and engaging simulations of CubeSat missions.\nFurther experimental evaluations also showed that HoneySat provides adversaries\nwith extensive interaction opportunities by supporting the majority of\nadversarial techniques (86.8%) and tactics (100%) that target satellites.\nAdditionally, we also obtained a series of real interactions from actual\nadversaries by deploying HoneySat on the internet over several months,\nconfirming that HoneySat can operate covertly and efficiently while collecting\nhighly valuable interaction data.", "AI": {"tldr": "The paper introduces HoneySat, the first high-interaction satellite honeypot framework that simulates a CubeSat convincingly. It has been validated by experienced SmallSat operators and effectively supports adversarial techniques and tactics. Real interactions from actual adversaries have confirmed its covert and efficient operation while collecting valuable interaction data.", "motivation": "There is no efficient way to collect data on adversarial techniques for satellites, which hinders the generation of security intelligence.", "method": "Presented HoneySat, a high-interaction satellite honeypot framework that simulates a CubeSat. Validated with experienced SmallSat operators and tested against adversarial techniques and tactics.", "result": "Majority of satellite operators agreed HoneySat provides realistic simulations. It supports most adversarial techniques and tactics targeting satellites. Real interactions from actual adversaries confirm its efficiency and value.", "conclusion": "HoneySat can operate covertly and efficiently, collecting highly valuable interaction data for satellite security intelligence."}}
{"id": "2505.23960", "pdf": "https://arxiv.org/pdf/2505.23960", "abs": "https://arxiv.org/abs/2505.23960", "authors": ["Henry Conklin"], "title": "Information Structure in Mappings: An Approach to Learning, Representation, and Generalisation", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "PhD Thesis, 204 pages; entropy estimation discussed from p.94", "summary": "Despite the remarkable success of large large-scale neural networks, we still\nlack unified notation for thinking about and describing their representational\nspaces. We lack methods to reliably describe how their representations are\nstructured, how that structure emerges over training, and what kinds of\nstructures are desirable. This thesis introduces quantitative methods for\nidentifying systematic structure in a mapping between spaces, and leverages\nthem to understand how deep-learning models learn to represent information,\nwhat representational structures drive generalisation, and how design decisions\ncondition the structures that emerge. To do this I identify structural\nprimitives present in a mapping, along with information theoretic\nquantifications of each. These allow us to analyse learning, structure, and\ngeneralisation across multi-agent reinforcement learning models,\nsequence-to-sequence models trained on a single task, and Large Language\nModels. I also introduce a novel, performant, approach to estimating the\nentropy of vector space, that allows this analysis to be applied to models\nranging in size from 1 million to 12 billion parameters.\n  The experiments here work to shed light on how large-scale distributed models\nof cognition learn, while allowing us to draw parallels between those systems\nand their human analogs. They show how the structures of language and the\nconstraints that give rise to them in many ways parallel the kinds of\nstructures that drive performance of contemporary neural networks.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u6211\u4eec\u4ecd\u7f3a\u4e4f\u7edf\u4e00\u7684\u7b26\u53f7\u6765\u601d\u8003\u548c\u63cf\u8ff0\u5b83\u4eec\u7684\u8868\u793a\u7a7a\u95f4\u3002\u672c\u8bba\u6587\u5f15\u5165\u4e86\u5b9a\u91cf\u65b9\u6cd5\u4ee5\u8bc6\u522b\u7a7a\u95f4\u6620\u5c04\u4e2d\u7684\u7cfb\u7edf\u7ed3\u6784\uff0c\u5e76\u5229\u7528\u8fd9\u4e9b\u65b9\u6cd5\u7406\u89e3\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5982\u4f55\u5b66\u4e60\u8868\u793a\u4fe1\u606f\u3001\u54ea\u4e9b\u8868\u793a\u7ed3\u6784\u9a71\u52a8\u6cdb\u5316\u4ee5\u53ca\u8bbe\u8ba1\u51b3\u7b56\u5982\u4f55\u5f71\u54cd\u51fa\u73b0\u7684\u7ed3\u6784\u3002\u6b64\u5916\uff0c\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u9ad8\u6027\u80fd\u65b9\u6cd5\u6765\u4f30\u8ba1\u5411\u91cf\u7a7a\u95f4\u7684\u71b5\uff0c\u9002\u7528\u4e8e\u4ece1\u767e\u4e07\u5230120\u4ebf\u53c2\u6570\u7684\u6a21\u578b\u3002\u5b9e\u9a8c\u63ed\u793a\u4e86\u5927\u89c4\u6a21\u5206\u5e03\u5f0f\u8ba4\u77e5\u6a21\u578b\u7684\u5b66\u4e60\u65b9\u5f0f\uff0c\u5e76\u63a2\u8ba8\u4e86\u5176\u4e0e\u4eba\u7c7b\u7cfb\u7edf\u7684\u76f8\u4f3c\u4e4b\u5904\u3002", "motivation": "\u6211\u4eec\u7f3a\u4e4f\u53ef\u9760\u7684\u65b9\u6cd5\u6765\u63cf\u8ff0\u795e\u7ecf\u7f51\u7edc\u8868\u793a\u7a7a\u95f4\u7684\u7ed3\u6784\u3001\u8be5\u7ed3\u6784\u5982\u4f55\u5728\u8bad\u7ec3\u4e2d\u51fa\u73b0\u4ee5\u53ca\u4f55\u79cd\u7ed3\u6784\u662f\u7406\u60f3\u7684\u3002", "method": "\u8bc6\u522b\u6620\u5c04\u4e2d\u7684\u7ed3\u6784\u57fa\u5143\u5e76\u7ed3\u5408\u4fe1\u606f\u8bba\u91cf\u5316\u5206\u6790\uff1b\u5f15\u5165\u4e00\u79cd\u65b0\u65b9\u6cd5\u4f30\u8ba1\u5411\u91cf\u7a7a\u95f4\u7684\u71b5\u3002", "result": "\u80fd\u591f\u5206\u6790\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u6a21\u578b\u3001\u5e8f\u5217\u5230\u5e8f\u5217\u6a21\u578b\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5b66\u4e60\u3001\u7ed3\u6784\u548c\u6cdb\u5316\u80fd\u529b\uff1b\u63ed\u793a\u4e86\u8bed\u8a00\u7ed3\u6784\u53ca\u5176\u7ea6\u675f\u4e0e\u73b0\u4ee3\u795e\u7ecf\u7f51\u7edc\u6027\u80fd\u9a71\u52a8\u7ed3\u6784\u7684\u5e73\u884c\u6027\u3002", "conclusion": "\u901a\u8fc7\u5b9a\u91cf\u65b9\u6cd5\u548c\u65b0\u63d0\u51fa\u7684\u71b5\u4f30\u8ba1\u65b9\u6cd5\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u5927\u578b\u795e\u7ecf\u7f51\u7edc\u7684\u8868\u793a\u5b66\u4e60\u548c\u6cdb\u5316\u673a\u5236\uff0c\u5e76\u627e\u5230\u4e0e\u4eba\u7c7b\u8ba4\u77e5\u7cfb\u7edf\u7684\u76f8\u4f3c\u4e4b\u5904\u3002"}}
{"id": "2505.24601", "pdf": "https://arxiv.org/pdf/2505.24601", "abs": "https://arxiv.org/abs/2505.24601", "authors": ["Zekun Wang", "Ethan L. Haarer", "Nicki Barari", "Christopher J. MacLellan"], "title": "Taxonomic Networks: A Representation for Neuro-Symbolic Pairing", "categories": ["cs.AI"], "comment": "10 pages, 3 figures, NeuS 2025", "summary": "We introduce the concept of a \\textbf{neuro-symbolic pair} -- neural and\nsymbolic approaches that are linked through a common knowledge representation.\nNext, we present \\textbf{taxonomic networks}, a type of discrimination network\nin which nodes represent hierarchically organized taxonomic concepts. Using\nthis representation, we construct a novel neuro-symbolic pair and evaluate its\nperformance. We show that our symbolic method learns taxonomic nets more\nefficiently with less data and compute, while the neural method finds\nhigher-accuracy taxonomic nets when provided with greater resources. As a\nneuro-symbolic pair, these approaches can be used interchangeably based on\nsituational needs, with seamless translation between them when necessary. This\nwork lays the foundation for future systems that more fundamentally integrate\nneural and symbolic computation.", "AI": {"tldr": "The paper introduces neuro-symbolic pairs and taxonomic networks, showing their complementary advantages in learning taxonomic nets.", "motivation": "To create a system that integrates neural and symbolic approaches through a common knowledge representation for more efficient and accurate learning.", "method": "Development of neuro-symbolic pairs consisting of neural and symbolic methods linked by a common knowledge representation, specifically using taxonomic networks where nodes represent hierarchically organized concepts.", "result": "Symbolic method learns taxonomic nets more efficiently with less data and compute; neural method finds higher-accuracy taxonomic nets when provided with greater resources. These approaches can be used interchangeably based on situational needs.", "conclusion": "This work lays the foundation for future systems that more fundamentally integrate neural and symbolic computation."}}
{"id": "2505.24019", "pdf": "https://arxiv.org/pdf/2505.24019", "abs": "https://arxiv.org/abs/2505.24019", "authors": ["Kaiyuan Zhang", "Zian Su", "Pin-Yu Chen", "Elisa Bertino", "Xiangyu Zhang", "Ninghui Li"], "title": "LLM Agents Should Employ Security Principles", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Model (LLM) agents show considerable promise for automating\ncomplex tasks using contextual reasoning; however, interactions involving\nmultiple agents and the system's susceptibility to prompt injection and other\nforms of context manipulation introduce new vulnerabilities related to privacy\nleakage and system exploitation. This position paper argues that the\nwell-established design principles in information security, which are commonly\nreferred to as security principles, should be employed when deploying LLM\nagents at scale. Design principles such as defense-in-depth, least privilege,\ncomplete mediation, and psychological acceptability have helped guide the\ndesign of mechanisms for securing information systems over the last five\ndecades, and we argue that their explicit and conscientious adoption will help\nsecure agentic systems. To illustrate this approach, we introduce AgentSandbox,\na conceptual framework embedding these security principles to provide\nsafeguards throughout an agent's life-cycle. We evaluate with state-of-the-art\nLLMs along three dimensions: benign utility, attack utility, and attack success\nrate. AgentSandbox maintains high utility for its intended functions under both\nbenign and adversarial evaluations while substantially mitigating privacy\nrisks. By embedding secure design principles as foundational elements within\nemerging LLM agent protocols, we aim to promote trustworthy agent ecosystems\naligned with user privacy expectations and evolving regulatory requirements.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u5728\u5927\u89c4\u6a21\u90e8\u7f72\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u4ee3\u7406\u65f6\uff0c\u5e94\u91c7\u7528\u4fe1\u606f\u5b89\u5168\u9886\u57df\u7684\u6210\u719f\u8bbe\u8ba1\u539f\u5219\u6765\u5e94\u5bf9\u591a\u4ee3\u7406\u4ea4\u4e92\u548c\u7cfb\u7edf\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u7b49\u6f0f\u6d1e\u95ee\u9898\uff0c\u5e76\u5f15\u5165\u4e86AgentSandbox\u6846\u67b6\u4f5c\u4e3a\u6982\u5ff5\u9a8c\u8bc1\uff0c\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u9ad8\u529f\u80fd\u6548\u7528\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u9690\u79c1\u98ce\u9669\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u81ea\u52a8\u5316\u590d\u6742\u4efb\u52a1\u65b9\u9762\u5c55\u73b0\u51fa\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u591a\u4ee3\u7406\u4ea4\u4e92\u548c\u7cfb\u7edf\u6613\u53d7\u63d0\u793a\u6ce8\u5165\u7b49\u95ee\u9898\u5e26\u6765\u4e86\u65b0\u7684\u9690\u79c1\u6cc4\u9732\u548c\u7cfb\u7edf\u5229\u7528\u7684\u6f0f\u6d1e\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u5b89\u5168\u673a\u5236\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5f15\u5165AgentSandbox\u8fd9\u4e00\u6982\u5ff5\u6846\u67b6\uff0c\u5c06\u9632\u5fa1\u7eb5\u6df1\u3001\u6700\u5c0f\u7279\u6743\u3001\u5b8c\u5168\u4e2d\u4ecb\u548c\u5fc3\u7406\u53ef\u63a5\u53d7\u6027\u7b49\u5b89\u5168\u8bbe\u8ba1\u539f\u5219\u5d4c\u5165\u5230\u4ee3\u7406\u7684\u751f\u547d\u5468\u671f\u4e2d\uff0c\u5e76\u4ece\u826f\u6027\u6548\u7528\u3001\u653b\u51fb\u6548\u7528\u548c\u653b\u51fb\u6210\u529f\u7387\u4e09\u4e2a\u7ef4\u5ea6\u5bf9\u6700\u5148\u8fdb\u7684LLM\u8fdb\u884c\u4e86\u8bc4\u4f30\u3002", "result": "AgentSandbox\u6846\u67b6\u5728\u826f\u6027\u53ca\u5bf9\u6297\u6027\u8bc4\u4f30\u4e0b\u5747\u4fdd\u6301\u4e86\u9ad8\u529f\u80fd\u6548\u7528\uff0c\u540c\u65f6\u5927\u5e45\u7f13\u89e3\u4e86\u9690\u79c1\u98ce\u9669\u3002", "conclusion": "\u901a\u8fc7\u5c06\u5b89\u5168\u8bbe\u8ba1\u539f\u5219\u4f5c\u4e3a\u57fa\u7840\u5143\u7d20\u5d4c\u5165\u65b0\u5174\u7684LLM\u4ee3\u7406\u534f\u8bae\u4e2d\uff0c\u53ef\u4ee5\u63a8\u52a8\u503c\u5f97\u4fe1\u8d56\u7684\u4ee3\u7406\u751f\u6001\u7cfb\u7edf\u7684\u53d1\u5c55\uff0c\u4e0e\u7528\u6237\u7684\u9690\u79c1\u671f\u671b\u548c\u4e0d\u65ad\u53d1\u5c55\u7684\u76d1\u7ba1\u8981\u6c42\u76f8\u4e00\u81f4\u3002"}}
{"id": "2505.23967", "pdf": "https://arxiv.org/pdf/2505.23967", "abs": "https://arxiv.org/abs/2505.23967", "authors": ["Anders Aamand", "Justin Y. Chen", "Siddharth Gollapudi", "Sandeep Silwal", "Hao Wu"], "title": "Improved Approximations for Hard Graph Problems using Predictions", "categories": ["cs.LG", "cs.DS"], "comment": null, "summary": "We design improved approximation algorithms for NP-hard graph problems by\nincorporating predictions (e.g., learned from past data). Our prediction model\nbuilds upon and extends the $\\varepsilon$-prediction framework by Cohen-Addad,\nd'Orsi, Gupta, Lee, and Panigrahi (NeurIPS 2024). We consider an edge-based\nversion of this model, where each edge provides two bits of information,\ncorresponding to predictions about whether each of its endpoints belong to an\noptimal solution. Even with weak predictions where each bit is only\n$\\varepsilon$-correlated with the true solution, this information allows us to\nbreak approximation barriers in the standard setting. We develop algorithms\nwith improved approximation ratios for MaxCut, Vertex Cover, Set Cover, and\nMaximum Independent Set problems (among others). Across these problems, our\nalgorithms share a unifying theme, where we separately satisfy constraints\nrelated to high degree vertices (using predictions) and low-degree vertices\n(without using predictions) and carefully combine the answers.", "AI": {"tldr": "This paper designs improved approximation algorithms for NP-hard graph problems by incorporating predictions, achieving better approximation ratios for several classic problems.", "motivation": "The motivation of this paper is to break through the existing approximation barriers in solving NP-hard graph problems by utilizing predictions that can be learned from past data.", "method": "The method involves an edge-based prediction model where each edge provides two bits of information about whether its endpoints belong to an optimal solution. This builds upon and extends the $\\varepsilon$-prediction framework. Algorithms are developed with a unifying theme of separately handling constraints related to high-degree vertices (using predictions) and low-degree vertices (without using predictions), then carefully combining the results.", "result": "The result is the development of algorithms with improved approximation ratios for various NP-hard graph problems such as MaxCut, Vertex Cover, Set Cover, and Maximum Independent Set problems.", "conclusion": "By incorporating predictions into algorithm design, the paper successfully achieves better approximation ratios for several classic NP-hard graph problems, demonstrating the potential of using predictions in computational problem-solving."}}
{"id": "2505.24622", "pdf": "https://arxiv.org/pdf/2505.24622", "abs": "https://arxiv.org/abs/2505.24622", "authors": ["Ben Griffin", "Joseph Ternasky", "Fuat Alican", "Yigit Ihlamur"], "title": "Random Rule Forest (RRF): Interpretable Ensembles of LLM-Generated Questions for Predicting Startup Success", "categories": ["cs.AI", "cs.LG", "I.2.7"], "comment": "9 pages, 4 figures", "summary": "Predicting startup success requires models that are both accurate and\ninterpretable. We present a lightweight ensemble framework that combines YES/NO\nquestions generated by large language models (LLMs), forming a transparent\ndecision-making system. Each question acts as a weak heuristic, and by\nfiltering, ranking, and aggregating them through a threshold-based voting\nmechanism, we construct a strong ensemble predictor. On a test set where 10% of\nstartups are classified as successful, our approach achieves a precision rate\nof 50%, representing a 5x improvement over random selection, while remaining\nfully transparent. When we incorporate expert-guided heuristics into the\ngeneration process, performance improves further to 54% precision. These\nresults highlight the value of combining LLM reasoning with human insight and\ndemonstrate that simple, interpretable ensembles can support high-stakes\ndecisions in domains such as venture capital (VC).", "AI": {"tldr": "\u901a\u8fc7\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210\u7684YES/NO\u95ee\u9898\u548c\u4e13\u5bb6\u6307\u5bfc\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u96c6\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u7684\u6210\u529f\u3002\u8be5\u6846\u67b6\u5728\u4fdd\u6301\u5b8c\u5168\u900f\u660e\u7684\u540c\u65f6\uff0c\u6bd4\u968f\u673a\u9009\u62e9\u63d0\u9ad8\u4e865\u500d\u7684\u7cbe\u5ea6\u3002", "motivation": "\u9884\u6d4b\u521d\u521b\u4f01\u4e1a\u6210\u529f\u9700\u8981\u65e2\u51c6\u786e\u53c8\u53ef\u89e3\u91ca\u7684\u6a21\u578b\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u53ef\u80fd\u7f3a\u4e4f\u900f\u660e\u5ea6\u6216\u4e0d\u591f\u51c6\u786e\u3002", "method": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u751f\u6210YES/NO\u95ee\u9898\u4f5c\u4e3a\u5f31\u542f\u53d1\u5f0f\uff0c\u901a\u8fc7\u57fa\u4e8e\u9608\u503c\u7684\u6295\u7968\u673a\u5236\u5bf9\u8fd9\u4e9b\u95ee\u9898\u8fdb\u884c\u8fc7\u6ee4\u3001\u6392\u540d\u548c\u805a\u5408\uff0c\u4ece\u800c\u6784\u5efa\u4e00\u4e2a\u5f3a\u5927\u7684\u96c6\u6210\u9884\u6d4b\u5668\u3002\u8fd8\u53ef\u4ee5\u5c06\u4e13\u5bb6\u6307\u5bfc\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u7eb3\u5165\u751f\u6210\u8fc7\u7a0b\u4ee5\u63d0\u9ad8\u6027\u80fd\u3002", "result": "\u5728\u6d4b\u8bd5\u96c6\u4e2d\uff0c\u670910%\u7684\u521d\u521b\u4f01\u4e1a\u88ab\u5206\u7c7b\u4e3a\u6210\u529f\u7684\uff0c\u8be5\u65b9\u6cd5\u8fbe\u5230\u4e8650%\u7684\u7cbe\u786e\u7387\uff0c\u6bd4\u968f\u673a\u9009\u62e9\u63d0\u9ad8\u4e865\u500d\u3002\u52a0\u5165\u4e13\u5bb6\u6307\u5bfc\u7684\u542f\u53d1\u5f0f\u65b9\u6cd5\u540e\uff0c\u7cbe\u786e\u7387\u8fdb\u4e00\u6b65\u63d0\u9ad8\u523054%\u3002", "conclusion": "\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\u63a8\u7406\u4e0e\u4eba\u7c7b\u6d1e\u5bdf\u529b\u5177\u6709\u4ef7\u503c\uff0c\u7b80\u5355\u7684\u3001\u53ef\u89e3\u91ca\u7684\u96c6\u6210\u53ef\u4ee5\u652f\u6301\u8bf8\u5982\u98ce\u9669\u6295\u8d44\u7b49\u9ad8\u98ce\u9669\u9886\u57df\u7684\u51b3\u7b56\u3002"}}
{"id": "2505.24021", "pdf": "https://arxiv.org/pdf/2505.24021", "abs": "https://arxiv.org/abs/2505.24021", "authors": ["Akila Herath", "Chen-Ching Liu", "Junho Hong", "Mansi Girdhar"], "title": "An Advanced Cyber-Physical System Security Testbed for Substation Automation", "categories": ["cs.CR", "cs.SY", "eess.SY"], "comment": "CIGRE Symposium 2025, Trondheim, Norway", "summary": "A Cyber-Physical System (CPS) testbed serves as a powerful platform for\ntesting and validating cyber intrusion detection and mitigation strategies in\nsubstations. This study presents the design and development of a CPS testbed\nthat can effectively assess the real-time dynamics of a substation. Cyber\nattacks exploiting IEC 61850-based SV and GOOSE protocols are demonstrated\nusing the testbed, along with an analysis on attack detection. Realistic timing\nmeasurements are obtained, and the time frames for deploying detection and\nmitigation strategies are evaluated.", "AI": {"tldr": "This paper discusses the design and development of a Cyber-Physical System (CPS) testbed for assessing substation dynamics, demonstrating cyber attacks on IEC 61850 protocols, and evaluating detection/mitigation strategies.", "motivation": "To create an effective platform for testing and validating cyber intrusion detection and mitigation strategies in substations using a CPS testbed.", "method": "Design and develop a CPS testbed that can assess real-time substation dynamics, demonstrate cyber attacks exploiting IEC 61850-based SV and GOOSE protocols, obtain realistic timing measurements, and evaluate time frames for deploying detection and mitigation strategies.", "result": "The CPS testbed successfully demonstrated cyber attacks on IEC 61850 protocols and provided realistic timing measurements to evaluate the effectiveness of detection and mitigation strategies.", "conclusion": "A CPS testbed is a powerful tool for testing and validating cyber intrusion detection and mitigation strategies in substations, providing valuable insights into real-time dynamics and attack detection."}}
{"id": "2505.23971", "pdf": "https://arxiv.org/pdf/2505.23971", "abs": "https://arxiv.org/abs/2505.23971", "authors": ["William Merrill", "Shane Arora", "Dirk Groeneveld", "Hannaneh Hajishirzi"], "title": "Critical Batch Size Revisited: A Simple Empirical Approach to Large-Batch Language Model Training", "categories": ["cs.LG"], "comment": null, "summary": "The right batch size is important when training language models at scale: a\nlarge batch size is necessary for fast training, but a batch size that is too\nlarge will harm token efficiency. To navigate this tradeoff, McCandlish et al.\n(2018) suggest that a critical batch size (CBS), below which training will not\nsubstantially degrade loss, can be estimated based on the gradient noise scale\nduring training. While their method has been adopted in practice, e.g., when\ntraining GPT-3, strong assumptions are required to justify gradient noise as a\nproxy for the CBS, which makes it unclear whether their approach should be\ntrusted in practice, limiting its applicability. In this paper, we introduce a\nsimple, empirical approach to directly measure the CBS and show how the CBS\nevolves over training. Applying our approach to the OLMo models, we find that\nCBS is near 0 at initialization, increases rapidly at first, and then plateaus\nas training progresses. Furthermore, we find that this trend holds across\ndifferent model sizes (1B and 7B), suggesting CBS from small training runs can\ninform larger-scale training runs. Our findings about how the CBS changes over\ntraining motivate batch size warmup as a natural way to reliably train language\nmodels at large batch size: start the batch size small and increase it as the\nCBS grows. To validate this claim, we use batch size warmup to train OLMo 1B to\nslightly better loss than the original training run with 43% fewer gradient\nsteps. This shows how our framework can be applied to reliably train language\nmodels at larger batch sizes, increasing data parallelism without compromising\nperformance.", "AI": {"tldr": "\u5728\u8bad\u7ec3\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u786e\u5b9a\u5408\u9002\u7684\u6279\u91cf\u5927\u5c0f\u5f88\u91cd\u8981\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u76f4\u63a5\u6d4b\u91cf\u5173\u952e\u6279\u91cf\u5927\u5c0f\uff08CBS\uff09\u7684\u65b9\u6cd5\uff0c\u5e76\u53d1\u73b0CBS\u5728\u8bad\u7ec3\u521d\u671f\u8fc5\u901f\u589e\u52a0\uff0c\u968f\u540e\u8d8b\u4e8e\u5e73\u7a33\u3002\u57fa\u4e8e\u6b64\uff0c\u6587\u7ae0\u63d0\u51fa\u4e86\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\uff0c\u4ece\u5c0f\u6279\u91cf\u5f00\u59cb\u9010\u6e10\u589e\u5927\uff0c\u4ee5\u9002\u5e94CBS\u7684\u53d8\u5316\u3002\u901a\u8fc7\u8fd9\u79cd\u65b9\u6cd5\uff0c\u5728OLMo 1B\u6a21\u578b\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u539f\u8bad\u7ec3\u66f4\u597d\u7684\u635f\u5931\uff0c\u540c\u65f6\u51cf\u5c11\u4e8643%\u7684\u68af\u5ea6\u6b65\u9aa4\u3002", "motivation": "\u73b0\u6709\u7684\u4f30\u8ba1\u5173\u952e\u6279\u91cf\u5927\u5c0f\uff08CBS\uff09\u7684\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u68af\u5ea6\u566a\u58f0\u89c4\u6a21\uff0c\u4f46\u5176\u5047\u8bbe\u5728\u5b9e\u8df5\u4e2d\u53ef\u80fd\u4e0d\u6210\u7acb\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u9002\u7528\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u53ef\u9760\u3001\u76f4\u63a5\u6d4b\u91cfCBS\u7684\u65b9\u6cd5\u3002", "method": "\u5f15\u5165\u4e00\u79cd\u7b80\u5355\u7684\u7ecf\u9a8c\u65b9\u6cd5\u76f4\u63a5\u6d4b\u91cfCBS\uff0c\u5e76\u89c2\u5bdf\u5176\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u53d8\u5316\u8d8b\u52bf\u3002\u5c06\u8be5\u65b9\u6cd5\u5e94\u7528\u4e8eOLMo\u6a21\u578b\uff0c\u7814\u7a76\u4e0d\u540c\u6a21\u578b\u5c3a\u5bf8\u4e0b\u7684CBS\u53d8\u5316\u89c4\u5f8b\u3002\u6839\u636eCBS\u7684\u53d8\u5316\u8d8b\u52bf\uff0c\u63d0\u51fa\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\uff1a\u4ece\u8f83\u5c0f\u7684\u6279\u91cf\u5f00\u59cb\uff0c\u968f\u7740CBS\u7684\u589e\u957f\u9010\u6b65\u589e\u52a0\u6279\u91cf\u5927\u5c0f\u3002", "result": "\u53d1\u73b0CBS\u5728\u521d\u59cb\u5316\u65f6\u63a5\u8fd10\uff0c\u968f\u540e\u5feb\u901f\u589e\u52a0\u5e76\u8d8b\u4e8e\u5e73\u7a33\u3002\u8fd9\u79cd\u8d8b\u52bf\u5728\u4e0d\u540c\u6a21\u578b\u5c3a\u5bf8\uff081B\u548c7B\uff09\u95f4\u4fdd\u6301\u4e00\u81f4\u3002\u4f7f\u7528\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\u8bad\u7ec3OLMo 1B\u6a21\u578b\uff0c\u83b7\u5f97\u4e86\u7565\u4f18\u4e8e\u539f\u8bad\u7ec3\u7684\u635f\u5931\u503c\uff0c\u5e76\u51cf\u5c11\u4e8643%\u7684\u68af\u5ea6\u6b65\u9aa4\u3002", "conclusion": "\u63d0\u51fa\u7684\u76f4\u63a5\u6d4b\u91cfCBS\u7684\u65b9\u6cd5\u63ed\u793a\u4e86\u5176\u5728\u8bad\u7ec3\u4e2d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u652f\u6301\u4e86\u6279\u91cf\u5927\u5c0f\u9884\u70ed\u7b56\u7565\u7684\u6709\u6548\u6027\u3002\u8be5\u7b56\u7565\u80fd\u591f\u53ef\u9760\u5730\u5728\u8f83\u5927\u6279\u91cf\u4e0b\u8bad\u7ec3\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u9ad8\u6570\u636e\u5e76\u884c\u6027\u800c\u4e0d\u635f\u5bb3\u6027\u80fd\u3002"}}
{"id": "2505.24655", "pdf": "https://arxiv.org/pdf/2505.24655", "abs": "https://arxiv.org/abs/2505.24655", "authors": ["Frederike L\u00fcbeck", "Jonas Wildberger", "Frederik Tr\u00e4uble", "Maximilian Mordig", "Sergios Gatidis", "Andreas Krause", "Bernhard Sch\u00f6lkopf"], "title": "Adaptable Cardiovascular Disease Risk Prediction from Heterogeneous Data using Large Language Models", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Cardiovascular disease (CVD) risk prediction models are essential for\nidentifying high-risk individuals and guiding preventive actions. However,\nexisting models struggle with the challenges of real-world clinical practice as\nthey oversimplify patient profiles, rely on rigid input schemas, and are\nsensitive to distribution shifts. We developed AdaCVD, an adaptable CVD risk\nprediction framework built on large language models extensively fine-tuned on\nover half a million participants from the UK Biobank. In benchmark comparisons,\nAdaCVD surpasses established risk scores and standard machine learning\napproaches, achieving state-of-the-art performance. Crucially, for the first\ntime, it addresses key clinical challenges across three dimensions: it flexibly\nincorporates comprehensive yet variable patient information; it seamlessly\nintegrates both structured data and unstructured text; and it rapidly adapts to\nnew patient populations using minimal additional data. In stratified analyses,\nit demonstrates robust performance across demographic, socioeconomic, and\nclinical subgroups, including underrepresented cohorts. AdaCVD offers a\npromising path toward more flexible, AI-driven clinical decision support tools\nsuited to the realities of heterogeneous and dynamic healthcare environments.", "AI": {"tldr": "The paper introduces AdaCVD, a new framework for predicting cardiovascular disease (CVD) risk that overcomes limitations of existing models by flexibly incorporating diverse patient data, integrating structured and unstructured information, and adapting to different populations.", "motivation": "Existing CVD risk prediction models have difficulty handling real-world clinical challenges due to oversimplified patient profiles, rigid input requirements, and sensitivity to distribution shifts.", "method": "AdaCVD is an adaptable framework built using large language models fine-tuned on extensive UK Biobank data. It incorporates comprehensive patient information, handles both structured and unstructured data, and can quickly adapt to new patient populations with minimal additional data.", "result": "AdaCVD outperforms established risk scores and standard machine learning methods, achieving state-of-the-art performance in benchmark comparisons. It shows robustness across various subgroups, including underrepresented ones.", "conclusion": "AdaCVD represents a significant advancement in flexible, AI-driven clinical decision support tools tailored to diverse and changing healthcare settings."}}
{"id": "2505.24252", "pdf": "https://arxiv.org/pdf/2505.24252", "abs": "https://arxiv.org/abs/2505.24252", "authors": ["Yizhong Ding"], "title": "A Reward-driven Automated Webshell Malicious-code Generator for Red-teaming", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Frequent cyber-attacks have elevated WebShell exploitation and defense to a\ncritical research focus within network security. However, there remains a\nsignificant shortage of publicly available, well-categorized malicious-code\ndatasets organized by obfuscation method. Existing malicious-code generation\nmethods, which primarily rely on prompt engineering, often suffer from limited\ndiversity and high redundancy in the payloads they produce. To address these\nlimitations, we propose \\textbf{RAWG}, a \\textbf{R}eward-driven\n\\textbf{A}utomated \\textbf{W}ebshell Malicious-code \\textbf{G}enerator designed\nfor red-teaming applications. Our approach begins by categorizing webshell\nsamples from common datasets into seven distinct types of obfuscation. We then\nemploy a large language model (LLM) to extract and normalize key tokens from\neach sample, creating a standardized, high-quality corpus. Using this curated\ndataset, we perform supervised fine-tuning (SFT) on an open-source large model\nto enable the generation of diverse, highly obfuscated webshell malicious\npayloads. To further enhance generation quality, we apply Proximal Policy\nOptimization (PPO), treating malicious-code samples as \"chosen\" data and benign\ncode as \"rejected\" data during reinforcement learning. Extensive experiments\ndemonstrate that RAWG significantly outperforms current state-of-the-art\nmethods in both payload diversity and escape effectiveness.", "AI": {"tldr": "To address the lack of diverse and non-redundant malicious-code datasets, this paper proposes RAWG, a Reward-driven Automated Webshell Malicious-code Generator. It categorizes webshell samples by obfuscation types, uses an LLM for token extraction and normalization, applies SFT and PPO for enhancing generation quality, and shows superior performance in payload diversity and escape effectiveness.", "motivation": "The motivation lies in the critical need for effective WebShell defense mechanisms due to frequent cyber-attacks, coupled with the shortage of publicly available, well-categorized malicious-code datasets organized by obfuscation method. Existing methods suffer from limited diversity and high redundancy in generated payloads.", "method": "1. Categorize webshell samples into seven distinct types of obfuscation.\n2. Use a large language model (LLM) to extract and normalize key tokens from each sample, creating a standardized corpus.\n3. Perform supervised fine-tuning (SFT) on an open-source large model for generating diverse, highly obfuscated payloads.\n4. Apply Proximal Policy Optimization (PPO), treating malicious-code samples as 'chosen' data and benign code as 'rejected' data during reinforcement learning.", "result": "Extensive experiments demonstrate that RAWG significantly outperforms current state-of-the-art methods in both payload diversity and escape effectiveness.", "conclusion": "RAWG is an effective solution for generating diverse and highly obfuscated webshell malicious payloads, addressing the limitations of existing methods."}}
{"id": "2505.23973", "pdf": "https://arxiv.org/pdf/2505.23973", "abs": "https://arxiv.org/abs/2505.23973", "authors": ["Asaf Goren", "Natalie Lang", "Nir Shlezinger", "Alejandro Cohen"], "title": "Adaptive Deadline and Batch Layered Synchronized Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "Federated learning (FL) enables collaborative model training across\ndistributed edge devices while preserving data privacy, and typically operates\nin a round-based synchronous manner. However, synchronous FL suffers from\nlatency bottlenecks due to device heterogeneity, where slower clients\n(stragglers) delay or degrade global updates. Prior solutions, such as fixed\ndeadlines, client selection, and layer-wise partial aggregation, alleviate the\neffect of stragglers, but treat round timing and local workload as static\nparameters, limiting their effectiveness under strict time constraints. We\npropose ADEL-FL, a novel framework that jointly optimizes per-round deadlines\nand user-specific batch sizes for layer-wise aggregation. Our approach\nformulates a constrained optimization problem minimizing the expected L2\ndistance to the global optimum under total training time and global rounds. We\nprovide a convergence analysis under exponential compute models and prove that\nADEL-FL yields unbiased updates with bounded variance. Extensive experiments\ndemonstrate that ADEL-FL outperforms alternative methods in both convergence\nrate and final accuracy under heterogeneous conditions.", "AI": {"tldr": "The paper proposes ADEL-FL, a framework that optimizes deadlines and batch sizes for federated learning to reduce the impact of slow devices.", "motivation": "Existing solutions for handling stragglers in synchronous federated learning treat round timing and local workload as static parameters, limiting their effectiveness under strict time constraints.", "method": "ADEL-FL jointly optimizes per-round deadlines and user-specific batch sizes for layer-wise aggregation by formulating a constrained optimization problem minimizing the expected L2 distance to the global optimum under total training time and global rounds.", "result": "Experiments demonstrate that ADEL-FL outperforms alternative methods in both convergence rate and final accuracy under heterogeneous conditions.", "conclusion": "ADEL-FL provides a solution to optimize federated learning processes considering device heterogeneity and strict time constraints."}}
{"id": "2505.24784", "pdf": "https://arxiv.org/pdf/2505.24784", "abs": "https://arxiv.org/abs/2505.24784", "authors": ["Conor Heins", "Toon Van de Maele", "Alexander Tschantz", "Hampus Linander", "Dimitrije Markovic", "Tommaso Salvatori", "Corrado Pezzato", "Ozan Catal", "Ran Wei", "Magnus Koudahl", "Marco Perin", "Karl Friston", "Tim Verbelen", "Christopher Buckley"], "title": "AXIOM: Learning to Play Games in Minutes with Expanding Object-Centric Models", "categories": ["cs.AI", "cs.LG", "stat.ML"], "comment": "10 pages main text, 4 figures, 2 tables; 25 pages supplementary\n  material, 8 figures", "summary": "Current deep reinforcement learning (DRL) approaches achieve state-of-the-art\nperformance in various domains, but struggle with data efficiency compared to\nhuman learning, which leverages core priors about objects and their\ninteractions. Active inference offers a principled framework for integrating\nsensory information with prior knowledge to learn a world model and quantify\nthe uncertainty of its own beliefs and predictions. However, active inference\nmodels are usually crafted for a single task with bespoke knowledge, so they\nlack the domain flexibility typical of DRL approaches. To bridge this gap, we\npropose a novel architecture that integrates a minimal yet expressive set of\ncore priors about object-centric dynamics and interactions to accelerate\nlearning in low-data regimes. The resulting approach, which we call AXIOM,\ncombines the usual data efficiency and interpretability of Bayesian approaches\nwith the across-task generalization usually associated with DRL. AXIOM\nrepresents scenes as compositions of objects, whose dynamics are modeled as\npiecewise linear trajectories that capture sparse object-object interactions.\nThe structure of the generative model is expanded online by growing and\nlearning mixture models from single events and periodically refined through\nBayesian model reduction to induce generalization. AXIOM masters various games\nwithin only 10,000 interaction steps, with both a small number of parameters\ncompared to DRL, and without the computational expense of gradient-based\noptimization.", "AI": {"tldr": "AXIOM is a novel architecture that combines Bayesian data efficiency and DRL generalization by using core priors about object-centric dynamics to accelerate learning in low-data regimes.", "motivation": "Current deep reinforcement learning approaches struggle with data efficiency compared to human learning, which leverages core priors about objects and their interactions. Active inference models lack the domain flexibility typical of DRL approaches.", "method": "AXIOM represents scenes as compositions of objects, whose dynamics are modeled as piecewise linear trajectories capturing sparse object-object interactions. The generative model structure is expanded online by growing and learning mixture models from single events and refined through Bayesian model reduction.", "result": "AXIOM masters various games within only 10,000 interaction steps, using a small number of parameters compared to DRL, and without the computational expense of gradient-based optimization.", "conclusion": "AXIOM bridges the gap between active inference and DRL by combining data efficiency and interpretability of Bayesian approaches with across-task generalization usually associated with DRL."}}
{"id": "2505.24267", "pdf": "https://arxiv.org/pdf/2505.24267", "abs": "https://arxiv.org/abs/2505.24267", "authors": ["Liancheng Fang", "Aiwei Liu", "Henry Peng Zou", "Yankai Chen", "Hengrui Zhang", "Zhongfen Deng", "Philip S. Yu"], "title": "MUSE: Model-Agnostic Tabular Watermarking via Multi-Sample Selection", "categories": ["cs.CR"], "comment": null, "summary": "We introduce MUSE, a watermarking algorithm for tabular generative models.\nPrevious approaches typically leverage DDIM invertibility to watermark tabular\ndiffusion models, but tabular diffusion models exhibit significantly poorer\ninvertibility compared to other modalities, compromising performance.\nSimultaneously, tabular diffusion models require substantially less computation\nthan other modalities, enabling a multi-sample selection approach to tabular\ngenerative model watermarking. MUSE embeds watermarks by generating multiple\ncandidate samples and selecting one based on a specialized scoring function,\nwithout relying on model invertibility. Our theoretical analysis establishes\nthe relationship between watermark detectability, candidate count, and dataset\nsize, allowing precise calibration of watermarking strength. Extensive\nexperiments demonstrate that MUSE achieves state-of-the-art watermark\ndetectability and robustness against various attacks while maintaining data\nquality, and remains compatible with any tabular generative model supporting\nrepeated sampling, effectively addressing key challenges in tabular data\nwatermarking. Specifically, it reduces the distortion rates on fidelity metrics\nby 81-89%, while achieving a 1.0 TPR@0.1%FPR detection rate. Implementation of\nMUSE can be found at https://github.com/fangliancheng/MUSE.", "AI": {"tldr": "The paper introduces MUSE, a watermarking algorithm for tabular generative models which achieves state-of-the-art watermark detectability and robustness while maintaining data quality.", "motivation": "Existing watermarking methods for tabular diffusion models rely on DDIM invertibility, but such models have poorer invertibility compared to other modalities, resulting in compromised performance. Additionally, these models require less computation, enabling alternative approaches.", "method": "MUSE embeds watermarks by generating multiple candidate samples and selecting one using a specialized scoring function, without relying on model invertibility. Theoretical analysis relates watermark detectability to candidate count and dataset size, allowing calibration of watermark strength.", "result": "MUSE reduces distortion rates on fidelity metrics by 81-89% and achieves a 1.0 TPR@0.1%FPR detection rate, demonstrating state-of-the-art watermark detectability and robustness against various attacks while preserving data quality.", "conclusion": "MUSE effectively addresses key challenges in tabular data watermarking and is compatible with any tabular generative model supporting repeated sampling."}}
{"id": "2505.23987", "pdf": "https://arxiv.org/pdf/2505.23987", "abs": "https://arxiv.org/abs/2505.23987", "authors": ["Vishal Dey", "Xiao Hu", "Xia Ning"], "title": "Large Language Models for Controllable Multi-property Multi-objective Molecule Optimization", "categories": ["cs.LG", "cs.AI", "cs.CL", "q-bio.BM"], "comment": null, "summary": "In real-world drug design, molecule optimization requires selectively\nimproving multiple molecular properties up to pharmaceutically relevant levels,\nwhile maintaining others that already meet such criteria. However, existing\ncomputational approaches and instruction-tuned LLMs fail to capture such\nnuanced property-specific objectives, limiting their practical applicability.\nTo address this, we introduce C-MuMOInstruct, the first instruction-tuning\ndataset focused on multi-property optimization with explicit, property-specific\nobjectives. Leveraging C-MuMOInstruct, we develop GeLLMO-Cs, a series of\ninstruction-tuned LLMs that can perform targeted property-specific\noptimization. Our experiments across 5 in-distribution and 5\nout-of-distribution tasks show that GeLLMO-Cs consistently outperform strong\nbaselines, achieving up to 126% higher success rate. Notably, GeLLMO-Cs exhibit\nimpressive 0-shot generalization to novel optimization tasks and unseen\ninstructions. This offers a step toward a foundational LLM to support\nrealistic, diverse optimizations with property-specific objectives.\nC-MuMOInstruct and code are accessible through\nhttps://github.com/ninglab/GeLLMO-C.", "AI": {"tldr": "In real-world drug design, molecule optimization requires selectively improving multiple molecular properties up to pharmaceutically relevant levels, while maintaining others that already meet such criteria. To address this, we introduce C-MuMOInstruct and develop GeLLMO-Cs which can perform targeted property-specific optimization.", "motivation": "Existing computational approaches and instruction-tuned LLMs fail to capture nuanced property-specific objectives in molecule optimization, limiting their practical applicability.", "method": "Introduced C-MuMOInstruct, the first instruction-tuning dataset focused on multi-property optimization with explicit, property-specific objectives. Leveraging C-MuMOInstruct, developed GeLLMO-Cs, a series of instruction-tuned LLMs that can perform targeted property-specific optimization.", "result": "Experiments across 5 in-distribution and 5 out-of-distribution tasks show that GeLLMO-Cs consistently outperform strong baselines, achieving up to 126% higher success rate. Notably, GeLLMO-Cs exhibit impressive 0-shot generalization to novel optimization tasks and unseen instructions.", "conclusion": "C-MuMOInstruct and code are accessible through https://github.com/ninglab/GeLLMO-C."}}
{"id": "2505.24785", "pdf": "https://arxiv.org/pdf/2505.24785", "abs": "https://arxiv.org/abs/2505.24785", "authors": ["Patrick Tser Jern Kon", "Jiachen Liu", "Xinyi Zhu", "Qiuyi Ding", "Jingjia Peng", "Jiarong Xing", "Yibo Huang", "Yiming Qiu", "Jayanth Srinivasa", "Myungjin Lee", "Mosharaf Chowdhury", "Matei Zaharia", "Ang Chen"], "title": "EXP-Bench: Can AI Conduct AI Research Experiments?", "categories": ["cs.AI"], "comment": "45 pages, 13 figures", "summary": "Automating AI research holds immense potential for accelerating scientific\nprogress, yet current AI agents struggle with the complexities of rigorous,\nend-to-end experimentation. We introduce EXP-Bench, a novel benchmark designed\nto systematically evaluate AI agents on complete research experiments sourced\nfrom influential AI publications. Given a research question and incomplete\nstarter code, EXP-Bench challenges AI agents to formulate hypotheses, design\nand implement experimental procedures, execute them, and analyze results. To\nenable the creation of such intricate and authentic tasks with high-fidelity,\nwe design a semi-autonomous pipeline to extract and structure crucial\nexperimental details from these research papers and their associated\nopen-source code. With the pipeline, EXP-Bench curated 461 AI research tasks\nfrom 51 top-tier AI research papers. Evaluations of leading LLM-based agents,\nsuch as OpenHands and IterativeAgent on EXP-Bench demonstrate partial\ncapabilities: while scores on individual experimental aspects such as design or\nimplementation correctness occasionally reach 20-35%, the success rate for\ncomplete, executable experiments was a mere 0.5%. By identifying these\nbottlenecks and providing realistic step-by-step experiment procedures,\nEXP-Bench serves as a vital tool for future AI agents to improve their ability\nto conduct AI research experiments. EXP-Bench is open-sourced at\nhttps://github.com/Just-Curieous/Curie/tree/main/benchmark/exp_bench.", "AI": {"tldr": "EXP-Bench is a new benchmark that evaluates AI agents on complete research experiments from influential AI publications. It highlights the current limitations of AI agents in conducting end-to-end experiments and serves as a tool for future improvements.", "motivation": "Automating AI research can accelerate scientific progress, but current AI agents face challenges with rigorous, end-to-end experimentation.", "method": "Introduced EXP-Bench, a benchmark that evaluates AI agents on complete research experiments. It uses a semi-autonomous pipeline to extract and structure experimental details from research papers and open-source code, curating 461 tasks from 51 top-tier papers.", "result": "Leading LLM-based agents scored 20-35% on individual experimental aspects, but only 0.5% success rate for complete experiments.", "conclusion": "EXP-Bench identifies bottlenecks in AI agents' capabilities and provides procedures to improve their ability to conduct AI research experiments."}}
{"id": "2505.24284", "pdf": "https://arxiv.org/pdf/2505.24284", "abs": "https://arxiv.org/abs/2505.24284", "authors": ["Gordon Y. Liao", "Ziming Zeng", "Mira Belenkiy", "Jacob Hirshman"], "title": "Transaction Proximity: A Graph-Based Approach to Blockchain Fraud Prevention", "categories": ["cs.CR", "cs.CE", "econ.GN", "q-fin.EC", "H.3.5; K.4.4; H.2.8"], "comment": null, "summary": "This paper introduces a fraud-deterrent access validation system for public\nblockchains, leveraging two complementary concepts: \"Transaction Proximity\",\nwhich measures the distance between wallets in the transaction graph, and\n\"Easily Attainable Identities (EAIs)\", wallets with direct transaction\nconnections to centralized exchanges. Recognizing the limitations of\ntraditional approaches like blocklisting (reactive, slow) and strict allow\nlisting (privacy-invasive, adoption barriers), we propose a system that\nanalyzes transaction patterns to identify wallets with close connections to\ncentralized exchanges.\n  Our directed graph analysis of the Ethereum blockchain reveals that 56% of\nlarge USDC wallets (with a lifetime maximum balance greater than \\$10,000) are\nEAI and 88% are within one transaction hop of an EAI. For transactions\nexceeding \\$2,000, 91% involve at least one EAI. Crucially, an analysis of past\nexploits shows that 83% of the known exploiter addresses are not EAIs, with 21%\nbeing more than five hops away from any regulated exchange. We present three\nimplementation approaches with varying gas cost and privacy tradeoffs,\ndemonstrating that EAI-based access control can potentially prevent most of\nthese incidents while preserving blockchain openness. Importantly, our approach\ndoes not restrict access or share personally identifiable information, but it\nprovides information for protocols to implement their own validation or risk\nscoring systems based on specific needs. This middle-ground solution enables\nprogrammatic compliance while maintaining the core values of open blockchain.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.24003", "pdf": "https://arxiv.org/pdf/2505.24003", "abs": "https://arxiv.org/abs/2505.24003", "authors": ["ChengAo Shen", "Wenchao Yu", "Ziming Zhao", "Dongjin Song", "Wei Cheng", "Haifeng Chen", "Jingchao Ni"], "title": "Multi-Modal View Enhanced Large Vision Models for Long-Term Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series, typically represented as numerical sequences, can also be\ntransformed into images and texts, offering multi-modal views (MMVs) of the\nsame underlying signal. These MMVs can reveal complementary patterns and enable\nthe use of powerful pre-trained large models, such as large vision models\n(LVMs), for long-term time series forecasting (LTSF). However, as we identified\nin this work, applying LVMs to LTSF poses an inductive bias towards\n\"forecasting periods\". To harness this bias, we propose DMMV, a novel\ndecomposition-based multi-modal view framework that leverages trend-seasonal\ndecomposition and a novel backcast residual based adaptive decomposition to\nintegrate MMVs for LTSF. Comparative evaluations against 14 state-of-the-art\n(SOTA) models across diverse datasets show that DMMV outperforms single-view\nand existing multi-modal baselines, achieving the best mean squared error (MSE)\non 6 out of 8 benchmark datasets.", "AI": {"tldr": "A new framework called DMMV is proposed, which uses multi-modal views from time series data for long-term forecasting and performs better than existing models.", "motivation": "To address the challenge of long-term time series forecasting by utilizing the power of pre-trained large vision models through transforming time series into multi-modal views.", "method": "DMMV, a decomposition-based multi-modal view framework that integrates MMVs using trend-seasonal decomposition and a backcast residual based adaptive decomposition.", "result": "DMMV outperforms single-view and existing multi-modal baselines, achieving the best mean squared error on 6 out of 8 benchmark datasets.", "conclusion": "The proposed DMMV framework effectively leverages multi-modal views for long-term time series forecasting and shows superior performance compared to state-of-the-art models."}}
{"id": "2505.24846", "pdf": "https://arxiv.org/pdf/2505.24846", "abs": "https://arxiv.org/abs/2505.24846", "authors": ["Jingyan Shen", "Jiarui Yao", "Rui Yang", "Yifan Sun", "Feng Luo", "Rui Pan", "Tong Zhang", "Han Zhao"], "title": "MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning", "categories": ["cs.AI", "cs.CL"], "comment": null, "summary": "Reward modeling is a key step in building safe foundation models when\napplying reinforcement learning from human feedback (RLHF) to align Large\nLanguage Models (LLMs). However, reward modeling based on the Bradley-Terry\n(BT) model assumes a global reward function, failing to capture the inherently\ndiverse and heterogeneous human preferences. Hence, such oversimplification\nlimits LLMs from supporting personalization and pluralistic alignment.\nTheoretically, we show that when human preferences follow a mixture\ndistribution of diverse subgroups, a single BT model has an irreducible error.\nWhile existing solutions, such as multi-objective learning with fine-grained\nannotations, help address this issue, they are costly and constrained by\npredefined attributes, failing to fully capture the richness of human values.\nIn this work, we introduce MiCRo, a two-stage framework that enhances\npersonalized preference learning by leveraging large-scale binary preference\ndatasets without requiring explicit fine-grained annotations. In the first\nstage, MiCRo introduces context-aware mixture modeling approach to capture\ndiverse human preferences. In the second stage, MiCRo integrates an online\nrouting strategy that dynamically adapts mixture weights based on specific\ncontext to resolve ambiguity, allowing for efficient and scalable preference\nadaptation with minimal additional supervision. Experiments on multiple\npreference datasets demonstrate that MiCRo effectively captures diverse human\npreferences and significantly improves downstream personalization.", "AI": {"tldr": "MiCRo is a two-stage framework that enhances personalized preference learning by leveraging large-scale binary preference datasets without requiring explicit fine-grained annotations.", "motivation": "Reward modeling based on the Bradley-Terry (BT) model assumes a global reward function, failing to capture the inherently diverse and heterogeneous human preferences. This limits LLMs from supporting personalization and pluralistic alignment.", "method": "MiCRo introduces context-aware mixture modeling approach in the first stage to capture diverse human preferences. In the second stage, it integrates an online routing strategy that dynamically adapts mixture weights based on specific context to resolve ambiguity.", "result": "Experiments on multiple preference datasets demonstrate that MiCRo effectively captures diverse human preferences and significantly improves downstream personalization.", "conclusion": "MiCRo is a promising solution for enhancing personalized preference learning and improving downstream personalization."}}
{"id": "2505.24289", "pdf": "https://arxiv.org/pdf/2505.24289", "abs": "https://arxiv.org/abs/2505.24289", "authors": ["Kareem Shehata", "Han Fangqi", "Sri AravindaKrishnan Thyagarajan"], "title": "Verifiable Weighted Secret Sharing", "categories": ["cs.CR"], "comment": null, "summary": "Traditionally, threshold secret sharing (TSS) schemes assume all parties have\nequal weight, yet emerging systems like blockchains reveal disparities in party\ntrustworthiness, such as stake or reputation. Weighted Secret Sharing (WSS)\naddresses this by assigning varying weights to parties, ensuring security even\nif adversaries control parties with total weight at most a threshold $t$.\nCurrent WSS schemes assume honest dealers, resulting in security from only\nhonest-but-curious behaviour but not protection from malicious adversaries for\ndownstream applications. \\emph{Verifiable} secret sharing (VSS) is a well-known\ntechnique to address this, but existing VSS schemes are either tailored to TSS,\nor require additional trust assumptions. We propose the first efficient\nverifiable WSS scheme that tolerates malicious dealers and is compatible with\nthe latest CRT-based WSS~\\cite{crypto_w_weights}. Our solution uses\nBulletproofs for efficient verification and introduces new privacy-preserving\ntechniques for proving relations between committed values, which may be of\nindependent interest. Evaluation on Ethereum show up to a $100\\times$\nimprovement in communication complexity compared to the current design and\n$20\\times$ improvement compared to unweighted VSS schemes.", "AI": {"tldr": "The paper presents an efficient verifiable weighted secret sharing (WSS) scheme that can handle malicious dealers, using Bulletproofs for verification and new privacy-preserving techniques, showing significant improvements in communication complexity on Ethereum.", "motivation": "Traditional threshold secret sharing schemes assume equal party weights, but emerging systems like blockchains reveal disparities in trustworthiness. Existing WSS schemes only ensure security from honest-but-curious behavior and lack protection from malicious adversaries.", "method": "The authors propose a verifiable WSS scheme compatible with the latest CRT-based WSS, utilizing Bulletproofs for efficient verification and introducing new privacy-preserving techniques to prove relations between committed values.", "result": "Evaluation on Ethereum demonstrates up to a 100x improvement in communication complexity compared to current designs and a 20x improvement compared to unweighted VSS schemes.", "conclusion": "This work provides the first efficient verifiable WSS scheme that tolerates malicious dealers, significantly enhancing communication efficiency, with potential applications in blockchain systems."}}
{"id": "2505.24005", "pdf": "https://arxiv.org/pdf/2505.24005", "abs": "https://arxiv.org/abs/2505.24005", "authors": ["Priya Kasimbeg", "Vincent Roulet", "Naman Agarwal", "Sourabh Medapati", "Fabian Pedregosa", "Atish Agarwala", "George E. Dahl"], "title": "How far away are truly hyperparameter-free learning algorithms?", "categories": ["cs.LG"], "comment": null, "summary": "Despite major advances in methodology, hyperparameter tuning remains a\ncrucial (and expensive) part of the development of machine learning systems.\nEven ignoring architectural choices, deep neural networks have a large number\nof optimization and regularization hyperparameters that need to be tuned\ncarefully per workload in order to obtain the best results. In a perfect world,\ntraining algorithms would not require workload-specific hyperparameter tuning,\nbut would instead have default settings that performed well across many\nworkloads. Recently, there has been a growing literature on optimization\nmethods which attempt to reduce the number of hyperparameters -- particularly\nthe learning rate and its accompanying schedule. Given these developments, how\nfar away is the dream of neural network training algorithms that completely\nobviate the need for painful tuning?\n  In this paper, we evaluate the potential of learning-rate-free methods as\ncomponents of hyperparameter-free methods. We freeze their (non-learning rate)\nhyperparameters to default values, and score their performance using the\nrecently-proposed AlgoPerf: Training Algorithms benchmark. We found that\nliterature-supplied default settings performed poorly on the benchmark, so we\nperformed a search for hyperparameter configurations that performed well across\nall workloads simultaneously. The best AlgoPerf-calibrated learning-rate-free\nmethods had much improved performance but still lagged slightly behind a\nsimilarly calibrated NadamW baseline in overall benchmark score. Our results\nsuggest that there is still much room for improvement for learning-rate-free\nmethods, and that testing against a strong, workload-agnostic baseline is\nimportant to improve hyperparameter reduction techniques.", "AI": {"tldr": "\u5c3d\u7ba1\u5728\u4f18\u5316\u65b9\u6cd5\u4e0a\u53d6\u5f97\u4e86\u91cd\u5927\u8fdb\u5c55\uff0c\u4f46\u8d85\u53c2\u6570\u8c03\u6574\u4ecd\u7136\u662f\u673a\u5668\u5b66\u4e60\u7cfb\u7edf\u5f00\u53d1\u4e2d\u81f3\u5173\u91cd\u8981\u4e14\u6602\u8d35\u7684\u4e00\u90e8\u5206\u3002\u672c\u6587\u8bc4\u4f30\u4e86\u65e0\u5b66\u4e60\u7387\u65b9\u6cd5\u4f5c\u4e3a\u65e0\u8d85\u53c2\u6570\u65b9\u6cd5\u7684\u6f5c\u529b\uff0c\u5e76\u901a\u8fc7AlgoPerf\u57fa\u51c6\u6d4b\u8bd5\u5176\u6027\u80fd\u3002\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u4ecd\u6709\u5f88\u5927\u7684\u6539\u8fdb\u7a7a\u95f4\uff0c\u540c\u65f6\u5f3a\u8c03\u4e86\u4f7f\u7528\u5f3a\u5927\u7684\u3001\u4e0e\u5de5\u4f5c\u8d1f\u8f7d\u65e0\u5173\u7684\u57fa\u7ebf\u8fdb\u884c\u6d4b\u8bd5\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5373\u4f7f\u5ffd\u7565\u67b6\u6784\u9009\u62e9\uff0c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4ecd\u9700\u8981\u9488\u5bf9\u6bcf\u4e2a\u4efb\u52a1\u7cbe\u5fc3\u8c03\u6574\u5927\u91cf\u4f18\u5316\u548c\u6b63\u5219\u5316\u8d85\u53c2\u6570\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u8bad\u7ec3\u7b97\u6cd5\u5e94\u65e0\u9700\u7279\u5b9a\u4efb\u52a1\u7684\u8d85\u53c2\u6570\u8c03\u6574\uff0c\u800c\u5177\u6709\u9002\u7528\u4e8e\u591a\u79cd\u4efb\u52a1\u7684\u9ed8\u8ba4\u8bbe\u7f6e\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u51cf\u5c11\u8d85\u53c2\u6570\u9700\u6c42\uff08\u7279\u522b\u662f\u5b66\u4e60\u7387\uff09\u7684\u65b9\u6cd5\u53d8\u5f97\u91cd\u8981\u3002", "method": "\u4f5c\u8005\u8bc4\u4f30\u4e86\u65e0\u5b66\u4e60\u7387\u65b9\u6cd5\u4f5c\u4e3a\u65e0\u8d85\u53c2\u6570\u65b9\u6cd5\u7ec4\u4ef6\u7684\u6f5c\u529b\u3002\u4ed6\u4eec\u5c06\u975e\u5b66\u4e60\u7387\u8d85\u53c2\u6570\u56fa\u5b9a\u4e3a\u9ed8\u8ba4\u503c\uff0c\u5e76\u4f7f\u7528AlgoPerf\u57fa\u51c6\u6d4b\u8bd5\u5176\u6027\u80fd\u3002\u7531\u4e8e\u6587\u732e\u63d0\u4f9b\u7684\u9ed8\u8ba4\u8bbe\u7f6e\u8868\u73b0\u4e0d\u4f73\uff0c\u4f5c\u8005\u8fdb\u4e00\u6b65\u641c\u7d22\u4e86\u5728\u6240\u6709\u4efb\u52a1\u4e0a\u8868\u73b0\u826f\u597d\u7684\u8d85\u53c2\u6570\u914d\u7f6e\u3002", "result": "\u6700\u4f73\u7684\u3001\u7ecf\u8fc7AlgoPerf\u6821\u51c6\u7684\u65e0\u5b66\u4e60\u7387\u65b9\u6cd5\u6027\u80fd\u6709\u6240\u63d0\u9ad8\uff0c\u4f46\u5728\u6574\u4f53\u57fa\u51c6\u5206\u6570\u4e0a\u4ecd\u7565\u900a\u4e8e\u540c\u6837\u6821\u51c6\u7684NadamW\u57fa\u7ebf\u3002\u8fd9\u8868\u660e\u65e0\u5b66\u4e60\u7387\u65b9\u6cd5\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "conclusion": "\u65e0\u5b66\u4e60\u7387\u65b9\u6cd5\u867d\u7136\u6709\u6240\u8fdb\u6b65\uff0c\u4f46\u4ecd\u9700\u8fdb\u4e00\u6b65\u6539\u8fdb\u4ee5\u8fbe\u5230\u4e0e\u5f3a\u57fa\u7ebf\u76f8\u5f53\u7684\u6027\u80fd\u3002\u6b64\u5916\uff0c\u6d4b\u8bd5\u65f6\u5e94\u4f7f\u7528\u5f3a\u5927\u7684\u3001\u4e0e\u5de5\u4f5c\u8d1f\u8f7d\u65e0\u5173\u7684\u57fa\u7ebf\u6765\u6539\u8fdb\u8d85\u53c2\u6570\u51cf\u5c11\u6280\u672f\u3002"}}
{"id": "2505.24878", "pdf": "https://arxiv.org/pdf/2505.24878", "abs": "https://arxiv.org/abs/2505.24878", "authors": ["Yaxin Luo", "Zhaoyi Li", "Jiacheng Liu", "Jiacheng Cui", "Xiaohan Zhao", "Zhiqiang Shen"], "title": "Open CaptchaWorld: A Comprehensive Web-based Platform for Testing and Benchmarking Multimodal LLM Agents", "categories": ["cs.AI", "cs.CL", "cs.CV", "cs.LG"], "comment": "Code at: https://github.com/MetaAgentX/OpenCaptchaWorld", "summary": "CAPTCHAs have been a critical bottleneck for deploying web agents in\nreal-world applications, often blocking them from completing end-to-end\nautomation tasks. While modern multimodal LLM agents have demonstrated\nimpressive performance in static perception tasks, their ability to handle\ninteractive, multi-step reasoning challenges like CAPTCHAs is largely untested.\nTo address this gap, we introduce Open CaptchaWorld, the first web-based\nbenchmark and platform specifically designed to evaluate the visual reasoning\nand interaction capabilities of MLLM-powered agents through diverse and dynamic\nCAPTCHA puzzles. Our benchmark spans 20 modern CAPTCHA types, totaling 225\nCAPTCHAs, annotated with a new metric we propose: CAPTCHA Reasoning Depth,\nwhich quantifies the number of cognitive and motor steps required to solve each\npuzzle. Experimental results show that humans consistently achieve near-perfect\nscores, state-of-the-art MLLM agents struggle significantly, with success rates\nat most 40.0% by Browser-Use Openai-o3, far below human-level performance,\n93.3%. This highlights Open CaptchaWorld as a vital benchmark for diagnosing\nthe limits of current multimodal agents and guiding the development of more\nrobust multimodal reasoning systems. Code and Data are available at this https\nURL.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86Open CaptchaWorld\uff0c\u8fd9\u662f\u4e00\u4e2a\u57fa\u4e8e\u7f51\u7edc\u7684\u57fa\u51c6\u548c\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30\u7531\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff08MLLM\uff09\u9a71\u52a8\u7684\u4ee3\u7406\u5728\u89e3\u51b3\u5404\u79cd\u52a8\u6001\u9a8c\u8bc1\u7801\u6311\u6218\u4e2d\u7684\u89c6\u89c9\u63a8\u7406\u548c\u4ea4\u4e92\u80fd\u529b\u3002\u8be5\u57fa\u51c6\u6db5\u76d6\u4e8620\u79cd\u73b0\u4ee3\u9a8c\u8bc1\u7801\u7c7b\u578b\uff0c\u603b\u8ba1225\u4e2a\u9a8c\u8bc1\u7801\uff0c\u5e76\u5f15\u5165\u4e86\u4e00\u4e2a\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u9a8c\u8bc1\u7801\u63a8\u7406\u6df1\u5ea6\uff0c\u4ee5\u91cf\u5316\u89e3\u51b3\u6bcf\u4e2a\u8c1c\u9898\u6240\u9700\u7684\u8ba4\u77e5\u548c\u8fd0\u52a8\u6b65\u9aa4\u6570\u91cf\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4eba\u7c7b\u7684\u8868\u73b0\u63a5\u8fd1\u5b8c\u7f8e\uff0c\u800c\u6700\u5148\u8fdb\u7684MLLM\u4ee3\u7406\u5219\u663e\u8457\u6323\u624e\uff0c\u6210\u529f\u7387\u6700\u9ad8\u4ec5\u4e3a40.0%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u768493.3%\u3002\u8fd9\u51f8\u663e\u4e86Open CaptchaWorld\u4f5c\u4e3a\u8bca\u65ad\u5f53\u524d\u591a\u6a21\u6001\u4ee3\u7406\u5c40\u9650\u6027\u548c\u6307\u5bfc\u66f4\u5f3a\u5927\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u53d1\u5c55\u7684\u5173\u952e\u57fa\u51c6\u7684\u91cd\u8981\u6027\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u4ee3\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5728\u9759\u6001\u611f\u77e5\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u5904\u7406\u50cf\u9a8c\u8bc1\u7801\u8fd9\u6837\u7684\u4ea4\u4e92\u5f0f\u3001\u591a\u6b65\u63a8\u7406\u6311\u6218\u7684\u80fd\u529b\u5c1a\u672a\u5f97\u5230\u5145\u5206\u6d4b\u8bd5\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e00\u5dee\u8ddd\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u8bbe\u8ba1\u7684\u57fa\u51c6\u548c\u5e73\u53f0\u6765\u8bc4\u4f30\u8fd9\u4e9b\u4ee3\u7406\u7684\u80fd\u529b\u3002", "method": "\u7814\u7a76\u4eba\u5458\u521b\u5efa\u4e86Open CaptchaWorld\uff0c\u5305\u542b20\u79cd\u73b0\u4ee3\u9a8c\u8bc1\u7801\u7c7b\u578b\uff0c\u5171\u8ba1225\u4e2a\u9a8c\u8bc1\u7801\u3002\u4ed6\u4eec\u8fd8\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u5ea6\u91cf\u6807\u51c6\u2014\u2014\u9a8c\u8bc1\u7801\u63a8\u7406\u6df1\u5ea6\uff0c\u7528\u4ee5\u91cf\u5316\u89e3\u51b3\u6bcf\u4e2a\u9a8c\u8bc1\u7801\u6240\u9700\u7684\u8ba4\u77e5\u548c\u8fd0\u52a8\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4eba\u7c7b\u5728\u89e3\u51b3\u9a8c\u8bc1\u7801\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u63a5\u8fd1\u5b8c\u7f8e\u5206\u6570\uff0c\u800c\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u4ee3\u7406\u5219\u663e\u8457\u6323\u624e\uff0c\u6210\u529f\u7387\u6700\u9ad8\u4ec5\u4e3a40.0%\uff0c\u8fdc\u4f4e\u4e8e\u4eba\u7c7b\u6c34\u5e73\u768493.3%\u3002", "conclusion": "Open CaptchaWorld\u88ab\u8bc1\u660e\u662f\u4e00\u4e2a\u91cd\u8981\u7684\u57fa\u51c6\uff0c\u80fd\u591f\u8bca\u65ad\u5f53\u524d\u591a\u6a21\u6001\u4ee3\u7406\u7684\u5c40\u9650\u6027\uff0c\u5e76\u6307\u5bfc\u5f00\u53d1\u66f4\u52a0\u7a33\u5065\u7684\u591a\u6a21\u6001\u63a8\u7406\u7cfb\u7edf\u3002\u4ee3\u7801\u548c\u6570\u636e\u5df2\u5728\u6307\u5b9aURL\u4e0a\u63d0\u4f9b\u3002"}}
{"id": "2505.24393", "pdf": "https://arxiv.org/pdf/2505.24393", "abs": "https://arxiv.org/abs/2505.24393", "authors": ["Suhyeon Lee"], "title": "Looking for Attention: Randomized Attention Test Design for Validator Monitoring in Optimistic Rollups", "categories": ["cs.CR", "cs.CE", "cs.GT", "K.6.5; C.2.2; F.2"], "comment": null, "summary": "Optimistic Rollups (ORUs) significantly enhance blockchain scalability but\ninherently suffer from the verifier's dilemma, particularly concerning\nvalidator attentiveness. Current systems lack mechanisms to proactively ensure\nvalidators are diligently monitoring L2 state transitions, creating a\nvulnerability where fraudulent states could be finalized. This paper introduces\nthe Randomized Attention Test (RAT), a novel L1-based protocol designed to\nprobabilistically challenge validators in ORUs, thereby verifying their\nliveness and computational readiness. Our game-theoretic analysis demonstrates\nthat an Ideal Security Equilibrium, where all validators are attentive and\nproposers are honest, can be achieved with RAT. Notably, this equilibrium is\nattainable and stable with relatively low economic penalties (e.g., under\n$1000) for non-responsive validators and a low attention test frequency (e.g.,\nunder 1% per epoch). RAT thus provides a crucial, practical mechanism to\nenforce validator diligence, fortifying the overall security and integrity of\nORU systems with minimizing additional costs.", "AI": {"tldr": "Optimistic Rollups (ORUs) improve blockchain scalability but face the verifier's dilemma. This paper proposes Randomized Attention Test (RAT), a protocol to probabilistically challenge validators' attentiveness in ORUs, ensuring their diligence and system security with low costs.", "motivation": "ORUs enhance blockchain scalability but suffer from the verifier's dilemma due to lack of mechanisms to ensure validator attentiveness, potentially leading to finalization of fraudulent states.", "method": "Introduces RAT, an L1-based protocol that probabilistically challenges validators in ORUs to verify their liveness and computational readiness using game-theoretic analysis.", "result": "Achieves Ideal Security Equilibrium where all validators are attentive and proposers are honest, with relatively low economic penalties for non-responsive validators and low attention test frequency.", "conclusion": "RAT provides a practical mechanism to enforce validator diligence in ORUs, enhancing system security and integrity while minimizing additional costs."}}
{"id": "2505.24022", "pdf": "https://arxiv.org/pdf/2505.24022", "abs": "https://arxiv.org/abs/2505.24022", "authors": ["Bhavya Vasudeva", "Jung Whan Lee", "Vatsal Sharan", "Mahdi Soltanolkotabi"], "title": "The Rich and the Simple: On the Implicit Bias of Adam and SGD", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "27 pages, 11 figures, 16 tables", "summary": "Adam is the de facto optimization algorithm for several deep learning\napplications, but an understanding of its implicit bias and how it differs from\nother algorithms, particularly standard first-order methods such as\n(stochastic) gradient descent (GD), remains limited. In practice, neural\nnetworks trained with SGD are known to exhibit simplicity bias -- a tendency to\nfind simple solutions. In contrast, we show that Adam is more resistant to such\nsimplicity bias. To demystify this phenomenon, in this paper, we investigate\nthe differences in the implicit biases of Adam and GD when training two-layer\nReLU neural networks on a binary classification task involving synthetic data\nwith Gaussian clusters. We find that GD exhibits a simplicity bias, resulting\nin a linear decision boundary with a suboptimal margin, whereas Adam leads to\nmuch richer and more diverse features, producing a nonlinear boundary that is\ncloser to the Bayes' optimal predictor. This richer decision boundary also\nallows Adam to achieve higher test accuracy both in-distribution and under\ncertain distribution shifts. We theoretically prove these results by analyzing\nthe population gradients. To corroborate our theoretical findings, we present\nempirical results showing that this property of Adam leads to superior\ngeneralization across datasets with spurious correlations where neural networks\ntrained with SGD are known to show simplicity bias and don't generalize well\nunder certain distributional shifts.", "AI": {"tldr": "Adam\u4f18\u5316\u7b97\u6cd5\u5728\u6df1\u5ea6\u5b66\u4e60\u5e94\u7528\u4e2d\u5360\u636e\u91cd\u8981\u5730\u4f4d\uff0c\u4f46\u5bf9\u5176\u9690\u5f0f\u504f\u5dee\u53ca\u5176\u4e0e\u968f\u673a\u68af\u5ea6\u4e0b\u964d\uff08SGD\uff09\u7b49\u4e00\u9636\u65b9\u6cd5\u5dee\u5f02\u7684\u7406\u89e3\u4ecd\u7136\u6709\u9650\u3002\u672c\u6587\u901a\u8fc7\u7814\u7a76\u4e24\u5c42ReLU\u795e\u7ecf\u7f51\u7edc\u5728\u5408\u6210\u9ad8\u65af\u805a\u7c7b\u6570\u636e\u4e0a\u7684\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u63ed\u793a\u4e86GD\u503e\u5411\u4e8e\u7b80\u5355\u7684\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\uff0c\u800cAdam\u5219\u4ea7\u751f\u66f4\u4e30\u5bcc\u3001\u66f4\u591a\u6837\u7684\u975e\u7ebf\u6027\u7279\u5f81\u548c\u51b3\u7b56\u8fb9\u754c\u3002\u8fd9\u4f7f\u5f97Adam\u5728\u6d4b\u8bd5\u7cbe\u5ea6\u548c\u6cdb\u5316\u80fd\u529b\u4e0a\u8868\u73b0\u66f4\u4f18\u3002\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u7ed3\u679c\u5747\u652f\u6301\u8fd9\u4e00\u53d1\u73b0\u3002", "motivation": "\u5c3d\u7ba1Adam\u5728\u6df1\u5ea6\u5b66\u4e60\u4e2d\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u9690\u5f0f\u504f\u5dee\u53ca\u4e0eSGD\u7684\u5dee\u5f02\u5c1a\u672a\u88ab\u5145\u5206\u7406\u89e3\u3002\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7a76Adam\u4e3a\u4f55\u5728\u5b9e\u8df5\u4e2d\u8868\u73b0\u51fa\u4e0d\u540c\u4e8eSGD\u7684\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u7279\u5f81\u5b66\u4e60\u548c\u51b3\u7b56\u8fb9\u754c\u5f62\u6210\u65b9\u9762\u7684\u5dee\u5f02\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u8bad\u7ec3\u4e24\u5c42ReLU\u795e\u7ecf\u7f51\u7edc\u5b8c\u6210\u4e8c\u5206\u7c7b\u4efb\u52a1\uff0c\u6bd4\u8f83Adam\u548cGD\u5728\u5408\u6210\u9ad8\u65af\u805a\u7c7b\u6570\u636e\u4e0a\u7684\u884c\u4e3a\u3002\u5229\u7528\u79cd\u7fa4\u68af\u5ea6\u5206\u6790\uff0c\u7406\u8bba\u8bc1\u660eAdam\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u548c\u975e\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\uff0c\u800cGD\u503e\u5411\u4e8e\u7b80\u5355\u7ebf\u6027\u8fb9\u754c\u3002\u540c\u65f6\uff0c\u901a\u8fc7\u5b9e\u9a8c\u8bc1\u660eAdam\u5728\u5e26\u865a\u5047\u76f8\u5173\u6027\u7684\u6570\u636e\u96c6\u4e0a\u5177\u6709\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cAdam\u80fd\u591f\u751f\u6210\u66f4\u590d\u6742\u548c\u591a\u6837\u7684\u7279\u5f81\uff0c\u4ece\u800c\u5f62\u6210\u63a5\u8fd1\u8d1d\u53f6\u65af\u6700\u4f18\u9884\u6d4b\u5668\u7684\u975e\u7ebf\u6027\u51b3\u7b56\u8fb9\u754c\u3002\u76f8\u6bd4\u4e4b\u4e0b\uff0cGD\u8868\u73b0\u51fa\u7b80\u5355\u504f\u5dee\uff0c\u5bfc\u81f4\u6b21\u4f18\u7684\u7ebf\u6027\u8fb9\u754c\u3002\u5b9e\u9a8c\u7ed3\u679c\u4e5f\u9a8c\u8bc1\u4e86Adam\u5728\u4e0d\u540c\u6570\u636e\u5206\u5e03\u4e0b\u7684\u4f18\u8d8a\u6cdb\u5316\u6027\u80fd\u3002", "conclusion": "Adam\u76f8\u6bd4SGD\u5c55\u73b0\u51fa\u66f4\u5f3a\u7684\u6297\u7b80\u5355\u504f\u5dee\u80fd\u529b\uff0c\u80fd\u751f\u6210\u66f4\u4e30\u5bcc\u7684\u7279\u5f81\u548c\u66f4\u590d\u6742\u7684\u51b3\u7b56\u8fb9\u754c\uff0c\u4ece\u800c\u5728\u67d0\u4e9b\u6570\u636e\u5206\u5e03\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u7684\u6d4b\u8bd5\u51c6\u786e\u7387\u548c\u66f4\u597d\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.18334", "pdf": "https://arxiv.org/pdf/2505.18334", "abs": "https://arxiv.org/abs/2505.18334", "authors": ["Jiaxun Cui", "Chen Tang", "Jarrett Holtz", "Janice Nguyen", "Alessandro G. Allievi", "Hang Qiu", "Peter Stone"], "title": "Towards Natural Language Communication for Cooperative Autonomous Driving via Self-Play", "categories": ["cs.RO", "cs.AI", "cs.MA"], "comment": null, "summary": "Past work has demonstrated that autonomous vehicles can drive more safely if\nthey communicate with one another than if they do not. However, their\ncommunication has often not been human-understandable. Using natural language\nas a vehicle-to-vehicle (V2V) communication protocol offers the potential for\nautonomous vehicles to drive cooperatively not only with each other but also\nwith human drivers. In this work, we propose a suite of traffic tasks in\nautonomous driving where vehicles in a traffic scenario need to communicate in\nnatural language to facilitate coordination in order to avoid an imminent\ncollision and/or support efficient traffic flow. To this end, this paper\nintroduces a novel method, LLM+Debrief, to learn a message generation and\nhigh-level decision-making policy for autonomous vehicles through multi-agent\ndiscussion. To evaluate LLM agents for driving, we developed a gym-like\nsimulation environment that contains a range of driving scenarios. Our\nexperimental results demonstrate that LLM+Debrief is more effective at\ngenerating meaningful and human-understandable natural language messages to\nfacilitate cooperation and coordination than a zero-shot LLM agent. Our code\nand demo videos are available at https://talking-vehicles.github.io/.", "AI": {"tldr": "The paper proposes LLM+Debrief method for autonomous vehicles to communicate in natural language, facilitating cooperation and coordination.", "motivation": "Autonomous vehicles can drive more safely with communication, but current communication methods are not human-understandable.", "method": "Proposes LLM+Debrief method for generating natural language messages through multi-agent discussion.", "result": "LLM+Debrief is more effective than zero-shot LLM agent in generating meaningful and human-understandable messages.", "conclusion": "Natural language communication among autonomous vehicles can enhance cooperation and coordination."}}
{"id": "2505.24440", "pdf": "https://arxiv.org/pdf/2505.24440", "abs": "https://arxiv.org/abs/2505.24440", "authors": ["Akaki Mamageishvili", "Benny Sudakov"], "title": "The Cost of Restaking vs. Proof-of-Stake", "categories": ["cs.CR", "econ.TH"], "comment": null, "summary": "We compare the efficiency of restaking and Proof-of-Stake (PoS) protocols in\nterms of stake requirements. First, we consider the sufficient condition for\nthe restaking graph to be secure. We show that the condition implies that it is\nalways possible to transform such a restaking graph into secure PoS protocols.\nNext, we derive two main results, giving upper and lower bounds on required\nextra stakes that one needs to add to validators of the secure restaking graph\nto be able to transform it into secure PoS protocols. In particular, we show\nthat the restaking savings compared to PoS protocols can be very large and can\nasymptotically grow in the worst case as a square root of the number of\nvalidators. We also study a complementary question of transforming secure PoS\nprotocols into an aggregate secure restaking graph and provide lower and upper\nbounds on the PoS savings compared to restaking.", "AI": {"tldr": "The paper compares the efficiency of restaking and Proof-of-Stake (PoS) protocols in terms of stake requirements, finding that restaking can offer significant savings compared to PoS, potentially growing as the square root of the number of validators.", "motivation": "To evaluate and compare the efficiency of restaking and PoS protocols in terms of stake requirements, focusing on transforming restaking graphs into secure PoS protocols and vice versa.", "method": "Analyzing the sufficient condition for a restaking graph to be secure, deriving upper and lower bounds on extra stakes needed for transformation between restaking and PoS protocols, and studying the complementary question of converting secure PoS protocols into an aggregate secure restaking graph.", "result": "It is always possible to transform a secure restaking graph into secure PoS protocols. Restaking can provide substantial savings compared to PoS protocols, with the savings asymptotically growing in the worst case as the square root of the number of validators.", "conclusion": "Restaking offers significant advantages over traditional PoS protocols in terms of stake efficiency, with clear bounds established for transformations between the two."}}
{"id": "2505.24030", "pdf": "https://arxiv.org/pdf/2505.24030", "abs": "https://arxiv.org/abs/2505.24030", "authors": ["Ziming Zhao", "ChengAo Shen", "Hanghang Tong", "Dongjin Song", "Zhigang Deng", "Qingsong Wen", "Jingchao Ni"], "title": "From Images to Signals: Are Large Vision Models Useful for Time Series Analysis?", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Transformer-based models have gained increasing attention in time series\nresearch, driving interest in Large Language Models (LLMs) and foundation\nmodels for time series analysis. As the field moves toward multi-modality,\nLarge Vision Models (LVMs) are emerging as a promising direction. In the past,\nthe effectiveness of Transformer and LLMs in time series has been debated. When\nit comes to LVMs, a similar question arises: are LVMs truely useful for time\nseries analysis? To address it, we design and conduct the first principled\nstudy involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across\nboth high-level (classification) and low-level (forecasting) tasks, with\nextensive ablation analysis. Our findings indicate LVMs are indeed useful for\ntime series classification but face challenges in forecasting. Although\neffective, the contemporary best LVM forecasters are limited to specific types\nof LVMs and imaging methods, exhibit a bias toward forecasting periods, and\nhave limited ability to utilize long look-back windows. We hope our findings\ncould serve as a cornerstone for future research on LVM- and multimodal-based\nsolutions to different time series tasks.", "AI": {"tldr": "The first principled study on the effectiveness of LVMs in time series analysis, testing 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines. LVMs are useful for classification but challenged in forecasting.", "motivation": "To explore whether Large Vision Models (LVMs) are truly useful for time series analysis as Transformer-based models and LLMs have gained increasing attention in this field.", "method": "Designed and conducted a study involving 4 LVMs, 8 imaging methods, 18 datasets and 26 baselines across both high-level (classification) and low-level (forecasting) tasks with extensive ablation analysis.", "result": "LVMs are indeed useful for time series classification but face challenges in forecasting. The best LVM forecasters are limited to specific types of LVMs and imaging methods, exhibit a bias toward forecasting periods, and have limited ability to utilize long look-back windows.", "conclusion": "This study serves as a cornerstone for future research on LVM- and multimodal-based solutions to different time series tasks."}}
{"id": "2505.18754", "pdf": "https://arxiv.org/pdf/2505.18754", "abs": "https://arxiv.org/abs/2505.18754", "authors": ["Elsen Ronando", "Sozo Inoue"], "title": "Few-Shot Optimization for Sensor Data Using Large Language Models: A Case Study on Fatigue Detection", "categories": ["cs.CL", "cs.AI", "cs.LG", "I.2.7"], "comment": "43 pages, 18 figures. Accepted for publication in MDPI Sensors\n  (2025). Final version before journal publication", "summary": "In this paper, we propose a novel few-shot optimization with HED-LM (Hybrid\nEuclidean Distance with Large Language Models) to improve example selection for\nsensor-based classification tasks. While few-shot prompting enables efficient\ninference with limited labeled data, its performance largely depends on the\nquality of selected examples. HED-LM addresses this challenge through a hybrid\nselection pipeline that filters candidate examples based on Euclidean distance\nand re-ranks them using contextual relevance scored by large language models\n(LLMs). To validate its effectiveness, we apply HED-LM to a fatigue detection\ntask using accelerometer data characterized by overlapping patterns and high\ninter-subject variability. Unlike simpler tasks such as activity recognition,\nfatigue detection demands more nuanced example selection due to subtle\ndifferences in physiological signals. Our experiments show that HED-LM achieves\na mean macro F1-score of 69.13$\\pm$10.71%, outperforming both random selection\n(59.30$\\pm$10.13%) and distance-only filtering (67.61$\\pm$11.39%). These\nrepresent relative improvements of 16.6% and 2.3%, respectively. The results\nconfirm that combining numerical similarity with contextual relevance improves\nthe robustness of few-shot prompting. Overall, HED-LM offers a practical\nsolution to improve performance in real-world sensor-based learning tasks and\nshows potential for broader applications in healthcare monitoring, human\nactivity recognition, and industrial safety scenarios.", "AI": {"tldr": "This paper proposes HED-LM, a novel few-shot optimization method combining numerical similarity and contextual relevance for sensor-based classification tasks. It improves example selection and outperforms existing methods in fatigue detection using accelerometer data.", "motivation": "Few-shot prompting is effective for inference with limited labeled data, but its performance heavily relies on the quality of selected examples. Current methods struggle with nuanced example selection, especially in complex tasks like fatigue detection from sensor data.", "method": "The paper introduces HED-LM, which uses a hybrid selection pipeline involving Euclidean distance to filter candidate examples and large language models (LLMs) to re-rank them based on contextual relevance. This approach aims to improve the robustness of few-shot prompting by combining numerical similarity with contextual understanding.", "result": "HED-LM achieved a mean macro F1-score of 69.13\u00b110.71% in fatigue detection tasks, surpassing random selection (59.30\u00b110.13%) and distance-only filtering (67.61\u00b111.39%). This represents relative improvements of 16.6% and 2.3%, respectively.", "conclusion": "HED-LM effectively enhances the performance of few-shot prompting in sensor-based classification tasks, particularly in scenarios requiring nuanced example selection. The method shows promise for broader applications in healthcare monitoring, human activity recognition, and industrial safety."}}
{"id": "2505.24451", "pdf": "https://arxiv.org/pdf/2505.24451", "abs": "https://arxiv.org/abs/2505.24451", "authors": ["Luis Ibanez-Lissen", "Lorena Gonzalez-Manzano", "Jose Maria de Fuentes", "Nicolas Anciaux"], "title": "LPASS: Linear Probes as Stepping Stones for vulnerability detection using compressed LLMs", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) are being extensively used for cybersecurity\npurposes. One of them is the detection of vulnerable codes. For the sake of\nefficiency and effectiveness, compression and fine-tuning techniques are being\ndeveloped, respectively. However, they involve spending substantial\ncomputational efforts. In this vein, we analyse how Linear Probes (LPs) can be\nused to provide an estimation on the performance of a compressed LLM at an\nearly phase -- before fine-tuning. We also show their suitability to set the\ncut-off point when applying layer pruning compression. Our approach, dubbed\n$LPASS$, is applied in BERT and Gemma for the detection of 12 of MITRE's Top 25\nmost dangerous vulnerabilities on 480k C/C++ samples. LPs can be computed in\n142.97 s. and provide key findings: (1) 33.3 \\% and 72.2\\% of layers can be\nremoved, respectively, with no precision loss; (2) they provide an early\nestimate of the post-fine-tuning and post-compression model effectiveness, with\n3\\% and 8.68\\% as the lowest and average precision errors, respectively.\n$LPASS$-based LLMs outperform the state of the art, reaching 86.9\\% of accuracy\nin multi-class vulnerability detection. Interestingly, $LPASS$-based compressed\nversions of Gemma outperform the original ones by 1.6\\% of F1-score at a\nmaximum while saving 29.4 \\% and 23.8\\% of training and inference time and\n42.98\\% of model size.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5982\u4f55\u4f7f\u7528\u7ebf\u6027\u63a2\u6d4b\u5668\uff08LPs\uff09\u6765\u4f30\u8ba1\u538b\u7f29\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u6027\u80fd\uff0c\u5e76\u5728\u5fae\u8c03\u4e4b\u524d\u786e\u5b9a\u526a\u679d\u538b\u7f29\u7684\u6700\u4f73\u622a\u65ad\u70b9\u3002\u63d0\u51fa\u7684\u65b9\u6cd5$LPASS$\u5e94\u7528\u4e8eBERT\u548cGemma\uff0c\u7528\u4e8e\u68c0\u6d4bMITRE Top 25\u4e2d\u768412\u79cd\u6700\u5371\u9669\u6f0f\u6d1e\uff0c\u572848\u4e07C/C++\u6837\u672c\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002\u7ed3\u679c\u8868\u660e\uff1a(1) \u53ef\u4ee5\u5206\u522b\u79fb\u966433.3%\u548c72.2%\u7684\u5c42\u800c\u4e0d\u4f1a\u635f\u5931\u7cbe\u5ea6\uff1b(2) LPs\u80fd\u63d0\u524d\u4f30\u8ba1\u5fae\u8c03\u540e\u548c\u538b\u7f29\u540e\u7684\u6a21\u578b\u6548\u679c\uff0c\u8bef\u5dee\u8303\u56f4\u4e3a3%-8.68%\u3002\u57fa\u4e8e$LPASS$\u7684LLMs\u5728\u591a\u7c7b\u6f0f\u6d1e\u68c0\u6d4b\u4e2d\u51c6\u786e\u7387\u8fbe\u523086.9%\uff0c\u8d85\u8fc7\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u538b\u7f29\u7248Gemma\u6bd4\u539f\u7248\u5728F1\u5206\u6570\u4e0a\u63d0\u9ad81.6%\uff0c\u540c\u65f6\u51cf\u5c11\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u5206\u522b\u4e3a29.4%\u548c23.8%\uff0c\u6a21\u578b\u5927\u5c0f\u51cf\u5c1142.98%\u3002", "motivation": "\u5f53\u524d\u7528\u4e8e\u7f51\u7edc\u5b89\u5168\u76ee\u7684\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u9700\u8981\u901a\u8fc7\u538b\u7f29\u548c\u5fae\u8c03\u6280\u672f\u63d0\u5347\u6548\u7387\u548c\u6548\u679c\uff0c\u4f46\u8fd9\u4e9b\u8fc7\u7a0b\u9700\u8981\u5927\u91cf\u8ba1\u7b97\u8d44\u6e90\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u4e00\u79cd\u5feb\u901f\u3001\u4f4e\u8017\u7684\u65b9\u5f0f\uff0c\u63d0\u524d\u8bc4\u4f30\u538b\u7f29LLMs\u7684\u6027\u80fd\u5e76\u6307\u5bfc\u526a\u679d\u64cd\u4f5c\u6210\u4e3a\u5fc5\u8981\u3002", "method": "\u5f15\u5165\u7ebf\u6027\u63a2\u6d4b\u5668\uff08LPs\uff09\uff0c\u7ed3\u5408\u63d0\u51fa\u7684\u65b9\u6cd5$LPASS$\uff0c\u5e94\u7528\u4e8eBERT\u548cGemma\u6a21\u578b\u3002\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u5c42\u5bf9\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u786e\u5b9a\u6700\u4f73\u526a\u679d\u70b9\uff0c\u5e76\u4f30\u8ba1\u5fae\u8c03\u548c\u538b\u7f29\u540e\u7684\u6a21\u578b\u6548\u679c\u3002\u8be5\u65b9\u6cd5\u7528\u4e8e\u68c0\u6d4bMITRE Top 25\u4e2d\u768412\u79cd\u6f0f\u6d1e\u7c7b\u578b\uff0c\u6d89\u53ca48\u4e07C/C++\u4ee3\u7801\u6837\u672c\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c(1) \u5206\u522b\u53ef\u4ee5\u79fb\u966433.3%\u548c72.2%\u7684\u6a21\u578b\u5c42\u800c\u4e0d\u5f71\u54cd\u7cbe\u5ea6\uff1b(2) LPs\u80fd\u591f\u63d0\u524d\u9884\u6d4b\u5fae\u8c03\u548c\u538b\u7f29\u540e\u7684\u6a21\u578b\u6027\u80fd\uff0c\u8bef\u5dee\u8303\u56f4\u4e3a3%-8.68%\u3002\u57fa\u4e8e$LPASS$\u7684LLMs\u5728\u591a\u7c7b\u6f0f\u6d1e\u68c0\u6d4b\u4efb\u52a1\u4e2d\u8fbe\u523086.9%\u7684\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u6c34\u5e73\u3002\u6b64\u5916\uff0c\u538b\u7f29\u7248Gemma\u6bd4\u539f\u7248\u5728F1\u5206\u6570\u4e0a\u63d0\u9ad81.6%\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u548c\u63a8\u7406\u65f6\u95f4\u4ee5\u53ca\u6a21\u578b\u5927\u5c0f\u3002", "conclusion": "\u7ebf\u6027\u63a2\u6d4b\u5668\uff08LPs\uff09\u4e0e$LPASS$\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u538b\u7f29LLMs\u7684\u6027\u80fd\u5e76\u6307\u5bfc\u526a\u679d\u64cd\u4f5c\u3002\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\uff0c$LPASS$\u4e0d\u4ec5\u63d0\u5347\u4e86\u6f0f\u6d1e\u68c0\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u8fd8\u663e\u8457\u51cf\u5c11\u4e86\u8ba1\u7b97\u8d44\u6e90\u6d88\u8017\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2505.24034", "pdf": "https://arxiv.org/pdf/2505.24034", "abs": "https://arxiv.org/abs/2505.24034", "authors": ["Bo Wu", "Sid Wang", "Yunhao Tang", "Jia Ding", "Eryk Helenowski", "Liang Tan", "Tengyu Xu", "Tushar Gowda", "Zhengxing Chen", "Chen Zhu", "Xiaocheng Tang", "Yundi Qian", "Beibei Zhu", "Rui Hou"], "title": "LlamaRL: A Distributed Asynchronous Reinforcement Learning Framework for Efficient Large-scale LLM Trainin", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement Learning (RL) has become the most effective post-training\napproach for improving the capabilities of Large Language Models (LLMs). In\npractice, because of the high demands on latency and memory, it is particularly\nchallenging to develop an efficient RL framework that reliably manages policy\nmodels with hundreds to thousands of billions of parameters.\n  In this paper, we present LlamaRL, a fully distributed, asynchronous RL\nframework optimized for efficient training of large-scale LLMs with various\nmodel sizes (8B, 70B, and 405B parameters) on GPU clusters ranging from a\nhandful to thousands of devices. LlamaRL introduces a streamlined,\nsingle-controller architecture built entirely on native PyTorch, enabling\nmodularity, ease of use, and seamless scalability to thousands of GPUs. We also\nprovide a theoretical analysis of LlamaRL's efficiency, including a formal\nproof that its asynchronous design leads to strict RL speed-up. Empirically, by\nleveraging best practices such as colocated model offloading, asynchronous\noff-policy training, and distributed direct memory access for weight\nsynchronization, LlamaRL achieves significant efficiency gains -- up to 10.7x\nspeed-up compared to DeepSpeed-Chat-like systems on a 405B-parameter policy\nmodel. Furthermore, the efficiency advantage continues to grow with increasing\nmodel scale, demonstrating the framework's suitability for future large-scale\nRL training.", "AI": {"tldr": "The paper introduces LlamaRL, an efficient, distributed RL framework for training large-scale LLMs. It achieves significant speed-ups over existing systems and scales well with model size.", "motivation": "There is a need for an efficient reinforcement learning framework to handle large language models with billions of parameters due to the high demands on latency and memory.", "method": "LlamaRL is a fully distributed, asynchronous RL framework built on native PyTorch. It features a single-controller architecture, modularity, ease of use, and scalability to thousands of GPUs. The framework employs techniques such as colocated model offloading, asynchronous off-policy training, and distributed direct memory access for weight synchronization.", "result": "LlamaRL achieves up to 10.7x speed-up compared to DeepSpeed-Chat-like systems on a 405B-parameter policy model. The efficiency advantage increases with larger model sizes.", "conclusion": "LlamaRL is suitable for future large-scale RL training due to its significant efficiency gains and scalability."}}
{"id": "2505.24536", "pdf": "https://arxiv.org/pdf/2505.24536", "abs": "https://arxiv.org/abs/2505.24536", "authors": ["Chaohui Xu", "Qi Cui", "Chip-Hong Chang"], "title": "CHIP: Chameleon Hash-based Irreversible Passport for Robust Deep Model Ownership Verification and Active Usage Control", "categories": ["cs.CR", "cs.AI"], "comment": null, "summary": "The pervasion of large-scale Deep Neural Networks (DNNs) and their enormous\ntraining costs make their intellectual property (IP) protection of paramount\nimportance. Recently introduced passport-based methods attempt to steer DNN\nwatermarking towards strengthening ownership verification against ambiguity\nattacks by modulating the affine parameters of normalization layers.\nUnfortunately, neither watermarking nor passport-based methods provide a\nholistic protection with robust ownership proof, high fidelity, active usage\nauthorization and user traceability for offline access distributed models and\nmulti-user Machine-Learning as a Service (MLaaS) cloud model. In this paper, we\npropose a Chameleon Hash-based Irreversible Passport (CHIP) protection\nframework that utilizes the cryptographic chameleon hash function to achieve\nall these goals. The collision-resistant property of chameleon hash allows for\nstrong model ownership claim upon IP infringement and liable user traceability,\nwhile the trapdoor-collision property enables hashing of multiple user\npassports and licensee certificates to the same immutable signature to realize\nactive usage control. Using the owner passport as an oracle, multiple\nuser-specific triplets, each contains a passport-aware user model, a user\npassport, and a licensee certificate can be created for secure offline\ndistribution. The watermarked master model can also be deployed for MLaaS with\nusage permission verifiable by the provision of any trapdoor-colliding user\npassports. CHIP is extensively evaluated on four datasets and two architectures\nto demonstrate its protection versatility and robustness. Our code is released\nat https://github.com/Dshm212/CHIP.", "AI": {"tldr": "A new framework named CHIP is proposed for DNNs IP protection, which uses cryptographic chameleon hash function to ensure strong ownership proof, high fidelity, active usage authorization and user traceability.", "motivation": "Existing watermarking and passport-based methods lack a holistic protection with robust ownership proof, high fidelity, active usage authorization and user traceability for offline access distributed models and multi-user MLaaS cloud model.", "method": "The CHIP protection framework utilizes the cryptographic chameleon hash function. The collision-resistant property allows for strong model ownership claim and liable user traceability, while the trapdoor-collision property enables hashing of multiple user passports and licensee certificates to the same immutable signature for active usage control. Using the owner passport as an oracle, multiple user-specific triplets can be created for secure offline distribution. The watermarked master model can also be deployed for MLaaS with usage permission verifiable by the provision of any trapdoor-colliding user passports.", "result": "CHIP is extensively evaluated on four datasets and two architectures to demonstrate its protection versatility and robustness.", "conclusion": "CHIP provides a comprehensive solution for DNNs IP protection with strong ownership proof, high fidelity, active usage authorization and user traceability."}}
{"id": "2505.24048", "pdf": "https://arxiv.org/pdf/2505.24048", "abs": "https://arxiv.org/abs/2505.24048", "authors": ["Guangtao Zheng", "Wenqian Ye", "Aidong Zhang"], "title": "NeuronTune: Towards Self-Guided Spurious Bias Mitigation", "categories": ["cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Deep neural networks often develop spurious bias, reliance on correlations\nbetween non-essential features and classes for predictions. For example, a\nmodel may identify objects based on frequently co-occurring backgrounds rather\nthan intrinsic features, resulting in degraded performance on data lacking\nthese correlations. Existing mitigation approaches typically depend on external\nannotations of spurious correlations, which may be difficult to obtain and are\nnot relevant to the spurious bias in a model. In this paper, we take a step\ntowards self-guided mitigation of spurious bias by proposing NeuronTune, a post\nhoc method that directly intervenes in a model's internal decision process. Our\nmethod probes in a model's latent embedding space to identify and regulate\nneurons that lead to spurious prediction behaviors. We theoretically justify\nour approach and show that it brings the model closer to an unbiased one.\nUnlike previous methods, NeuronTune operates without requiring spurious\ncorrelation annotations, making it a practical and effective tool for improving\nmodel robustness. Experiments across different architectures and data\nmodalities demonstrate that our method significantly mitigates spurious bias in\na self-guided way.", "AI": {"tldr": "Deep neural networks can develop spurious bias, relying on non-essential features for predictions. Existing mitigation approaches need external annotations which may be hard to obtain. This paper proposes NeuronTune, a post hoc method that intervenes in the model's internal decision process to mitigate spurious bias without requiring these annotations.", "motivation": "Deep neural networks often develop spurious bias, leading to degraded performance when correlations between non-essential features and classes are absent. Current mitigation methods rely on external annotations of spurious correlations, which are difficult to obtain and not always relevant.", "method": "NeuronTune is proposed as a post hoc method that directly intervenes in a model's internal decision process by probing the latent embedding space to identify and regulate neurons responsible for spurious prediction behaviors.", "result": "Experiments across different architectures and data modalities demonstrate that NeuronTune significantly mitigates spurious bias in a self-guided way.", "conclusion": "NeuronTune is a practical and effective tool for improving model robustness as it operates without requiring spurious correlation annotations."}}
{"id": "2505.23780", "pdf": "https://arxiv.org/pdf/2505.23780", "abs": "https://arxiv.org/abs/2505.23780", "authors": ["\u00c9milie Fabre", "Katie Seaborn", "Shuta Koiwai", "Mizuki Watanabe", "Paul Riesch"], "title": "More-than-Human Storytelling: Designing Longitudinal Narrative Engagements with Generative AI", "categories": ["cs.HC", "cs.AI", "cs.CY", "cs.SD", "eess.AS"], "comment": "CHI EA '25", "summary": "Longitudinal engagement with generative AI (GenAI) storytelling agents is a\ntimely but less charted domain. We explored multi-generational experiences with\n\"Dreamsmithy,\" a daily dream-crafting app, where participants (N = 28)\nco-created stories with AI narrator \"Makoto\" every day. Reflections and\ninteractions were captured through a two-week diary study. Reflexive thematic\nanalysis revealed themes likes \"oscillating ambivalence\" and\n\"socio-chronological bonding,\" highlighting the complex dynamics that emerged\nbetween individuals and the AI narrator over time. Findings suggest that while\npeople appreciated the personal notes, opportunities for reflection, and AI\ncreativity, limitations in narrative coherence and control occasionally caused\nfrustration. The results underscore the potential of GenAI for longitudinal\nstorytelling, but also raise critical questions about user agency and ethics.\nWe contribute initial empirical insights and design considerations for\ndeveloping adaptive, more-than-human storytelling systems.", "AI": {"tldr": "The study explored longitudinal engagement with generative AI storytelling agents through a two-week diary study of an app called Dreamsmithy, revealing themes like 'oscillating ambivalence' and 'socio-chronological bonding', while highlighting both the potential and limitations of GenAI for storytelling.", "motivation": "To understand the complex dynamics that emerge between individuals and generative AI (GenAI) storytelling agents over time, especially focusing on multi-generational experiences.", "method": "A daily dream-crafting app named Dreamsmithy was used where participants co-created stories with an AI narrator called Makoto every day. A two-week diary study captured reflections and interactions.", "result": "Participants appreciated personal notes, opportunities for reflection, and AI creativity but faced limitations in narrative coherence and control leading to frustration. Themes such as 'oscillating ambivalence' and 'socio-chronological bonding' emerged from reflexive thematic analysis.", "conclusion": "GenAI has potential for longitudinal storytelling but raises critical questions about user agency and ethics, contributing empirical insights and design considerations for adaptive storytelling systems."}}
{"id": "2505.24685", "pdf": "https://arxiv.org/pdf/2505.24685", "abs": "https://arxiv.org/abs/2505.24685", "authors": ["Vasilis Katos", "Emily Rosenorn-Lanng", "Jane Henriksen-Bulmer", "Ala Yankouskaya"], "title": "So, I climbed to the top of the pyramid of pain -- now what?", "categories": ["cs.CR", "cs.CY"], "comment": null, "summary": "This paper explores the evolving dynamics of cybersecurity in the age of\nadvanced AI, from the perspective of the introduced Human Layer Kill Chain\nframework. As traditional attack models like Lockheed Martin's Cyber Kill Chain\nbecome inadequate in addressing human vulnerabilities exploited by modern\nadversaries, the Humal Layer Kill Chain offers a nuanced approach that\nintegrates human psychology and behaviour into the analysis of cyber threats.\nWe detail the eight stages of the Human Layer Kill Chain, illustrating how\nAI-enabled techniques can enhance psychological manipulation in attacks. By\nmerging the Human Layer with the Cyber Kill Chain, we propose a Sociotechnical\nKill Plane that allows for a holistic examination of attackers' tactics,\ntechniques, and procedures (TTPs) across the sociotechnical landscape. This\nframework not only aids cybersecurity professionals in understanding\nadversarial methods, but also empowers non-technical personnel to engage in\nthreat identification and response. The implications for incident response and\norganizational resilience are significant, particularly as AI continues to\nshape the threat landscape.", "AI": {"tldr": "This paper introduces the Human Layer Kill Chain framework to address human vulnerabilities in cybersecurity, proposing a Sociotechnical Kill Plane that integrates human psychology and AI-enabled techniques.", "motivation": "Traditional attack models like Lockheed Martin's Cyber Kill Chain are insufficient for addressing human vulnerabilities exploited by modern adversaries.", "method": "The paper details an eight-stage Human Layer Kill Chain and proposes merging it with the Cyber Kill Chain to form a Sociotechnical Kill Plane.", "result": "This framework allows for a holistic examination of attackers' TTPs across the sociotechnical landscape, enhancing understanding of adversarial methods.", "conclusion": "The proposed framework has significant implications for incident response and organizational resilience as AI continues to shape the threat landscape."}}
{"id": "2505.24054", "pdf": "https://arxiv.org/pdf/2505.24054", "abs": "https://arxiv.org/abs/2505.24054", "authors": ["Elpiniki Maria Lygizou", "M\u00f3nika Farsang", "Radu Grosu"], "title": "Differential Gated Self-Attention", "categories": ["cs.LG"], "comment": null, "summary": "Transformers excel across a large variety of tasks but remain susceptible to\ncorrupted inputs, since standard self-attention treats all query-key\ninteractions uniformly. Inspired by lateral inhibition in biological neural\ncircuits and building on the recent use by the Differential Transformer's use\nof two parallel softmax subtraction for noise cancellation, we propose\nMultihead Differential Gated Self-Attention (M-DGSA) that learns per-head\ninput-dependent gating to dynamically suppress attention noise. Each head\nsplits into excitatory and inhibitory branches whose dual softmax maps are\nfused by a sigmoid gate predicted from the token embedding, yielding a\ncontext-aware contrast enhancement. M-DGSA integrates seamlessly into existing\nTransformer stacks with minimal computational overhead. We evaluate on both\nvision and language benchmarks, demonstrating consistent robustness gains over\nvanilla Transformer, Vision Transformer, and Differential Transformer\nbaselines. Our contributions are (i) a novel input-dependent gating mechanism\nfor self-attention grounded in lateral inhibition, (ii) a principled synthesis\nof biological contrast-enhancement and self-attention theory, and (iii)\ncomprehensive experiments demonstrating noise resilience and cross-domain\napplicability.", "AI": {"tldr": "Transformers are great but weak to corrupted inputs. This paper proposes Multihead Differential Gated Self-Attention (M-DGSA) which uses a gating mechanism derived from biological concepts to suppress attention noise. It shows robustness gains in vision and language tasks.", "motivation": "Transformers, despite their success, struggle with corrupted inputs due to uniform treatment of query-key interactions in self-attention.", "method": "Proposes M-DGSA that incorporates per-head input-dependent gating using excitatory and inhibitory branches and a sigmoid gate predicted from token embeddings for context-aware contrast enhancement.", "result": "Demonstrates consistent robustness improvements over standard Transformers, Vision Transformers, and Differential Transformers in both vision and language benchmarks.", "conclusion": "Contributes a new gating mechanism for self-attention inspired by biology, integrates theory from biology and self-attention, and provides extensive experiments showing effectiveness across domains."}}
{"id": "2505.23782", "pdf": "https://arxiv.org/pdf/2505.23782", "abs": "https://arxiv.org/abs/2505.23782", "authors": ["Andrew P. Berg", "Qian Zhang", "Mia Y. Wang"], "title": "4,500 Seconds: Small Data Training Approaches for Deep UAV Audio Classification", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": "Accepted at the 14th International Conference on Data Science,\n  Technology, and Applications (DATA), 2025", "summary": "Unmanned aerial vehicle (UAV) usage is expected to surge in the coming\ndecade, raising the need for heightened security measures to prevent airspace\nviolations and security threats. This study investigates deep learning\napproaches to UAV classification focusing on the key issue of data scarcity. To\ninvestigate this we opted to train the models using a total of 4,500 seconds of\naudio samples, evenly distributed across a 9-class dataset. We leveraged\nparameter efficient fine-tuning (PEFT) and data augmentations to mitigate the\ndata scarcity. This paper implements and compares the use of convolutional\nneural networks (CNNs) and attention-based transformers. Our results show that,\nCNNs outperform transformers by 1-2\\% accuracy, while still being more\ncomputationally efficient. These early findings, however, point to potential in\nusing transformers models; suggesting that with more data and further\noptimizations they could outperform CNNs. Future works aims to upscale the\ndataset to better understand the trade-offs between these approaches.", "AI": {"tldr": "The paper explores deep learning methods for UAV classification focusing on data scarcity, comparing CNNs and transformers, finding CNNs currently slightly outperform transformers but transformers show potential with more data.", "motivation": "UAV usage is expected to increase significantly, necessitating better security measures. The challenge of data scarcity for training models in UAV classification needs addressing.", "method": "Trained models using 4,500 seconds of audio samples across a 9-class dataset. Used PEFT and data augmentations to handle data scarcity. Implemented and compared CNNs and attention-based transformers.", "result": "CNNs outperformed transformers by 1-2% accuracy and were more computationally efficient. However, transformers showed potential for improved performance with more data.", "conclusion": "Future work will involve increasing the dataset size to further understand the trade-offs between CNNs and transformers."}}
{"id": "2505.24698", "pdf": "https://arxiv.org/pdf/2505.24698", "abs": "https://arxiv.org/abs/2505.24698", "authors": ["Rodrigo Men\u00e9ndez", "Andres Munoz-Arcentales", "Joaqu\u00edn Salvach\u00faa", "Carlos Aparicio", "Irene Plaza", "Gabriel Huecas"], "title": "Next Generation Authentication for Data Spaces: An Authentication Flow Based On Grant Negotiation And Authorization Protocol For Verifiable Presentations (GNAP4VP)", "categories": ["cs.CR", "cs.ET"], "comment": "Accepted in The 22nd International Conference on Mobile Systems and\n  Pervasive Computing (MobiSPC) \\\\ August 4-6, 2025, Leuven, Belgium", "summary": "Identity verification in Data Spaces is a fundamental aspect of ensuring\nsecurity and privacy in digital environments. This paper presents an identity\nverification protocol tailored for shared data environments within Data Spaces.\nThis protocol extends the Grant Negotiation and Authorization Protocol (GNAP)\nand integrates OpenID Connect for Verifiable Presentations (OIDC4VP) along with\nsupport for Linked Verifiable Presentations (LVP), providing a robust\nfoundation for secure and privacy-preserving interactions. The proposed\nsolution adheres to the principles of Self-Sovereign Identity (SSI) to\nfacilitate decentralized, user-centric identity management while maintaining\nflexibility through protocol negotiation. Two alternative interaction flows are\nintroduced: a \"Wallet-Driven Interaction\" utilizing OIDC4VP, and a \"LVP\nAuthorization\" model for fully automated machine-to-machine communication.\nThese flows address critical challenges encountered in Data Spaces, including\nprivacy, interoperability, and regulatory compliance while simultaneously\nensuring scalability and minimizing trust assumptions. The paper provides a\ndetailed technical design, outlining the implementation considerations, and\ndemonstrating how the proposed flows guarantee verifiable, secure, and\nefficient interactions between participants. This work contributes towards the\nestablishment of a more trustworthy and sovereign digital infrastructure, in\nalignment with emerging European data governance initiatives.", "AI": {"tldr": "This paper proposes an identity verification protocol for shared data environments in Data Spaces, extending GNAP and integrating OIDC4VP and LVP. It presents two interaction flows to address privacy, interoperability, and regulatory compliance issues.", "motivation": "To ensure security and privacy in digital environments within Data Spaces by providing a robust identity verification protocol that supports decentralized, user-centric identity management.", "method": "Extending the Grant Negotiation and Authorization Protocol (GNAP) and integrating OpenID Connect for Verifiable Presentations (OIDC4VP) along with support for Linked Verifiable Presentations (LVP). Introducing two alternative interaction flows: Wallet-Driven Interaction utilizing OIDC4VP and LVP Authorization for machine-to-machine communication.", "result": "The proposed solution adheres to the principles of Self-Sovereign Identity (SSI), facilitating decentralized, user-centric identity management while maintaining flexibility through protocol negotiation. It addresses challenges like privacy, interoperability, and regulatory compliance ensuring scalability and minimizing trust assumptions.", "conclusion": "This work contributes towards establishing a more trustworthy and sovereign digital infrastructure aligning with emerging European data governance initiatives."}}
{"id": "2505.24055", "pdf": "https://arxiv.org/pdf/2505.24055", "abs": "https://arxiv.org/abs/2505.24055", "authors": ["Yilong Wang", "Tianxiang Zhao", "Zongyu Wu", "Suhang Wang"], "title": "Bridging Source and Target Domains via Link Prediction for Unsupervised Domain Adaptation on Graphs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Graph neural networks (GNNs) have shown great ability for node classification\non graphs. However, the success of GNNs relies on abundant labeled data, while\nobtaining high-quality labels is costly and challenging, especially for newly\nemerging domains. Hence, unsupervised domain adaptation (UDA), which trains a\nclassifier on the labeled source graph and adapts it to the unlabeled target\ngraph, is attracting increasing attention. Various approaches have been\nproposed to alleviate the distribution shift between the source and target\ngraphs to facilitate the classifier adaptation. However, most of them simply\nadopt existing UDA techniques developed for independent and identically\ndistributed data to gain domain-invariant node embeddings for graphs, which do\nnot fully consider the graph structure and message-passing mechanism of GNNs\nduring the adaptation and will fail when label distribution shift exists among\ndomains. In this paper, we proposed a novel framework that adopts link\nprediction to connect nodes between source and target graphs, which can\nfacilitate message-passing between the source and target graphs and augment the\ntarget nodes to have ``in-distribution'' neighborhoods with the source domain.\nThis strategy modified the target graph on the input level to reduce its\ndeviation from the source domain in the embedding space and is insensitive to\ndisproportional label distributions across domains. To prevent the loss of\ndiscriminative information in the target graph, we further design a novel\nidentity-preserving learning objective, which guides the learning of the edge\ninsertion module together with reconstruction and adaptation losses.\nExperimental results on real-world datasets demonstrate the effectiveness of\nour framework.", "AI": {"tldr": "This paper proposes a novel framework for unsupervised domain adaptation in graph neural networks (GNNs) that uses link prediction to connect nodes between source and target graphs, facilitating message-passing and reducing distribution shift. It also introduces an identity-preserving learning objective to maintain discriminative information in the target graph.", "motivation": "Existing unsupervised domain adaptation methods for GNNs do not fully consider the graph structure and message-passing mechanism during adaptation, leading to failures when label distribution shifts exist among domains.", "method": "The method involves using link prediction to connect nodes between the source and target graphs, thereby facilitating message-passing and augmenting target nodes with 'in-distribution' neighborhoods from the source domain. An identity-preserving learning objective is designed to prevent loss of discriminative information in the target graph.", "result": "Experimental results on real-world datasets demonstrate the effectiveness of the proposed framework.", "conclusion": "The proposed framework successfully reduces the deviation of the target graph from the source domain in the embedding space and is insensitive to disproportional label distributions across domains."}}
{"id": "2505.23783", "pdf": "https://arxiv.org/pdf/2505.23783", "abs": "https://arxiv.org/abs/2505.23783", "authors": ["Korel Gundem", "Juncheng Dong", "Dennis Zhang", "Vahid Tarokh", "Zhengling Qi"], "title": "Boosting In-Context Learning in LLMs Through the Lens of Classical Supervised Learning", "categories": ["stat.ML", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "In-Context Learning (ICL) allows Large Language Models (LLMs) to adapt to new\ntasks with just a few examples, but their predictions often suffer from\nsystematic biases, leading to unstable performances in classification. While\ncalibration techniques are proposed to mitigate these biases, we show that, in\nthe logit space, many of these methods are equivalent to merely shifting the\nLLM's decision boundary without having the ability to alter its orientation.\nThis proves inadequate when biases cause the LLM to be severely misdirected. To\naddress these limitations and provide a unifying framework, we propose\nSupervised Calibration (SC), a loss-minimization based framework which learns\nan optimal, per-class affine transformation of the LLM's predictive\nprobabilities in the logit space without requiring external data beyond the\ncontext. By using a more expressive functional class, SC not only subsumes many\nexisting calibration methods in ICL as special cases, but also enables the\nability to alter and even completely reverse the orientation of the LLM's\ndecision boundary. Furthermore, SC's loss-based nature facilitates the seamless\nintegration of two purpose-built regularization techniques: context-invariance\nand directional trust-region. The former is designed to tackle the instability\nissue in ICL, while the latter controls the degree of calibration. Finally, SC\ndelivers state-of-the-art performance over calibration baselines in the 4-shot,\n8-shot, and 16-shot settings across all nine datasets for\nMistral-7B-Instruct-v0.3, LLaMA-2-7B-chat, and Qwen2-7B-Instruct.", "AI": {"tldr": "Supervised Calibration (SC) is proposed to address the limitations of current calibration methods in In-Context Learning (ICL) by learning an optimal, per-class affine transformation of LLM's predictive probabilities.", "motivation": "In-Context Learning (ICL) allows Large Language Models (LLMs) to adapt to new tasks with just a few examples. However, their predictions often suffer from systematic biases leading to unstable performances in classification.", "method": "The authors propose Supervised Calibration (SC), a loss-minimization based framework which learns an optimal, per-class affine transformation of the LLM's predictive probabilities in the logit space without requiring external data beyond the context.", "result": "SC delivers state-of-the-art performance over calibration baselines in the 4-shot, 8-shot, and 16-shot settings across all nine datasets for Mistral-7B-Instruct-v0.3, LLaMA-2-7B-chat, and Qwen2-7B-Instruct.", "conclusion": "Supervised Calibration (SC) addresses the limitations of current calibration methods in ICL and provides a unifying framework that subsumes many existing calibration methods as special cases."}}
{"id": "2505.24703", "pdf": "https://arxiv.org/pdf/2505.24703", "abs": "https://arxiv.org/abs/2505.24703", "authors": ["Dennis Jacob", "Chong Xiang", "Prateek Mittal"], "title": "PatchDEMUX: A Certifiably Robust Framework for Multi-label Classifiers Against Adversarial Patches", "categories": ["cs.CR", "cs.CV", "cs.LG"], "comment": "CVPR 2025", "summary": "Deep learning techniques have enabled vast improvements in computer vision\ntechnologies. Nevertheless, these models are vulnerable to adversarial patch\nattacks which catastrophically impair performance. The physically realizable\nnature of these attacks calls for certifiable defenses, which feature provable\nguarantees on robustness. While certifiable defenses have been successfully\napplied to single-label classification, limited work has been done for\nmulti-label classification. In this work, we present PatchDEMUX, a certifiably\nrobust framework for multi-label classifiers against adversarial patches. Our\napproach is a generalizable method which can extend any existing certifiable\ndefense for single-label classification; this is done by considering the\nmulti-label classification task as a series of isolated binary classification\nproblems to provably guarantee robustness. Furthermore, in the scenario where\nan attacker is limited to a single patch we propose an additional certification\nprocedure that can provide tighter robustness bounds. Using the current\nstate-of-the-art (SOTA) single-label certifiable defense PatchCleanser as a\nbackbone, we find that PatchDEMUX can achieve non-trivial robustness on the\nMS-COCO and PASCAL VOC datasets while maintaining high clean performance", "AI": {"tldr": "Deep learning models are vulnerable to adversarial patch attacks, which impair performance. While certifiable defenses have been successfully applied to single-label classification, limited work has been done for multi-label classification. This paper presents PatchDEMUX, a certifiably robust framework for multi-label classifiers against adversarial patches.", "motivation": "Current certifiable defenses mainly focus on single-label classification and lack effective methods for multi-label classification tasks.", "method": "PatchDEMUX considers the multi-label classification task as a series of isolated binary classification problems to provably guarantee robustness. In addition, when an attacker is limited to a single patch, an additional certification procedure is proposed to provide tighter robustness bounds.", "result": "Using PatchCleanser as a backbone, PatchDEMUX can achieve non-trivial robustness on the MS-COCO and PASCAL VOC datasets while maintaining high clean performance.", "conclusion": "PatchDEMUX is a generalizable method that extends existing certifiable defenses for single-label classification to multi-label classification tasks."}}
{"id": "2505.24059", "pdf": "https://arxiv.org/pdf/2505.24059", "abs": "https://arxiv.org/abs/2505.24059", "authors": ["Sean Foley", "Hong Nguyen", "Jihwan Lee", "Sudarsana Reddy Kadiri", "Dani Byrd", "Louis Goldstein", "Shrikanth Narayanan"], "title": "Towards disentangling the contributions of articulation and acoustics in multimodal phoneme recognition", "categories": ["cs.LG"], "comment": null, "summary": "Although many previous studies have carried out multimodal learning with\nreal-time MRI data that captures the audio-visual kinematics of the vocal tract\nduring speech, these studies have been limited by their reliance on\nmulti-speaker corpora. This prevents such models from learning a detailed\nrelationship between acoustics and articulation due to considerable\ncross-speaker variability. In this study, we develop unimodal audio and video\nmodels as well as multimodal models for phoneme recognition using a long-form\nsingle-speaker MRI corpus, with the goal of disentangling and interpreting the\ncontributions of each modality. Audio and multimodal models show similar\nperformance on different phonetic manner classes but diverge on places of\narticulation. Interpretation of the models' latent space shows similar encoding\nof the phonetic space across audio and multimodal models, while the models'\nattention weights highlight differences in acoustic and articulatory timing for\ncertain phonemes.", "AI": {"tldr": "This paper explores phoneme recognition using unimodal and multimodal models on a single-speaker MRI corpus, revealing similar performance in some areas but differences in others.", "motivation": "Previous studies of multimodal learning with real-time MRI data have been constrained by multi-speaker corpora which limits detailed relationship learning between acoustics and articulation due to cross-speaker variability.", "method": "Developed unimodal audio and video models along with multimodal models for phoneme recognition using a long-form single-speaker MRI corpus.", "result": "Audio and multimodal models perform similarly on different phonetic manner classes but differ on places of articulation. Latent space interpretation shows similar encoding of phonetic space across models, while attention weights highlight timing differences for certain phonemes.", "conclusion": "Using a single-speaker MRI corpus helps disentangle contributions of each modality in phoneme recognition, showing both similarities and differences in performance and model interpretations."}}
{"id": "2505.23785", "pdf": "https://arxiv.org/pdf/2505.23785", "abs": "https://arxiv.org/abs/2505.23785", "authors": ["Cody Kommers", "Drew Hemment", "Maria Antoniak", "Joel Z. Leibo", "Hoyt Long", "Emily Robinson", "Adam Sobey"], "title": "Meaning Is Not A Metric: Using LLMs to make cultural context legible at scale", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Position paper", "summary": "This position paper argues that large language models (LLMs) can make\ncultural context, and therefore human meaning, legible at an unprecedented\nscale in AI-based sociotechnical systems. We argue that such systems have\npreviously been unable to represent human meaning because they rely on thin\ndescriptions: numerical representations that enforce standardization and\ntherefore strip human activity of the cultural context that gives it meaning.\nBy contrast, scholars in the humanities and qualitative social sciences have\ndeveloped frameworks for representing meaning through thick description: verbal\nrepresentations that accommodate heterogeneity and retain contextual\ninformation needed to represent human meaning. While these methods can\neffectively codify meaning, they are difficult to deploy at scale. However, the\nverbal capabilities of LLMs now provide a means of (at least partially)\nautomating the generation and processing of thick descriptions, potentially\novercoming this bottleneck. We argue that the problem of rendering human\nmeaning legible is not just about selecting better metrics, but about\ndeveloping new representational formats (based on thick description). We frame\nthis as a crucial direction for the application of generative AI and identify\nfive key challenges: preserving context, maintaining interpretive pluralism,\nintegrating perspectives based on lived experience and critical distance,\ndistinguishing qualitative content from quantitative magnitude, and\nacknowledging meaning as dynamic rather than static. Furthermore, we suggest\nthat thick description has the potential to serve as a unifying framework to\naddress a number of emerging concerns about the difficulties of representing\nculture in (or using) LLMs.", "AI": {"tldr": "This paper argues that large language models can represent human meaning through thick description, which accommodates heterogeneity and retains contextual information. It identifies five key challenges and suggests thick description as a unifying framework to address concerns about representing culture in LLMs.", "motivation": "The motivation of this paper is to explore how large language models can make cultural context and human meaning legible at an unprecedented scale in AI-based sociotechnical systems, overcoming the limitations of thin descriptions that strip human activity of cultural context.", "method": "The method involves utilizing the verbal capabilities of LLMs to automate the generation and processing of thick descriptions, which are verbal representations that accommodate heterogeneity and retain contextual information needed to represent human meaning.", "result": "The result is a proposal for developing new representational formats based on thick description to render human meaning legible, identifying five key challenges in doing so.", "conclusion": "The conclusion frames thick description as a crucial direction for the application of generative AI and a potential unifying framework to address emerging concerns about representing culture in or using LLMs."}}
{"id": "2505.24724", "pdf": "https://arxiv.org/pdf/2505.24724", "abs": "https://arxiv.org/abs/2505.24724", "authors": ["Xihan Xiong", "Zhipeng Wang", "Qin Wang", "Endong Liu", "Pascal Berrang", "William Knottenbelt"], "title": "Talking Transactions: Decentralized Communication through Ethereum Input Data Messages (IDMs)", "categories": ["cs.CR"], "comment": null, "summary": "Can you imagine, blockchain transactions can talk! In this paper, we study\nhow they talk and what they talk about. We focus on the input data field of\nEthereum transactions, which is designed to allow external callers to interact\nwith smart contracts. In practice, this field also enables users to embed\nnatural language messages into transactions. Users can leverage these Input\nData Messages (IDMs) for peer-to-peer communication. This means that, beyond\nEthereum's well-known role as a financial infrastructure, it also serves as a\ndecentralized communication medium.\n  We present the first large-scale analysis of Ethereum IDMs from the genesis\nblock to February 2024 (3134 days). We filter IDMs to extract 867,140\ntransactions with informative IDMs and use LLMs for language detection. We find\nthat English (95.4%) and Chinese (4.4%) dominate the use of natural languages\nin IDMs. Interestingly, English IDMs center on security and scam warnings (24%)\nwith predominantly negative emotions, while Chinese IDMs emphasize emotional\nexpression and social connection (44%) with a more positive tone. We also\nobserve that longer English IDMs often transfer high ETH values for\nprotocol-level purposes, while longer Chinese IDMs tend to involve symbolic\ntransfer amounts for emotional intent. Moreover, we find that the IDM\nparticipants tend to form small, loosely connected communities (59.99%). Our\nfindings highlight culturally and functionally divergent use cases of the IDM\nchannel across user communities. We further examine the security relevance of\nIDMs in on-chain attacks. Many victims use them to appeal to attackers for fund\nrecovery. IDMs containing negotiations or reward offers are linked to higher\nreply rates. We also analyze IDMs' regulatory implications. Their misuse for\nabuse, threats, and sexual solicitation reveals the urgent need for content\nmoderation and regulation in decentralized systems.", "AI": {"tldr": "This paper conducts a large-scale analysis of Ethereum Input Data Messages (IDMs) from the genesis block to February 2024, exploring their linguistic characteristics, cultural differences, and security/regulatory implications.", "motivation": "To understand how blockchain transactions 'talk' through the input data field of Ethereum transactions and what they communicate about, beyond its role as a financial infrastructure.", "method": "Analyzed Ethereum IDMs from genesis block to February 2024 (3134 days), extracting 867,140 transactions with informative IDMs. Used LLMs for language detection and examined IDM content, user communities, and security/regulatory implications.", "result": "English (95.4%) and Chinese (4.4%) dominate natural language use in IDMs. English IDMs focus on security/scam warnings with negative emotions, while Chinese IDMs emphasize emotional expression/social connection with positive tones. Longer English IDMs relate to high ETH values for protocol purposes, whereas longer Chinese IDMs involve symbolic amounts for emotional intent. IDM participants form small, loosely connected communities (59.99%). Victims use IDMs in on-chain attacks for fund recovery negotiations, and misuse for abuse/threats/sexual solicitation highlights the need for regulation.", "conclusion": "Ethereum IDMs serve as a decentralized communication medium with culturally and functionally divergent use cases. They have security relevance in on-chain attacks and regulatory implications due to potential misuse."}}
{"id": "2505.24060", "pdf": "https://arxiv.org/pdf/2505.24060", "abs": "https://arxiv.org/abs/2505.24060", "authors": ["Chris Mingard", "Lukas Seier", "Niclas G\u00f6ring", "Andrei-Vlad Badelita", "Charles London", "Ard Louis"], "title": "Characterising the Inductive Biases of Neural Networks on Boolean Data", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Deep neural networks are renowned for their ability to generalise well across\ndiverse tasks, even when heavily overparameterized. Existing works offer only\npartial explanations (for example, the NTK-based task-model alignment\nexplanation neglects feature learning). Here, we provide an end-to-end,\nanalytically tractable case study that links a network's inductive prior, its\ntraining dynamics including feature learning, and its eventual generalisation.\nSpecifically, we exploit the one-to-one correspondence between depth-2 discrete\nfully connected networks and disjunctive normal form (DNF) formulas by training\non Boolean functions. Under a Monte Carlo learning algorithm, our model\nexhibits predictable training dynamics and the emergence of interpretable\nfeatures. This framework allows us to trace, in detail, how inductive bias and\nfeature formation drive generalisation.", "AI": {"tldr": "\u901a\u8fc7\u7814\u7a76\u6df1\u5ea6\u4e3a2\u7684\u5168\u8fde\u63a5\u7f51\u7edc\u4e0e\u5e03\u5c14\u51fd\u6570\u7684\u5173\u7cfb\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5f52\u7eb3\u504f\u7f6e\u3001\u7279\u5f81\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u8054\u7cfb\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684\u5de5\u4f5c\uff08\u5982\u57fa\u4e8eNTK\u7684\u4efb\u52a1\u6a21\u578b\u5bf9\u9f50\u89e3\u91ca\uff09\u90e8\u5206\u89e3\u91ca\u4e86\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u7684\u826f\u597d\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u5ffd\u7565\u4e86\u7279\u5f81\u5b66\u4e60\u7684\u4f5c\u7528\u3002\u672c\u6587\u65e8\u5728\u63d0\u4f9b\u4e00\u4e2a\u7aef\u5230\u7aef\u7684\u89e3\u6790\u6848\u4f8b\uff0c\u7efc\u5408\u5206\u6790\u7f51\u7edc\u7684\u5f52\u7eb3\u5148\u9a8c\u3001\u8bad\u7ec3\u52a8\u6001\uff08\u5305\u62ec\u7279\u5f81\u5b66\u4e60\uff09\u4ee5\u53ca\u6700\u7ec8\u7684\u6cdb\u5316\u6027\u80fd\u3002", "method": "\u5229\u7528\u6df1\u5ea6\u4e3a2\u7684\u79bb\u6563\u5168\u8fde\u63a5\u7f51\u7edc\u4e0e\u6790\u53d6\u8303\u5f0f\uff08DNF\uff09\u516c\u5f0f\u4e4b\u95f4\u7684\u4e00\u4e00\u5bf9\u5e94\u5173\u7cfb\uff0c\u901a\u8fc7\u5728\u5e03\u5c14\u51fd\u6570\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u91c7\u7528\u8499\u7279\u5361\u6d1b\u5b66\u4e60\u7b97\u6cd5\uff0c\u89c2\u5bdf\u6a21\u578b\u7684\u53ef\u9884\u6d4b\u8bad\u7ec3\u52a8\u6001\u53ca\u53ef\u89e3\u91ca\u7279\u5f81\u7684\u51fa\u73b0\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u8be6\u7ec6\u8ffd\u8e2a\u5f52\u7eb3\u504f\u5dee\u548c\u7279\u5f81\u5f62\u6210\u5982\u4f55\u9a71\u52a8\u6cdb\u5316\u8fc7\u7a0b\uff0c\u63ed\u793a\u4e86\u795e\u7ecf\u7f51\u7edc\u5728\u7279\u5f81\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u7684\u4f5c\u7528\u673a\u5236\u3002", "conclusion": "\u672c\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u5206\u6790\u7b80\u5355\u7684\u7f51\u7edc\u7ed3\u6784\u548c\u8bad\u7ec3\u65b9\u6cd5\uff0c\u53ef\u4ee5\u6df1\u5165\u7406\u89e3\u795e\u7ecf\u7f51\u7edc\u7684\u5f52\u7eb3\u504f\u7f6e\u3001\u7279\u5f81\u5b66\u4e60\u548c\u6cdb\u5316\u80fd\u529b\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u4e3a\u8fdb\u4e00\u6b65\u7814\u7a76\u590d\u6742\u7f51\u7edc\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2505.24742", "pdf": "https://arxiv.org/pdf/2505.24742", "abs": "https://arxiv.org/abs/2505.24742", "authors": ["Irene Plaza-Ortiz", "Andres Munoz-Arcentales", "Joaqu\u00edn Salvach\u00faa", "Carlos Aparicio", "Gabriel Huecas", "Enrique Barra"], "title": "Authentication and authorization in Data Spaces: A relationship-based access control approach for policy specification based on ODRL", "categories": ["cs.CR", "cs.ET"], "comment": "Accepted: OPAL 2025: ODRL And Beyond: Practical Applications And\n  Challenges For Policy-Base Access And Usage Control., June 01--02, 2025,\n  Portoro\\v{z}, Slovenia", "summary": "Data has become a crucial resource in the digital economy, fostering\ninitiatives for secure and sovereign data sharing frameworks such as Data\nSpaces. However, these distributed environments require fine-grained access\ncontrol mechanisms that balance openness with sovereignty and security. This\npaper proposes an extension of the Open Digital Rights Language (ODRL)\nstandard, the ODRL Data Spaces (ODS) profile, aimed at supporting authorization\nand complementing existing authentication mechanisms throughout the data\nlifecycle. Additionally, a policy execution engine is introduced to translate\nODRL policies into executable formats, enabling effective enforcement. The\napproach is validated through a use case involving OpenFGA, demonstrating its\napplicability to relationship-based access control scenarios.", "AI": {"tldr": "This paper proposes an extension of the ODRL standard, called the ODRL Data Spaces (ODS) profile, and a policy execution engine to translate ODRL policies into executable formats. It is validated through a use case involving OpenFGA.", "motivation": "Data has become a crucial resource in the digital economy and distributed environments such as Data Spaces require fine-grained access control mechanisms that balance openness with sovereignty and security.", "method": "Propose an extension of the ODRL standard (ODRL Data Spaces profile) and introduce a policy execution engine to translate ODRL policies into executable formats for effective enforcement.", "result": "The approach is validated through a use case involving OpenFGA, proving its applicability to relationship-based access control scenarios.", "conclusion": "The ODRL Data Spaces profile and policy execution engine can effectively support authorization and complement existing authentication mechanisms throughout the data lifecycle."}}
{"id": "2505.24061", "pdf": "https://arxiv.org/pdf/2505.24061", "abs": "https://arxiv.org/abs/2505.24061", "authors": ["Jiashun Liu", "Zihao Wu", "Johan Obando-Ceron", "Pablo Samuel Castro", "Aaron Courville", "Ling Pan"], "title": "Measure gradients, not activations! Enhancing neuronal activity in deep reinforcement learning", "categories": ["cs.LG"], "comment": null, "summary": "Deep reinforcement learning (RL) agents frequently suffer from neuronal\nactivity loss, which impairs their ability to adapt to new data and learn\ncontinually. A common method to quantify and address this issue is the\ntau-dormant neuron ratio, which uses activation statistics to measure the\nexpressive ability of neurons. While effective for simple MLP-based agents,\nthis approach loses statistical power in more complex architectures. To address\nthis, we argue that in advanced RL agents, maintaining a neuron's learning\ncapacity, its ability to adapt via gradient updates, is more critical than\npreserving its expressive ability. Based on this insight, we shift the\nstatistical objective from activations to gradients, and introduce GraMa\n(Gradient Magnitude Neural Activity Metric), a lightweight,\narchitecture-agnostic metric for quantifying neuron-level learning capacity. We\nshow that GraMa effectively reveals persistent neuron inactivity across diverse\narchitectures, including residual networks, diffusion models, and agents with\nvaried activation functions. Moreover, resetting neurons guided by GraMa\n(ReGraMa) consistently improves learning performance across multiple deep RL\nalgorithms and benchmarks, such as MuJoCo and the DeepMind Control Suite.", "AI": {"tldr": "In deep reinforcement learning, neuronal activity loss affects continual learning. While tau-dormant neuron ratio works for simple MLP-based agents, it lacks statistical power in complex architectures. This paper proposes GraMa (Gradient Magnitude Neural Activity Metric) to quantify neuron-level learning capacity and ReGraMa to improve learning performance.", "motivation": "Deep RL agents often suffer from neuronal activity loss, which hinders their ability to adapt and learn continually. Existing methods like the tau-dormant neuron ratio are effective for simple architectures but lack power in more complex ones.", "method": "The authors shift the focus from activations to gradients, introducing GraMa as a lightweight metric to measure neuron-level learning capacity across diverse architectures. They also propose ReGraMa, a method that resets neurons based on GraMa's guidance.", "result": "GraMa successfully reveals persistent neuron inactivity in various architectures such as residual networks and diffusion models. ReGraMa improves learning performance across multiple deep RL algorithms and benchmarks including MuJoCo and the DeepMind Control Suite.", "conclusion": "GraMa and ReGraMa offer new tools to address neuronal activity loss in complex deep RL architectures, improving the adaptability and learning capacity of advanced RL agents."}}
{"id": "2505.23788", "pdf": "https://arxiv.org/pdf/2505.23788", "abs": "https://arxiv.org/abs/2505.23788", "authors": ["Aakash Sen Sharma", "Debdeep Sanyal", "Priyansh Srivastava", "Sundar Atreya H.", "Shirish Karande", "Mohan Kankanhalli", "Murari Mandal"], "title": "Nine Ways to Break Copyright Law and Why Our LLM Won't: A Fair Use Aligned Generation Framework", "categories": ["cs.CL", "cs.AI"], "comment": "30 Pages", "summary": "Large language models (LLMs) commonly risk copyright infringement by\nreproducing protected content verbatim or with insufficient transformative\nmodifications, posing significant ethical, legal, and practical concerns.\nCurrent inference-time safeguards predominantly rely on restrictive\nrefusal-based filters, often compromising the practical utility of these\nmodels. To address this, we collaborated closely with intellectual property\nexperts to develop FUA-LLM (Fair Use Aligned Language Models), a\nlegally-grounded framework explicitly designed to align LLM outputs with\nfair-use doctrine. Central to our method is FairUseDB, a carefully constructed\ndataset containing 18,000 expert-validated examples covering nine realistic\ninfringement scenarios. Leveraging this dataset, we apply Direct Preference\nOptimization (DPO) to fine-tune open-source LLMs, encouraging them to produce\nlegally compliant and practically useful alternatives rather than resorting to\nblunt refusal. Recognizing the shortcomings of traditional evaluation metrics,\nwe propose new measures: Weighted Penalty Utility and Compliance Aware Harmonic\nMean (CAH) to balance infringement risk against response utility. Extensive\nquantitative experiments coupled with expert evaluations confirm that FUA-LLM\nsubstantially reduces problematic outputs (up to 20\\%) compared to\nstate-of-the-art approaches, while preserving real-world usability.", "AI": {"tldr": "Large language models (LLMs) have the risk of copyright infringement. Current safeguards compromise the practical utility of these models. This paper introduces FUA-LLM, a framework that aligns LLM outputs with fair-use doctrine using FairUseDB and Direct Preference Optimization (DPO). It also proposes new evaluation metrics and shows substantial reduction in problematic outputs while preserving usability.", "motivation": "To address the issue of copyright infringement in LLMs and improve their practical utility without relying on restrictive refusal-based filters.", "method": "Developed FUA-LLM using FairUseDB, a dataset with expert-validated examples, and applied Direct Preference Optimization (DPO) to fine-tune open-source LLMs for legally compliant and useful responses. Proposed new evaluation metrics: Weighted Penalty Utility and Compliance Aware Harmonic Mean (CAH).", "result": "FUA-LLM reduces problematic outputs by up to 20% compared to state-of-the-art approaches while maintaining real-world usability, as confirmed by quantitative experiments and expert evaluations.", "conclusion": "FUA-LLM successfully aligns LLM outputs with fair-use doctrine, reducing copyright infringement risks and preserving practical utility."}}
{"id": "2505.24089", "pdf": "https://arxiv.org/pdf/2505.24089", "abs": "https://arxiv.org/abs/2505.24089", "authors": ["Marcus Lassila", "Johan \u00d6stman", "Khac-Hoang Ngo", "Alexandre Graell i Amat"], "title": "Practical Bayes-Optimal Membership Inference Attacks", "categories": ["cs.LG", "cs.CR"], "comment": "9 pages plus 13 pages of appendices", "summary": "We develop practical and theoretically grounded membership inference attacks\n(MIAs) against both independent and identically distributed (i.i.d.) data and\ngraph-structured data. Building on the Bayesian decision-theoretic framework of\nSablayrolles et al., we derive the Bayes-optimal membership inference rule for\nnode-level MIAs against graph neural networks, addressing key open questions\nabout optimal query strategies in the graph setting. We introduce BASE and\nG-BASE, computationally efficient approximations of the Bayes-optimal attack.\nG-BASE achieves superior performance compared to previously proposed\nclassifier-based node-level MIA attacks. BASE, which is also applicable to\nnon-graph data, matches or exceeds the performance of prior state-of-the-art\nMIAs, such as LiRA and RMIA, at a significantly lower computational cost.\nFinally, we show that BASE and RMIA are equivalent under a specific\nhyperparameter setting, providing a principled, Bayes-optimal justification for\nthe RMIA attack.", "AI": {"tldr": "The paper develops practical and theoretically grounded membership inference attacks (MIAs) for both i.i.d. data and graph-structured data, introduces BASE and G-BASE methods which are computationally efficient approximations of the Bayes-optimal attack, and shows that BASE matches or exceeds previous MIAs' performance at lower cost.", "motivation": "To create practical and theoretically grounded membership inference attacks (MIAs) against both independent and identically distributed (i.i.d.) data and graph-structured data, addressing open questions about optimal query strategies in the graph setting.", "method": "Derive the Bayes-optimal membership inference rule for node-level MIAs against graph neural networks based on the Bayesian decision-theoretic framework. Introduce BASE and G-BASE as computationally efficient approximations of the Bayes-optimal attack.", "result": "G-BASE outperforms previously proposed classifier-based node-level MIA attacks. BASE matches or exceeds the performance of prior state-of-the-art MIAs like LiRA and RMIA at a significantly lower computational cost. BASE and RMIA are equivalent under a specific hyperparameter setting.", "conclusion": "BASE and G-BASE provide efficient approximations of the Bayes-optimal attack for MIAs. BASE is effective for non-graph data while G-BASE is superior for graph-structured data."}}
{"id": "2505.24067", "pdf": "https://arxiv.org/pdf/2505.24067", "abs": "https://arxiv.org/abs/2505.24067", "authors": ["Yu He", "Ellen Vitercik"], "title": "Primal-Dual Neural Algorithmic Reasoning", "categories": ["cs.LG"], "comment": "The 42nd International Conference on Machine Learning, 2025", "summary": "Neural Algorithmic Reasoning (NAR) trains neural networks to simulate\nclassical algorithms, enabling structured and interpretable reasoning over\ncomplex data. While prior research has predominantly focused on learning exact\nalgorithms for polynomial-time-solvable problems, extending NAR to harder\nproblems remains an open challenge. In this work, we introduce a general NAR\nframework grounded in the primal-dual paradigm, a classical method for\ndesigning efficient approximation algorithms. By leveraging a bipartite\nrepresentation between primal and dual variables, we establish an alignment\nbetween primal-dual algorithms and Graph Neural Networks. Furthermore, we\nincorporate optimal solutions from small instances to greatly enhance the\nmodel's reasoning capabilities. Our empirical results demonstrate that our\nmodel not only simulates but also outperforms approximation algorithms for\nmultiple tasks, exhibiting robust generalization to larger and\nout-of-distribution graphs. Moreover, we highlight the framework's practical\nutility by integrating it with commercial solvers and applying it to real-world\ndatasets.", "AI": {"tldr": "The paper presents a new NAR framework based on the primal-dual paradigm, which enhances neural networks' ability to approximate algorithmic reasoning for complex problems.", "motivation": "To address the limitation of existing NAR approaches focusing on polynomial-time solvable problems, this work aims to extend NAR to harder computational problems by leveraging the primal-dual paradigm.", "method": "A general NAR framework is developed using the primal-dual paradigm. This includes creating a bipartite representation between primal and dual variables to align with Graph Neural Networks, and incorporating optimal solutions from small instances to improve reasoning capabilities.", "result": "The model not only simulates but also outperforms approximation algorithms in various tasks, showing robust generalization to larger and out-of-distribution graphs. It also proves practically useful when integrated with commercial solvers and applied to real-world datasets.", "conclusion": "This NAR framework grounded in the primal-dual paradigm successfully extends algorithmic reasoning to more complex problems, offering both theoretical and practical advancements."}}
{"id": "2505.23790", "pdf": "https://arxiv.org/pdf/2505.23790", "abs": "https://arxiv.org/abs/2505.23790", "authors": ["Shaojie Wang", "Sirui Ding", "Na Zou"], "title": "Rethinking the Understanding Ability across LLMs through Mutual Information", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Recent advances in large language models (LLMs) have revolutionized natural\nlanguage processing, yet evaluating their intrinsic linguistic understanding\nremains challenging. Moving beyond specialized evaluation tasks, we propose an\ninformation-theoretic framework grounded in mutual information (MI) to achieve\nthis. We formalize the understanding as MI between an input sentence and its\nlatent representation (sentence-level MI), measuring how effectively input\ninformation is preserved in latent representation. Given that LLMs learn\nembeddings for individual tokens, we decompose sentence-level MI into\ntoken-level MI between tokens and sentence embeddings, establishing theoretical\nbounds connecting these measures. Based on this foundation, we theoretically\nderive a computable lower bound for token-level MI using Fano's inequality,\nwhich directly relates to token-level recoverability-the ability to predict\noriginal tokens from sentence embedding. We implement this recoverability task\nto comparatively measure MI across different LLMs, revealing that encoder-only\nmodels consistently maintain higher information fidelity than their\ndecoder-only counterparts, with the latter exhibiting a distinctive late-layer\n\"forgetting\" pattern where mutual information is first enhanced and then\ndiscarded. Moreover, fine-tuning to maximize token-level recoverability\nconsistently improves understanding ability of LLMs on tasks without\ntask-specific supervision, demonstrating that mutual information can serve as a\nfoundation for understanding and improving language model capabilities.", "AI": {"tldr": "Recent advances in large language models (LLMs) have made it difficult to evaluate their intrinsic linguistic understanding. This paper proposes an information-theoretic framework based on mutual information (MI) to address this issue. The authors formalize understanding as MI between an input sentence and its latent representation, decompose sentence-level MI into token-level MI, derive a computable lower bound for token-level MI, and implement a recoverability task to measure MI across different LLMs. Results show that encoder-only models maintain higher information fidelity than decoder-only models, and fine-tuning to maximize token-level recoverability improves LLM understanding ability.", "motivation": "Evaluating the intrinsic linguistic understanding of large language models remains challenging. Current evaluation methods are often specialized tasks that do not fully capture the nuances of linguistic understanding.", "method": "The authors propose an information-theoretic framework based on mutual information (MI). They formalize understanding as MI between an input sentence and its latent representation, decompose sentence-level MI into token-level MI, derive a computable lower bound for token-level MI using Fano's inequality, and implement a recoverability task to measure MI across different LLMs.", "result": "Encoder-only models consistently maintain higher information fidelity than decoder-only models. Decoder-only models exhibit a late-layer 'forgetting' pattern where mutual information is first enhanced and then discarded. Fine-tuning to maximize token-level recoverability improves understanding ability of LLMs on tasks without task-specific supervision.", "conclusion": "Mutual information can serve as a foundation for understanding and improving language model capabilities."}}
{"id": "2505.24227", "pdf": "https://arxiv.org/pdf/2505.24227", "abs": "https://arxiv.org/abs/2505.24227", "authors": ["Ying Yang", "Jie Zhang", "Xiao Lv", "Di Lin", "Tao Xiang", "Qing Guo"], "title": "Light as Deception: GPT-driven Natural Relighting Against Vision-Language Pre-training Models", "categories": ["cs.CV", "cs.CR"], "comment": null, "summary": "While adversarial attacks on vision-and-language pretraining (VLP) models\nhave been explored, generating natural adversarial samples crafted through\nrealistic and semantically meaningful perturbations remains an open challenge.\nExisting methods, primarily designed for classification tasks, struggle when\nadapted to VLP models due to their restricted optimization spaces, leading to\nineffective attacks or unnatural artifacts. To address this, we propose\n\\textbf{LightD}, a novel framework that generates natural adversarial samples\nfor VLP models via semantically guided relighting. Specifically, LightD\nleverages ChatGPT to propose context-aware initial lighting parameters and\nintegrates a pretrained relighting model (IC-light) to enable diverse lighting\nadjustments. LightD expands the optimization space while ensuring perturbations\nalign with scene semantics. Additionally, gradient-based optimization is\napplied to the reference lighting image to further enhance attack effectiveness\nwhile maintaining visual naturalness. The effectiveness and superiority of the\nproposed LightD have been demonstrated across various VLP models in tasks such\nas image captioning and visual question answering.", "AI": {"tldr": "An abstract about a new framework LightD that generates natural adversarial samples for VLP models via semantically guided relighting.", "motivation": "Adversarial attacks on VLP models have been explored, but generating natural adversarial samples with realistic and meaningful perturbations remains challenging. Existing methods designed for classification tasks are not effective for VLP models due to restricted optimization spaces.", "method": "Propose LightD which uses ChatGPT for context-aware initial lighting parameters and integrates a pretrained relighting model (IC-light) for diverse lighting adjustments. Gradient-based optimization is applied to the reference lighting image to enhance attack effectiveness while maintaining visual naturalness.", "result": "LightD expands the optimization space while ensuring perturbations align with scene semantics and has been shown to be effective in generating natural adversarial samples.", "conclusion": "LightD demonstrates effectiveness and superiority across various VLP models in tasks such as image captioning and visual question answering."}}
{"id": "2505.24069", "pdf": "https://arxiv.org/pdf/2505.24069", "abs": "https://arxiv.org/abs/2505.24069", "authors": ["Yu He", "Yingxi Li", "Colin White", "Ellen Vitercik"], "title": "DSR-Bench: Evaluating the Structural Reasoning Abilities of LLMs via Data Structures", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) are increasingly deployed for real-world tasks\nthat fundamentally involve data manipulation. A core requirement across these\ntasks is the ability to perform structural reasoning--that is, to understand\nand reason about data relationships. For example, customer requests require a\ntemporal ordering, which can be represented by data structures such as queues.\nHowever, existing benchmarks primarily focus on high-level, application-driven\nevaluations without isolating this fundamental capability. To address this gap,\nwe introduce DSR-Bench, a novel benchmark evaluating LLMs' structural reasoning\ncapabilities through data structures, which provide interpretable\nrepresentations of data relationships. DSR-Bench includes 20 data structures,\n35 operations, and 4,140 problem instances, organized hierarchically for\nfine-grained analysis of reasoning limitations. Our evaluation pipeline is\nfully automated and deterministic, eliminating subjective human or model-based\njudgments. Its synthetic nature also ensures scalability and minimizes data\ncontamination risks. We benchmark nine state-of-the-art LLMs. Our analysis\nshows that instruction-tuned models struggle with basic multi-attribute and\nmulti-hop reasoning. Furthermore, while reasoning-oriented models perform\nbetter, they remain fragile on complex and hybrid structures, with the best\nmodel achieving an average score of only 47% on the challenge subset.\nCrucially, models often perform poorly on multi-dimensional data and natural\nlanguage task descriptions, highlighting a critical gap for real-world\ndeployment.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u6570\u636e\u64cd\u4f5c\u76f8\u5173\u4efb\u52a1\u4e2d\u9700\u8981\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u6d4b\u8bd5\u672a\u5145\u5206\u8bc4\u4f30\u6b64\u80fd\u529b\u3002\u672c\u6587\u63d0\u51faDSR-Bench\u57fa\u51c6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u6a21\u578b\u5728\u591a\u5c5e\u6027\u548c\u591a\u8df3\u63a8\u7406\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u5728\u590d\u6742\u7ed3\u6784\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u65b9\u9762\u5b58\u5728\u660e\u663e\u77ed\u677f\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u88ab\u5e7f\u6cdb\u5e94\u7528\u4e8e\u6d89\u53ca\u6570\u636e\u64cd\u4f5c\u7684\u4efb\u52a1\u4e2d\uff0c\u8fd9\u4e9b\u4efb\u52a1\u9700\u8981\u6a21\u578b\u5177\u5907\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u4ee5\u7406\u89e3\u6570\u636e\u5173\u7cfb\u3002\u7136\u800c\uff0c\u5f53\u524d\u7684\u57fa\u51c6\u6d4b\u8bd5\u4e3b\u8981\u5173\u6ce8\u5e94\u7528\u5c42\u9762\u7684\u8868\u73b0\uff0c\u672a\u80fd\u5355\u72ec\u8bc4\u4f30\u8fd9\u79cd\u57fa\u7840\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86DSR-Bench\u8fd9\u4e00\u65b0\u57fa\u51c6\uff0c\u5305\u542b20\u79cd\u6570\u636e\u7ed3\u6784\u300135\u79cd\u64cd\u4f5c\u548c4,140\u4e2a\u95ee\u9898\u5b9e\u4f8b\uff0c\u901a\u8fc7\u5206\u5c42\u7ec4\u7ec7\u7684\u65b9\u5f0f\u5bf9LLM\u7684\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u6790\u3002\u8be5\u57fa\u51c6\u5b8c\u5168\u81ea\u52a8\u5316\u4e14\u786e\u5b9a\u6027\uff0c\u907f\u514d\u4e3b\u89c2\u5224\u65ad\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u786e\u4fdd\u53ef\u6269\u5c55\u6027\u548c\u51cf\u5c11\u6c61\u67d3\u98ce\u9669\u3002", "result": "\u8bc4\u4f30\u4e86\u4e5d\u4e2a\u6700\u5148\u8fdb\u7684LLM\uff0c\u7ed3\u679c\u663e\u793a\u6307\u4ee4\u8c03\u4f18\u6a21\u578b\u5728\u591a\u5c5e\u6027\u548c\u591a\u8df3\u63a8\u7406\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u4e13\u6ce8\u4e8e\u63a8\u7406\u7684\u6a21\u578b\u867d\u7136\u8868\u73b0\u8f83\u597d\uff0c\u4f46\u5728\u590d\u6742\u548c\u6df7\u5408\u7ed3\u6784\u4e0a\u7684\u8868\u73b0\u4ecd\u7136\u8106\u5f31\uff0c\u6700\u4f73\u6a21\u578b\u5728\u6311\u6218\u5b50\u96c6\u4e0a\u7684\u5e73\u5747\u5f97\u5206\u4ec5\u4e3a47%\u3002\u6a21\u578b\u5728\u591a\u7ef4\u6570\u636e\u548c\u81ea\u7136\u8bed\u8a00\u4efb\u52a1\u63cf\u8ff0\u65b9\u9762\u7684\u8868\u73b0\u8f83\u5dee\u3002", "conclusion": "\u73b0\u6709LLM\u5728\u7ed3\u6784\u5316\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u6570\u636e\u7ed3\u6784\u548c\u81ea\u7136\u8bed\u8a00\u63cf\u8ff0\u65f6\uff0c\u8fd9\u5bf9\u5b9e\u9645\u90e8\u7f72\u6784\u6210\u4e86\u91cd\u8981\u6311\u6218\u3002"}}
{"id": "2505.24231", "pdf": "https://arxiv.org/pdf/2505.24231", "abs": "https://arxiv.org/abs/2505.24231", "authors": ["Md Shahnawaz", "Bishwajit Prasad Gond", "Durga Prasad Mohapatra"], "title": "Dynamic Malware Classification of Windows PE Files using CNNs and Greyscale Images Derived from Runtime API Call Argument Conversion", "categories": ["cs.LG", "cs.AI", "cs.CR"], "comment": null, "summary": "Malware detection and classification remains a topic of concern for\ncybersecurity, since it is becoming common for attackers to use advanced\nobfuscation on their malware to stay undetected. Conventional static analysis\nis not effective against polymorphic and metamorphic malware as these change\ntheir appearance without modifying their behavior, thus defying the analysis by\ncode structure alone. This makes it important to use dynamic detection that\nmonitors malware behavior at runtime. In this paper, we present a dynamic\nmalware categorization framework that extracts API argument calls at the\nruntime execution of Windows Portable Executable (PE) files. Extracting and\nencoding the dynamic features of API names, argument return values, and other\nrelative features, we convert raw behavioral data to temporal patterns. To\nenhance feature portrayal, the generated patterns are subsequently converted\ninto grayscale pictures using a magma colormap. These improved photos are used\nto teach a Convolutional Neural Network (CNN) model discriminative features,\nwhich allows for reliable and accurate malware classification. Results from\nexperiments indicate that our method, with an average accuracy of 98.36% is\neffective in classifying different classes of malware and benign by integrating\ndynamic analysis and deep learning. It not only achieves high classification\naccuracy but also demonstrates significant resilience against typical evasion\nstrategies.", "AI": {"tldr": "The paper proposes a dynamic malware categorization framework that converts API behavioral data into grayscale images and uses CNN for classification.", "motivation": "Malware detection and classification is crucial in cybersecurity due to attackers using advanced obfuscation techniques. Conventional static analysis is ineffective against polymorphic and metamorphic malware, necessitating dynamic detection methods.", "method": "The method involves extracting API argument calls during the runtime execution of Windows PE files, encoding these dynamic features, converting them into temporal patterns, transforming these patterns into grayscale images, and then training a CNN model on these images for classification.", "result": "Experiments show an average accuracy of 98.36% in classifying different types of malware and benign software, demonstrating high accuracy and resilience against typical evasion strategies.", "conclusion": "The proposed framework effectively integrates dynamic analysis and deep learning for reliable and accurate malware classification."}}
{"id": "2505.24085", "pdf": "https://arxiv.org/pdf/2505.24085", "abs": "https://arxiv.org/abs/2505.24085", "authors": ["Alireza Jafari", "Fereshteh Yousefirizi", "Vahid Seydi"], "title": "DeepBoost-AF: A Novel Unsupervised Feature Learning and Gradient Boosting Fusion for Robust Atrial Fibrillation Detection in Raw ECG Signals", "categories": ["cs.LG"], "comment": "12-page,4 figures,3 tables, Achieves 95.20% F1-score (99.99%\n  sensitivity) on 8,528 PhysioNet 2017 recordings, Mean inference time: 4\n  seconds, Python implementation will be open-sourced upon publication", "summary": "Atrial fibrillation (AF) is a prevalent cardiac arrhythmia associated with\nelevated health risks, where timely detection is pivotal for mitigating\nstroke-related morbidity. This study introduces an innovative hybrid\nmethodology integrating unsupervised deep learning and gradient boosting models\nto improve AF detection. A 19-layer deep convolutional autoencoder (DCAE) is\ncoupled with three boosting classifiers-AdaBoost, XGBoost, and LightGBM\n(LGBM)-to harness their complementary advantages while addressing individual\nlimitations. The proposed framework uniquely combines DCAE with gradient\nboosting, enabling end-to-end AF identification devoid of manual feature\nextraction. The DCAE-LGBM model attains an F1-score of 95.20%, sensitivity of\n99.99%, and inference latency of four seconds, outperforming existing methods\nand aligning with clinical deployment requirements. The DCAE integration\nsignificantly enhances boosting models, positioning this hybrid system as a\nreliable tool for automated AF detection in clinical settings.", "AI": {"tldr": "Atrial fibrillation (AF) is a common heart arrhythmia associated with increased health risks. This study proposes a hybrid methodology integrating unsupervised deep learning and gradient boosting models to improve AF detection.", "motivation": "Timely detection of atrial fibrillation (AF) is crucial for reducing stroke-related morbidity.", "method": "The study introduces a 19-layer deep convolutional autoencoder (DCAE) coupled with three boosting classifiers - AdaBoost, XGBoost, and LightGBM (LGBM). This hybrid system enables end-to-end AF identification without manual feature extraction.", "result": "The DCAE-LGBM model achieves an F1-score of 95.20%, sensitivity of 99.99%, and inference latency of four seconds, surpassing existing methods and meeting clinical deployment requirements.", "conclusion": "The integration of DCAE significantly enhances the performance of boosting models, making this hybrid system a reliable tool for automated AF detection in clinical settings."}}
{"id": "2505.24379", "pdf": "https://arxiv.org/pdf/2505.24379", "abs": "https://arxiv.org/abs/2505.24379", "authors": ["Xiaoyu Wu", "Yifei Pang", "Terrance Liu", "Zhiwei Steven Wu"], "title": "Breaking the Gold Standard: Extracting Forgotten Data under Exact Unlearning in Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL", "cs.CR"], "comment": null, "summary": "Large language models are typically trained on datasets collected from the\nweb, which may inadvertently contain harmful or sensitive personal information.\nTo address growing privacy concerns, unlearning methods have been proposed to\nremove the influence of specific data from trained models. Of these, exact\nunlearning -- which retrains the model from scratch without the target data --\nis widely regarded the gold standard, believed to be robust against\nprivacy-related attacks. In this paper, we challenge this assumption by\nintroducing a novel data extraction attack that compromises even exact\nunlearning. Our method leverages both the pre- and post-unlearning models: by\nguiding the post-unlearning model using signals from the pre-unlearning model,\nwe uncover patterns that reflect the removed data distribution. Combining model\nguidance with a token filtering strategy, our attack significantly improves\nextraction success rates -- doubling performance in some cases -- across common\nbenchmarks such as MUSE, TOFU, and WMDP. Furthermore, we demonstrate our\nattack's effectiveness on a simulated medical diagnosis dataset to highlight\nreal-world privacy risks associated with exact unlearning. In light of our\nfindings, which suggest that unlearning may, in a contradictory way, increase\nthe risk of privacy leakage, we advocate for evaluation of unlearning methods\nto consider broader threat models that account not only for post-unlearning\nmodels but also for adversarial access to prior checkpoints.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u6570\u636e\u63d0\u53d6\u653b\u51fb\u65b9\u6cd5\uff0c\u6311\u6218\u4e86\u5373\u4f7f\u5b8c\u5168\u9057\u5fd8\u4e5f\u65e0\u6cd5\u4fdd\u969c\u9690\u79c1\u7684\u5047\u8bbe\u3002\u901a\u8fc7\u7ed3\u5408\u9057\u5fd8\u524d\u540e\u7684\u6a21\u578b\u4fe1\u53f7\u548c\u6807\u8bb0\u8fc7\u6ee4\u7b56\u7565\uff0c\u8be5\u653b\u51fb\u663e\u8457\u63d0\u9ad8\u4e86\u4ece\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u63d0\u53d6\u88ab\u9057\u5fd8\u6570\u636e\u7684\u6210\u529f\u7387\uff0c\u5e76\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u9a8c\u8bc1\u4e86\u5176\u6548\u679c\u3002\u6b64\u5916\uff0c\u5728\u6a21\u62df\u533b\u7597\u8bca\u65ad\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5b8c\u5168\u9057\u5fd8\u53ef\u80fd\u53cd\u800c\u589e\u52a0\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5efa\u8bae\u5728\u8bc4\u4f30\u9057\u5fd8\u65b9\u6cd5\u65f6\u5e94\u8003\u8651\u66f4\u5e7f\u6cdb\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u5305\u62ec\u5bf9\u5148\u524d\u68c0\u67e5\u70b9\u7684\u5bf9\u6297\u8bbf\u95ee\u3002", "motivation": "\u5c3d\u7ba1\u5b8c\u5168\u9057\u5fd8\uff08exact unlearning\uff09\u88ab\u8ba4\u4e3a\u662f\u53bb\u9664\u7279\u5b9a\u6570\u636e\u5f71\u54cd\u7684\u9ec4\u91d1\u6807\u51c6\uff0c\u4f46\u5176\u662f\u5426\u771f\u6b63\u80fd\u591f\u62b5\u5fa1\u9690\u79c1\u76f8\u5173\u653b\u51fb\u4ecd\u9700\u9a8c\u8bc1\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u6570\u636e\u63d0\u53d6\u653b\u51fb\u65b9\u6cd5\uff0c\u5229\u7528\u9057\u5fd8\u524d\u540e\u6a21\u578b\u7684\u4fe1\u53f7\u5f15\u5bfc\u4ee5\u53ca\u6807\u8bb0\u8fc7\u6ee4\u7b56\u7565\uff0c\u63ed\u793a\u53cd\u6620\u5df2\u79fb\u9664\u6570\u636e\u5206\u5e03\u7684\u6a21\u5f0f\u3002", "result": "\u5728MUSE\u3001TOFU\u548cWMDP\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u653b\u51fb\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u63d0\u53d6\u6210\u529f\u7387\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u6027\u80fd\u7ffb\u500d\u3002\u540c\u65f6\uff0c\u5728\u6a21\u62df\u533b\u7597\u8bca\u65ad\u6570\u636e\u96c6\u4e0a\u8bc1\u660e\u4e86\u5b8c\u5168\u9057\u5fd8\u53ef\u80fd\u589e\u52a0\u9690\u79c1\u6cc4\u9732\u98ce\u9669\u3002", "conclusion": "\u5b8c\u5168\u9057\u5fd8\u5e76\u4e0d\u8db3\u4ee5\u4fdd\u969c\u9690\u79c1\uff0c\u8bc4\u4f30\u9057\u5fd8\u65b9\u6cd5\u65f6\u9700\u8981\u8003\u8651\u66f4\u5e7f\u6cdb\u7684\u5a01\u80c1\u6a21\u578b\uff0c\u5305\u62ec\u5bf9\u6297\u6027\u8bbf\u95ee\u5148\u524d\u6a21\u578b\u68c0\u67e5\u70b9\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2505.24088", "pdf": "https://arxiv.org/pdf/2505.24088", "abs": "https://arxiv.org/abs/2505.24088", "authors": ["Chen Huang", "Skyler Seto", "Hadi Pouransari", "Mehrdad Farajtabar", "Raviteja Vemulapalli", "Fartash Faghri", "Oncel Tuzel", "Barry-John Theobald", "Josh Susskind"], "title": "Proxy-FDA: Proxy-based Feature Distribution Alignment for Fine-tuning Vision Foundation Models without Forgetting", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025", "summary": "Vision foundation models pre-trained on massive data encode rich\nrepresentations of real-world concepts, which can be adapted to downstream\ntasks by fine-tuning. However, fine-tuning foundation models on one task often\nleads to the issue of concept forgetting on other tasks. Recent methods of\nrobust fine-tuning aim to mitigate forgetting of prior knowledge without\naffecting the fine-tuning performance. Knowledge is often preserved by matching\nthe original and fine-tuned model weights or feature pairs. However, such\npoint-wise matching can be too strong, without explicit awareness of the\nfeature neighborhood structures that encode rich knowledge as well. We propose\na novel regularization method Proxy-FDA that explicitly preserves the\nstructural knowledge in feature space. Proxy-FDA performs Feature Distribution\nAlignment (using nearest neighbor graphs) between the pre-trained and\nfine-tuned feature spaces, and the alignment is further improved by informative\nproxies that are generated dynamically to increase data diversity. Experiments\nshow that Proxy-FDA significantly reduces concept forgetting during\nfine-tuning, and we find a strong correlation between forgetting and a\ndistributional distance metric (in comparison to L2 distance). We further\ndemonstrate Proxy-FDA's benefits in various fine-tuning settings (end-to-end,\nfew-shot and continual tuning) and across different tasks like image\nclassification, captioning and VQA.", "AI": {"tldr": "A new regularization method called Proxy-FDA is proposed to reduce concept forgetting during fine-tuning of vision foundation models. It preserves structural knowledge in feature space by performing Feature Distribution Alignment using nearest neighbor graphs and informative proxies.", "motivation": "Vision foundation models pre-trained on large amounts of data can be adapted to downstream tasks through fine-tuning. However, fine-tuning often leads to the problem of concept forgetting on other tasks. Existing methods preserve knowledge via point-wise matching of model weights or features, which may be too strong and lack explicit awareness of feature neighborhood structures encoding rich knowledge.", "method": "The proposed method, Proxy-FDA, explicitly preserves structural knowledge in feature space. It performs Feature Distribution Alignment between pre-trained and fine-tuned feature spaces using nearest neighbor graphs. The alignment is further improved by informative proxies that are generated dynamically to increase data diversity.", "result": "Experiments demonstrate that Proxy-FDA significantly reduces concept forgetting during fine-tuning. There is a strong correlation between forgetting and a distributional distance metric compared to L2 distance. Proxy-FDA shows benefits in various fine-tuning settings (end-to-end, few-shot, continual tuning) and across different tasks such as image classification, captioning, and VQA.", "conclusion": "Proxy-FDA is an effective regularization method for reducing concept forgetting in fine-tuning vision foundation models. It highlights the importance of preserving structural knowledge in feature space and shows potential in diverse fine-tuning scenarios and tasks."}}
{"id": "2505.24486", "pdf": "https://arxiv.org/pdf/2505.24486", "abs": "https://arxiv.org/abs/2505.24486", "authors": ["Falih Gozi Febrinanto", "Kristen Moore", "Chandra Thapa", "Jiangang Ma", "Vidya Saikrishna", "Feng Xia"], "title": "Rehearsal with Auxiliary-Informed Sampling for Audio Deepfake Detection", "categories": ["cs.SD", "cs.AI", "cs.CR", "cs.LG", "eess.AS"], "comment": "Accepted by Interspeech 2025", "summary": "The performance of existing audio deepfake detection frameworks degrades when\nconfronted with new deepfake attacks. Rehearsal-based continual learning (CL),\nwhich updates models using a limited set of old data samples, helps preserve\nprior knowledge while incorporating new information. However, existing\nrehearsal techniques don't effectively capture the diversity of audio\ncharacteristics, introducing bias and increasing the risk of forgetting. To\naddress this challenge, we propose Rehearsal with Auxiliary-Informed Sampling\n(RAIS), a rehearsal-based CL approach for audio deepfake detection. RAIS\nemploys a label generation network to produce auxiliary labels, guiding diverse\nsample selection for the memory buffer. Extensive experiments show RAIS\noutperforms state-of-the-art methods, achieving an average Equal Error Rate\n(EER) of 1.953 % across five experiences. The code is available at:\nhttps://github.com/falihgoz/RAIS.", "AI": {"tldr": "The paper proposes Rehearsal with Auxiliary-Informed Sampling (RAIS) for audio deepfake detection, which outperforms current methods with an average Equal Error Rate of 1.953%.", "motivation": "Existing rehearsal techniques fail to effectively capture the diversity of audio characteristics, leading to bias and increased risk of forgetting prior knowledge when faced with new deepfake attacks.", "method": "RAIS employs a label generation network to produce auxiliary labels that guide diverse sample selection for the memory buffer in rehearsal-based continual learning approach.", "result": "Extensive experiments demonstrate that RAIS outperforms state-of-the-art methods, achieving an average Equal Error Rate (EER) of 1.953% across five experiences.", "conclusion": "Rehearsal with Auxiliary-Informed Sampling (RAIS) is an effective rehearsal-based continual learning approach for audio deepfake detection."}}
{"id": "2505.23794", "pdf": "https://arxiv.org/pdf/2505.23794", "abs": "https://arxiv.org/abs/2505.23794", "authors": ["Yuan Li", "Qi Luo", "Xiaonan Li", "Bufan Li", "Qinyuan Cheng", "Bo Wang", "Yining Zheng", "Yuxin Wang", "Zhangyue Yin", "Xipeng Qiu"], "title": "R3-RAG: Learning Step-by-Step Reasoning and Retrieval for LLMs via Reinforcement Learning", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Retrieval-Augmented Generation (RAG) integrates external knowledge with Large\nLanguage Models (LLMs) to enhance factual correctness and mitigate\nhallucination. However, dense retrievers often become the bottleneck of RAG\nsystems due to their limited parameters compared to LLMs and their inability to\nperform step-by-step reasoning. While prompt-based iterative RAG attempts to\naddress these limitations, it is constrained by human-designed workflows. To\naddress these limitations, we propose $\\textbf{R3-RAG}$, which uses\n$\\textbf{R}$einforcement learning to make the LLM learn how to\n$\\textbf{R}$eason and $\\textbf{R}$etrieve step by step, thus retrieving\ncomprehensive external knowledge and leading to correct answers. R3-RAG is\ndivided into two stages. We first use cold start to make the model learn the\nmanner of iteratively interleaving reasoning and retrieval. Then we use\nreinforcement learning to further harness its ability to better explore the\nexternal retrieval environment. Specifically, we propose two rewards for\nR3-RAG: 1) answer correctness for outcome reward, which judges whether the\ntrajectory leads to a correct answer; 2) relevance-based document verification\nfor process reward, encouraging the model to retrieve documents that are\nrelevant to the user question, through which we can let the model learn how to\niteratively reason and retrieve relevant documents to get the correct answer.\nExperimental results show that R3-RAG significantly outperforms baselines and\ncan transfer well to different retrievers. We release R3-RAG at\nhttps://github.com/Yuan-Li-FNLP/R3-RAG.", "AI": {"tldr": "R3-RAG is a new method that uses reinforcement learning to improve Retrieval-Augmented Generation (RAG) systems. It helps large language models learn how to reason and retrieve information step by step, leading to more accurate answers. The system has two stages and includes rewards for answer correctness and document relevance.", "motivation": "Current RAG systems face limitations due to dense retrievers being a bottleneck, having limited parameters compared to LLMs, and lacking step-by-step reasoning capabilities. Prompt-based iterative RAG is constrained by human-designed workflows.", "method": "The R3-RAG model is divided into two stages: 1) Cold start - teaching the model to interleave reasoning and retrieval iteratively; 2) Reinforcement learning - enhancing the model's ability to explore the external retrieval environment. Two rewards are proposed: answer correctness for outcome reward and relevance-based document verification for process reward.", "result": "Experimental results demonstrate that R3-RAG significantly outperforms baseline methods and shows good transferability across different retrievers.", "conclusion": "R3-RAG successfully addresses the limitations of current RAG systems by using reinforcement learning to teach LLMs how to reason and retrieve information step by step, resulting in improved performance and factual correctness."}}
{"id": "2505.24101", "pdf": "https://arxiv.org/pdf/2505.24101", "abs": "https://arxiv.org/abs/2505.24101", "authors": ["Zhenran Xu"], "title": "A SHAP-based explainable multi-level stacking ensemble learning method for predicting the length of stay in acute stroke", "categories": ["cs.LG"], "comment": "Master Minor Thesis, Preprint", "summary": "Length of stay (LOS) prediction in acute stroke is critical for improving\ncare planning. Existing machine learning models have shown suboptimal\npredictive performance, limited generalisability, and have overlooked\nsystem-level factors. We aimed to enhance model efficiency, performance, and\ninterpretability by refining predictors and developing an interpretable\nmulti-level stacking ensemble model. Data were accessed from the biennial\nStroke Foundation Acute Audit (2015, 2017, 2019, 2021) in Australia. Models\nwere developed for ischaemic and haemorrhagic stroke separately. The outcome\nwas prolonged LOS (the LOS above the 75th percentile). Candidate predictors\n(ischaemic: n=89; haemorrhagic: n=83) were categorised into patient, clinical,\nand system domains. Feature selection with correlation-based approaches was\nused to refine key predictors. The evaluation of models included discrimination\n(AUC), calibration curves, and interpretability (SHAP plots). In ischaemic\nstroke (N=12,575), prolonged LOS was >=9 days, compared to >=11 days in\nhaemorrhagic stroke (N=1,970). The ensemble model achieved superior performance\n[AUC: 0.824 (95% CI: 0.801-0.846)] and statistically outperformed logistic\nregression [AUC: 0.805 (95% CI: 0.782-0.829); P=0.0004] for ischaemic. However,\nthe model [AUC: 0.843 (95% CI: 0.790-0.895)] did not statistically outperform\nlogistic regression [AUC: 0.828 (95% CI: 0.774-0.882); P=0.136] for\nhaemorrhagic. SHAP analysis identified shared predictors for both types of\nstroke: rehabilitation assessment, urinary incontinence, stroke unit care,\ninability to walk independently, physiotherapy, and stroke care coordinators\ninvolvement. An explainable ensemble model effectively predicted the prolonged\nLOS in ischaemic stroke. Further validation in larger cohorts is needed for\nhaemorrhagic stroke.", "AI": {"tldr": "An explainable ensemble model effectively predicted the prolonged Length of Stay (LOS) in ischaemic stroke, but further validation is needed for haemorrhagic stroke.", "motivation": "To enhance model efficiency, performance, and interpretability by refining predictors and developing an interpretable multi-level stacking ensemble model for predicting prolonged LOS in acute stroke patients.", "method": "Data from Stroke Foundation Acute Audit in Australia were used to develop models separately for ischaemic and haemorrhagic stroke. Candidate predictors were categorised into patient, clinical, and system domains and refined using feature selection with correlation-based approaches. An interpretable multi-level stacking ensemble model was developed and evaluated using discrimination (AUC), calibration curves, and interpretability (SHAP plots).", "result": "The ensemble model achieved superior performance for ischaemic stroke [AUC: 0.824 (95% CI: 0.801-0.846)] compared to logistic regression [AUC: 0.805 (95% CI: 0.782-0.829); P=0.0004]. For haemorrhagic stroke, the model [AUC: 0.843 (95% CI: 0.790-0.895)] did not statistically outperform logistic regression [AUC: 0.828 (95% CI: 0.774-0.882); P=0.136]. Shared predictors for both types of stroke included rehabilitation assessment, urinary incontinence, stroke unit care, inability to walk independently, physiotherapy, and stroke care coordinators involvement.", "conclusion": "An explainable ensemble model effectively predicted prolonged LOS in ischaemic stroke. Further validation in larger cohorts is needed for haemorrhagic stroke."}}
{"id": "2505.23797", "pdf": "https://arxiv.org/pdf/2505.23797", "abs": "https://arxiv.org/abs/2505.23797", "authors": ["Zaihan Yang", "Ryan Leonard", "Hien Tran", "Rory Driscoll", "Chadbourne Davis"], "title": "Detection of Suicidal Risk on Social Media: A Hybrid Model", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG", "cs.SI"], "comment": null, "summary": "Suicidal thoughts and behaviors are increasingly recognized as a critical\nsocietal concern, highlighting the urgent need for effective tools to enable\nearly detection of suicidal risk. In this work, we develop robust machine\nlearning models that leverage Reddit posts to automatically classify them into\nfour distinct levels of suicide risk severity. We frame this as a multi-class\nclassification task and propose a RoBERTa-TF-IDF-PCA Hybrid model, integrating\nthe deep contextual embeddings from Robustly Optimized BERT Approach (RoBERTa),\na state-of-the-art deep learning transformer model, with the statistical\nterm-weighting of TF-IDF, further compressed with PCA, to boost the accuracy\nand reliability of suicide risk assessment. To address data imbalance and\noverfitting, we explore various data resampling techniques and data\naugmentation strategies to enhance model generalization. Additionally, we\ncompare our model's performance against that of using RoBERTa only, the BERT\nmodel and other traditional machine learning classifiers. Experimental results\ndemonstrate that the hybrid model can achieve improved performance, giving a\nbest weighted $F_{1}$ score of 0.7512.", "AI": {"tldr": "The paper develops a RoBERTa-TF-IDF-PCA Hybrid model for classifying Reddit posts into four levels of suicide risk severity. It achieves an F1 score of 0.7512.", "motivation": "Suicidal thoughts and behaviors are a growing societal concern, creating a need for tools that can enable early detection of suicidal risk.", "method": "A multi-class classification task is framed using a RoBERTa-TF-IDF-PCA Hybrid model which integrates deep contextual embeddings from RoBERTa with TF-IDF term weighting compressed by PCA. Data resampling techniques and data augmentation strategies are also explored to address data imbalance and overfitting.", "result": "The hybrid model outperforms other models including RoBERTa only, BERT model and traditional machine learning classifiers, achieving a best weighted F1 score of 0.7512.", "conclusion": "The proposed RoBERTa-TF-IDF-PCA Hybrid model provides an effective method for classifying suicide risk severity from social media posts."}}
{"id": "2505.24110", "pdf": "https://arxiv.org/pdf/2505.24110", "abs": "https://arxiv.org/abs/2505.24110", "authors": ["Sahil Rajesh Dhayalkar"], "title": "Neural Networks as Universal Finite-State Machines: A Constructive ReLU Simulation Framework for NFAs", "categories": ["cs.LG", "cs.FL"], "comment": "16 pages, with proofs in Appendix", "summary": "We present a formal and constructive framework establishing the equivalence\nbetween nondeterministic finite automata (NFAs) and standard feedforward ReLU\nneural networks. By encoding automaton states as binary vectors and transitions\nas sparse linear layers, we show that ReLU activations simulate\nnondeterministic branching, subset construction, and $\\epsilon$-closures in a\nmathematically precise manner. Our core theoretical results prove that a\nthree-layer ReLU network of width $\\mathcal{O}(n)$ can exactly recognize any\nregular language accepted by an $n$-state NFA-without recurrence, memory, or\napproximation. Furthermore, we show that gradient descent over\nstructure-preserving networks preserves symbolic semantics and acceptance\nbehavior. Extensive experiments across multiple validation tasks-including\nparallel path tracking, symbolic subset construction, $\\epsilon$-closure\nconvergence, acceptance classification, structural training invariants, and\nfunctional equivalence-achieve perfect or near-perfect empirical alignment with\nground-truth automata. This work provides the first provably complete symbolic\nsimulation of NFAs within standard deep learning architectures, uniting\nautomata theory with neural computation through ReLU dynamics.", "AI": {"tldr": "This paper presents a framework proving the equivalence between nondeterministic finite automata (NFAs) and ReLU neural networks, showing that a three-layer ReLU network can recognize any regular language accepted by an NFA.", "motivation": "To establish a formal connection between automata theory and neural computation by proving the equivalence between nondeterministic finite automata (NFAs) and standard feedforward ReLU neural networks.", "method": "Encoding automaton states as binary vectors and transitions as sparse linear layers, utilizing ReLU activations to simulate nondeterministic branching, subset construction, and epsilon-closures. Theoretical results prove that a three-layer ReLU network of width O(n) can exactly recognize any regular language accepted by an n-state NFA. Gradient descent over structure-preserving networks preserves symbolic semantics and acceptance behavior.", "result": "Extensive experiments across multiple validation tasks achieve perfect or near-perfect empirical alignment with ground-truth automata, demonstrating the practicality and correctness of the theoretical findings.", "conclusion": "The work provides the first provably complete symbolic simulation of NFAs within standard deep learning architectures, uniting automata theory with neural computation through ReLU dynamics."}}
{"id": "2505.23798", "pdf": "https://arxiv.org/pdf/2505.23798", "abs": "https://arxiv.org/abs/2505.23798", "authors": ["Jian Lan", "Yifei Fu", "Udo Schlegel", "Gengyuan Zhang", "Tanveer Hannan", "Haokun Chen", "Thomas Seidl"], "title": "My Answer Is NOT 'Fair': Mitigating Social Bias in Vision-Language Models via Fair and Biased Residuals", "categories": ["cs.CL", "cs.AI", "cs.CV"], "comment": null, "summary": "Social bias is a critical issue in large vision-language models (VLMs), where\nfairness- and ethics-related problems harm certain groups of people in society.\nIt is unknown to what extent VLMs yield social bias in generative responses. In\nthis study, we focus on evaluating and mitigating social bias on both the\nmodel's response and probability distribution. To do so, we first evaluate four\nstate-of-the-art VLMs on PAIRS and SocialCounterfactuals datasets with the\nmultiple-choice selection task. Surprisingly, we find that models suffer from\ngenerating gender-biased or race-biased responses. We also observe that models\nare prone to stating their responses are fair, but indeed having mis-calibrated\nconfidence levels towards particular social groups. While investigating why\nVLMs are unfair in this study, we observe that VLMs' hidden layers exhibit\nsubstantial fluctuations in fairness levels. Meanwhile, residuals in each layer\nshow mixed effects on fairness, with some contributing positively while some\nlead to increased bias. Based on these findings, we propose a post-hoc method\nfor the inference stage to mitigate social bias, which is training-free and\nmodel-agnostic. We achieve this by ablating bias-associated residuals while\namplifying fairness-associated residuals on model hidden layers during\ninference. We demonstrate that our post-hoc method outperforms the competing\ntraining strategies, helping VLMs have fairer responses and more reliable\nconfidence levels.", "AI": {"tldr": "Social bias in large vision-language models (VLMs) is evaluated and mitigated, revealing gender and race biases, mis-calibrated confidence levels, and fluctuating fairness in hidden layers. A post-hoc method is proposed to improve fairness without re-training.", "motivation": "The motivation of this paper is to address the critical issue of social bias in large vision-language models (VLMs), where fairness and ethics-related problems harm certain groups of people in society. The authors aim to evaluate the extent of social bias in generative responses and develop a solution to mitigate it.", "method": "The authors first evaluate four state-of-the-art VLMs on PAIRS and SocialCounterfactuals datasets using a multiple-choice selection task. They observe gender and race biases in model responses, as well as mis-calibrated confidence levels towards specific social groups. Further investigation reveals substantial fluctuations in fairness levels within VLMs' hidden layers and mixed effects of residuals on fairness. Based on these findings, they propose a post-hoc method that ablates bias-associated residuals and amplifies fairness-associated residuals during inference, which is training-free and model-agnostic.", "result": "The proposed post-hoc method outperforms competing training strategies in improving the fairness of VLMs' responses and achieving more reliable confidence levels.", "conclusion": "This study highlights the presence of social bias in VLMs and demonstrates the effectiveness of a post-hoc method in mitigating such bias without re-training the models."}}
{"id": "2505.24138", "pdf": "https://arxiv.org/pdf/2505.24138", "abs": "https://arxiv.org/abs/2505.24138", "authors": ["Yichen Shi", "Ze Zhang", "Hongyang Wang", "Zhuofu Tao", "Zhongyi Li", "Bingyu Chen", "Yaxin Wang", "Zhiping Yu", "Ting-Jung Lin", "Lei He"], "title": "AMSbench: A Comprehensive Benchmark for Evaluating MLLM Capabilities in AMS Circuits", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Analog/Mixed-Signal (AMS) circuits play a critical role in the integrated\ncircuit (IC) industry. However, automating Analog/Mixed-Signal (AMS) circuit\ndesign has remained a longstanding challenge due to its difficulty and\ncomplexity. Recent advances in Multi-modal Large Language Models (MLLMs) offer\npromising potential for supporting AMS circuit analysis and design. However,\ncurrent research typically evaluates MLLMs on isolated tasks within the domain,\nlacking a comprehensive benchmark that systematically assesses model\ncapabilities across diverse AMS-related challenges. To address this gap, we\nintroduce AMSbench, a benchmark suite designed to evaluate MLLM performance\nacross critical tasks including circuit schematic perception, circuit analysis,\nand circuit design. AMSbench comprises approximately 8000 test questions\nspanning multiple difficulty levels and assesses eight prominent models,\nencompassing both open-source and proprietary solutions such as Qwen 2.5-VL and\nGemini 2.5 Pro. Our evaluation highlights significant limitations in current\nMLLMs, particularly in complex multi-modal reasoning and sophisticated circuit\ndesign tasks. These results underscore the necessity of advancing MLLMs'\nunderstanding and effective application of circuit-specific knowledge, thereby\nnarrowing the existing performance gap relative to human expertise and moving\ntoward fully automated AMS circuit design workflows. Our data is released at\nhttps://huggingface.co/datasets/wwhhyy/AMSBench", "AI": {"tldr": "Analog/Mixed-Signal (AMS) circuits are crucial in the IC industry, yet automating their design is challenging. Multi-modal Large Language Models (MLLMs) show potential for AMS circuit analysis and design, but lack a comprehensive benchmark. The authors introduce AMSbench, which evaluates MLLMs on tasks such as circuit schematic perception, analysis, and design, revealing limitations in complex reasoning and design tasks.", "motivation": "Automating AMS circuit design has been difficult due to its complexity, and while MLLMs show promise, there's no systematic benchmark to evaluate their capabilities across diverse AMS-related challenges.", "method": "The authors developed AMSbench, a benchmark suite with around 8000 test questions at multiple difficulty levels, to assess MLLM performance on critical tasks like circuit schematic perception, analysis, and design.", "result": "Evaluation of eight prominent models using AMSbench highlighted significant limitations in current MLLMs, especially in complex multi-modal reasoning and sophisticated circuit design tasks.", "conclusion": "Advancing MLLMs' understanding and application of circuit-specific knowledge is necessary to close the performance gap relative to human expertise and progress towards fully automated AMS circuit design."}}
{"id": "2505.23799", "pdf": "https://arxiv.org/pdf/2505.23799", "abs": "https://arxiv.org/abs/2505.23799", "authors": ["Xiaoyuan Wu", "Weiran Lin", "Omer Akgul", "Lujo Bauer"], "title": "Estimating LLM Consistency: A User Baseline vs Surrogate Metrics", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) are prone to hallucinations and sensitive to\nprompt perturbations, often resulting in inconsistent or unreliable generated\ntext. Different methods have been proposed to mitigate such hallucinations and\nfragility -- one of them being measuring the consistency (the model's\nconfidence in the response, or likelihood of generating a similar response when\nresampled) of LLM responses. In previous work, measuring consistency often\nrelied on the probability of a response appearing within a pool of resampled\nresponses, or internal states or logits of responses. However, it is not yet\nclear how well these approaches approximate how humans perceive the consistency\nof LLM responses. We performed a user study (n=2,976) and found current methods\ntypically do not approximate users' perceptions of LLM consistency very well.\nWe propose a logit-based ensemble method for estimating LLM consistency, and we\nshow that this method matches the performance of the best-performing existing\nmetric in estimating human ratings of LLM consistency. Our results suggest that\nmethods of estimating LLM consistency without human evaluation are sufficiently\nimperfect that we suggest evaluation with human input be more broadly used.", "AI": {"tldr": "Large language models (LLMs) suffer from hallucinations and fragility. Current methods to measure LLM consistency do not align well with human perceptions. A new logit-based ensemble method is proposed, performing as well as the best existing metric but still imperfect, suggesting the need for more human evaluation.", "motivation": "To address the issue of hallucinations and fragility in LLMs, and to better align consistency measurement methods with human perceptions.", "method": "A user study was conducted with 2,976 participants to evaluate current consistency measurement methods. A logit-based ensemble method was then proposed for estimating LLM consistency.", "result": "The proposed method matches the performance of the best existing metric in estimating human ratings of LLM consistency. However, all non-human evaluation methods are found to be imperfect.", "conclusion": "Evaluation of LLM consistency should incorporate more human input due to the imperfections of current automatic estimation methods."}}
{"id": "2505.24145", "pdf": "https://arxiv.org/pdf/2505.24145", "abs": "https://arxiv.org/abs/2505.24145", "authors": ["Wilfried Genuist", "\u00c9ric Savin", "Filippo Gatti", "Didier Clouteau"], "title": "Autoregressive regularized score-based diffusion models for multi-scenarios fluid flow prediction", "categories": ["cs.LG", "physics.flu-dyn", "65N75, 35Q30, 60H15, 76F55, 68T07", "I.2.6; G.1.7; I.6.1; I.6.3"], "comment": "34 pages, 17 figures", "summary": "Building on recent advances in scientific machine learning and generative\nmodeling for computational fluid dynamics, we propose a conditional score-based\ndiffusion model designed for multi-scenarios fluid flow prediction. Our model\nintegrates an energy constraint rooted in the statistical properties of\nturbulent flows, improving prediction quality with minimal training, while\nenabling efficient sampling at low cost. The method features a simple and\ngeneral architecture that requires no problem-specific design, supports\nplug-and-play enhancements, and enables fast and flexible solution generation.\nIt also demonstrates an efficient conditioning mechanism that simplifies\ntraining across different scenarios without demanding a redesign of existing\nmodels. We further explore various stochastic differential equation\nformulations to demonstrate how thoughtful design choices enhance performance.\nWe validate the proposed methodology through extensive experiments on complex\nfluid dynamics datasets encompassing a variety of flow regimes and\nconfigurations. Results demonstrate that our model consistently achieves\nstable, robust, and physically faithful predictions, even under challenging\nturbulent conditions. With properly tuned parameters, it achieves accurate\nresults across multiple scenarios while preserving key physical and statistical\nproperties. We present a comprehensive analysis of stochastic differential\nequation impact and discuss our approach across diverse fluid mechanics tasks.", "AI": {"tldr": "The paper proposes a conditional score-based diffusion model for multi-scenarios fluid flow prediction, which integrates an energy constraint from turbulent flows' statistical properties. It provides stable and physically faithful predictions even under challenging conditions.", "motivation": "To develop a model that can efficiently predict multi-scenario fluid flows with minimal training while maintaining physical fidelity.", "method": "A conditional score-based diffusion model is used, integrating an energy constraint based on the statistical properties of turbulent flows. The method features a general architecture without problem-specific design, supports plug-and-play enhancements, and enables fast solution generation. Stochastic differential equation formulations are explored to enhance performance.", "result": "The model achieves stable, robust, and physically faithful predictions across various flow regimes and configurations, even in challenging turbulent conditions. With properly tuned parameters, it delivers accurate results while preserving key physical and statistical properties.", "conclusion": "The proposed model effectively predicts multi-scenario fluid flows with high accuracy and physical fidelity, validated through extensive experiments."}}
{"id": "2505.23801", "pdf": "https://arxiv.org/pdf/2505.23801", "abs": "https://arxiv.org/abs/2505.23801", "authors": ["Sajid Hussain", "Muhammad Sohail", "Nauman Ali Khan"], "title": "SEMFED: Semantic-Aware Resource-Efficient Federated Learning for Heterogeneous NLP Tasks", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "13 pages", "summary": "Background: Federated Learning (FL) has emerged as a promising paradigm for\ntraining machine learning models while preserving data privacy. However,\napplying FL to Natural Language Processing (NLP) tasks presents unique\nchallenges due to semantic heterogeneity across clients, vocabulary mismatches,\nand varying resource constraints on edge devices. Objectives: This paper\nintroduces SEMFED, a novel semantic-aware resource-efficient federated learning\nframework specifically designed for heterogeneous NLP tasks. Methods: SEMFED\nincorporates three key innovations: (1) a semantic-aware client selection\nmechanism that balances semantic diversity with resource constraints, (2)\nadaptive NLP-specific model architectures tailored to device capabilities while\npreserving semantic information, and (3) a communication-efficient semantic\nfeature compression technique that significantly reduces bandwidth\nrequirements. Results: Experimental results on various NLP classification tasks\ndemonstrate that SEMFED achieves an 80.5% reduction in communication costs\nwhile maintaining model accuracy above 98%, outperforming state-of-the-art FL\napproaches. Conclusion: SEMFED effectively manages heterogeneous client\nenvironments with varying computational resources, network reliability, and\nsemantic data distributions, making it particularly suitable for real-world\nfederated NLP deployments.", "AI": {"tldr": "SEMFED is a new framework for federated learning in NLP tasks which reduces communication costs by 80.5% while keeping model accuracy over 98%.", "motivation": "Federated Learning (FL) shows great potential in training machine learning models with data privacy, but applying it to NLP tasks has challenges like semantic heterogeneity, vocabulary mismatches and resource constraints.", "method": "SEMFED includes three key innovations: semantic-aware client selection mechanism, adaptive NLP-specific model architectures and communication-efficient semantic feature compression technique.", "result": "Experiments show SEMFED reduces communication costs by 80.5% and maintains model accuracy above 98%, outperforming other FL approaches.", "conclusion": "SEMFED can handle heterogeneous client environments well, making it suitable for real-world federated NLP deployments."}}
{"id": "2505.24149", "pdf": "https://arxiv.org/pdf/2505.24149", "abs": "https://arxiv.org/abs/2505.24149", "authors": ["Adam Piaseczny", "Md Kamran Chowdhury Shisher", "Shiqiang Wang", "Christopher G. Brinton"], "title": "RCCDA: Adaptive Model Updates in the Presence of Concept Drift under a Constrained Resource Budget", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Machine learning (ML) algorithms deployed in real-world environments are\noften faced with the challenge of adapting models to concept drift, where the\ntask data distributions are shifting over time. The problem becomes even more\ndifficult when model performance must be maintained under adherence to strict\nresource constraints. Existing solutions often depend on drift-detection\nmethods that produce high computational overhead for resource-constrained\nenvironments, and fail to provide strict guarantees on resource usage or\ntheoretical performance assurances. To address these shortcomings, we propose\nRCCDA: a dynamic model update policy that optimizes ML training dynamics while\nensuring strict compliance to predefined resource constraints, utilizing only\npast loss information and a tunable drift threshold. In developing our policy,\nwe analytically characterize the evolution of model loss under concept drift\nwith arbitrary training update decisions. Integrating these results into a\nLyapunov drift-plus-penalty framework produces a lightweight policy based on a\nmeasurable accumulated loss threshold that provably limits update frequency and\ncost. Experimental results on three domain generalization datasets demonstrate\nthat our policy outperforms baseline methods in inference accuracy while\nadhering to strict resource constraints under several schedules of concept\ndrift, making our solution uniquely suited for real-time ML deployments.", "AI": {"tldr": "\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7ecf\u5e38\u9762\u4e34\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\u7684\u6311\u6218\uff0c\u5373\u4efb\u52a1\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\u3002\u5f53\u6a21\u578b\u6027\u80fd\u5fc5\u987b\u5728\u4e25\u683c\u7684\u8d44\u6e90\u9650\u5236\u4e0b\u4fdd\u6301\u65f6\uff0c\u95ee\u9898\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f9d\u8d56\u4e8e\u4ea7\u751f\u9ad8\u8ba1\u7b97\u5f00\u9500\u7684\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u4e14\u65e0\u6cd5\u63d0\u4f9b\u5bf9\u8d44\u6e90\u4f7f\u7528\u6216\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u7684\u4e25\u683c\u4fdd\u969c\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e9b\u7f3a\u70b9\uff0c\u6211\u4eec\u63d0\u51fa\u4e86RCCDA\uff1a\u4e00\u79cd\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5728\u786e\u4fdd\u4e25\u683c\u9075\u5b88\u9884\u5b9a\u4e49\u8d44\u6e90\u9650\u5236\u7684\u540c\u65f6\u4f18\u5316ML\u8bad\u7ec3\u52a8\u529b\u5b66\uff0c\u4ec5\u5229\u7528\u8fc7\u53bb\u7684\u635f\u5931\u4fe1\u606f\u548c\u53ef\u8c03\u7684\u6f02\u79fb\u9608\u503c\u3002\u901a\u8fc7\u5c06\u8fd9\u4e9b\u7ed3\u679c\u96c6\u6210\u5230\u674e\u96c5\u666e\u8bfa\u592b\u6f02\u79fb\u52a0\u60e9\u7f5a\u6846\u67b6\u4e2d\uff0c\u53ef\u4ee5\u751f\u6210\u4e00\u4e2a\u57fa\u4e8e\u53ef\u6d4b\u91cf\u7d2f\u79ef\u635f\u5931\u9608\u503c\u7684\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u53ef\u4ee5\u8bc1\u660e\u9650\u5236\u66f4\u65b0\u9891\u7387\u548c\u6210\u672c\u3002\u5728\u4e09\u4e2a\u9886\u57df\u6cdb\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u7b56\u7565\u5728\u63a8\u7406\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u51e0\u79cd\u6982\u5ff5\u6f02\u79fb\u8ba1\u5212\u4e0b\u4e25\u683c\u9075\u5b88\u8d44\u6e90\u9650\u5236\uff0c\u4f7f\u6211\u4eec\u7684\u89e3\u51b3\u65b9\u6848\u7279\u522b\u9002\u5408\u5b9e\u65f6ML\u90e8\u7f72\u3002", "motivation": "\u5728\u5b9e\u9645\u73af\u5883\u4e2d\u90e8\u7f72\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u7ecf\u5e38\u9762\u4e34\u9002\u5e94\u6982\u5ff5\u6f02\u79fb\u7684\u6311\u6218\uff0c\u5373\u4efb\u52a1\u6570\u636e\u5206\u5e03\u968f\u65f6\u95f4\u53d8\u5316\u3002\u5f53\u6a21\u578b\u6027\u80fd\u5fc5\u987b\u5728\u4e25\u683c\u7684\u8d44\u6e90\u9650\u5236\u4e0b\u4fdd\u6301\u65f6\uff0c\u95ee\u9898\u53d8\u5f97\u66f4\u52a0\u56f0\u96be\u3002\u73b0\u6709\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f9d\u8d56\u4e8e\u4ea7\u751f\u9ad8\u8ba1\u7b97\u5f00\u9500\u7684\u6f02\u79fb\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5e76\u4e14\u65e0\u6cd5\u63d0\u4f9b\u5bf9\u8d44\u6e90\u4f7f\u7528\u6216\u7406\u8bba\u6027\u80fd\u4fdd\u8bc1\u7684\u4e25\u683c\u4fdd\u969c\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86RCCDA\uff1a\u4e00\u79cd\u52a8\u6001\u6a21\u578b\u66f4\u65b0\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u5728\u786e\u4fdd\u4e25\u683c\u9075\u5b88\u9884\u5b9a\u4e49\u8d44\u6e90\u9650\u5236\u7684\u540c\u65f6\u4f18\u5316ML\u8bad\u7ec3\u52a8\u529b\u5b66\uff0c\u4ec5\u5229\u7528\u8fc7\u53bb\u7684\u635f\u5931\u4fe1\u606f\u548c\u53ef\u8c03\u7684\u6f02\u79fb\u9608\u503c\u3002\u901a\u8fc7\u5c06\u8fd9\u4e9b\u7ed3\u679c\u96c6\u6210\u5230\u674e\u96c5\u666e\u8bfa\u592b\u6f02\u79fb\u52a0\u60e9\u7f5a\u6846\u67b6\u4e2d\uff0c\u53ef\u4ee5\u751f\u6210\u4e00\u4e2a\u57fa\u4e8e\u53ef\u6d4b\u91cf\u7d2f\u79ef\u635f\u5931\u9608\u503c\u7684\u8f7b\u91cf\u7ea7\u7b56\u7565\uff0c\u8be5\u7b56\u7565\u53ef\u4ee5\u8bc1\u660e\u9650\u5236\u66f4\u65b0\u9891\u7387\u548c\u6210\u672c\u3002", "result": "\u5728\u4e09\u4e2a\u9886\u57df\u6cdb\u5316\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6211\u4eec\u7684\u7b56\u7565\u5728\u63a8\u7406\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u540c\u65f6\u5728\u51e0\u79cd\u6982\u5ff5\u6f02\u79fb\u8ba1\u5212\u4e0b\u4e25\u683c\u9075\u5b88\u8d44\u6e90\u9650\u5236\u3002", "conclusion": "\u63d0\u51fa\u7684RCCDA\u7b56\u7565\u5728\u786e\u4fdd\u4e25\u683c\u9075\u5b88\u8d44\u6e90\u9650\u5236\u7684\u540c\u65f6\u4f18\u5316\u4e86ML\u8bad\u7ec3\u52a8\u529b\u5b66\uff0c\u4ec5\u5229\u7528\u8fc7\u53bb\u7684\u635f\u5931\u4fe1\u606f\u548c\u53ef\u8c03\u7684\u6f02\u79fb\u9608\u503c\u3002\u5b83\u5728\u63a8\u7406\u51c6\u786e\u6027\u65b9\u9762\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6ML\u90e8\u7f72\u3002"}}
{"id": "2505.23802", "pdf": "https://arxiv.org/pdf/2505.23802", "abs": "https://arxiv.org/abs/2505.23802", "authors": ["Suhana Bedi", "Hejie Cui", "Miguel Fuentes", "Alyssa Unell", "Michael Wornow", "Juan M. Banda", "Nikesh Kotecha", "Timothy Keyes", "Yifan Mai", "Mert Oez", "Hao Qiu", "Shrey Jain", "Leonardo Schettini", "Mehr Kashyap", "Jason Alan Fries", "Akshay Swaminathan", "Philip Chung", "Fateme Nateghi", "Asad Aali", "Ashwin Nayak", "Shivam Vedak", "Sneha S. Jain", "Birju Patel", "Oluseyi Fayanju", "Shreya Shah", "Ethan Goh", "Dong-han Yao", "Brian Soetikno", "Eduardo Reis", "Sergios Gatidis", "Vasu Divi", "Robson Capasso", "Rachna Saralkar", "Chia-Chun Chiang", "Jenelle Jindal", "Tho Pham", "Faraz Ghoddusi", "Steven Lin", "Albert S. Chiou", "Christy Hong", "Mohana Roy", "Michael F. Gensheimer", "Hinesh Patel", "Kevin Schulman", "Dev Dash", "Danton Char", "Lance Downing", "Francois Grolleau", "Kameron Black", "Bethel Mieso", "Aydin Zahedivash", "Wen-wai Yim", "Harshita Sharma", "Tony Lee", "Hannah Kirsch", "Jennifer Lee", "Nerissa Ambers", "Carlene Lugtu", "Aditya Sharma", "Bilal Mawji", "Alex Alekseyev", "Vicky Zhou", "Vikas Kakkar", "Jarrod Helzer", "Anurang Revri", "Yair Bannett", "Roxana Daneshjou", "Jonathan Chen", "Emily Alsentzer", "Keith Morse", "Nirmal Ravi", "Nima Aghaeepour", "Vanessa Kennedy", "Akshay Chaudhari", "Thomas Wang", "Sanmi Koyejo", "Matthew P. Lungren", "Eric Horvitz", "Percy Liang", "Mike Pfeffer", "Nigam H. Shah"], "title": "MedHELM: Holistic Evaluation of Large Language Models for Medical Tasks", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "While large language models (LLMs) achieve near-perfect scores on medical\nlicensing exams, these evaluations inadequately reflect the complexity and\ndiversity of real-world clinical practice. We introduce MedHELM, an extensible\nevaluation framework for assessing LLM performance for medical tasks with three\nkey contributions. First, a clinician-validated taxonomy spanning 5 categories,\n22 subcategories, and 121 tasks developed with 29 clinicians. Second, a\ncomprehensive benchmark suite comprising 35 benchmarks (17 existing, 18 newly\nformulated) providing complete coverage of all categories and subcategories in\nthe taxonomy. Third, a systematic comparison of LLMs with improved evaluation\nmethods (using an LLM-jury) and a cost-performance analysis. Evaluation of 9\nfrontier LLMs, using the 35 benchmarks, revealed significant performance\nvariation. Advanced reasoning models (DeepSeek R1: 66% win-rate; o3-mini: 64%\nwin-rate) demonstrated superior performance, though Claude 3.5 Sonnet achieved\ncomparable results at 40% lower estimated computational cost. On a normalized\naccuracy scale (0-1), most models performed strongly in Clinical Note\nGeneration (0.73-0.85) and Patient Communication & Education (0.78-0.83),\nmoderately in Medical Research Assistance (0.65-0.75), and generally lower in\nClinical Decision Support (0.56-0.72) and Administration & Workflow\n(0.53-0.63). Our LLM-jury evaluation method achieved good agreement with\nclinician ratings (ICC = 0.47), surpassing both average clinician-clinician\nagreement (ICC = 0.43) and automated baselines including ROUGE-L (0.36) and\nBERTScore-F1 (0.44). Claude 3.5 Sonnet achieved comparable performance to top\nmodels at lower estimated cost. These findings highlight the importance of\nreal-world, task-specific evaluation for medical use of LLMs and provides an\nopen source framework to enable this.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u5b66\u6267\u7167\u8003\u8bd5\u4e2d\u63a5\u8fd1\u6ee1\u5206\uff0c\u4f46\u8fd9\u4e9b\u8bc4\u4f30\u672a\u80fd\u5145\u5206\u53cd\u6620\u73b0\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\u3002\u672c\u6587\u4ecb\u7ecd\u4e86MedHELM\uff0c\u4e00\u4e2a\u53ef\u6269\u5c55\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u7528\u4e8e\u8bc4\u4f30LLM\u5728\u533b\u5b66\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\uff0c\u5177\u6709\u4e09\u4e2a\u5173\u952e\u8d21\u732e\uff1a1. \u7ecf\u8fc7\u4e34\u5e8a\u533b\u751f\u9a8c\u8bc1\u7684\u5206\u7c7b\u6cd5\uff1b2. \u5168\u9762\u7684\u57fa\u51c6\u6d4b\u8bd5\u5957\u4ef6\uff1b3. \u7cfb\u7edf\u6bd4\u8f83\u548c\u6210\u672c\u6027\u80fd\u5206\u6790\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cClaude 3.5 Sonnet\u5728\u8f83\u4f4e\u8ba1\u7b97\u6210\u672c\u4e0b\u5b9e\u73b0\u4e86\u76f8\u5f53\u7684\u7ed3\u679c\u3002\u6b64\u5916\uff0cLLM-jury\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u4e34\u5e8a\u533b\u751f\u8bc4\u5206\u6709\u826f\u597d\u4e00\u81f4\u6027\u3002", "motivation": "\u5f53\u524d\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u533b\u5b66\u9886\u57df\u7684\u8bc4\u4f30\u672a\u80fd\u5145\u5206\u53cd\u6620\u73b0\u5b9e\u4e34\u5e8a\u5b9e\u8df5\u7684\u590d\u6742\u6027\u548c\u591a\u6837\u6027\uff0c\u9700\u8981\u66f4\u5168\u9762\u3001\u7ec6\u81f4\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u8861\u91cfLLM\u5728\u533b\u7597\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u540d\u4e3aMedHELM\u7684\u53ef\u6269\u5c55\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b\u7ecf\u8fc7\u4e34\u5e8a\u533b\u751f\u9a8c\u8bc1\u7684\u5206\u7c7b\u6cd5\uff08\u6db5\u76d65\u4e2a\u7c7b\u522b\u300122\u4e2a\u5b50\u7c7b\u522b\u548c121\u9879\u4efb\u52a1\uff09\uff0c\u4e00\u4e2a\u753135\u4e2a\u57fa\u51c6\u7ec4\u6210\u7684\u7efc\u5408\u57fa\u51c6\u5957\u4ef6\uff08\u5305\u62ec17\u4e2a\u73b0\u6709\u57fa\u51c6\u548c18\u4e2a\u65b0\u5236\u5b9a\u57fa\u51c6\uff09\uff0c\u4ee5\u53ca\u4f7f\u7528LLM-jury\u8fdb\u884c\u7cfb\u7edf\u6bd4\u8f83\u548c\u6210\u672c\u6027\u80fd\u5206\u6790\u7684\u65b9\u6cd5\u3002", "result": "\u8bc4\u4f30\u4e869\u4e2a\u524d\u6cbfLLM\uff0c\u53d1\u73b0\u5728\u4e0d\u540c\u533b\u5b66\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\u5dee\u5f02\u663e\u8457\u3002\u9ad8\u7ea7\u63a8\u7406\u6a21\u578b\u8868\u73b0\u6700\u4f73\uff0cClaude 3.5 Sonnet\u4ee5\u8f83\u4f4e\u7684\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u76f8\u5f53\u7684\u7ed3\u679c\u3002LLM-jury\u8bc4\u4f30\u65b9\u6cd5\u4e0e\u4e34\u5e8a\u533b\u751f\u8bc4\u5206\u7684\u4e00\u81f4\u6027\u826f\u597d\uff0c\u8d85\u8fc7\u4e86\u81ea\u52a8\u5316\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u672c\u7814\u7a76\u5f3a\u8c03\u4e86\u9488\u5bf9\u533b\u5b66\u9886\u57df\u5b9e\u9645\u4efb\u52a1\u8fdb\u884c\u7279\u5b9a\u8bc4\u4f30\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5f00\u6e90\u6846\u67b6\u4ee5\u652f\u6301\u8fd9\u4e00\u76ee\u6807\u3002"}}
{"id": "2505.24155", "pdf": "https://arxiv.org/pdf/2505.24155", "abs": "https://arxiv.org/abs/2505.24155", "authors": ["Ehtesamul Azim", "Dongjie Wang", "Tae Hyun Hwang", "Yanjie Fu", "Wei Zhang"], "title": "Biological Pathway Guided Gene Selection Through Collaborative Reinforcement Learning", "categories": ["cs.LG"], "comment": "31st SIGKDD Conference on Knowledge Discovery and Data Mining (KDD\n  2025)", "summary": "Gene selection in high-dimensional genomic data is essential for\nunderstanding disease mechanisms and improving therapeutic outcomes.\nTraditional feature selection methods effectively identify predictive genes but\noften ignore complex biological pathways and regulatory networks, leading to\nunstable and biologically irrelevant signatures. Prior approaches, such as\nLasso-based methods and statistical filtering, either focus solely on\nindividual gene-outcome associations or fail to capture pathway-level\ninteractions, presenting a key challenge: how to integrate biological pathway\nknowledge while maintaining statistical rigor in gene selection? To address\nthis gap, we propose a novel two-stage framework that integrates statistical\nselection with biological pathway knowledge using multi-agent reinforcement\nlearning (MARL). First, we introduce a pathway-guided pre-filtering strategy\nthat leverages multiple statistical methods alongside KEGG pathway information\nfor initial dimensionality reduction. Next, for refined selection, we model\ngenes as collaborative agents in a MARL framework, where each agent optimizes\nboth predictive power and biological relevance. Our framework incorporates\npathway knowledge through Graph Neural Network-based state representations, a\nreward mechanism combining prediction performance with gene centrality and\npathway coverage, and collaborative learning strategies using shared memory and\na centralized critic component. Extensive experiments on multiple gene\nexpression datasets demonstrate that our approach significantly improves both\nprediction accuracy and biological interpretability compared to traditional\nmethods.", "AI": {"tldr": "This paper proposes a two-stage framework combining statistical selection with biological pathway knowledge via multi-agent reinforcement learning (MARL) for gene selection in genomic data. It improves prediction accuracy and biological interpretability compared to traditional methods.", "motivation": "Traditional feature selection methods often ignore complex biological pathways and regulatory networks, leading to unstable and biologically irrelevant signatures. There is a need to integrate biological pathway knowledge while maintaining statistical rigor in gene selection.", "method": "The method involves a two-stage framework. The first stage is a pathway-guided pre-filtering strategy using multiple statistical methods alongside KEGG pathway information for initial dimensionality reduction. The second stage models genes as collaborative agents in a MARL framework, incorporating pathway knowledge through Graph Neural Network-based state representations, a reward mechanism combining prediction performance with gene centrality and pathway coverage, and collaborative learning strategies.", "result": "Extensive experiments on multiple gene expression datasets demonstrate that the proposed approach significantly improves both prediction accuracy and biological interpretability compared to traditional methods.", "conclusion": "The proposed two-stage framework effectively integrates statistical selection with biological pathway knowledge, offering a more stable and biologically relevant approach to gene selection in high-dimensional genomic data."}}
{"id": "2505.24157", "pdf": "https://arxiv.org/pdf/2505.24157", "abs": "https://arxiv.org/abs/2505.24157", "authors": ["Seungjoon Lee", "Suhwan Kim", "Minhyeon Oh", "Youngsik Yoon", "Jungseul Ok"], "title": "Don't Just Follow MLLM Plans: Robust and Efficient Planning for Open-world Agents", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing autonomous agents capable of mastering complex, multi-step tasks\nin unpredictable, interactive environments presents a significant challenge.\nWhile Large Language Models (LLMs) offer promise for planning, existing\napproaches often rely on problematic internal knowledge or make unrealistic\nenvironmental assumptions. Although recent work explores learning planning\nknowledge, they still retain limitations due to partial reliance on external\nknowledge or impractical setups. Indeed, prior research has largely overlooked\ndeveloping agents capable of acquiring planning knowledge from scratch,\ndirectly in realistic settings. While realizing this capability is necessary,\nit presents significant challenges, primarily achieving robustness given the\nsubstantial risk of incorporating LLMs' inaccurate knowledge. Moreover,\nefficiency is crucial for practicality as learning can demand prohibitive\nexploration. In response, we introduce Robust and Efficient Planning for\nOpen-world Agents (REPOA), a novel framework designed to tackle these issues.\nREPOA features three key components: adaptive dependency learning and\nfine-grained failure-aware operation memory to enhance robustness to knowledge\ninaccuracies, and difficulty-based exploration to improve learning efficiency.\nOur evaluation in two established open-world testbeds demonstrates REPOA's\nrobust and efficient planning, showcasing its capability to successfully obtain\nchallenging late-game items that were beyond the reach of prior approaches.", "AI": {"tldr": "The paper introduces Robust and Efficient Planning for Open-world Agents (REPOA), a novel framework with three key components to enhance robustness and efficiency in planning for autonomous agents capable of mastering complex tasks in unpredictable environments. Evaluated in two open-world testbeds, REPOA successfully obtains challenging late-game items.", "motivation": "Developing autonomous agents that can master complex, multi-step tasks in unpredictable, interactive environments is a significant challenge. Existing approaches have limitations due to reliance on problematic internal knowledge or unrealistic environmental assumptions. There is a need for agents capable of acquiring planning knowledge from scratch in realistic settings while addressing the challenges of robustness and efficiency.", "method": "REPOA features three key components: adaptive dependency learning, fine-grained failure-aware operation memory to enhance robustness to knowledge inaccuracies, and difficulty-based exploration to improve learning efficiency.", "result": "Evaluation in two established open-world testbeds demonstrates REPOA's robust and efficient planning, as it successfully obtains challenging late-game items that were beyond the reach of prior approaches.", "conclusion": "REPOA addresses the challenges of developing autonomous agents capable of mastering complex tasks in unpredictable environments by enhancing robustness and efficiency in planning."}}
{"id": "2505.23804", "pdf": "https://arxiv.org/pdf/2505.23804", "abs": "https://arxiv.org/abs/2505.23804", "authors": ["Terrance Liu", "Shuyi Wang", "Daniel Preotiuc-Pietro", "Yash Chandarana", "Chirag Gupta"], "title": "Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "While large language models (LLMs) achieve strong performance on text-to-SQL\nparsing, they sometimes exhibit unexpected failures in which they are\nconfidently incorrect. Building trustworthy text-to-SQL systems thus requires\neliciting reliable uncertainty measures from the LLM. In this paper, we study\nthe problem of providing a calibrated confidence score that conveys the\nlikelihood of an output query being correct. Our work is the first to establish\na benchmark for post-hoc calibration of LLM-based text-to-SQL parsing. In\nparticular, we show that Platt scaling, a canonical method for calibration,\nprovides substantial improvements over directly using raw model output\nprobabilities as confidence scores. Furthermore, we propose a method for\ntext-to-SQL calibration that leverages the structured nature of SQL queries to\nprovide more granular signals of correctness, named \"sub-clause frequency\"\n(SCF) scores. Using multivariate Platt scaling (MPS), our extension of the\ncanonical Platt scaling technique, we combine individual SCF scores into an\noverall accurate and calibrated score. Empirical evaluation on two popular\ntext-to-SQL datasets shows that our approach of combining MPS and SCF yields\nfurther improvements in calibration and the related task of error detection\nover traditional Platt scaling.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u672c\u5230SQL\u89e3\u6790\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u6709\u65f6\u4f1a\u8868\u73b0\u51fa\u81ea\u4fe1\u7684\u9519\u8bef\u3002\u672c\u6587\u7814\u7a76\u4e86\u63d0\u4f9b\u6821\u51c6\u7f6e\u4fe1\u5206\u6570\u7684\u95ee\u9898\uff0c\u8be5\u5206\u6570\u4f20\u8fbe\u8f93\u51fa\u67e5\u8be2\u6b63\u786e\u7684\u53ef\u80fd\u6027\u3002\u9996\u6b21\u5efa\u7acb\u4e86\u57fa\u4e8eLLM\u7684\u6587\u672c\u5230SQL\u89e3\u6790\u7684\u540e\u9a8c\u6821\u51c6\u57fa\u51c6\u3002\u7ed3\u679c\u8868\u660e\uff0cPlatt\u7f29\u653e\u6cd5\u6bd4\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u6a21\u578b\u8f93\u51fa\u6982\u7387\u4f5c\u4e3a\u7f6e\u4fe1\u5ea6\u5f97\u5206\u63d0\u4f9b\u4e86\u663e\u8457\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u6211\u4eec\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528SQL\u67e5\u8be2\u7ed3\u6784\u6027\u8d28\u7684\u65b9\u6cd5\uff0c\u4ee5\u63d0\u4f9b\u66f4\u7ec6\u81f4\u7684\u6b63\u786e\u6027\u4fe1\u53f7\uff0c\u79f0\u4e3a\u201c\u5b50\u53e5\u9891\u7387\u201d(SCF)\u5f97\u5206\u3002\u901a\u8fc7\u591a\u53d8\u91cfPlatt\u7f29\u653e(MPS)\uff0c\u6211\u4eec\u5c06\u5404\u4e2aSCF\u5f97\u5206\u5408\u5e76\u4e3a\u4e00\u4e2a\u603b\u4f53\u51c6\u786e\u4e14\u6821\u51c6\u7684\u5f97\u5206\u3002\u5728\u4e24\u4e2a\u6d41\u884c\u7684\u6587\u672c\u5230SQL\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u8bc4\u4f30\u8868\u660e\uff0c\u7ed3\u5408MPS\u548cSCF\u7684\u65b9\u6cd5\u5728\u6821\u51c6\u548c\u76f8\u5173\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u4f18\u4e8e\u4f20\u7edf\u7684Platt\u7f29\u653e\u3002", "motivation": "\u5c3d\u7ba1\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6587\u672c\u5230SQL\u89e3\u6790\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5b83\u4eec\u6709\u65f6\u4f1a\u51fa\u73b0\u81ea\u4fe1\u7684\u9519\u8bef\u3002\u56e0\u6b64\uff0c\u5efa\u7acb\u53ef\u4fe1\u8d56\u7684\u6587\u672c\u5230SQL\u7cfb\u7edf\u9700\u8981\u4eceLLM\u4e2d\u5f15\u51fa\u53ef\u9760\u7684\u4e0d\u786e\u5b9a\u6027\u5ea6\u91cf\u3002", "method": "\u672c\u6587\u5f15\u5165\u4e86Platt\u7f29\u653e\u6cd5\u6765\u6821\u51c6\u7f6e\u4fe1\u5ea6\u5f97\u5206\uff0c\u5e76\u63d0\u51fa\u4e86\u5229\u7528SQL\u67e5\u8be2\u7ed3\u6784\u7279\u6027\u7684\u201c\u5b50\u53e5\u9891\u7387\u201d(SCF)\u5f97\u5206\u65b9\u6cd5\u3002\u8fd8\u6269\u5c55\u4e86\u7ecf\u5178\u7684Platt\u7f29\u653e\u6280\u672f\uff0c\u5373\u591a\u53d8\u91cfPlatt\u7f29\u653e(MPS)\uff0c\u5c06\u5404\u4e2aSCF\u5f97\u5206\u5408\u5e76\u6210\u4e00\u4e2a\u6574\u4f53\u51c6\u786e\u4e14\u6821\u51c6\u7684\u5f97\u5206\u3002", "result": "\u5b9e\u8bc1\u8bc4\u4f30\u663e\u793a\uff0c\u7ed3\u5408\u591a\u53d8\u91cfPlatt\u7f29\u653e(MPS)\u548c\u5b50\u53e5\u9891\u7387(SCF)\u5f97\u5206\u7684\u65b9\u6cd5\u5728\u6821\u51c6\u548c\u9519\u8bef\u68c0\u6d4b\u4efb\u52a1\u4e0a\u53d6\u5f97\u4e86\u8fdb\u4e00\u6b65\u7684\u6539\u8fdb\uff0c\u4f18\u4e8e\u4f20\u7edf\u7684Platt\u7f29\u653e\u3002", "conclusion": "\u672c\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u57fa\u4e8eLLM\u7684\u6587\u672c\u5230SQL\u89e3\u6790\u7684\u540e\u9a8c\u6821\u51c6\u57fa\u51c6\uff0c\u5c55\u793a\u4e86Platt\u7f29\u653e\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u7ed3\u5408MPS\u548cSCF\u5f97\u5206\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6821\u51c6\u548c\u9519\u8bef\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2505.24178", "pdf": "https://arxiv.org/pdf/2505.24178", "abs": "https://arxiv.org/abs/2505.24178", "authors": ["Katherine Tieu", "Dongqi Fu", "Jun Wu", "Jingrui He"], "title": "Invariant Link Selector for Spatial-Temporal Out-of-Distribution Problem", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted by AISTATS 2025. 22 pages, 2 figures, 6 tables", "summary": "In the era of foundation models, Out-of- Distribution (OOD) problems, i.e.,\nthe data discrepancy between the training environments and testing\nenvironments, hinder AI generalization. Further, relational data like graphs\ndisobeying the Independent and Identically Distributed (IID) condition makes\nthe problem more challenging, especially much harder when it is associated with\ntime. Motivated by this, to realize the robust invariant learning over temporal\ngraphs, we want to investigate what components in temporal graphs are most\ninvariant and representative with respect to labels. With the Information\nBottleneck (IB) method, we propose an error-bounded Invariant Link Selector\nthat can distinguish invariant components and variant components during the\ntraining process to make the deep learning model generalizable for different\ntesting scenarios. Besides deriving a series of rigorous generalizable\noptimization functions, we also equip the training with task-specific loss\nfunctions, e.g., temporal link prediction, to make pretrained models solve\nreal-world application tasks like citation recommendation and merchandise\nrecommendation, as demonstrated in our experiments with state-of-the-art (SOTA)\nmethods. Our code is available at https://github.com/kthrn22/OOD-Linker.", "AI": {"tldr": "In the era of foundation models, Out-of-Distribution (OOD) problems hinder AI generalization. We investigate invariant components in temporal graphs for robust learning and propose an error-bounded Invariant Link Selector with Information Bottleneck method to distinguish invariant and variant components during training.", "motivation": "The motivation arises from the challenge of OOD problems which prevent AI generalization, especially in relational data like graphs that do not follow the IID condition and are further complicated by time-related factors.", "method": "Using the Information Bottleneck (IB) method, we propose an error-bounded Invariant Link Selector that can differentiate between invariant and variant components within temporal graphs during the training process. This is supplemented with rigorous optimization functions and task-specific loss functions such as temporal link prediction.", "result": "The proposed method enables deep learning models to be more generalizable across different testing scenarios, and it demonstrates effectiveness in real-world applications like citation recommendation and merchandise recommendation through experiments with state-of-the-art methods.", "conclusion": "An error-bounded Invariant Link Selector using the IB method has been developed to enhance model generalizability over temporal graphs, addressing OOD challenges effectively."}}
{"id": "2505.24179", "pdf": "https://arxiv.org/pdf/2505.24179", "abs": "https://arxiv.org/abs/2505.24179", "authors": ["Xiaodong Ji", "Hailin Zhang", "Fangcheng Fu", "Bin Cui"], "title": "SALE : Low-bit Estimation for Efficient Sparse Attention in Long-context LLM Prefilling", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Many advanced Large Language Model (LLM) applications require long-context\nprocessing, but the self-attention module becomes a bottleneck during the\nprefilling stage of inference due to its quadratic time complexity with respect\nto sequence length. Existing sparse attention methods accelerate attention\ncomputation by skipping less significant regions of the attention map. However,\nthese approaches typically perform coarse-grained inspection of the attention\nmap, rendering considerable loss in model accuracy. In this paper, we propose\nSALE, a fine-grained sparse attention method that accelerates the long-context\nprefilling stage of LLM with negligible loss in model accuracy. SALE achieves\nfast and accurate fine-grained attention weight estimation through 4-bit\nquantized query-key products, followed by block-sparse attention to accelerate\nprefilling computations. For importance evaluation for query-key pairs, we\nadopt our Relative Attention Score metric, which offers significantly higher\nefficiency within our framework. We implement a custom CUDA kernel optimized\nfor our approach for hardware efficiency, reducing the additional overhead to\napproximately 11% of the full attention latency. Notably, SALE requires no\nparameter training and can be seamlessly integrated into existing systems with\ntrivial code modifications. Experiments on long-context benchmarks demonstrate\nthat our method outperforms existing approaches in accuracy-efficiency\ntrade-offs, achieving at least 3.36x speedups on Llama-3.1-8B for sequences\nlonger than 64K while maintaining model quality.", "AI": {"tldr": "SALE\uff0c\u4e00\u79cd\u7ec6\u7c92\u5ea6\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc74\u4f4d\u91cf\u5316\u67e5\u8be2\u952e\u4ea7\u54c1\u548c\u5757\u7a00\u758f\u6ce8\u610f\u529b\u52a0\u901f\u957f\u4e0a\u4e0b\u6587\u9884\u586b\u5145\u9636\u6bb5\uff0c\u663e\u8457\u63d0\u9ad8\u5904\u7406\u6548\u7387\u5e76\u4fdd\u6301\u6a21\u578b\u51c6\u786e\u6027\uff0c\u65e0\u9700\u53c2\u6570\u8bad\u7ec3\u4e14\u6613\u4e8e\u96c6\u6210\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5e94\u7528\u4e2d\uff0c\u81ea\u6ce8\u610f\u529b\u6a21\u5757\u5728\u63a8\u7406\u7684\u9884\u586b\u5145\u9636\u6bb5\u7531\u4e8e\u5176\u4e0e\u5e8f\u5217\u957f\u5ea6\u76f8\u5173\u7684\u4e8c\u6b21\u65f6\u95f4\u590d\u6742\u5ea6\u6210\u4e3a\u74f6\u9888\uff0c\u800c\u73b0\u6709\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\u867d\u7136\u52a0\u901f\u4e86\u8ba1\u7b97\uff0c\u4f46\u901a\u5e38\u4f1a\u5bfc\u81f4\u6a21\u578b\u51c6\u786e\u6027\u7684\u5927\u5e45\u635f\u5931\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSALE\u7684\u7ec6\u7c92\u5ea6\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u901a\u8fc74\u4f4d\u91cf\u5316\u67e5\u8be2\u952e\u4ea7\u54c1\u8fdb\u884c\u5feb\u901f\u51c6\u786e\u7684\u7ec6\u7c92\u5ea6\u6ce8\u610f\u529b\u6743\u91cd\u4f30\u8ba1\uff0c\u7136\u540e\u91c7\u7528\u5757\u7a00\u758f\u6ce8\u610f\u529b\u52a0\u901f\u9884\u586b\u5145\u8ba1\u7b97\uff0c\u5e76\u5f15\u5165\u76f8\u5bf9\u6ce8\u610f\u529b\u8bc4\u5206\u6307\u6807\u6765\u8bc4\u4f30\u67e5\u8be2\u952e\u5bf9\u7684\u91cd\u8981\u6027\u3002\u4e3a\u4e86\u786c\u4ef6\u6548\u7387\uff0c\u8fd8\u5b9e\u73b0\u4e86\u5b9a\u5236\u7684CUDA\u5185\u6838\uff0c\u5c06\u989d\u5916\u5f00\u9500\u51cf\u5c11\u5230\u5b8c\u6574\u6ce8\u610f\u529b\u5ef6\u8fdf\u7684\u5927\u7ea611%\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u957f\u4e0a\u4e0b\u6587\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u7684\u6743\u8861\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5bf9\u4e8e\u8d85\u8fc764K\u7684\u5e8f\u5217\uff0cLlama-3.1-8B\u6a21\u578b\u81f3\u5c11\u5b9e\u73b03.36\u500d\u7684\u901f\u5ea6\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u8d28\u91cf\u3002", "conclusion": "SALE\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u7a00\u758f\u6ce8\u610f\u529b\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u51e0\u4e4e\u4e0d\u5f71\u54cd\u6a21\u578b\u51c6\u786e\u6027\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u52a0\u901f\u957f\u4e0a\u4e0b\u6587\u9884\u586b\u5145\u9636\u6bb5\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u73b0\u6709\u7cfb\u7edf\u4e2d\uff0c\u65e0\u9700\u53c2\u6570\u8bad\u7ec3\u3002"}}
{"id": "2505.23806", "pdf": "https://arxiv.org/pdf/2505.23806", "abs": "https://arxiv.org/abs/2505.23806", "authors": ["Sihyeon Lee", "Hyunjoo Song", "Jong-chan Lee", "Yoon Jin Lee", "Boram Lee", "Hee-Eon Lim", "Dongyeong Kim", "Jinwook Seo", "Bohyoung Kim"], "title": "MedOrchestra: A Hybrid Cloud-Local LLM Approach for Clinical Data Interpretation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Deploying large language models (LLMs) in clinical settings faces critical\ntrade-offs: cloud LLMs, with their extensive parameters and superior\nperformance, pose risks to sensitive clinical data privacy, while local LLMs\npreserve privacy but often fail at complex clinical interpretation tasks. We\npropose MedOrchestra, a hybrid framework where a cloud LLM decomposes complex\nclinical tasks into manageable subtasks and prompt generation, while a local\nLLM executes these subtasks in a privacy-preserving manner. Without accessing\nclinical data, the cloud LLM generates and validates subtask prompts using\nclinical guidelines and synthetic test cases. The local LLM executes subtasks\nlocally and synthesizes outputs generated by the cloud LLM. We evaluate\nMedOrchestra on pancreatic cancer staging using 100 radiology reports under\nNCCN guidelines. On free-text reports, MedOrchestra achieves 70.21% accuracy,\noutperforming local model baselines (without guideline: 48.94%, with guideline:\n56.59%) and board-certified clinicians (gastroenterologists: 59.57%, surgeons:\n65.96%, radiologists: 55.32%). On structured reports, MedOrchestra reaches\n85.42% accuracy, showing clear superiority across all settings.", "AI": {"tldr": "MedOrchestra is a hybrid framework combining cloud and local LLMs for clinical tasks, preserving privacy while enhancing performance. Evaluated on pancreatic cancer staging, it outperforms local models and clinicians.", "motivation": "To address the trade-offs in deploying large language models in clinical settings, balancing privacy concerns with the need for accurate and complex clinical interpretation.", "method": "A cloud LLM decomposes complex clinical tasks into subtasks and generates prompts based on clinical guidelines and synthetic test cases without accessing clinical data. A local LLM executes these subtasks and synthesizes outputs locally to preserve privacy.", "result": "On free-text radiology reports, MedOrchestra achieves 70.21% accuracy, surpassing local models and board-certified clinicians. On structured reports, it reaches 85.42% accuracy, demonstrating superiority across all settings.", "conclusion": "MedOrchestra effectively leverages the strengths of both cloud and local LLMs, providing a privacy-preserving solution that enhances accuracy in clinical interpretation tasks."}}
{"id": "2505.24183", "pdf": "https://arxiv.org/pdf/2505.24183", "abs": "https://arxiv.org/abs/2505.24183", "authors": ["Yaoyu Zhu", "Di Huang", "Hanqi Lyu", "Xiaoyun Zhang", "Chongxiao Li", "Wenxuan Shi", "Yutong Wu", "Jianan Mu", "Jinghua Wang", "Yang Zhao", "Pengwei Jin", "Shuyao Cheng", "Shengwen Liang", "Xishan Zhang", "Rui Zhang", "Zidong Du", "Qi Guo", "Xing Hu", "Yunji Chen"], "title": "CodeV-R1: Reasoning-Enhanced Verilog Generation", "categories": ["cs.LG", "cs.AR", "cs.PL"], "comment": null, "summary": "Large language models (LLMs) trained via reinforcement learning with\nverifiable reward (RLVR) have achieved breakthroughs on tasks with explicit,\nautomatable verification, such as software programming and mathematical\nproblems. Extending RLVR to electronic design automation (EDA), especially\nautomatically generating hardware description languages (HDLs) like Verilog\nfrom natural-language (NL) specifications, however, poses three key challenges:\nthe lack of automated and accurate verification environments, the scarcity of\nhigh-quality NL-code pairs, and the prohibitive computation cost of RLVR. To\nthis end, we introduce CodeV-R1, an RLVR framework for training Verilog\ngeneration LLMs. First, we develop a rule-based testbench generator that\nperforms robust equivalence checking against golden references. Second, we\npropose a round-trip data synthesis method that pairs open-source Verilog\nsnippets with LLM-generated NL descriptions, verifies code-NL-code consistency\nvia the generated testbench, and filters out inequivalent examples to yield a\nhigh-quality dataset. Third, we employ a two-stage \"distill-then-RL\" training\npipeline: distillation for the cold start of reasoning abilities, followed by\nadaptive DAPO, our novel RLVR algorithm that can reduce training cost by\nadaptively adjusting sampling rate. The resulting model, CodeV-R1-7B, achieves\n68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1, respectively,\nsurpassing prior state-of-the-art by 12~20%, while matching or even exceeding\nthe performance of 671B DeepSeek-R1. We will release our model, training\npipeline, and dataset to facilitate research in EDA and LLM communities.", "AI": {"tldr": "CodeV-R1 is an RLVR framework designed for training Verilog generation LLMs, overcoming challenges in verification environments, dataset scarcity and computation cost.", "motivation": "To extend reinforcement learning with verifiable reward (RLVR) to electronic design automation (EDA), particularly for automatically generating hardware description languages (HDLs) like Verilog from natural language specifications.", "method": "Developed a rule-based testbench generator for robust equivalence checking, proposed a round-trip data synthesis method to create high-quality NL-code pairs, and employed a two-stage 'distill-then-RL' training pipeline that includes adaptive DAPO to reduce training cost.", "result": "The model CodeV-R1-7B achieved 68.6% and 72.9% pass@1 on VerilogEval v2 and RTLLM v1.1 respectively, surpassing prior state-of-the-art by 12~20%, while matching or even exceeding the performance of 671B DeepSeek-R1.", "conclusion": "CodeV-R1 successfully addresses key challenges in applying RLVR to EDA, demonstrating superior performance compared to previous models and comparable results to much larger models."}}
{"id": "2505.23807", "pdf": "https://arxiv.org/pdf/2505.23807", "abs": "https://arxiv.org/abs/2505.23807", "authors": ["Yuli Chen", "Bo Cheng", "Jiale Han", "Yingying Zhang", "Yingting Li", "Shuhao Zhang"], "title": "DLP: Dynamic Layerwise Pruning in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted by ICML 2025", "summary": "Pruning has recently been widely adopted to reduce the parameter scale and\nimprove the inference efficiency of Large Language Models (LLMs). Mainstream\npruning techniques often rely on uniform layerwise pruning strategies, which\ncan lead to severe performance degradation at high sparsity levels. Recognizing\nthe varying contributions of different layers in LLMs, recent studies have\nshifted their focus toward non-uniform layerwise pruning. However, these\napproaches often rely on pre-defined values, which can result in suboptimal\nperformance. To overcome these limitations, we propose a novel method called\nDynamic Layerwise Pruning (DLP). This approach adaptively determines the\nrelative importance of each layer by integrating model weights with input\nactivation information, assigning pruning rates accordingly. Experimental\nresults show that DLP effectively preserves model performance at high sparsity\nlevels across multiple LLMs. Specifically, at 70% sparsity, DLP reduces the\nperplexity of LLaMA2-7B by 7.79 and improves the average accuracy by 2.7%\ncompared to state-of-the-art methods. Moreover, DLP is compatible with various\nexisting LLM compression techniques and can be seamlessly integrated into\nParameter-Efficient Fine-Tuning (PEFT). We release the code at\nhttps://github.com/ironartisan/DLP to facilitate future research.", "AI": {"tldr": "\u4e3a\u4e86\u514b\u670d\u4e3b\u6d41\u526a\u679d\u6280\u672f\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u53ef\u80fd\u5bfc\u81f4\u7684\u6027\u80fd\u663e\u8457\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u52a8\u6001\u5c42\u5185\u526a\u679d\uff08DLP\uff09\u65b9\u6cd5\uff0c\u80fd\u591f\u81ea\u9002\u5e94\u5730\u786e\u5b9a\u6bcf\u4e00\u5c42\u7684\u91cd\u8981\u6027\u5e76\u5206\u914d\u526a\u679d\u7387\u3002\u5b9e\u9a8c\u8868\u660e\uff0cDLP\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u80fd\u6709\u6548\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u5e76\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u4e3b\u6d41\u526a\u679d\u6280\u672f\u901a\u5e38\u4f9d\u8d56\u4e8e\u5747\u5300\u7684\u5c42\u5185\u526a\u679d\u7b56\u7565\uff0c\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u53ef\u80fd\u5bfc\u81f4\u4e25\u91cd\u7684\u6027\u80fd\u4e0b\u964d\u3002\u867d\u7136\u975e\u5747\u5300\u5c42\u5185\u526a\u679d\u7b56\u7565\u6709\u6240\u6539\u8fdb\uff0c\u4f46\u5176\u4f9d\u8d56\u9884\u5b9a\u4e49\u503c\u53ef\u80fd\u9020\u6210\u6b21\u4f18\u6027\u80fd\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u53ef\u4ee5\u81ea\u9002\u5e94\u786e\u5b9a\u6bcf\u4e00\u5c42\u91cd\u8981\u6027\u5e76\u5206\u914d\u526a\u679d\u7387\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u52a8\u6001\u5c42\u5185\u526a\u679d\uff08DLP\uff09\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u6574\u5408\u6a21\u578b\u6743\u91cd\u4e0e\u8f93\u5165\u6fc0\u6d3b\u4fe1\u606f\uff0c\u81ea\u9002\u5e94\u5730\u786e\u5b9a\u6bcf\u4e00\u5c42\u7684\u76f8\u5bf9\u91cd\u8981\u6027\uff0c\u5e76\u6839\u636e\u91cd\u8981\u6027\u5206\u914d\u526a\u679d\u7387\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cDLP\u80fd\u591f\u5728\u591a\u4e2a\u5927\u8bed\u8a00\u6a21\u578b\u4e0a\u6709\u6548\u5730\u4fdd\u6301\u9ad8\u7a00\u758f\u5ea6\u4e0b\u7684\u6a21\u578b\u6027\u80fd\u3002\u5177\u4f53\u6765\u8bf4\uff0c\u572870%\u7a00\u758f\u5ea6\u4e0b\uff0cDLP\u5c06LLaMA2-7B\u7684\u56f0\u60d1\u5ea6\u964d\u4f4e\u4e867.79\uff0c\u5e76\u4f7f\u5e73\u5747\u51c6\u786e\u7387\u63d0\u9ad8\u4e862.7%\u3002\u6b64\u5916\uff0cDLP\u53ef\u4e0e\u73b0\u6709\u7684\u591a\u79cd\u5927\u8bed\u8a00\u6a21\u578b\u538b\u7f29\u6280\u672f\u517c\u5bb9\uff0c\u5e76\u80fd\u65e0\u7f1d\u96c6\u6210\u5230\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\uff08PEFT\uff09\u4e2d\u3002", "conclusion": "DLP\u65b9\u6cd5\u5728\u9ad8\u7a00\u758f\u5ea6\u4e0b\u80fd\u591f\u6709\u6548\u4fdd\u6301\u6a21\u578b\u6027\u80fd\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e0e\u591a\u79cd\u73b0\u6709\u6280\u672f\u517c\u5bb9\uff0c\u4e3a\u672a\u6765\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u4fbf\u5229\u3002"}}
{"id": "2505.24185", "pdf": "https://arxiv.org/pdf/2505.24185", "abs": "https://arxiv.org/abs/2505.24185", "authors": ["Yipan Wei", "Yuchen Zou", "Yapeng Li", "Bo Du"], "title": "Towards Unified Modeling in Federated Multi-Task Learning via Subspace Decoupling", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "Federated Multi-Task Learning (FMTL) enables multiple clients performing\nheterogeneous tasks without exchanging their local data, offering broad\npotential for privacy preserving multi-task collaboration. However, most\nexisting methods focus on building personalized models for each client and\nunable to support the aggregation of multiple heterogeneous tasks into a\nunified model. As a result, in real-world scenarios where task objectives,\nlabel spaces, and optimization paths vary significantly, conventional FMTL\nmethods struggle to achieve effective joint training. To address this\nchallenge, we propose FedDEA (Federated Decoupled Aggregation), an\nupdate-structure-aware aggregation method specifically designed for multi-task\nmodel integration. Our method dynamically identifies task-relevant dimensions\nbased on the response strength of local updates and enhances their optimization\neffectiveness through rescaling. This mechanism effectively suppresses\ncross-task interference and enables task-level decoupled aggregation within a\nunified global model. FedDEA does not rely on task labels or architectural\nmodifications, making it broadly applicable and deployment-friendly.\nExperimental results demonstrate that it can be easily integrated into various\nmainstream federated optimization algorithms and consistently delivers\nsignificant overall performance improvements on widely used NYUD-V2 and\nPASCAL-Context. These results validate the robustness and generalization\ncapabilities of FedDEA under highly heterogeneous task settings.", "AI": {"tldr": "FedDEA\u662f\u4e00\u79cd\u65b0\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u4e13\u4e3a\u591a\u4efb\u52a1\u6a21\u578b\u96c6\u6210\u800c\u8bbe\u8ba1\uff0c\u89e3\u51b3\u4e86\u73b0\u6709FMTL\u65b9\u6cd5\u5728\u5f02\u6784\u4efb\u52a1\u8054\u5408\u8bad\u7ec3\u4e2d\u7684\u4e0d\u8db3\u3002\u901a\u8fc7\u52a8\u6001\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\u548c\u4f18\u5316\u8c03\u6574\uff0c\u6291\u5236\u8de8\u4efb\u52a1\u5e72\u6270\uff0c\u5b9e\u73b0\u7edf\u4e00\u5168\u5c40\u6a21\u578b\u5185\u7684\u4efb\u52a1\u7ea7\u89e3\u8026\u805a\u5408\u3002\u5b9e\u9a8c\u8868\u660e\uff0cFedDEA\u6613\u4e8e\u96c6\u6210\u5230\u4e3b\u6d41\u8054\u90a6\u4f18\u5316\u7b97\u6cd5\u4e2d\uff0c\u5e76\u5728\u591a\u79cd\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684Federated Multi-Task Learning (FMTL)\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e3a\u6bcf\u4e2a\u5ba2\u6237\u7aef\u6784\u5efa\u4e2a\u6027\u5316\u6a21\u578b\uff0c\u4f46\u65e0\u6cd5\u5c06\u591a\u4e2a\u5f02\u6784\u4efb\u52a1\u805a\u5408\u5230\u4e00\u4e2a\u7edf\u4e00\u6a21\u578b\u4e2d\uff0c\u5bfc\u81f4\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u96be\u4ee5\u5b9e\u73b0\u6709\u6548\u7684\u8054\u5408\u8bad\u7ec3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aFedDEA\uff08Federated Decoupled Aggregation\uff09\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u6839\u636e\u672c\u5730\u66f4\u65b0\u7684\u54cd\u5e94\u5f3a\u5ea6\u52a8\u6001\u8bc6\u522b\u4efb\u52a1\u76f8\u5173\u7ef4\u5ea6\uff0c\u5e76\u901a\u8fc7\u91cd\u65b0\u7f29\u653e\u589e\u5f3a\u4f18\u5316\u6548\u679c\uff0c\u4ece\u800c\u6709\u6548\u6291\u5236\u8de8\u4efb\u52a1\u5e72\u6270\uff0c\u5e76\u5728\u7edf\u4e00\u7684\u5168\u5c40\u6a21\u578b\u5185\u5b9e\u73b0\u4efb\u52a1\u7ea7\u89e3\u8026\u805a\u5408\u3002\u6b64\u65b9\u6cd5\u4e0d\u4f9d\u8d56\u4efb\u52a1\u6807\u7b7e\u6216\u67b6\u6784\u4fee\u6539\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u548c\u90e8\u7f72\u53cb\u597d\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFedDEA\u53ef\u4ee5\u8f7b\u677e\u96c6\u6210\u5230\u5404\u79cd\u4e3b\u6d41\u8054\u90a6\u4f18\u5316\u7b97\u6cd5\u4e2d\uff0c\u5e76\u5728\u5e7f\u6cdb\u4f7f\u7528\u7684NYUD-V2\u548cPASCAL-Context\u6570\u636e\u96c6\u4e0a\u6301\u7eed\u63d0\u4f9b\u663e\u8457\u7684\u6574\u4f53\u6027\u80fd\u6539\u8fdb\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u9ad8\u5ea6\u5f02\u6784\u4efb\u52a1\u8bbe\u7f6e\u4e0b\u7684\u9c81\u68d2\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "FedDEA\u4f5c\u4e3a\u4e00\u79cd\u65b0\u9896\u7684\u3001\u65e0\u9700\u4efb\u52a1\u6807\u7b7e\u6216\u67b6\u6784\u4fee\u6539\u7684\u805a\u5408\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u4efb\u52a1\u6a21\u578b\u96c6\u6210\uff0c\u89e3\u51b3\u4e86\u73b0\u6709FMTL\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6027\u80fd\u63d0\u5347\u548c\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2505.23808", "pdf": "https://arxiv.org/pdf/2505.23808", "abs": "https://arxiv.org/abs/2505.23808", "authors": ["Lin Mu", "Xiaoyu Wang", "Li Ni", "Yang Li", "Zhize Wu", "Peiquan Jin", "Yiwen Zhang"], "title": "DenseLoRA: Dense Low-Rank Adaptation of Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Low-rank adaptation (LoRA) has been developed as an efficient approach for\nadapting large language models (LLMs) by fine-tuning two low-rank matrices,\nthereby reducing the number of trainable parameters. However, prior research\nindicates that many of the weights in these matrices are redundant, leading to\ninefficiencies in parameter utilization. To address this limitation, we\nintroduce Dense Low-Rank Adaptation (DenseLoRA), a novel approach that enhances\nparameter efficiency while achieving superior performance compared to LoRA.\nDenseLoRA builds upon the concept of representation fine-tuning, incorporating\na single Encoder-Decoder to refine and compress hidden representations across\nall adaptation layers before applying adaptation. Instead of relying on two\nredundant low-rank matrices as in LoRA, DenseLoRA adapts LLMs through a dense\nlow-rank matrix, improving parameter utilization and adaptation efficiency. We\nevaluate DenseLoRA on various benchmarks, showing that it achieves 83.8%\naccuracy with only 0.01% of trainable parameters, compared to LoRA's 80.8%\naccuracy with 0.70% of trainable parameters on LLaMA3-8B. Additionally, we\nconduct extensive experiments to systematically assess the impact of\nDenseLoRA's components on overall model performance. Code is available at\nhttps://github.com/mulin-ahu/DenseLoRA.", "AI": {"tldr": "DenseLoRA is a novel approach that improves upon LoRA by enhancing parameter efficiency and achieving superior performance through a dense low-rank matrix.", "motivation": "To address the inefficiency in parameter utilization found in LoRA, where many weights in the matrices are redundant.", "method": "DenseLoRA uses a single Encoder-Decoder to refine and compress hidden representations across all adaptation layers before applying adaptation. It adapts LLMs through a dense low-rank matrix instead of two redundant low-rank matrices.", "result": "DenseLoRA achieves 83.8% accuracy with only 0.01% of trainable parameters on LLaMA3-8B, compared to LoRA's 80.8% accuracy with 0.70% of trainable parameters. Extensive experiments show the impact of DenseLoRA's components on model performance.", "conclusion": "DenseLoRA enhances parameter efficiency and achieves better performance than LoRA."}}
{"id": "2505.24189", "pdf": "https://arxiv.org/pdf/2505.24189", "abs": "https://arxiv.org/abs/2505.24189", "authors": ["Orlando Marquez Ayala", "Patrice Bechard", "Emily Chen", "Maggie Baird", "Jingfei Chen"], "title": "Fine-Tune an SLM or Prompt an LLM? The Case of Generating Low-Code Workflows", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large Language Models (LLMs) such as GPT-4o can handle a wide range of\ncomplex tasks with the right prompt. As per token costs are reduced, the\nadvantages of fine-tuning Small Language Models (SLMs) for real-world\napplications -- faster inference, lower costs -- may no longer be clear. In\nthis work, we present evidence that, for domain-specific tasks that require\nstructured outputs, SLMs still have a quality advantage. We compare fine-tuning\nan SLM against prompting LLMs on the task of generating low-code workflows in\nJSON form. We observe that while a good prompt can yield reasonable results,\nfine-tuning improves quality by 10% on average. We also perform systematic\nerror analysis to reveal model limitations.", "AI": {"tldr": "For domain-specific tasks requiring structured outputs, small language models (SLMs) fine-tuned still have a quality advantage over large language models (LLMs) prompted. Fine-tuning an SLM improves quality by 10% on average.", "motivation": "To determine whether small language models (SLMs) still hold an advantage in specific tasks that require structured outputs, especially with the decreasing cost of using large language models (LLMs).", "method": "Compare fine-tuning an SLM with prompting LLMs on generating low-code workflows in JSON form and conduct systematic error analysis to reveal model limitations.", "result": "Fine-tuning an SLM leads to a 10% improvement in quality on average compared to using a good prompt for LLMs.", "conclusion": "Small language models retain a quality advantage for domain-specific tasks requiring structured outputs."}}
{"id": "2505.23809", "pdf": "https://arxiv.org/pdf/2505.23809", "abs": "https://arxiv.org/abs/2505.23809", "authors": ["Haowei Yang", "Haotian Lyu", "Tianle Zhang", "Dingzhou Wang", "Yushang Zhao"], "title": "LLM-Driven E-Commerce Marketing Content Optimization: Balancing Creativity and Conversion", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": null, "summary": "As e-commerce competition intensifies, balancing creative content with\nconversion effectiveness becomes critical. Leveraging LLMs' language generation\ncapabilities, we propose a framework that integrates prompt engineering,\nmulti-objective fine-tuning, and post-processing to generate marketing copy\nthat is both engaging and conversion-driven. Our fine-tuning method combines\nsentiment adjustment, diversity enhancement, and CTA embedding. Through offline\nevaluations and online A/B tests across categories, our approach achieves a\n12.5 % increase in CTR and an 8.3 % increase in CVR while maintaining content\nnovelty. This provides a practical solution for automated copy generation and\nsuggests paths for future multimodal, real-time personalization.", "AI": {"tldr": "E-commerce competition prompts a need to balance creative content with conversion. This paper proposes a framework leveraging LLMs for generating effective marketing copy, achieving 12.5% CTR and 8.3% CVR increase.", "motivation": "With the intensifying e-commerce competition, there is a critical need to balance creative content with conversion effectiveness in marketing copy.", "method": "The proposed framework integrates prompt engineering, multi-objective fine-tuning, and post-processing using LLMs' language generation capabilities. The fine-tuning method combines sentiment adjustment, diversity enhancement, and CTA embedding.", "result": "The approach achieves a 12.5% increase in CTR and an 8.3% increase in CVR through offline evaluations and online A/B tests across categories, while maintaining content novelty.", "conclusion": "This provides a practical solution for automated copy generation and suggests potential for future multimodal and real-time personalization."}}
{"id": "2505.24190", "pdf": "https://arxiv.org/pdf/2505.24190", "abs": "https://arxiv.org/abs/2505.24190", "authors": ["Lan-Cuong Nguyen", "Quan Nguyen-Tri", "Bang Tran Khanh", "Dung D. Le", "Long Tran-Thanh", "Khoat Than"], "title": "Provably Improving Generalization of Few-Shot Models with Synthetic Data", "categories": ["cs.LG", "cs.CV"], "comment": "ICML 2025. Our code will be released soon", "summary": "Few-shot image classification remains challenging due to the scarcity of\nlabeled training examples. Augmenting them with synthetic data has emerged as a\npromising way to alleviate this issue, but models trained on synthetic samples\noften face performance degradation due to the inherent gap between real and\nsynthetic distributions. To address this limitation, we develop a theoretical\nframework that quantifies the impact of such distribution discrepancies on\nsupervised learning, specifically in the context of image classification. More\nimportantly, our framework suggests practical ways to generate good synthetic\nsamples and to train a predictor with high generalization ability. Building\nupon this framework, we propose a novel theoretical-based algorithm that\nintegrates prototype learning to optimize both data partitioning and model\ntraining, effectively bridging the gap between real few-shot data and synthetic\ndata. Extensive experiments results show that our approach demonstrates\nsuperior performance compared to state-of-the-art methods, outperforming them\nacross multiple datasets.", "AI": {"tldr": "Few-shot image classification faces challenges due to limited labeled data. While augmenting with synthetic data is promising, it often leads to performance degradation because of the gap between real and synthetic distributions. This paper develops a theoretical framework to quantify this impact and proposes a novel algorithm integrating prototype learning to bridge the gap. Extensive experiments show superior performance compared to state-of-the-art methods.", "motivation": "Few-shot image classification is challenging due to the scarcity of labeled training examples. Augmenting with synthetic data can help but causes performance degradation due to discrepancies between real and synthetic distributions.", "method": "The paper develops a theoretical framework to quantify the impact of distribution discrepancies on supervised learning in image classification. It suggests practical ways to generate good synthetic samples and train predictors with high generalization ability. A novel theoretical-based algorithm integrating prototype learning is proposed to optimize data partitioning and model training.", "result": "Extensive experimental results demonstrate that the proposed approach outperforms state-of-the-art methods across multiple datasets.", "conclusion": "The developed theoretical framework and proposed algorithm effectively address the limitations caused by the gap between real and synthetic data distributions in few-shot image classification."}}
{"id": "2505.23810", "pdf": "https://arxiv.org/pdf/2505.23810", "abs": "https://arxiv.org/abs/2505.23810", "authors": ["Chenghao Yang", "Yinbo Luo", "Zhoufutu Wen", "Qi Chu", "Tao Gong", "Longxiang Liu", "Kaiyuan Zhang", "Jianpeng Jiao", "Ge Zhang", "Wenhao Huang", "Nenghai Yu"], "title": "MARS-Bench: A Multi-turn Athletic Real-world Scenario Benchmark for Dialogue Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": "29 pages, 13 figures", "summary": "Large Language Models (\\textbf{LLMs}), e.g. ChatGPT, have been widely adopted\nin real-world dialogue applications. However, LLMs' robustness, especially in\nhandling long complex dialogue sessions, including frequent motivation\ntransfer, sophisticated cross-turn dependency, is criticized all along.\nNevertheless, no existing benchmarks can fully reflect these weaknesses. We\npresent \\textbf{MARS-Bench}, a \\textbf{M}ulti-turn \\textbf{A}thletic\n\\textbf{R}eal-world \\textbf{S}cenario Dialogue \\textbf{Bench}mark, designed to\nremedy the gap. MARS-Bench is constructed from play-by-play text commentary so\nto feature realistic dialogues specifically designed to evaluate three critical\naspects of multi-turn conversations: Ultra Multi-turn, Interactive Multi-turn,\nand Cross-turn Tasks. Extensive experiments on MARS-Bench also reveal that\nclosed-source LLMs significantly outperform open-source alternatives, explicit\nreasoning significantly boosts LLMs' robustness on handling long complex\ndialogue sessions, and LLMs indeed face significant challenges when handling\nmotivation transfer and sophisticated cross-turn dependency. Moreover, we\nprovide mechanistic interpretability on how attention sinks due to special\ntokens lead to LLMs' performance degradation when handling long complex\ndialogue sessions based on attention visualization experiment in\nQwen2.5-7B-Instruction.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5982ChatGPT\u5728\u5b9e\u9645\u5bf9\u8bdd\u5e94\u7528\u4e2d\u88ab\u5e7f\u6cdb\u4f7f\u7528\uff0c\u4f46\u5176\u5904\u7406\u957f\u590d\u6742\u5bf9\u8bdd\u7684\u80fd\u529b\u4e00\u76f4\u53d7\u5230\u6279\u8bc4\u3002\u4e3a\u6b64\uff0c\u7814\u7a76\u8005\u63d0\u51fa\u4e86MARS-Bench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4e13\u95e8\u7528\u4e8e\u8bc4\u4f30\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u65b9\u9762\uff1a\u8d85\u591a\u8f6e\u3001\u4ea4\u4e92\u591a\u8f6e\u548c\u8de8\u8f6e\u4efb\u52a1\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u95ed\u6e90LLMs\u663e\u8457\u4f18\u4e8e\u5f00\u6e90\u66ff\u4ee3\u54c1\uff0c\u660e\u786e\u63a8\u7406\u80fd\u589e\u5f3aLLMs\u5904\u7406\u957f\u590d\u6742\u5bf9\u8bdd\u7684\u9c81\u68d2\u6027\uff0c\u4f46LLMs\u5728\u5904\u7406\u52a8\u673a\u8f6c\u79fb\u548c\u590d\u6742\u7684\u8de8\u8f6e\u4f9d\u8d56\u65f6\u4ecd\u9762\u4e34\u91cd\u5927\u6311\u6218\u3002\u6b64\u5916\uff0c\u901a\u8fc7\u6ce8\u610f\u529b\u53ef\u89c6\u5316\u5b9e\u9a8c\u63ed\u793a\u4e86\u7531\u4e8e\u7279\u6b8a\u6807\u8bb0\u5bfc\u81f4\u6ce8\u610f\u529b\u6c47\u805a\u800c\u5f15\u8d77\u7684LLMs\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u5f53\u524d\u6ca1\u6709\u57fa\u51c6\u80fd\u591f\u5168\u9762\u53cd\u6620\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5904\u7406\u957f\u590d\u6742\u5bf9\u8bdd\u4f1a\u8bdd\u4e2d\u7684\u5f31\u70b9\uff0c\u5305\u62ec\u9891\u7e41\u7684\u52a8\u673a\u8f6c\u79fb\u548c\u590d\u6742\u7684\u8de8\u8f6e\u4f9d\u8d56\u3002", "method": "\u6784\u5efa\u4e86\u4e00\u4e2a\u540d\u4e3aMARS-Bench\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u57fa\u51c6\u4ece\u9010\u573a\u6587\u672c\u8bc4\u8bba\u4e2d\u6784\u9020\uff0c\u4ee5\u53cd\u6620\u73b0\u5b9e\u5bf9\u8bdd\uff0c\u5e76\u4e13\u95e8\u8bbe\u8ba1\u7528\u4e8e\u8bc4\u4f30\u591a\u8f6e\u5bf9\u8bdd\u4e2d\u7684\u4e09\u4e2a\u65b9\u9762\uff1a\u8d85\u591a\u8f6e\u3001\u4ea4\u4e92\u591a\u8f6e\u548c\u8de8\u8f6e\u4efb\u52a1\u3002", "result": "\u95ed\u6e90LLMs\u663e\u8457\u4f18\u4e8e\u5f00\u6e90LLMs\uff1b\u660e\u786e\u63a8\u7406\u663e\u8457\u63d0\u9ad8\u4e86LLMs\u5904\u7406\u957f\u590d\u6742\u5bf9\u8bdd\u4f1a\u8bdd\u7684\u9c81\u68d2\u6027\uff1bLLMs\u5728\u5904\u7406\u52a8\u673a\u8f6c\u79fb\u548c\u590d\u6742\u7684\u8de8\u8f6e\u4f9d\u8d56\u65f6\u786e\u5b9e\u9762\u4e34\u91cd\u5927\u6311\u6218\uff1b\u6ce8\u610f\u529b\u6c47\u805a\u7531\u4e8e\u7279\u6b8a\u6807\u8bb0\u5f15\u8d77LLMs\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "MARS-Bench\u586b\u8865\u4e86\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5145\u5206\u53cd\u6620LLMs\u5728\u5904\u7406\u957f\u590d\u6742\u5bf9\u8bdd\u4f1a\u8bdd\u4e2d\u5f31\u70b9\u7684\u7a7a\u767d\uff0c\u63d0\u4f9b\u4e86\u5bf9LLMs\u6027\u80fd\u7684\u65b0\u89c1\u89e3\uff0c\u5e76\u6307\u51fa\u4e86\u8fdb\u4e00\u6b65\u6539\u8fdb\u7684\u65b9\u5411\u3002"}}
{"id": "2505.24193", "pdf": "https://arxiv.org/pdf/2505.24193", "abs": "https://arxiv.org/abs/2505.24193", "authors": ["Ofir Schlisselberg", "Tal Lancewicki", "Peter Auer", "Yishay Mansour"], "title": "Improved Best-of-Both-Worlds Regret for Bandits with Delayed Feedback", "categories": ["cs.LG"], "comment": null, "summary": "We study the multi-armed bandit problem with adversarially chosen delays in\nthe Best-of-Both-Worlds (BoBW) framework, which aims to achieve near-optimal\nperformance in both stochastic and adversarial environments. While prior work\nhas made progress toward this goal, existing algorithms suffer from significant\ngaps to the known lower bounds, especially in the stochastic settings. Our main\ncontribution is a new algorithm that, up to logarithmic factors, matches the\nknown lower bounds in each setting individually.\n  In the adversarial case, our algorithm achieves regret of\n$\\widetilde{O}(\\sqrt{KT} + \\sqrt{D})$, which is optimal up to logarithmic\nterms, where $T$ is the number of rounds, $K$ is the number of arms, and $D$ is\nthe cumulative delay. In the stochastic case, we provide a regret bound which\nscale as $\\sum_{i:\\Delta_i>0}\\left(\\log T/\\Delta_i\\right) + \\frac{1}{K}\\sum\n\\Delta_i \\sigma_{max}$, where $\\Delta_i$ is the sub-optimality gap of arm $i$\nand $\\sigma_{\\max}$ is the maximum number of missing observations.\n  To the best of our knowledge, this is the first BoBW algorithm to\nsimultaneously match the lower bounds in both stochastic and adversarial\nregimes in delayed environment. Moreover, even beyond the BoBW setting, our\nstochastic regret bound is the first to match the known lower bound under\nadversarial delays, improving the second term over the best known result by a\nfactor of $K$.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u5728Best-of-Both-Worlds (BoBW)\u6846\u67b6\u4e0b\u7684\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u8be5\u6846\u67b6\u65e8\u5728\u540c\u65f6\u5b9e\u73b0\u968f\u673a\u548c\u5bf9\u6297\u73af\u5883\u4e2d\u7684\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u3002\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86$\\widetilde{O}(\\sqrt{KT} + \\sqrt{D})$\u7684\u9057\u61be\u503c\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86$\\sum_{i:\\Delta_i>0}\\left(\\log T/\\Delta_i\\right) + \\frac{1}{K}\\sum \\Delta_i \\sigma_{max}$\u7684\u9057\u61be\u754c\u9650\u3002\u8fd9\u662f\u9996\u4e2a\u5728\u5ef6\u8fdf\u73af\u5883\u4e0b\u540c\u65f6\u5339\u914d\u968f\u673a\u548c\u5bf9\u6297\u73af\u5883\u9057\u61be\u4e0b\u754c\u7684BoBW\u7b97\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5148\u524d\u7684\u5de5\u4f5c\u5df2\u7ecf\u671d\u7740\u5728Best-of-Both-Worlds (BoBW)\u6846\u67b6\u4e2d\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u7684\u76ee\u6807\u53d6\u5f97\u4e86\u4e00\u4e9b\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u7b97\u6cd5\u4e0e\u5df2\u77e5\u4e0b\u754c\u4e4b\u95f4\u4ecd\u7136\u5b58\u5728\u663e\u8457\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u968f\u673a\u8bbe\u7f6e\u4e2d\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u7b97\u6cd5\u6765\u5f25\u8865\u8fd9\u4e9b\u5dee\u8ddd\u3002", "method": "\u7814\u7a76\u4eba\u5458\u8bbe\u8ba1\u4e86\u4e00\u79cd\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u9488\u5bf9\u591a\u81c2\u8d4c\u535a\u673a\u95ee\u9898\uff0c\u80fd\u591f\u9002\u5e94\u5bf9\u6297\u6027\u9009\u62e9\u7684\u5ef6\u8fdf\uff0c\u5e76\u4e14\u5728BoBW\u6846\u67b6\u4e0b\u5de5\u4f5c\u3002\u6b64\u7b97\u6cd5\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86$\\widetilde{O}(\\sqrt{KT} + \\sqrt{D})$\u7684\u9057\u61be\u503c\uff0c\u5e76\u5728\u968f\u673a\u73af\u5883\u4e2d\u63d0\u4f9b\u4e86\u7279\u5b9a\u7684\u9057\u61be\u754c\u9650\u3002", "result": "\u8be5\u7b97\u6cd5\u5728\u5bf9\u6297\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u4e0e\u5df2\u77e5\u4e0b\u754c\u76f8\u5339\u914d\u7684\u9057\u61be\u503c\uff0c\u5728\u968f\u673a\u73af\u5883\u4e2d\u4e5f\u9996\u6b21\u8fbe\u5230\u4e86\u76f8\u5e94\u7684\u4e0b\u754c\u3002\u6b64\u5916\uff0c\u5373\u4f7f\u8d85\u51faBoBW\u8bbe\u7f6e\uff0c\u5176\u968f\u673a\u9057\u61be\u754c\u9650\u4e5f\u662f\u9996\u4e2a\u5728\u5bf9\u6297\u6027\u5ef6\u8fdf\u4e0b\u5339\u914d\u5df2\u77e5\u4e0b\u754c\u7684\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b97\u6cd5\u662f\u7b2c\u4e00\u4e2a\u5728\u5ef6\u8fdf\u73af\u5883\u4e0b\u540c\u65f6\u5339\u914d\u968f\u673a\u548c\u5bf9\u6297\u73af\u5883\u9057\u61be\u4e0b\u754c\u7684BoBW\u7b97\u6cd5\uff0c\u5e76\u4e14\u5728\u968f\u673a\u9057\u61be\u754c\u9650\u4e0a\u6709\u6240\u6539\u8fdb\u3002"}}
{"id": "2505.23811", "pdf": "https://arxiv.org/pdf/2505.23811", "abs": "https://arxiv.org/abs/2505.23811", "authors": ["Hadi Askari", "Shivanshu Gupta", "Fei Wang", "Anshuman Chhabra", "Muhao Chen"], "title": "LayerIF: Estimating Layer Quality for Large Language Models using Influence Functions", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Under Review", "summary": "Pretrained Large Language Models (LLMs) achieve strong performance across a\nwide range of tasks, yet exhibit substantial variability in the various layers'\ntraining quality with respect to specific downstream applications, limiting\ntheir downstream performance.It is therefore critical to estimate layer-wise\ntraining quality in a manner that accounts for both model architecture and\ntraining data. However, existing approaches predominantly rely on model-centric\nheuristics (such as spectral statistics, outlier detection, or uniform\nallocation) while overlooking the influence of data. To address these\nlimitations, we propose LayerIF, a data-driven framework that leverages\nInfluence Functions to quantify the training quality of individual layers in a\nprincipled and task-sensitive manner. By isolating each layer's gradients and\nmeasuring the sensitivity of the validation loss to training examples by\ncomputing layer-wise influences, we derive data-driven estimates of layer\nimportance. Notably, our method produces task-specific layer importance\nestimates for the same LLM, revealing how layers specialize for different\ntest-time evaluation tasks. We demonstrate the utility of our scores by\nleveraging them for two downstream applications: (a) expert allocation in\nLoRA-MoE architectures and (b) layer-wise sparsity distribution for LLM\npruning. Experiments across multiple LLM architectures demonstrate that our\nmodel-agnostic, influence-guided allocation leads to consistent gains in task\nperformance.", "AI": {"tldr": "Pretrained Large Language Models (LLMs) show variability in layer training quality, impacting downstream performance. Current methods to assess this are model-centric and overlook data influence. This paper introduces LayerIF, a data-driven framework using Influence Functions to evaluate layer-wise training quality, considering both architecture and data. It provides task-specific importance estimates for LLM layers, showing how they specialize for different tasks. Demonstrated through two applications - expert allocation in LoRA-MoE and sparsity distribution in LLM pruning - LayerIF improves task performance across multiple LLM architectures.", "motivation": "The motivation is the need to accurately estimate layer-wise training quality in LLMs to enhance their downstream performance, addressing the limitation of current model-centric approaches that neglect data influence.", "method": "LayerIF is proposed, a data-driven framework leveraging Influence Functions. It isolates each layer's gradients and measures the sensitivity of validation loss to training examples to derive data-driven estimates of layer importance in a task-sensitive manner.", "result": "Experiments show that LayerIF produces task-specific layer importance estimates and leads to consistent gains in task performance when used for expert allocation in LoRA-MoE architectures and layer-wise sparsity distribution in LLM pruning.", "conclusion": "LayerIF offers a model-agnostic, influence-guided method to assess and improve LLM layer training quality, enhancing downstream task performance."}}
{"id": "2505.24205", "pdf": "https://arxiv.org/pdf/2505.24205", "abs": "https://arxiv.org/abs/2505.24205", "authors": ["Mingze Wang", "Weinan E"], "title": "On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks", "categories": ["cs.LG", "stat.ML"], "comment": "18 pages", "summary": "Mixture-of-experts networks (MoEs) have demonstrated remarkable efficiency in\nmodern deep learning. Despite their empirical success, the theoretical\nfoundations underlying their ability to model complex tasks remain poorly\nunderstood. In this work, we conduct a systematic study of the expressive power\nof MoEs in modeling complex tasks with two common structural priors:\nlow-dimensionality and sparsity. For shallow MoEs, we prove that they can\nefficiently approximate functions supported on low-dimensional manifolds,\novercoming the curse of dimensionality. For deep MoEs, we show that\n$\\cO(L)$-layer MoEs with $E$ experts per layer can approximate piecewise\nfunctions comprising $E^L$ pieces with compositional sparsity, i.e., they can\nexhibit an exponential number of structured tasks. Our analysis reveals the\nroles of critical architectural components and hyperparameters in MoEs,\nincluding the gating mechanism, expert networks, the number of experts, and the\nnumber of layers, and offers natural suggestions for MoE variants.", "AI": {"tldr": "Mixture-of-experts networks (MoEs) have great efficiency in deep learning. This study systematically explores the expressive power of MoEs for complex tasks with structural priors such as low-dimensionality and sparsity. It proves that shallow MoEs can efficiently approximate functions on low-dimensional manifolds, while deep MoEs can approximate piecewise functions with compositional sparsity.", "motivation": "To better understand the theoretical foundations of MoEs' ability to model complex tasks, especially those with structural priors like low-dimensionality and sparsity.", "method": "A systematic study analyzing the expressive power of both shallow and deep MoEs. For shallow MoEs, their efficiency in approximating functions supported on low-dimensional manifolds is examined. For deep MoEs, their capacity to approximate piecewise functions with compositional sparsity is analyzed.", "result": "Shallow MoEs can overcome the curse of dimensionality by efficiently approximating functions on low-dimensional manifolds. Deep MoEs can approximate an exponential number of structured tasks due to their ability to model piecewise functions with compositional sparsity.", "conclusion": "The study reveals the roles of key components in MoEs such as the gating mechanism, expert networks, number of experts, and layers, providing insights for designing effective MoE variants."}}
{"id": "2505.23812", "pdf": "https://arxiv.org/pdf/2505.23812", "abs": "https://arxiv.org/abs/2505.23812", "authors": ["Lata Pangtey", "Mohammad Zia Ur Rehman", "Prasad Chaudhari", "Shubhi Bansal", "Nagendra Kumar"], "title": "Emotion-aware Dual Cross-Attentive Neural Network with Label Fusion for Stance Detection in Misinformative Social Media Content", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "The rapid evolution of social media has generated an overwhelming volume of\nuser-generated content, conveying implicit opinions and contributing to the\nspread of misinformation. The method aims to enhance the detection of stance\nwhere misinformation can polarize user opinions. Stance detection has emerged\nas a crucial approach to effectively analyze underlying biases in shared\ninformation and combating misinformation. This paper proposes a novel method\nfor \\textbf{S}tance \\textbf{P}rediction through a \\textbf{L}abel-fused dual\ncross-\\textbf{A}ttentive \\textbf{E}motion-aware neural \\textbf{Net}work\n(SPLAENet) in misinformative social media user-generated content. The proposed\nmethod employs a dual cross-attention mechanism and a hierarchical attention\nnetwork to capture inter and intra-relationships by focusing on the relevant\nparts of source text in the context of reply text and vice versa. We\nincorporate emotions to effectively distinguish between different stance\ncategories by leveraging the emotional alignment or divergence between the\ntexts. We also employ label fusion that uses distance-metric learning to align\nextracted features with stance labels, improving the method's ability to\naccurately distinguish between stances. Extensive experiments demonstrate the\nsignificant improvements achieved by SPLAENet over existing state-of-the-art\nmethods. SPLAENet demonstrates an average gain of 8.92\\% in accuracy and\n17.36\\% in F1-score on the RumourEval dataset. On the SemEval dataset, it\nachieves average gains of 7.02\\% in accuracy and 10.92\\% in F1-score. On the\nP-stance dataset, it demonstrates average gains of 10.03\\% in accuracy and\n11.18\\% in F1-score. These results validate the effectiveness of the proposed\nmethod for stance detection in the context of misinformative social media\ncontent.", "AI": {"tldr": "The paper proposes SPLAENet, a novel method for stance prediction in misinformative social media content. It uses dual cross-attention, hierarchical attention, emotion incorporation, and label fusion to improve stance detection accuracy. Experiments show significant improvements over existing methods.", "motivation": "The motivation is the need to combat misinformation by effectively analyzing underlying biases in shared information through stance detection, which can polarize user opinions.", "method": "SPLAENet employs a dual cross-attention mechanism and a hierarchical attention network to capture inter and intra-relationships between source and reply texts. Emotions are incorporated to distinguish different stance categories based on emotional alignment or divergence. Label fusion using distance-metric learning aligns extracted features with stance labels.", "result": "SPLAENet achieves an average gain of 8.92% in accuracy and 17.36% in F1-score on the RumourEval dataset, 7.02% in accuracy and 10.92% in F1-score on the SemEval dataset, and 10.03% in accuracy and 11.18% in F1-score on the P-stance dataset.", "conclusion": "The proposed method demonstrates significant improvements in stance detection for misinformative social media content."}}
{"id": "2505.24243", "pdf": "https://arxiv.org/pdf/2505.24243", "abs": "https://arxiv.org/abs/2505.24243", "authors": ["Joohwan Ko", "Justin Domke"], "title": "Model Informed Flows for Bayesian Inference of Probabilistic Programs", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Variational inference often struggles with the posterior geometry exhibited\nby complex hierarchical Bayesian models. Recent advances in flow-based\nvariational families and Variationally Inferred Parameters (VIP) each address\naspects of this challenge, but their formal relationship is unexplored. Here,\nwe prove that the combination of VIP and a full-rank Gaussian can be\nrepresented exactly as a forward autoregressive flow augmented with a\ntranslation term and input from the model's prior. Guided by this theoretical\ninsight, we introduce the Model-Informed Flow (MIF) architecture, which adds\nthe necessary translation mechanism, prior information, and hierarchical\nordering. Empirically, MIF delivers tighter posterior approximations and\nmatches or exceeds state-of-the-art performance across a suite of hierarchical\nand non-hierarchical benchmarks.", "AI": {"tldr": "The paper combines VIP and a full-rank Gaussian into an exact representation of a forward autoregressive flow, introduces the MIF architecture for better posterior approximations.", "motivation": "Variational inference faces challenges with complex hierarchical Bayesian models due to posterior geometry. While advances in flow-based variational families and VIP address parts of this issue, their formal relationship remains unexplored.", "method": "Proves that combining VIP with a full-rank Gaussian equals a forward autoregressive flow plus translation and prior input; develops the MIF architecture incorporating translation, prior info, and hierarchy.", "result": "MIF provides tighter posterior approximations and matches or surpasses state-of-the-art performance on various benchmarks.", "conclusion": "MIF addresses challenges in variational inference for complex models by integrating theoretical insights and delivering superior empirical results."}}
{"id": "2505.23836", "pdf": "https://arxiv.org/pdf/2505.23836", "abs": "https://arxiv.org/abs/2505.23836", "authors": ["Joe Needham", "Giles Edkins", "Govind Pimpale", "Henning Bartsch", "Marius Hobbhahn"], "title": "Large Language Models Often Know When They Are Being Evaluated", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "If AI models can detect when they are being evaluated, the effectiveness of\nevaluations might be compromised. For example, models could have systematically\ndifferent behavior during evaluations, leading to less reliable benchmarks for\ndeployment and governance decisions. We investigate whether frontier language\nmodels can accurately classify transcripts based on whether they originate from\nevaluations or real-world deployment, a capability we call evaluation\nawareness. To achieve this, we construct a diverse benchmark of 1,000 prompts\nand transcripts from 61 distinct datasets. These span public benchmarks (e.g.,\nMMLU, SWEBench), real-world deployment interactions, and agent trajectories\nfrom scaffolding frameworks (e.g., web-browsing agents). Frontier models\nclearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches\nan AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of\n$0.92$). Furthermore, both AI models and humans are better at identifying\nevaluations in agentic settings compared to chat settings. Additionally, we\ntest whether models can identify the purpose of the evaluation. Under\nmultiple-choice and open-ended questioning, AI models far outperform random\nchance in identifying what an evaluation is testing for. Our results indicate\nthat frontier models already exhibit a substantial, though not yet superhuman,\nlevel of evaluation-awareness. We recommend tracking this capability in future\nmodels.", "AI": {"tldr": "\u5c3d\u7ba1\u524d\u6cbfAI\u6a21\u578b\uff08\u5982Gemini-2.5-Pro\uff0cAUC\u4e3a0.83\uff09\u5df2\u5c55\u73b0\u51fa\u663e\u8457\u7684\u8bc4\u4f30\u610f\u8bc6\u80fd\u529b\uff0c\u4f46\u4ecd\u672a\u8d85\u8d8a\u7b80\u5355\u7684\u4eba\u7c7b\u57fa\u51c6\uff08AUC\u4e3a0.92\uff09\u3002\u6b64\u5916\uff0c\u5728\u4ee3\u7406\u8bbe\u7f6e\u4e2d\uff0cAI\u6a21\u578b\u548c\u4eba\u7c7b\u66f4\u64c5\u957f\u8bc6\u522b\u8bc4\u4f30\u3002\u5e76\u4e14\uff0cAI\u6a21\u578b\u80fd\u591f\u8fdc\u8d85\u968f\u673a\u6c34\u5e73\u53bb\u8bc6\u522b\u8bc4\u4f30\u7684\u76ee\u7684\u3002\u56e0\u6b64\uff0c\u5efa\u8bae\u5728\u672a\u6765\u7684\u6a21\u578b\u4e2d\u8ffd\u8e2a\u8fd9\u4e00\u80fd\u529b\u3002", "motivation": "\u5982\u679cAI\u6a21\u578b\u80fd\u68c0\u6d4b\u5230\u5b83\u4eec\u6b63\u5728\u88ab\u8bc4\u4f30\uff0c\u90a3\u4e48\u8bc4\u4f30\u7684\u6709\u6548\u6027\u53ef\u80fd\u4f1a\u53d7\u5230\u635f\u5bb3\u3002\u4f8b\u5982\uff0c\u5728\u8bc4\u4f30\u671f\u95f4\u6a21\u578b\u7684\u884c\u4e3a\u53ef\u80fd\u7cfb\u7edf\u6027\u5730\u4e0d\u540c\uff0c\u8fd9\u5c06\u5bfc\u81f4\u7528\u4e8e\u90e8\u7f72\u548c\u6cbb\u7406\u51b3\u7b56\u7684\u57fa\u51c6\u53ef\u9760\u6027\u964d\u4f4e\u3002", "method": "\u6784\u5efa\u4e00\u4e2a\u5305\u542b1000\u4e2a\u63d0\u793a\u548c\u6765\u81ea61\u4e2a\u4e0d\u540c\u6570\u636e\u96c6\u7684\u8f6c\u5f55\u672c\u7684\u591a\u6837\u5316\u57fa\u51c6\uff0c\u8fd9\u4e9b\u6570\u636e\u96c6\u6db5\u76d6\u4e86\u516c\u5171\u57fa\u51c6\u3001\u73b0\u5b9e\u4e16\u754c\u90e8\u7f72\u4ea4\u4e92\u548c\u4ee3\u7406\u6846\u67b6\u7684\u4ee3\u7406\u8f68\u8ff9\u3002\u7136\u540e\u6d4b\u8bd5\u524d\u6cbf\u8bed\u8a00\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u6839\u636e\u8f6c\u5f55\u672c\u6765\u6e90\u662f\u8bc4\u4f30\u8fd8\u662f\u5b9e\u9645\u90e8\u7f72\u8fdb\u884c\u51c6\u786e\u5206\u7c7b\uff0c\u5e76\u8fdb\u4e00\u6b65\u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u8bc6\u522b\u8bc4\u4f30\u7684\u76ee\u7684\u3002", "result": "\u524d\u6cbf\u6a21\u578b\u5c55\u793a\u4e86\u9ad8\u4e8e\u968f\u673a\u6c34\u5e73\u7684\u8bc4\u4f30\u610f\u8bc6\uff08Gemini-2.5-Pro\u7684AUC\u4e3a0.83\uff09\uff0c\u4f46\u5c1a\u672a\u8d85\u8fc7\u7b80\u5355\u7684\u4eba\u7c7b\u57fa\u51c6\uff08AUC\u4e3a0.92\uff09\u3002\u6b64\u5916\uff0cAI\u6a21\u578b\u548c\u4eba\u7c7b\u5728\u4ee3\u7406\u8bbe\u7f6e\u4e2d\u6bd4\u5728\u804a\u5929\u8bbe\u7f6e\u4e2d\u66f4\u64c5\u957f\u8bc6\u522b\u8bc4\u4f30\u3002\u901a\u8fc7\u591a\u9879\u9009\u62e9\u548c\u5f00\u653e\u5f0f\u63d0\u95ee\uff0cAI\u6a21\u578b\u5728\u8bc6\u522b\u8bc4\u4f30\u76ee\u7684\u65b9\u9762\u8fdc\u8fdc\u8d85\u8fc7\u968f\u673a\u673a\u4f1a\u3002", "conclusion": "\u524d\u6cbf\u6a21\u578b\u5df2\u7ecf\u8868\u73b0\u51fa\u76f8\u5f53\u5927\u7684\u8bc4\u4f30\u610f\u8bc6\u80fd\u529b\uff0c\u4f46\u5c1a\u672a\u8fbe\u5230\u8d85\u4eba\u7684\u6c34\u5e73\u3002\u63a8\u8350\u5728\u672a\u6765\u7684\u6a21\u578b\u4e2d\u8ffd\u8e2a\u8fd9\u4e00\u80fd\u529b\u3002"}}
{"id": "2505.24254", "pdf": "https://arxiv.org/pdf/2505.24254", "abs": "https://arxiv.org/abs/2505.24254", "authors": ["Zheng Wang", "Wanhao Yu", "Li Yang", "Sen Lin"], "title": "Rethinking Continual Learning with Progressive Neural Collapse", "categories": ["cs.LG"], "comment": null, "summary": "Continual Learning (CL) seeks to build an agent that can continuously learn a\nsequence of tasks, where a key challenge, namely Catastrophic Forgetting,\npersists due to the potential knowledge interference among different tasks. On\nthe other hand, deep neural networks (DNNs) are shown to converge to a terminal\nstate termed Neural Collapse during training, where all class prototypes\ngeometrically form a static simplex equiangular tight frame (ETF). These\nmaximally and equally separated class prototypes make the ETF an ideal target\nfor model learning in CL to mitigate knowledge interference. Thus inspired,\nseveral studies have emerged very recently to leverage a fixed global ETF in\nCL, which however suffers from key drawbacks, such as impracticability and\nlimited performance.To address these challenges and fully unlock the potential\nof ETF in CL, we propose Progressive Neural Collapse (ProNC), a novel framework\nthat completely removes the need of a fixed global ETF in CL. Specifically,\nProNC progressively expands the ETF target in a principled way by adding new\nclass prototypes as vertices for new tasks, ensuring maximal separability\nacross all encountered classes with minimal shifts from the previous ETF. We\nnext develop a new CL framework by plugging ProNC into commonly used CL\nalgorithm designs, where distillation is further leveraged to balance between\ntarget shifting for old classes and target aligning for new classes. Extensive\nexperiments show that our approach significantly outperforms related baselines\nwhile maintaining superior flexibility, simplicity, and efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6301\u7eed\u5b66\u4e60\u6846\u67b6Progressive Neural Collapse (ProNC)\uff0c\u901a\u8fc7\u52a8\u6001\u6269\u5c55ETF\u76ee\u6807\u6765\u514b\u670d\u56fa\u5b9a\u5168\u5c40ETF\u7684\u7f3a\u70b9\uff0c\u663e\u8457\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\uff0c\u5e76\u4fdd\u6301\u7075\u6d3b\u6027\u3001\u7b80\u5355\u6027\u548c\u6548\u7387\u3002", "motivation": "\u6301\u7eed\u5b66\u4e60\u4e2d\u7684\u5173\u952e\u6311\u6218\u662f\u707e\u96be\u6027\u9057\u5fd8\uff0c\u800c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u4f1a\u6536\u655b\u5230\u795e\u7ecf\u5d29\u6e83\u72b6\u6001\uff0c\u5176\u4e2d\u7c7b\u522b\u539f\u578b\u5f62\u6210\u9759\u6001\u5355\u7eaf\u5f62\u7b49\u89d2\u7d27\u6846\u67b6(ETF)\uff0c\u8fd9\u4e3a\u7f13\u89e3\u77e5\u8bc6\u5e72\u6270\u63d0\u4f9b\u4e86\u7406\u60f3\u7684\u6a21\u578b\u5b66\u4e60\u76ee\u6807\u3002\u7136\u800c\uff0c\u4f7f\u7528\u56fa\u5b9a\u7684\u5168\u5c40ETF\u5b58\u5728\u4e0d\u5207\u5b9e\u9645\u548c\u6027\u80fd\u6709\u9650\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86Progressive Neural Collapse (ProNC)\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u901a\u8fc7\u4ee5\u539f\u5219\u6027\u65b9\u5f0f\u6dfb\u52a0\u65b0\u7c7b\u522b\u539f\u578b\u4f5c\u4e3a\u65b0\u4efb\u52a1\u7684\u9876\u70b9\uff0c\u9010\u6b65\u6269\u5c55ETF\u76ee\u6807\uff0c\u786e\u4fdd\u6240\u6709\u9047\u5230\u7684\u7c7b\u522b\u4e4b\u95f4\u5177\u6709\u6700\u5927\u53ef\u5206\u6027\uff0c\u5e76\u6700\u5c0f\u5316\u4ece\u5148\u524dETF\u7684\u504f\u79fb\u3002\u6b64\u5916\uff0c\u8fd8\u5c06ProNC\u96c6\u6210\u5230\u5e38\u89c1\u7684\u6301\u7eed\u5b66\u4e60\u7b97\u6cd5\u8bbe\u8ba1\u4e2d\uff0c\u5229\u7528\u84b8\u998f\u6280\u672f\u5e73\u8861\u65e7\u7c7b\u522b\u7684\u76ee\u6807\u504f\u79fb\u548c\u65b0\u7c7b\u522b\u7684\u76ee\u6807\u5bf9\u9f50\u3002", "result": "\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u76f8\u5173\u57fa\u7ebf\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u5353\u8d8a\u7684\u7075\u6d3b\u6027\u3001\u7b80\u5355\u6027\u548c\u6548\u7387\u3002", "conclusion": "Progressive Neural Collapse (ProNC)\u6846\u67b6\u514b\u670d\u4e86\u56fa\u5b9a\u5168\u5c40ETF\u7684\u7f3a\u70b9\uff0c\u5728\u6301\u7eed\u5b66\u4e60\u4e2d\u5c55\u73b0\u51fa\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u7279\u6027\u3002"}}
{"id": "2505.24261", "pdf": "https://arxiv.org/pdf/2505.24261", "abs": "https://arxiv.org/abs/2505.24261", "authors": ["Weiyi Wang", "Junwei Deng", "Yuzheng Hu", "Shiyuan Zhang", "Xirui Jiang", "Runting Zhang", "Han Zhao", "Jiaqi W. Ma"], "title": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "Data attribution methods, which quantify the influence of individual training\ndata points on a machine learning model, have gained increasing popularity in\ndata-centric applications in modern AI. Despite a recent surge of new methods\ndeveloped in this space, the impact of hyperparameter tuning in these methods\nremains under-explored. In this work, we present the first large-scale\nempirical study to understand the hyperparameter sensitivity of common data\nattribution methods. Our results show that most methods are indeed sensitive to\ncertain key hyperparameters. However, unlike typical machine learning\nalgorithms -- whose hyperparameters can be tuned using computationally-cheap\nvalidation metrics -- evaluating data attribution performance often requires\nretraining models on subsets of training data, making such metrics\nprohibitively costly for hyperparameter tuning. This poses a critical open\nchallenge for the practical application of data attribution methods. To address\nthis challenge, we advocate for better theoretical understandings of\nhyperparameter behavior to inform efficient tuning strategies. As a case study,\nwe provide a theoretical analysis of the regularization term that is critical\nin many variants of influence function methods. Building on this analysis, we\npropose a lightweight procedure for selecting the regularization value without\nmodel retraining, and validate its effectiveness across a range of standard\ndata attribution benchmarks. Overall, our study identifies a fundamental yet\noverlooked challenge in the practical application of data attribution, and\nhighlights the importance of careful discussion on hyperparameter selection in\nfuture method development.", "AI": {"tldr": "Data attribution methods are sensitive to hyperparameters, posing a challenge for practical application. This study advocates for better theoretical understanding and efficient tuning strategies, proposing a lightweight procedure for selecting the regularization value.", "motivation": "To understand the hyperparameter sensitivity of common data attribution methods and address the challenge it poses for practical application.", "method": "Presented the first large-scale empirical study on hyperparameter sensitivity of data attribution methods, provided a theoretical analysis of the regularization term in influence function methods, and proposed a lightweight procedure for selecting the regularization value without model retraining.", "result": "Most data attribution methods are sensitive to certain key hyperparameters. The proposed lightweight procedure for selecting the regularization value was validated as effective across a range of standard data attribution benchmarks.", "conclusion": "The study identified a fundamental challenge in the practical application of data attribution and emphasized the importance of careful discussion on hyperparameter selection in future method development."}}
{"id": "2505.24262", "pdf": "https://arxiv.org/pdf/2505.24262", "abs": "https://arxiv.org/abs/2505.24262", "authors": ["Hiroki Naganuma", "Kotaro Yoshida", "Laura Gomezjurado Gonzalez", "Takafumi Horie", "Yuji Naraki", "Ryotaro Shimizu"], "title": "On Fairness of Task Arithmetic: The Role of Task Vectors", "categories": ["cs.LG"], "comment": null, "summary": "Model editing techniques, particularly task arithmetic using task vectors,\nhave shown promise in efficiently modifying pre-trained models through\narithmetic operations like task addition and negation. Despite computational\nadvantages, these methods may inadvertently affect model fairness, creating\nrisks in sensitive applications like hate speech detection. However, the\nfairness implications of task arithmetic remain largely unexplored, presenting\na critical gap in the existing literature. We systematically examine how\nmanipulating task vectors affects fairness metrics, including Demographic\nParity and Equalized Odds. To rigorously assess these effects, we benchmark\ntask arithmetic against full fine-tuning, a costly but widely used baseline,\nand Low-Rank Adaptation (LoRA), a prevalent parameter-efficient fine-tuning\nmethod. Additionally, we explore merging task vectors from models fine-tuned on\ndemographic subgroups vulnerable to hate speech, investigating whether fairness\noutcomes can be controlled by adjusting task vector coefficients, potentially\nenabling tailored model behavior. Our results offer novel insights into the\nfairness implications of model editing and establish a foundation for\nfairness-aware and responsible model editing practices.", "AI": {"tldr": "Model editing techniques, especially task arithmetic using task vectors, can modify pre-trained models efficiently but may impact model fairness. This paper systematically examines the effects of manipulating task vectors on fairness metrics and compares them with full fine-tuning and LoRA methods. It also investigates merging task vectors from demographic subgroups to control fairness outcomes.", "motivation": "To explore the fairness implications of model editing techniques like task arithmetic using task vectors, which have computational advantages but may inadvertently affect model fairness in sensitive applications.", "method": "Systematically examine how manipulating task vectors affects fairness metrics by benchmarking against full fine-tuning and Low-Rank Adaptation (LoRA). Explore merging task vectors from models fine-tuned on demographic subgroups to control fairness outcomes.", "result": "The results provide novel insights into the fairness implications of model editing and demonstrate the potential to control fairness outcomes by adjusting task vector coefficients.", "conclusion": "This study establishes a foundation for fairness-aware and responsible model editing practices."}}
{"id": "2505.23851", "pdf": "https://arxiv.org/pdf/2505.23851", "abs": "https://arxiv.org/abs/2505.23851", "authors": ["Michael Shalyt", "Rotem Elimelech", "Ido Kaminer"], "title": "ASyMOB: Algebraic Symbolic Mathematical Operations Benchmark", "categories": ["cs.CL", "cs.AI", "cs.SC"], "comment": "Code repository: https://github.com/RamanujanMachine/ASyMOB Complete\n  benchmark dataset:\n  https://huggingface.co/datasets/Shalyt/ASyMOB-Algebraic_Symbolic_Mathematical_Operations_Benchmark", "summary": "Large language models (LLMs) are rapidly approaching the level of proficiency\nin university-level symbolic mathematics required for applications in advanced\nscience and technology. However, existing benchmarks fall short in assessing\nthe core skills of LLMs in symbolic mathematics-such as integration,\ndifferential equations, and algebraic simplification. To address this gap, we\nintroduce ASyMOB, a novel assessment framework focused exclusively on symbolic\nmanipulation, featuring 17,092 unique math challenges, organized by similarity\nand complexity. ASyMOB enables analysis of LLM generalization capabilities by\ncomparing performance in problems that differ by simple numerical or symbolic\n`perturbations'. Evaluated LLMs exhibit substantial degradation in performance\nfor all perturbation types (up to -70.3%), suggesting reliance on memorized\npatterns rather than deeper understanding of symbolic math, even among models\nachieving high baseline accuracy. Comparing LLM performance to computer algebra\nsystems, we identify examples where they fail while LLMs succeed, as well as\nproblems solved only by combining both approaches. Models capable of integrated\ncode execution yielded higher accuracy compared to their performance without\ncode, particularly stabilizing weaker models (up to +33.1% for certain\nperturbation types). Notably, the most advanced models (o4-mini, Gemini 2.5\nFlash) demonstrate not only high symbolic math proficiency (scoring 96.8% and\n97.6% on the unperturbed set), but also remarkable robustness against\nperturbations, (-21.7% and -21.2% vs. average -50.4% for the other models).\nThis may indicate a recent \"phase transition\" in the generalization\ncapabilities of frontier LLMs. It remains to be seen whether the path forward\nlies in deeper integration with sophisticated external tools, or in developing\nmodels so capable that symbolic math systems like CAS become unnecessary.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u7b26\u53f7\u6570\u5b66\u65b9\u9762\u7684\u80fd\u529b\u63a5\u8fd1\u5927\u5b66\u6c34\u5e73\uff0c\u4f46\u73b0\u6709\u57fa\u51c6\u65e0\u6cd5\u5145\u5206\u8bc4\u4f30\u5176\u6838\u5fc3\u6280\u80fd\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u5f15\u5165\u4e86ASyMOB\uff0c\u4e00\u4e2a\u4e13\u6ce8\u4e8e\u7b26\u53f7\u64cd\u4f5c\u7684\u8bc4\u4f30\u6846\u67b6\u3002\u901a\u8fc7\u5206\u6790LLMs\u5728\u4e0d\u540c\u6270\u52a8\u7c7b\u578b\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5176\u4f9d\u8d56\u4e8e\u8bb0\u5fc6\u6a21\u5f0f\u800c\u975e\u6df1\u5c42\u7406\u89e3\u3002\u7ed3\u5408\u4ee3\u7801\u6267\u884c\u80fd\u529b\u7684\u6a21\u578b\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u51c6\u786e\u6027\u3002\u6700\u5148\u8fdb\u6a21\u578b\u5c55\u73b0\u51fa\u9ad8\u7b26\u53f7\u6570\u5b66\u80fd\u529b\u548c\u5bf9\u6270\u52a8\u7684\u5f3a\u9c81\u68d2\u6027\uff0c\u53ef\u80fd\u6807\u5fd7\u7740\u524d\u6cbfLLMs\u6cdb\u5316\u80fd\u529b\u7684\u201c\u76f8\u53d8\u201d\u3002\u672a\u6765\u53d1\u5c55\u65b9\u5411\u5728\u4e8e\u66f4\u6df1\u5c42\u6b21\u7684\u5916\u90e8\u5de5\u5177\u96c6\u6210\u6216\u5f00\u53d1\u4f7fCAS\u7cfb\u7edf\u53d8\u5f97\u4e0d\u5fc5\u8981\u7684\u6a21\u578b\u3002", "motivation": "\u5f53\u524d\u8bc4\u4f30LLMs\u7b26\u53f7\u6570\u5b66\u80fd\u529b\u7684\u57fa\u51c6\u5b58\u5728\u4e0d\u8db3\uff0c\u65e0\u6cd5\u5168\u9762\u8861\u91cf\u5176\u6838\u5fc3\u6280\u80fd\uff0c\u5982\u79ef\u5206\u3001\u5fae\u5206\u65b9\u7a0b\u548c\u4ee3\u6570\u7b80\u5316\u7b49\u3002\u56e0\u6b64\u9700\u8981\u4e00\u4e2a\u65b0\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u63d0\u51faASyMOB\u8bc4\u4f30\u6846\u67b6\uff0c\u5305\u542b17,092\u4e2a\u72ec\u7279\u7684\u6570\u5b66\u6311\u6218\uff0c\u6309\u76f8\u4f3c\u6027\u548c\u590d\u6742\u6027\u7ec4\u7ec7\u3002\u901a\u8fc7\u6bd4\u8f83\u6a21\u578b\u5728\u7b80\u5355\u6570\u503c\u6216\u7b26\u53f7\u6270\u52a8\u95ee\u9898\u4e2d\u7684\u8868\u73b0\uff0c\u5206\u6790LLMs\u7684\u6cdb\u5316\u80fd\u529b\u3002\u540c\u65f6\u5bf9\u6bd4LLMs\u4e0e\u8ba1\u7b97\u673a\u4ee3\u6570\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "result": "\u88ab\u8bc4\u4f30\u7684LLMs\u5728\u6240\u6709\u6270\u52a8\u7c7b\u578b\u4e2d\u8868\u73b0\u663e\u8457\u4e0b\u964d\uff08\u9ad8\u8fbe-70.3%\uff09\uff0c\u8868\u660e\u5176\u4f9d\u8d56\u8bb0\u5fc6\u6a21\u5f0f\u800c\u975e\u6df1\u5c42\u7406\u89e3\u3002\u7ed3\u5408\u4ee3\u7801\u6267\u884c\u80fd\u529b\u7684\u6a21\u578b\u51c6\u786e\u7387\u66f4\u9ad8\uff0c\u7279\u522b\u662f\u5728\u67d0\u4e9b\u6270\u52a8\u7c7b\u578b\u4e2d\u53ef\u63d0\u5347+33.1%\u3002\u6700\u5148\u8fdb\u7684\u6a21\u578b\u5c55\u73b0\u51fa\u9ad8\u7b26\u53f7\u6570\u5b66\u80fd\u529b\u548c\u5bf9\u6270\u52a8\u7684\u5f3a\u9c81\u68d2\u6027\u3002", "conclusion": "\u6700\u5148\u8fdbLLMs\u5728\u7b26\u53f7\u6570\u5b66\u65b9\u9762\u5c55\u73b0\u51fa\u9ad8\u80fd\u529b\u548c\u5f3a\u9c81\u68d2\u6027\uff0c\u53ef\u80fd\u6807\u5fd7\u7740\u5176\u6cdb\u5316\u80fd\u529b\u7684\u201c\u76f8\u53d8\u201d\u3002\u672a\u6765\u7814\u7a76\u9700\u63a2\u8ba8\u662f\u901a\u8fc7\u66f4\u6df1\u5c42\u6b21\u7684\u5916\u90e8\u5de5\u5177\u96c6\u6210\u8fd8\u662f\u5f00\u53d1\u4f7fCAS\u7cfb\u7edf\u53d8\u5f97\u4e0d\u5fc5\u8981\u7684\u6a21\u578b\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u80fd\u529b\u3002"}}
{"id": "2505.24275", "pdf": "https://arxiv.org/pdf/2505.24275", "abs": "https://arxiv.org/abs/2505.24275", "authors": ["Mingze Wang", "Jinbo Wang", "Jiaqi Zhang", "Wei Wang", "Peng Pei", "Xunliang Cai", "Weinan E", "Lei Wu"], "title": "GradPower: Powering Gradients for Faster Language Model Pre-Training", "categories": ["cs.LG", "math.OC", "stat.ML"], "comment": "22 pages", "summary": "We propose GradPower, a lightweight gradient-transformation technique for\naccelerating language model pre-training. Given a gradient vector $g=(g_i)_i$,\nGradPower first applies the elementwise sign-power transformation:\n$\\varphi_p(g)=({\\rm sign}(g_i)|g_i|^p)_{i}$ for a fixed $p>0$, and then feeds\nthe transformed gradient into a base optimizer. Notably, GradPower requires\nonly a single-line code change and no modifications to the base optimizer's\ninternal logic, including the hyperparameters. When applied to Adam (termed\nAdamPower), GradPower consistently achieves lower terminal loss across diverse\narchitectures (LLaMA, Qwen2MoE), parameter scales (66M to 2B), datasets (C4,\nOpenWebText), and learning-rate schedules (cosine, warmup-stable-decay). The\nmost pronounced gains are observed when training modern mixture-of-experts\nmodels with warmup-stable-decay schedules. GradPower also integrates seamlessly\nwith other state-of-the-art optimizers, such as Muon, yielding further\nimprovements. Finally, we provide theoretical analyses that reveal the\nunderlying mechanism of GradPower and highlights the influence of gradient\nnoise.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aGradPower\u7684\u8f7b\u91cf\u7ea7\u68af\u5ea6\u8f6c\u6362\u6280\u672f\uff0c\u7528\u4e8e\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u7684\u9884\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u7b80\u5355\u7684\u4ee3\u7801\u66f4\u6539\uff0c\u65e0\u9700\u8c03\u6574\u57fa\u7840\u4f18\u5316\u5668\u7684\u5185\u90e8\u903b\u8f91\u548c\u8d85\u53c2\u6570\uff0c\u5373\u53ef\u663e\u8457\u964d\u4f4e\u591a\u79cd\u67b6\u6784\u3001\u53c2\u6570\u89c4\u6a21\u3001\u6570\u636e\u96c6\u548c\u5b66\u4e60\u7387\u8ba1\u5212\u4e0b\u7684\u6700\u7ec8\u635f\u5931\u3002\u7279\u522b\u662f\u5728\u4f7f\u7528warmup-stable-decay\u8ba1\u5212\u8bad\u7ec3\u73b0\u4ee3\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u65f6\uff0c\u6548\u679c\u6700\u4e3a\u663e\u8457\u3002\u6b64\u5916\uff0cGradPower\u8fd8\u53ef\u4e0e\u5176\u4ed6\u5148\u8fdb\u4f18\u5316\u5668\u7ed3\u5408\u4f7f\u7528\u4ee5\u8fdb\u4e00\u6b65\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5b58\u5728\u6548\u7387\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u4e14\u6709\u6548\u7684\u65b9\u6cd5\u6765\u52a0\u901f\u8fd9\u4e00\u8fc7\u7a0b\uff0c\u540c\u65f6\u4fdd\u6301\u6a21\u578b\u6027\u80fd\u3002", "method": "GradPower\u9996\u5148\u5bf9\u68af\u5ea6\u5411\u91cf\u5e94\u7528\u5143\u7d20\u7ea7\u7b26\u53f7\u5e42\u53d8\u6362\uff08sign-power transformation\uff09\uff0c\u7136\u540e\u5c06\u8f6c\u6362\u540e\u7684\u68af\u5ea6\u8f93\u5165\u57fa\u7840\u4f18\u5316\u5668\u3002\u6b64\u65b9\u6cd5\u4ec5\u9700\u5355\u884c\u4ee3\u7801\u66f4\u6539\uff0c\u4e0d\u6539\u53d8\u57fa\u7840\u4f18\u5316\u5668\u7684\u5185\u90e8\u903b\u8f91\u6216\u8d85\u53c2\u6570\u8bbe\u7f6e\u3002", "result": "GradPower\u5728\u4e0d\u540c\u67b6\u6784\uff08\u5982LLaMA\u3001Qwen2MoE\uff09\u3001\u53c2\u6570\u89c4\u6a21\uff0866M\u81f32B\uff09\u3001\u6570\u636e\u96c6\uff08C4\u3001OpenWebText\uff09\u53ca\u5b66\u4e60\u7387\u8ba1\u5212\uff08\u4f59\u5f26\u3001warmup-stable-decay\uff09\u4e0b\u5747\u80fd\u5b9e\u73b0\u66f4\u4f4e\u7684\u6700\u7ec8\u635f\u5931\uff0c\u5c24\u5176\u5728\u8bad\u7ec3\u73b0\u4ee3\u4e13\u5bb6\u6df7\u5408\u6a21\u578b\u65f6\u8868\u73b0\u7a81\u51fa\u3002", "conclusion": "GradPower\u662f\u4e00\u79cd\u6709\u6548\u7684\u68af\u5ea6\u8f6c\u6362\u6280\u672f\uff0c\u53ef\u52a0\u901f\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u5e76\u63d0\u9ad8\u6027\u80fd\uff0c\u4e14\u6613\u4e8e\u4e0e\u5176\u4ed6\u4f18\u5316\u5668\u7ed3\u5408\u4f7f\u7528\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u5176\u673a\u5236\u4ee5\u53ca\u68af\u5ea6\u566a\u58f0\u7684\u5f71\u54cd\u3002"}}
{"id": "2505.23852", "pdf": "https://arxiv.org/pdf/2505.23852", "abs": "https://arxiv.org/abs/2505.23852", "authors": ["Nic Dobbins", "Christelle Xiong", "Kristine Lan", "Meliha Yetisgen"], "title": "Large Language Model-Based Agents for Automated Research Reproducibility: An Exploratory Study in Alzheimer's Disease", "categories": ["cs.CL", "cs.AI", "cs.MA", "stat.AP"], "comment": null, "summary": "Objective: To demonstrate the capabilities of Large Language Models (LLMs) as\nautonomous agents to reproduce findings of published research studies using the\nsame or similar dataset.\n  Materials and Methods: We used the \"Quick Access\" dataset of the National\nAlzheimer's Coordinating Center (NACC). We identified highly cited published\nresearch manuscripts using NACC data and selected five studies that appeared\nreproducible using this dataset alone. Using GPT-4o, we created a simulated\nresearch team of LLM-based autonomous agents tasked with writing and executing\ncode to dynamically reproduce the findings of each study, given only study\nAbstracts, Methods sections, and data dictionary descriptions of the dataset.\n  Results: We extracted 35 key findings described in the Abstracts across 5\nAlzheimer's studies. On average, LLM agents approximately reproduced 53.2% of\nfindings per study. Numeric values and range-based findings often differed\nbetween studies and agents. The agents also applied statistical methods or\nparameters that varied from the originals, though overall trends and\nsignificance were sometimes similar.\n  Discussion: In some cases, LLM-based agents replicated research techniques\nand findings. In others, they failed due to implementation flaws or missing\nmethodological detail. These discrepancies show the current limits of LLMs in\nfully automating reproducibility assessments. Still, this early investigation\nhighlights the potential of structured agent-based systems to provide scalable\nevaluation of scientific rigor.\n  Conclusion: This exploratory work illustrates both the promise and\nlimitations of LLMs as autonomous agents for automating reproducibility in\nbiomedical research.", "AI": {"tldr": "This paper explores the ability of Large Language Models (LLMs) to autonomously reproduce findings from published biomedical research using the same dataset. The study used GPT-4o to simulate a research team that reproduced about 53.2% of findings across five Alzheimer's studies, highlighting both potential and limitations of LLMs in automating reproducibility assessments.", "motivation": "To evaluate the capabilities of LLMs as autonomous agents for reproducing published research findings in biomedical field using the same or similar dataset, thereby assessing their potential for automating reproducibility assessments.", "method": "The 'Quick Access' dataset from the National Alzheimer's Coordinating Center was utilized. Highly cited manuscripts using NACC data were identified, and five reproducible studies were selected. A simulated research team of LLM-based autonomous agents (using GPT-4o) was created to write and execute code for reproducing the findings based solely on study Abstracts, Methods sections, and data dictionary descriptions.", "result": "Across five Alzheimer's studies, LLM agents approximately reproduced 53.2% of key findings described in the Abstracts. Discrepancies were found in numeric values, range-based findings, and applied statistical methods compared to the original studies.", "conclusion": "The study demonstrates the potential and current limitations of LLMs as autonomous agents for automating reproducibility in biomedical research."}}
{"id": "2505.24293", "pdf": "https://arxiv.org/pdf/2505.24293", "abs": "https://arxiv.org/abs/2505.24293", "authors": ["James R. Golden"], "title": "Large Language Models are Locally Linear Mappings", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Version 0", "summary": "We demonstrate that the inference operations of several open-weight large\nlanguage models (LLMs) can be mapped to an exactly equivalent linear system for\nan input sequence without modifying the model weights or altering output\npredictions. Extending techniques from image diffusion models that exhibit\nlocal or piecewise linearity, we strategically alter the gradient computation\nwith respect to a given input sequence for a next-token prediction such that\nthe Jacobian of the model nearly exactly reproduces the forward prediction with\na linear system. We demonstrate this approach across models (Llama 3, Gemma 3,\nQwen 3, Phi 4, Mistral Ministral and OLMo 2, up to Llama 3.3 70B Q4) and show\nthrough the singular value decomposition of the detached Jacobian that these\nLLMs operate in extremely low-dimensional subspaces where many of the largest\nsingular vectors decode to concepts related to the most-likely output token.\nThis approach also allows us to examine the operation of each successive layer\n(and its attention and MLP components) as nearly-exact linear systems and\nobserve the emergence of semantic concepts. Despite their expressive power and\nglobal nonlinearity, modern LLMs can be interpreted through nearly-exact\nlocally linear decompositions that provide insights into their internal\nrepresentations and reveal interpretable semantic structures in the next-token\nprediction process.", "AI": {"tldr": "\u5c3d\u7ba1\u73b0\u4ee3\u5927\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u5177\u6709\u8868\u8fbe\u80fd\u529b\u548c\u5168\u5c40\u975e\u7ebf\u6027\uff0c\u4f46\u5b83\u4eec\u53ef\u4ee5\u901a\u8fc7\u8fd1\u4e4e\u7cbe\u786e\u7684\u5c40\u90e8\u7ebf\u6027\u5206\u89e3\u6765\u89e3\u91ca\uff0c\u8fd9\u4e3a\u7406\u89e3\u5176\u5185\u90e8\u8868\u793a\u548c\u63ed\u793a\u4e0b\u4e00\u4f4d\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u7684\u53ef\u89e3\u91ca\u8bed\u4e49\u7ed3\u6784\u63d0\u4f9b\u4e86\u6d1e\u5bdf\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u63a2\u7d22\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u64cd\u4f5c\u4e2d\u7684\u7ebf\u6027\u7279\u6027\uff0c\u5e76\u901a\u8fc7\u6620\u5c04\u5230\u4e00\u4e2a\u7b49\u6548\u7684\u7ebf\u6027\u7cfb\u7edf\uff0c\u65e0\u9700\u4fee\u6539\u6a21\u578b\u6743\u91cd\u6216\u6539\u53d8\u8f93\u51fa\u9884\u6d4b\uff0c\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u8fd9\u4e9b\u6a21\u578b\u7684\u5de5\u4f5c\u539f\u7406\u3002", "method": "\u901a\u8fc7\u6269\u5c55\u56fe\u50cf\u6269\u6563\u6a21\u578b\u4e2d\u5c55\u793a\u7684\u5c40\u90e8\u6216\u5206\u6bb5\u7ebf\u6027\u6280\u672f\uff0c\u7814\u7a76\u8005\u6218\u7565\u6027\u5730\u6539\u53d8\u4e86\u5173\u4e8e\u7ed9\u5b9a\u8f93\u5165\u5e8f\u5217\u8fdb\u884c\u4e0b\u4e00\u4e2a\u6807\u8bb0\u9884\u6d4b\u7684\u68af\u5ea6\u8ba1\u7b97\uff0c\u4f7f\u5f97\u6a21\u578b\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u51e0\u4e4e\u7cbe\u786e\u5730\u91cd\u73b0\u4e86\u5e26\u6709\u7ebf\u6027\u7cfb\u7edf\u7684\u524d\u5411\u9884\u6d4b\u3002\u7136\u540e\u5bf9\u5206\u79bb\u7684\u96c5\u53ef\u6bd4\u77e9\u9635\u8fdb\u884c\u5947\u5f02\u503c\u5206\u89e3\uff0c\u89c2\u5bdf\u5230\u8fd9\u4e9bLLMs\u5728\u6781\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u8fd0\u884c\uff0c\u5176\u4e2d\u8bb8\u591a\u6700\u5927\u7684\u5947\u5f02\u5411\u91cf\u89e3\u7801\u4e3a\u4e0e\u6700\u53ef\u80fd\u7684\u8f93\u51fa\u6807\u8bb0\u76f8\u5173\u7684\u6982\u5ff5\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u6a21\u578b\uff08\u5982Llama 3\u3001Gemma 3\u3001Qwen 3\u7b49\uff09\u4e0a\u8fdb\u884c\u4e86\u6f14\u793a\uff0c\u7ed3\u679c\u8868\u660e\u73b0\u4ee3LLMs\u53ef\u4ee5\u901a\u8fc7\u8fd1\u4e4e\u7cbe\u786e\u7684\u5c40\u90e8\u7ebf\u6027\u5206\u89e3\u6765\u89e3\u91ca\uff0c\u4ece\u800c\u63d0\u4f9b\u5bf9\u5176\u5185\u90e8\u8868\u793a\u7684\u6d1e\u5bdf\uff0c\u5e76\u63ed\u793a\u4e0b\u4e00\u4f4d\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u7684\u53ef\u89e3\u91ca\u8bed\u4e49\u7ed3\u6784\u3002", "conclusion": "\u73b0\u4ee3LLMs\u5c3d\u7ba1\u5177\u6709\u8868\u8fbe\u80fd\u529b\u548c\u5168\u5c40\u975e\u7ebf\u6027\uff0c\u4f46\u53ef\u4ee5\u901a\u8fc7\u5c40\u90e8\u7ebf\u6027\u5206\u89e3\u6765\u89e3\u91ca\uff0c\u8fd9\u79cd\u5206\u89e3\u63d0\u4f9b\u4e86\u5bf9\u6a21\u578b\u5185\u90e8\u8868\u793a\u7684\u6d1e\u5bdf\uff0c\u5e76\u63ed\u793a\u4e86\u4e0b\u4e00\u4f4d\u9884\u6d4b\u8fc7\u7a0b\u4e2d\u53ef\u89e3\u91ca\u7684\u8bed\u4e49\u7ed3\u6784\u3002"}}
{"id": "2505.23854", "pdf": "https://arxiv.org/pdf/2505.23854", "abs": "https://arxiv.org/abs/2505.23854", "authors": ["Linwei Tao", "Yi-Fan Yeh", "Minjing Dong", "Tao Huang", "Philip Torr", "Chang Xu"], "title": "Revisiting Uncertainty Estimation and Calibration of Large Language Models", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "As large language models (LLMs) are increasingly deployed in high-stakes\napplications, robust uncertainty estimation is essential for ensuring the safe\nand trustworthy deployment of LLMs. We present the most comprehensive study to\ndate of uncertainty estimation in LLMs, evaluating 80 models spanning open- and\nclosed-source families, dense and Mixture-of-Experts (MoE) architectures,\nreasoning and non-reasoning modes, quantization variants and parameter scales\nfrom 0.6B to 671B. Focusing on three representative black-box single-pass\nmethods, including token probability-based uncertainty (TPU), numerical verbal\nuncertainty (NVU), and linguistic verbal uncertainty (LVU), we systematically\nevaluate uncertainty calibration and selective classification using the\nchallenging MMLU-Pro benchmark, which covers both reasoning-intensive and\nknowledge-based tasks. Our results show that LVU consistently outperforms TPU\nand NVU, offering stronger calibration and discrimination while being more\ninterpretable. We also find that high accuracy does not imply reliable\nuncertainty, and that model scale, post-training, reasoning ability and\nquantization all influence estimation performance. Notably, LLMs exhibit better\nuncertainty estimates on reasoning tasks than on knowledge-heavy ones, and good\ncalibration does not necessarily translate to effective error ranking. These\nfindings highlight the need for multi-perspective evaluation and position LVU\nas a practical tool for improving the reliability of LLMs in real-world\nsettings.", "AI": {"tldr": "In this paper, researchers comprehensively study uncertainty estimation in large language models (LLMs), evaluating 80 models using various methods and tasks. They find that linguistic verbal uncertainty (LVU) outperforms other methods and emphasize the need for multi-perspective evaluation.", "motivation": "There is a growing need for robust uncertainty estimation as LLMs are increasingly used in high-stakes applications to ensure safe and trustworthy deployment.", "method": "The study evaluates 80 LLMs across different categories using three black-box single-pass methods: token probability-based uncertainty (TPU), numerical verbal uncertainty (NVU), and linguistic verbal uncertainty (LVU). The challenging MMLU-Pro benchmark was used for systematic evaluation of uncertainty calibration and selective classification.", "result": "LVU consistently outperforms TPU and NVU with stronger calibration and discrimination while being more interpretable. High accuracy does not imply reliable uncertainty, and factors like model scale, post-training, reasoning ability, and quantization influence estimation performance. LLMs show better uncertainty estimates on reasoning tasks than knowledge-heavy ones.", "conclusion": "The findings underline the importance of multi-perspective evaluation of LLMs and establish LVU as a practical tool for enhancing reliability in real-world settings."}}
{"id": "2505.24298", "pdf": "https://arxiv.org/pdf/2505.24298", "abs": "https://arxiv.org/abs/2505.24298", "authors": ["Wei Fu", "Jiaxuan Gao", "Xujie Shen", "Chen Zhu", "Zhiyu Mei", "Chuyi He", "Shusheng Xu", "Guo Wei", "Jun Mei", "Jiashu Wang", "Tongkai Yang", "Binhang Yuan", "Yi Wu"], "title": "AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Reinforcement learning (RL) has become a trending paradigm for training large\nlanguage models (LLMs), particularly for reasoning tasks. Effective RL for LLMs\nrequires massive parallelization and poses an urgent need for efficient\ntraining systems. Most existing large-scale RL systems for LLMs are synchronous\nby alternating generation and training in a batch setting, where the rollouts\nin each training batch are generated by the same (or latest) model. This\nstabilizes RL training but suffers from severe system-level inefficiency.\nGeneration must wait until the longest output in the batch is completed before\nmodel update, resulting in GPU underutilization. We present AReaL, a\n\\emph{fully asynchronous} RL system that completely decouples generation from\ntraining. Rollout workers in AReaL continuously generate new outputs without\nwaiting, while training workers update the model whenever a batch of data is\ncollected. AReaL also incorporates a collection of system-level optimizations,\nleading to substantially higher GPU utilization. To stabilize RL training,\nAReaL balances the workload of rollout and training workers to control data\nstaleness, and adopts a staleness-enhanced PPO variant to better handle\noutdated training samples. Extensive experiments on math and code reasoning\nbenchmarks show that AReaL achieves \\textbf{up to 2.57$\\times$ training\nspeedup} compared to the best synchronous systems with the same number of GPUs\nand matched or even improved final performance. The code of AReaL is available\nat https://github.com/inclusionAI/AReaL/.", "AI": {"tldr": "AReaL is a fully asynchronous RL system for LLMs that decouples generation from training, incorporates system-level optimizations for higher GPU utilization, balances workload to control data staleness, and uses a staleness-enhanced PPO variant. It achieves up to 2.57\u00d7 training speedup with improved or matched final performance.", "motivation": "Effective reinforcement learning (RL) for large language models (LLMs) requires massive parallelization and efficient training systems. Current synchronous RL systems suffer from system-level inefficiency due to waiting times in batch processing which leads to GPU underutilization.", "method": "AReaL completely decouples generation from training allowing rollout workers to continuously generate new outputs without waiting while training workers update the model whenever a batch of data is collected. System-level optimizations are incorporated for better GPU utilization and a staleness-enhanced PPO variant is used to handle outdated training samples effectively.", "result": "Extensive experiments on math and code reasoning benchmarks show that AReaL achieves up to 2.57\u00d7 training speedup compared to the best synchronous systems with the same number of GPUs, while maintaining or improving final performance.", "conclusion": "AReaL presents an efficient, fully asynchronous RL system for LLMs that significantly improves training speed and GPU utilization while stabilizing RL training through workload balancing and a staleness-enhanced PPO variant."}}
{"id": "2505.23856", "pdf": "https://arxiv.org/pdf/2505.23856", "abs": "https://arxiv.org/abs/2505.23856", "authors": ["Sahil Verma", "Keegan Hines", "Jeff Bilmes", "Charlotte Siska", "Luke Zettlemoyer", "Hila Gonen", "Chandan Singh"], "title": "OMNIGUARD: An Efficient Approach for AI Safety Moderation Across Modalities", "categories": ["cs.CL", "cs.AI", "cs.HC", "cs.LG"], "comment": null, "summary": "The emerging capabilities of large language models (LLMs) have sparked\nconcerns about their immediate potential for harmful misuse. The core approach\nto mitigate these concerns is the detection of harmful queries to the model.\nCurrent detection approaches are fallible, and are particularly susceptible to\nattacks that exploit mismatched generalization of model capabilities (e.g.,\nprompts in low-resource languages or prompts provided in non-text modalities\nsuch as image and audio). To tackle this challenge, we propose OMNIGUARD, an\napproach for detecting harmful prompts across languages and modalities. Our\napproach (i) identifies internal representations of an LLM/MLLM that are\naligned across languages or modalities and then (ii) uses them to build a\nlanguage-agnostic or modality-agnostic classifier for detecting harmful\nprompts. OMNIGUARD improves harmful prompt classification accuracy by 11.57\\%\nover the strongest baseline in a multilingual setting, by 20.44\\% for\nimage-based prompts, and sets a new SOTA for audio-based prompts. By\nrepurposing embeddings computed during generation, OMNIGUARD is also very\nefficient ($\\approx 120 \\times$ faster than the next fastest baseline). Code\nand data are available at: https://github.com/vsahil/OmniGuard.", "AI": {"tldr": "OMNIGUARD is a new approach that can detect harmful prompts across languages and modalities, achieving significant improvements in accuracy and efficiency.", "motivation": "The increasing capabilities of LLMs bring concerns about harmful misuse. Current detection approaches have limitations, especially for low-resource languages or non-text modalities.", "method": "OMNIGUARD identifies aligned internal representations of an LLM/MLLM across languages or modalities and uses them to build a language-agnostic or modality-agnostic classifier.", "result": "OMNIGUARD improves classification accuracy by 11.57% in multilingual settings, 20.44% for image-based prompts, and sets a new SOTA for audio-based prompts. It is also very efficient (\u2248120\u00d7 faster than the next fastest baseline).", "conclusion": "OMNIGUARD provides a robust and efficient solution for detecting harmful prompts across languages and modalities."}}
{"id": "2505.24313", "pdf": "https://arxiv.org/pdf/2505.24313", "abs": "https://arxiv.org/abs/2505.24313", "authors": ["Gengze Xu", "Wei Yao", "Ziqiao Wang", "Yong Liu"], "title": "On the Emergence of Weak-to-Strong Generalization: A Bias-Variance Perspective", "categories": ["cs.LG"], "comment": null, "summary": "Weak-to-strong generalization (W2SG) refers to the phenomenon where a strong\nstudent model, trained on a dataset labeled by a weak teacher, ultimately\noutperforms the teacher on the target task. Recent studies attribute this\nperformance gain to the prediction misfit between the student and teacher\nmodels. In this work, we theoretically investigate the emergence of W2SG\nthrough a generalized bias-variance decomposition of Bregman divergence.\nSpecifically, we show that the expected population risk gap between the student\nand teacher is quantified by the expected misfit between the two models. While\nthis aligns with previous results, our analysis removes several restrictive\nassumptions, most notably, the convexity of the student's hypothesis class,\nrequired in earlier works. Moreover, we show that W2SG is more likely to emerge\nwhen the student model approximates its posterior mean teacher, rather than\nmimicking an individual teacher. Using a concrete example, we demonstrate that\nif the student model has significantly larger capacity than the teacher, it can\nindeed converge to this posterior mean. Our analysis also suggests that\navoiding overfitting to the teacher's supervision and reducing the entropy of\nstudent's prediction further facilitate W2SG. In addition, we show that the\nreverse cross-entropy loss, unlike the standard forward cross-entropy, is less\nsensitive to the predictive uncertainty of the teacher. Finally, we empirically\nverify our theoretical insights and demonstrate that incorporating the reverse\ncross-entropy loss consistently improves student performance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5f31\u5230\u5f3a\u6cdb\u5316\uff08W2SG\uff09\u73b0\u8c61\uff0c\u901a\u8fc7\u5e7f\u4e49\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u548c\u5e03\u96f7\u683c\u66fc\u6563\u5ea6\u5206\u6790\uff0c\u63ed\u793a\u4e86\u5b66\u751f\u6a21\u578b\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\u7684\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u53cd\u5411\u4ea4\u53c9\u71b5\u635f\u5931\u80fd\u6709\u6548\u63d0\u5347\u5b66\u751f\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u7814\u7a76\u8005\u5e0c\u671b\u7406\u89e3\u5f31\u5230\u5f3a\u6cdb\u5316\uff08W2SG\uff09\u73b0\u8c61\u80cc\u540e\u7684\u539f\u56e0\uff0c\u7279\u522b\u662f\u5b66\u751f\u6a21\u578b\u5982\u4f55\u5728\u4f7f\u7528\u7531\u8f83\u5f31\u6559\u5e08\u6a21\u578b\u6807\u6ce8\u7684\u6570\u636e\u8bad\u7ec3\u540e\uff0c\u6700\u7ec8\u8d85\u8d8a\u6559\u5e08\u6a21\u578b\u7684\u8868\u73b0\u3002", "method": "\u4f5c\u8005\u901a\u8fc7\u5e7f\u4e49\u504f\u5dee-\u65b9\u5dee\u5206\u89e3\u548c\u5e03\u96f7\u683c\u66fc\u6563\u5ea6\u7684\u7406\u8bba\u5206\u6790\uff0c\u91cf\u5316\u4e86\u5b66\u751f\u4e0e\u6559\u5e08\u6a21\u578b\u4e4b\u95f4\u7684\u98ce\u9669\u5dee\u8ddd\uff0c\u5e76\u63a2\u8ba8\u4e86\u5b66\u751f\u6a21\u578b\u903c\u8fd1\u540e\u9a8c\u5747\u503c\u6559\u5e08\u800c\u975e\u5355\u4e00\u6559\u5e08\u7684\u91cd\u8981\u6027\u3002\u540c\u65f6\uff0c\u7814\u7a76\u4e86\u53cd\u5411\u4ea4\u53c9\u71b5\u635f\u5931\u5bf9\u5b66\u751f\u6a21\u578b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5f53\u5b66\u751f\u6a21\u578b\u5bb9\u91cf\u663e\u8457\u5927\u4e8e\u6559\u5e08\u6a21\u578b\u65f6\uff0c\u53ef\u4ee5\u6536\u655b\u5230\u540e\u9a8c\u5747\u503c\u6559\u5e08\uff0c\u4ece\u800c\u4fc3\u8fdbW2SG\u73b0\u8c61\u7684\u53d1\u751f\u3002\u6b64\u5916\uff0c\u5b9e\u9a8c\u8bc1\u660e\u53cd\u5411\u4ea4\u53c9\u71b5\u635f\u5931\u80fd\u591f\u6301\u7eed\u63d0\u9ad8\u5b66\u751f\u6a21\u578b\u7684\u6027\u80fd\u3002", "conclusion": "W2SG\u73b0\u8c61\u53ef\u4ee5\u901a\u8fc7\u51cf\u5c11\u5b66\u751f\u6a21\u578b\u5bf9\u6559\u5e08\u76d1\u7763\u7684\u8fc7\u62df\u5408\u3001\u964d\u4f4e\u9884\u6d4b\u71b5\u4ee5\u53ca\u4f7f\u7528\u53cd\u5411\u4ea4\u53c9\u71b5\u635f\u5931\u6765\u4fc3\u8fdb\u3002\u8fd9\u4e9b\u53d1\u73b0\u4e3a\u8bbe\u8ba1\u66f4\u6709\u6548\u7684\u5b66\u751f\u6a21\u578b\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2505.24317", "pdf": "https://arxiv.org/pdf/2505.24317", "abs": "https://arxiv.org/abs/2505.24317", "authors": ["Yongming Chen", "Miner Chen", "Liewen Liao", "Mingyang Jiang", "Xiang Zuo", "Hengrui Zhang", "Yuchen Xi", "Songan Zhang"], "title": "ROAD: Responsibility-Oriented Reward Design for Reinforcement Learning in Autonomous Driving", "categories": ["cs.LG"], "comment": null, "summary": "Reinforcement learning (RL) in autonomous driving employs a trial-and-error\nmechanism, enhancing robustness in unpredictable environments. However,\ncrafting effective reward functions remains challenging, as conventional\napproaches rely heavily on manual design and demonstrate limited efficacy in\ncomplex scenarios. To address this issue, this study introduces a\nresponsibility-oriented reward function that explicitly incorporates traffic\nregulations into the RL framework. Specifically, we introduced a Traffic\nRegulation Knowledge Graph and leveraged Vision-Language Models alongside\nRetrieval-Augmented Generation techniques to automate reward assignment. This\nintegration guides agents to adhere strictly to traffic laws, thus minimizing\nrule violations and optimizing decision-making performance in diverse driving\nconditions. Experimental validations demonstrate that the proposed methodology\nsignificantly improves the accuracy of assigning accident responsibilities and\neffectively reduces the agent's liability in traffic incidents.", "AI": {"tldr": "This paper proposes a responsibility-oriented reward function in reinforcement learning for autonomous driving by incorporating traffic regulations through a Traffic Regulation Knowledge Graph and Vision-Language Models, improving decision-making performance and reducing rule violations.", "motivation": "Reward functions in RL for autonomous driving are difficult to design effectively due to reliance on manual design and inefficacy in complex scenarios.", "method": "Introduction of a responsibility-oriented reward function that integrates traffic regulations via a Traffic Regulation Knowledge Graph and Vision-Language Models with Retrieval-Augmented Generation techniques to automate reward assignment.", "result": "The methodology improves the accuracy of assigning accident responsibilities and reduces the agent's liability in traffic incidents.", "conclusion": "Incorporating traffic regulations into the RL framework via automated reward assignment enhances robustness and optimizes decision-making in autonomous driving."}}
{"id": "2505.24324", "pdf": "https://arxiv.org/pdf/2505.24324", "abs": "https://arxiv.org/abs/2505.24324", "authors": ["Ivan Petrukha", "Yana Kurliak", "Nataliia Stulova"], "title": "SwiftEval: Developing a Language-Specific Benchmark for LLM-generated Code Evaluation", "categories": ["cs.LG", "cs.CL", "cs.PL", "cs.SE"], "comment": "Accepted to FORGE'25 Benchmarking on 15.01.2025, to be published by\n  IEEE under the CC BY-NC-ND 4.0 license. This is the accepted version of the\n  article (5 pages, 2 figures, 1 table). DOI will be added upon publication", "summary": "In recent years, large language models (LLMs) have showcased significant\nadvancements in code generation. However, most evaluation benchmarks are\nprimarily oriented towards Python, making it difficult to evaluate other\nprogramming languages, such as Swift, with high quality. By examining widely\nestablished multilingual benchmarks like HumanEval-XL and MultiPL-E, we\nidentified critical issues specific to their Swift components, making them\ninsufficient or even irrelevant for assessing LLM coding capabilities on Swift.\nUnlike these existing approaches, which prioritize rapid scaling and\ngeneralization by automatically translating Python-centric benchmarks with\nLLMs, we adopt a quality-over-quantity methodology. We present SwiftEval, the\nfirst Swift-oriented benchmark consisting of 28 carefully hand-crafted\nproblems, and evaluate 44 popular Code LLMs on it. Our results show significant\nLLM scores drop for problems requiring language-specific features, most\nnoticeable in the models of smaller sizes.", "AI": {"tldr": "In recent years, large language models have made significant progress in code generation. However, most evaluation benchmarks are mainly aimed at Python, making it difficult to evaluate other programming languages such as Swift. The paper presents SwiftEval, the first Swift-oriented benchmark consisting of 28 carefully hand-crafted problems, and evaluates 44 popular Code LLMs on it.", "motivation": "Most evaluation benchmarks for large language models are primarily oriented towards Python, making it difficult to evaluate other programming languages such as Swift with high quality.", "method": "The authors identified critical issues specific to Swift components in widely established multilingual benchmarks like HumanEval-XL and MultiPL-E. They adopted a quality-over-quantity methodology and presented SwiftEval, the first Swift-oriented benchmark consisting of 28 carefully hand-crafted problems.", "result": "Significant LLM scores drop for problems requiring language-specific features, especially noticeable in the models of smaller sizes.", "conclusion": "SwiftEval provides a high-quality benchmark for evaluating large language models' coding capabilities on Swift."}}
{"id": "2505.23860", "pdf": "https://arxiv.org/pdf/2505.23860", "abs": "https://arxiv.org/abs/2505.23860", "authors": ["Giovanni Acampora", "Andris Ambainis", "Natalia Ares", "Leonardo Banchi", "Pallavi Bhardwaj", "Daniele Binosi", "G. Andrew D. Briggs", "Tommaso Calarco", "Vedran Dunjko", "Jens Eisert", "Olivier Ezratty", "Paul Erker", "Federico Fedele", "Elies Gil-Fuster", "Martin G\u00e4rttner", "Mats Granath", "Markus Heyl", "Iordanis Kerenidis", "Matthias Klusch", "Anton Frisk Kockum", "Richard Kueng", "Mario Krenn", "J\u00f6rg L\u00e4ssig", "Antonio Macaluso", "Sabrina Maniscalco", "Florian Marquardt", "Kristel Michielsen", "Gorka Mu\u00f1oz-Gil", "Daniel M\u00fcssig", "Hendrik Poulsen Nautrup", "Evert van Nieuwenburg", "Roman Orus", "J\u00f6rg Schmiedmayer", "Markus Schmitt", "Philipp Slusallek", "Filippo Vicentini", "Christof Weitenberg", "Frank K. Wilhelm"], "title": "Quantum computing and artificial intelligence: status and perspectives", "categories": ["quant-ph", "cs.AI", "cs.LG"], "comment": "32 pages, 3 figures", "summary": "This white paper discusses and explores the various points of intersection\nbetween quantum computing and artificial intelligence (AI). It describes how\nquantum computing could support the development of innovative AI solutions. It\nalso examines use cases of classical AI that can empower research and\ndevelopment in quantum technologies, with a focus on quantum computing and\nquantum sensing. The purpose of this white paper is to provide a long-term\nresearch agenda aimed at addressing foundational questions about how AI and\nquantum computing interact and benefit one another. It concludes with a set of\nrecommendations and challenges, including how to orchestrate the proposed\ntheoretical work, align quantum AI developments with quantum hardware roadmaps,\nestimate both classical and quantum resources - especially with the goal of\nmitigating and optimizing energy consumption - advance this emerging hybrid\nsoftware engineering discipline, and enhance European industrial\ncompetitiveness while considering societal implications.", "AI": {"tldr": "This white paper explores the intersection of quantum computing and AI, discussing mutual benefits, use cases, and providing a long-term research agenda with recommendations.", "motivation": "To understand the interaction and mutual benefits between quantum computing and AI, and to provide a long-term research agenda addressing foundational questions and challenges in this field.", "method": "Discussion and exploration of various points of intersection between quantum computing and AI, examination of classical AI use cases empowering quantum technology research, and proposal of a research agenda.", "result": "Identification of how quantum computing can support innovative AI solutions and how classical AI can empower quantum technologies, along with a set of recommendations for advancing the field.", "conclusion": "The paper concludes with recommendations on orchestrating theoretical work, aligning developments with hardware roadmaps, estimating resources, optimizing energy consumption, advancing software engineering in the field, and enhancing industrial competitiveness while considering societal impacts."}}
{"id": "2505.24353", "pdf": "https://arxiv.org/pdf/2505.24353", "abs": "https://arxiv.org/abs/2505.24353", "authors": ["Federico Milanesio", "Matteo Santoro", "Pietro G. Fr\u00e9", "Guido Sanguinetti"], "title": "Cartan Networks: Group theoretical Hyperbolic Deep Learning", "categories": ["cs.LG"], "comment": "20 pages, 3 figures, under review", "summary": "Hyperbolic deep learning leverages the metric properties of hyperbolic spaces\nto develop efficient and informative embeddings of hierarchical data. Here, we\nfocus on the solvable group structure of hyperbolic spaces, which follows\nnaturally from their construction as symmetric spaces. This dual nature of Lie\ngroup and Riemannian manifold allows us to propose a new class of hyperbolic\ndeep learning algorithms where group homomorphisms are interleaved with\nmetric-preserving diffeomorphisms. The resulting algorithms, which we call\nCartan networks, show promising results on various benchmark data sets and open\nthe way to a novel class of hyperbolic deep learning architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u53cc\u66f2\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\u2014\u2014Cartan\u7f51\u7edc\uff0c\u901a\u8fc7\u7ed3\u5408\u7fa4\u540c\u6001\u548c\u5ea6\u91cf\u4fdd\u6301\u7684\u5fae\u5206\u540c\u80da\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5e76\u4e3a\u53cc\u66f2\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002", "motivation": "\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u7684\u53ef\u89e3\u7fa4\u7ed3\u6784\u548c\u5bf9\u79f0\u7a7a\u95f4\u6784\u9020\u7684\u81ea\u7136\u5c5e\u6027\uff0c\u63a2\u7d22\u5176Lie\u7fa4\u548cRiemann\u6d41\u5f62\u7684\u53cc\u91cd\u7279\u6027\uff0c\u4ee5\u6539\u8fdb\u5c42\u6b21\u6570\u636e\u7684\u5d4c\u5165\u65b9\u6cd5\u3002", "method": "\u5c06\u7fa4\u540c\u6001\u4e0e\u5ea6\u91cf\u4fdd\u6301\u7684\u5fae\u5206\u540c\u80da\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u51fa\u4e00\u7c7b\u65b0\u7684\u53cc\u66f2\u6df1\u5ea6\u5b66\u4e60\u7b97\u6cd5\uff0c\u79f0\u4e3aCartan\u7f51\u7edc\u3002", "result": "\u5728\u5404\u79cd\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6709\u5e0c\u671b\u7684\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u7b97\u6cd5\u7684\u6709\u6548\u6027\u3002", "conclusion": "Cartan\u7f51\u7edc\u7684\u6210\u529f\u5e94\u7528\u4e3a\u53cc\u66f2\u6df1\u5ea6\u5b66\u4e60\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u7814\u7a76\u65b9\u5411\u548c\u67b6\u6784\u53ef\u80fd\u6027\u3002"}}
{"id": "2505.24357", "pdf": "https://arxiv.org/pdf/2505.24357", "abs": "https://arxiv.org/abs/2505.24357", "authors": ["Xianglong Yan", "Zhiteng Li", "Tianao Zhang", "Linghe Kong", "Yulun Zhang", "Xiaokang Yang"], "title": "ReCalKV: Low-Rank KV Cache Compression via Head Reordering and Offline Calibration", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have achieved remarkable performance, yet their\ncapability on long-context reasoning is often constrained by the excessive\nmemory required to store the Key-Value (KV) cache. This makes KV cache\ncompression an essential step toward enabling efficient long-context reasoning.\nRecent methods have explored reducing the hidden dimensions of the KV cache,\nbut many introduce additional computation through projection layers or suffer\nfrom significant performance degradation under high compression ratios. To\naddress these challenges, we propose ReCalKV, a post-training KV cache\ncompression method that reduces the hidden dimensions of the KV cache. We\ndevelop distinct compression strategies for Keys and Values based on their\ndifferent roles and varying importance in the attention mechanism. For Keys, we\npropose Head-wise Similarity-aware Reordering (HSR), which clusters similar\nheads and applies grouped SVD to the key projection matrix, reducing additional\ncomputation while preserving accuracy. For Values, we propose Offline\nCalibration and Matrix Fusion (OCMF) to preserve accuracy without extra\ncomputational overhead. Experiments show that ReCalKV outperforms existing\nlow-rank compression methods, achieving high compression ratios with minimal\nperformance loss. Code is available at:\nhttps://github.com/XIANGLONGYAN/ReCalKV.", "AI": {"tldr": "ReCalKV is a post-training KV cache compression method for large language models that reduces hidden dimensions of the KV cache through distinct strategies for Keys and Values, achieving high compression ratios with minimal performance loss.", "motivation": "Large language models face challenges in long-context reasoning due to the excessive memory required to store the Key-Value (KV) cache. Existing methods for reducing the hidden dimensions of the KV cache either introduce additional computation or suffer from significant performance degradation under high compression ratios.", "method": "The paper proposes ReCalKV, which includes two main strategies: Head-wise Similarity-aware Reordering (HSR) for Keys and Offline Calibration and Matrix Fusion (OCMF) for Values. HSR clusters similar heads and applies grouped SVD to the key projection matrix, while OCMF preserves accuracy without extra computational overhead.", "result": "Experiments show that ReCalKV outperforms existing low-rank compression methods, achieving high compression ratios with minimal performance loss.", "conclusion": "ReCalKV provides an effective solution for KV cache compression in large language models, enabling more efficient long-context reasoning."}}
{"id": "2505.23862", "pdf": "https://arxiv.org/pdf/2505.23862", "abs": "https://arxiv.org/abs/2505.23862", "authors": ["Zheng Gong", "Ziyi Jiang", "Weihao Gao", "Deng Zhuo", "Lan Ma"], "title": "A New Deep-learning-Based Approach For mRNA Optimization: High Fidelity, Computation Efficiency, and Multiple Optimization Factors", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": "You can also contact hudenjear@gmail.com for more information", "summary": "The mRNA optimization is critical for therapeutic and biotechnological\napplications, since sequence features directly govern protein expression levels\nand efficacy. However, current methods face significant challenges in\nsimultaneously achieving three key objectives: (1) fidelity (preventing\nunintended amino acid changes), (2) computational efficiency (speed and\nscalability), and (3) the scope of optimization variables considered\n(multi-objective capability). Furthermore, existing methods often fall short of\ncomprehensively incorporating the factors related to the mRNA lifecycle and\ntranslation process, including intrinsic mRNA sequence properties, secondary\nstructure, translation elongation kinetics, and tRNA availability. To address\nthese limitations, we introduce \\textbf{RNop}, a novel deep learning-based\nmethod for mRNA optimization. We collect a large-scale dataset containing over\n3 million sequences and design four specialized loss functions, the GPLoss,\nCAILoss, tAILoss, and MFELoss, which simultaneously enable explicit control\nover sequence fidelity while optimizing species-specific codon adaptation, tRNA\navailability, and desirable mRNA secondary structure features. Then, we\ndemonstrate RNop's effectiveness through extensive in silico and in vivo\nexperiments. RNop ensures high sequence fidelity, achieves significant\ncomputational throughput up to 47.32 sequences/s, and yields optimized mRNA\nsequences resulting in a significant increase in protein expression for\nfunctional proteins compared to controls. RNop surpasses current methodologies\nin both quantitative metrics and experimental validation, enlightening a new\ndawn for efficient and effective mRNA design. Code and models will be available\nat https://github.com/HudenJear/RPLoss.", "AI": {"tldr": "The paper introduces RNop, a deep learning-based method for mRNA optimization that addresses current limitations in fidelity, computational efficiency, and multi-objective capability.", "motivation": "Current mRNA optimization methods struggle to achieve fidelity, computational efficiency, and comprehensive consideration of optimization variables simultaneously. They also often lack incorporation of factors related to the mRNA lifecycle and translation process.", "method": "The authors developed RNop using a large-scale dataset of over 3 million sequences and designed four specialized loss functions (GPLoss, CAILoss, tAILoss, MFELoss) to control sequence fidelity while optimizing codon adaptation, tRNA availability, and mRNA secondary structure features.", "result": "RNop ensures high sequence fidelity, achieves significant computational throughput (47.32 sequences/s), and increases protein expression levels in functional proteins compared to controls. It surpasses existing methodologies in both quantitative metrics and experimental validation.", "conclusion": "RNop represents a new approach for efficient and effective mRNA design, with potential for therapeutic and biotechnological applications."}}
{"id": "2505.24360", "pdf": "https://arxiv.org/pdf/2505.24360", "abs": "https://arxiv.org/abs/2505.24360", "authors": ["Stepan Shabalin", "Ayush Panda", "Dmitrii Kharlapenko", "Abdur Raheem Ali", "Yixiong Hao", "Arthur Conmy"], "title": "Interpreting Large Text-to-Image Diffusion Models with Dictionary Learning", "categories": ["cs.LG"], "comment": "10 pages, 10 figures, Mechanistic Interpretability for Vision at CVPR\n  2025", "summary": "Sparse autoencoders are a promising new approach for decomposing language\nmodel activations for interpretation and control. They have been applied\nsuccessfully to vision transformer image encoders and to small-scale diffusion\nmodels. Inference-Time Decomposition of Activations (ITDA) is a recently\nproposed variant of dictionary learning that takes the dictionary to be a set\nof data points from the activation distribution and reconstructs them with\ngradient pursuit. We apply Sparse Autoencoders (SAEs) and ITDA to a large\ntext-to-image diffusion model, Flux 1, and consider the interpretability of\nembeddings of both by introducing a visual automated interpretation pipeline.\nWe find that SAEs accurately reconstruct residual stream embeddings and beat\nMLP neurons on interpretability. We are able to use SAE features to steer image\ngeneration through activation addition. We find that ITDA has comparable\ninterpretability to SAEs.", "AI": {"tldr": "Sparse Autoencoders (SAEs) and Inference-Time Decomposition of Activations (ITDA) are applied to a large text-to-image diffusion model, Flux 1. SAEs accurately reconstruct residual stream embeddings and outperform MLP neurons on interpretability. SAE features can steer image generation through activation addition. ITDA has similar interpretability to SAEs.", "motivation": "To explore the effectiveness of Sparse Autoencoders (SAEs) and Inference-Time Decomposition of Activations (ITDA) in interpreting and controlling large text-to-image diffusion models, particularly Flux 1.", "method": "Applied Sparse Autoencoders (SAEs) and Inference-Time Decomposition of Activations (ITDA) to the Flux 1 text-to-image diffusion model. Introduced a visual automated interpretation pipeline to assess the interpretability of embeddings from both methods.", "result": "SAEs accurately reconstructed residual stream embeddings and demonstrated better interpretability than MLP neurons. SAE features were used to successfully steer image generation through activation addition. ITDA showed comparable interpretability to SAEs.", "conclusion": "Sparse Autoencoders and ITDA are effective for interpreting large text-to-image diffusion models like Flux 1, with SAEs showing strong reconstruction and interpretability capabilities, and ITDA being similarly interpretable."}}
{"id": "2505.24365", "pdf": "https://arxiv.org/pdf/2505.24365", "abs": "https://arxiv.org/abs/2505.24365", "authors": ["Vardhan Shorewala", "Shivam Shorewala"], "title": "Anomaly Detection and Improvement of Clusters using Enhanced K-Means Algorithm", "categories": ["cs.LG", "cs.PF"], "comment": "IEEE ICCCSP", "summary": "This paper introduces a unified approach to cluster refinement and anomaly\ndetection in datasets. We propose a novel algorithm that iteratively reduces\nthe intra-cluster variance of N clusters until a global minimum is reached,\nyielding tighter clusters than the standard k-means algorithm. We evaluate the\nmethod using intrinsic measures for unsupervised learning, including the\nsilhouette coefficient, Calinski-Harabasz index, and Davies-Bouldin index, and\nextend it to anomaly detection by identifying points whose assignment causes a\nsignificant variance increase. External validation on synthetic data and the\nUCI Breast Cancer and UCI Wine Quality datasets employs the Jaccard similarity\nscore, V-measure, and F1 score. Results show variance reductions of 18.7% and\n88.1% on the synthetic and Wine Quality datasets, respectively, along with\naccuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality\ndataset.", "AI": {"tldr": "This paper proposes a unified approach for cluster refinement and anomaly detection, which reduces intra-cluster variance more effectively than k-means, as demonstrated by evaluations using various indices and external validation on multiple datasets.", "motivation": "To develop a method that refines clusters more tightly than the standard k-means algorithm and extends it to detect anomalies in datasets.", "method": "A novel algorithm iteratively decreases intra-cluster variance of N clusters until reaching a global minimum. Anomaly detection is achieved by identifying points causing significant variance increase.", "result": "The algorithm reduced variance by 18.7% and 88.1% on synthetic and Wine Quality datasets respectively, with accuracy and F1 score improvements of 22.5% and 20.8% on the Wine Quality dataset.", "conclusion": "The proposed approach effectively refines clusters and detects anomalies, outperforming k-means in terms of variance reduction and classification performance."}}
{"id": "2505.24369", "pdf": "https://arxiv.org/pdf/2505.24369", "abs": "https://arxiv.org/abs/2505.24369", "authors": ["Yuanfu Wang", "Pengyu Wang", "Chenyang Xi", "Bo Tang", "Junyi Zhu", "Wenqiang Wei", "Chen Chen", "Chao Yang", "Jingfeng Zhang", "Chaochao Lu", "Yijun Niu", "Keming Mao", "Zhiyu Li", "Feiyu Xiong", "Jie Hu", "Mingchuan Yang"], "title": "Adversarial Preference Learning for Robust LLM Alignment", "categories": ["cs.LG", "cs.AI"], "comment": "Accepted at ACL2025 Findings", "summary": "Modern language models often rely on Reinforcement Learning from Human\nFeedback (RLHF) to encourage safe behaviors. However, they remain vulnerable to\nadversarial attacks due to three key limitations: (1) the inefficiency and high\ncost of human annotation, (2) the vast diversity of potential adversarial\nattacks, and (3) the risk of feedback bias and reward hacking. To address these\nchallenges, we introduce Adversarial Preference Learning (APL), an iterative\nadversarial training method incorporating three key innovations. First, a\ndirect harmfulness metric based on the model's intrinsic preference\nprobabilities, eliminating reliance on external assessment. Second, a\nconditional generative attacker that synthesizes input-specific adversarial\nvariations. Third, an iterative framework with automated closed-loop feedback,\nenabling continuous adaptation through vulnerability discovery and mitigation.\nExperiments on Mistral-7B-Instruct-v0.3 demonstrate that APL significantly\nenhances robustness, achieving 83.33% harmlessness win rate over the base model\n(evaluated by GPT-4o), reducing harmful outputs from 5.88% to 0.43% (measured\nby LLaMA-Guard), and lowering attack success rate by up to 65% according to\nHarmBench. Notably, APL maintains competitive utility, with an MT-Bench score\nof 6.59 (comparable to the baseline 6.78) and an LC-WinRate of 46.52% against\nthe base model.", "AI": {"tldr": "Adversarial Preference Learning (APL) is developed to enhance the robustness of language models against adversarial attacks by introducing a direct harmfulness metric, conditional generative attacker, and iterative framework. Experiments show APL significantly improves harmlessness while maintaining utility.", "motivation": "Modern language models using RLHF are still vulnerable to adversarial attacks due to inefficiency and cost of human annotation, diversity of attacks, and risk of feedback bias and reward hacking.", "method": "APL incorporates three innovations: a direct harmfulness metric based on intrinsic preference probabilities, a conditional generative attacker for synthesizing adversarial variations, and an iterative closed-loop feedback framework for continuous adaptation.", "result": "APL achieves 83.33% harmlessness win rate, reduces harmful outputs from 5.88% to 0.43%, lowers attack success rate by up to 65%, maintains competitive utility with MT-Bench score of 6.59 and LC-WinRate of 46.52%.", "conclusion": "APL significantly enhances the robustness of language models against adversarial attacks while preserving their utility."}}
{"id": "2505.24378", "pdf": "https://arxiv.org/pdf/2505.24378", "abs": "https://arxiv.org/abs/2505.24378", "authors": ["Yilun Kong", "Guozheng Ma", "Qi Zhao", "Haoyu Wang", "Li Shen", "Xueqian Wang", "Dacheng Tao"], "title": "Mastering Massive Multi-Task Reinforcement Learning via Mixture-of-Expert Decision Transformer", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025", "summary": "Despite recent advancements in offline multi-task reinforcement learning\n(MTRL) have harnessed the powerful capabilities of the Transformer\narchitecture, most approaches focus on a limited number of tasks, with scaling\nto extremely massive tasks remaining a formidable challenge. In this paper, we\nfirst revisit the key impact of task numbers on current MTRL method, and\nfurther reveal that naively expanding the parameters proves insufficient to\ncounteract the performance degradation as the number of tasks escalates.\nBuilding upon these insights, we propose M3DT, a novel mixture-of-experts (MoE)\nframework that tackles task scalability by further unlocking the model's\nparameter scalability. Specifically, we enhance both the architecture and the\noptimization of the agent, where we strengthen the Decision Transformer (DT)\nbackbone with MoE to reduce task load on parameter subsets, and introduce a\nthree-stage training mechanism to facilitate efficient training with optimal\nperformance. Experimental results show that, by increasing the number of\nexperts, M3DT not only consistently enhances its performance as model expansion\non the fixed task numbers, but also exhibits remarkable task scalability,\nsuccessfully extending to 160 tasks with superior performance.", "AI": {"tldr": "The paper proposes M3DT, a mixture-of-experts framework for multi-task reinforcement learning that improves performance and task scalability.", "motivation": "Current multi-task reinforcement learning methods struggle with scaling to a large number of tasks; simply increasing parameters does not solve the issue of performance degradation as task numbers grow.", "method": "M3DT enhances Decision Transformer with a mixture-of-experts approach to reduce task load on parameter subsets and introduces a three-stage training mechanism for efficient optimization.", "result": "M3DT shows consistent performance improvement with increased number of experts and successfully scales to 160 tasks with superior results.", "conclusion": "M3DT addresses the challenge of task scalability in multi-task reinforcement learning by leveraging model parameter scalability through a mixture-of-experts framework."}}
{"id": "2505.23867", "pdf": "https://arxiv.org/pdf/2505.23867", "abs": "https://arxiv.org/abs/2505.23867", "authors": ["Zeyu Liu", "Zhitian Hou", "Yining Di", "Kejing Yang", "Zhijie Sang", "Congkai Xie", "Jingwen Yang", "Siyuan Liu", "Jialu Wang", "Chunming Li", "Ming Li", "Hongxia Yang"], "title": "Infi-Med: Low-Resource Medical MLLMs with Robust Reasoning Evaluation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) have demonstrated promising\nprospects in healthcare, particularly for addressing complex medical tasks,\nsupporting multidisciplinary treatment (MDT), and enabling personalized\nprecision medicine. However, their practical deployment faces critical\nchallenges in resource efficiency, diagnostic accuracy, clinical\nconsiderations, and ethical privacy. To address these limitations, we propose\nInfi-Med, a comprehensive framework for medical MLLMs that introduces three key\ninnovations: (1) a resource-efficient approach through curating and\nconstructing high-quality supervised fine-tuning (SFT) datasets with minimal\nsample requirements, with a forward-looking design that extends to both\npretraining and posttraining phases; (2) enhanced multimodal reasoning\ncapabilities for cross-modal integration and clinical task understanding; and\n(3) a systematic evaluation system that assesses model performance across\nmedical modalities and task types. Our experiments demonstrate that Infi-Med\nachieves state-of-the-art (SOTA) performance in general medical reasoning while\nmaintaining rapid adaptability to clinical scenarios. The framework establishes\na solid foundation for deploying MLLMs in real-world healthcare settings by\nbalancing model effectiveness with operational constraints.", "AI": {"tldr": "Infi-Med is a framework for medical MLLMs with three key innovations that addresses challenges in resource efficiency, diagnostic accuracy, clinical considerations, and ethical privacy. It achieves SOTA performance in general medical reasoning.", "motivation": "Multimodal large language models show potential in healthcare but face challenges in practical deployment such as resource efficiency, diagnostic accuracy, clinical considerations, and ethical privacy.", "method": "Proposes Infi-Med, a framework with three innovations: 1) resource-efficient approach with high-quality SFT datasets; 2) enhanced multimodal reasoning capabilities; 3) systematic evaluation system.", "result": "Experiments show Infi-Med achieves state-of-the-art performance in general medical reasoning while being adaptable to clinical scenarios.", "conclusion": "Infi-Med provides a strong foundation for deploying MLLMs in real-world healthcare settings by balancing model effectiveness and operational constraints."}}
{"id": "2505.24399", "pdf": "https://arxiv.org/pdf/2505.24399", "abs": "https://arxiv.org/abs/2505.24399", "authors": ["Yifei Cheng", "Li Shen", "Hao Sun", "Nan Yin", "Xiaochun Cao", "Enhong Chen"], "title": "LightSAM: Parameter-Agnostic Sharpness-Aware Minimization", "categories": ["cs.LG"], "comment": null, "summary": "Sharpness-Aware Minimization (SAM) optimizer enhances the generalization\nability of the machine learning model by exploring the flat minima landscape\nthrough weight perturbations. Despite its empirical success, SAM introduces an\nadditional hyper-parameter, the perturbation radius, which causes the\nsensitivity of SAM to it. Moreover, it has been proved that the perturbation\nradius and learning rate of SAM are constrained by problem-dependent parameters\nto guarantee convergence. These limitations indicate the requirement of\nparameter-tuning in practical applications. In this paper, we propose the\nalgorithm LightSAM which sets the perturbation radius and learning rate of SAM\nadaptively, thus extending the application scope of SAM. LightSAM employs three\npopular adaptive optimizers, including AdaGrad-Norm, AdaGrad and Adam, to\nreplace the SGD optimizer for weight perturbation and model updating, reducing\nsensitivity to parameters. Theoretical results show that under weak\nassumptions, LightSAM could converge ideally with any choices of perturbation\nradius and learning rate, thus achieving parameter-agnostic. We conduct\npreliminary experiments on several deep learning tasks, which together with the\ntheoretical findings validate the the effectiveness of LightSAM.", "AI": {"tldr": "LightSAM\u662f\u4e00\u79cd\u6539\u8fdb\u7684SAM\u7b97\u6cd5\uff0c\u5b83\u901a\u8fc7\u4f7f\u7528\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08\u5982AdaGrad-Norm\u3001AdaGrad\u548cAdam\uff09\u66ff\u4ee3SGD\u4f18\u5316\u5668\uff0c\u4ece\u800c\u80fd\u591f\u81ea\u9002\u5e94\u5730\u8bbe\u7f6e\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\uff0c\u51cf\u5c11\u4e86\u53c2\u6570\u654f\u611f\u6027\u5e76\u6269\u5c55\u4e86SAM\u7684\u5e94\u7528\u8303\u56f4\u3002\u7406\u8bba\u5206\u6790\u8868\u660e\uff0cLightSAM\u5728\u8f83\u5f31\u5047\u8bbe\u4e0b\u53ef\u4ee5\u5b9e\u73b0\u7406\u60f3\u6536\u655b\uff0c\u5e76\u4e14\u5bf9\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\u7684\u9009\u62e9\u5177\u6709\u9c81\u68d2\u6027\u3002\u5b9e\u9a8c\u7ed3\u679c\u9a8c\u8bc1\u4e86LightSAM\u7684\u6709\u6548\u6027\u3002", "motivation": "\u5c3d\u7ba1Sharpness-Aware Minimization (SAM) \u5728\u63d0\u9ad8\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5b83\u5b58\u5728\u5bf9\u6270\u52a8\u534a\u5f84\u8fd9\u4e00\u8d85\u53c2\u6570\u7684\u654f\u611f\u6027\u95ee\u9898\uff0c\u540c\u65f6\u5176\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\u53d7\u95ee\u9898\u76f8\u5173\u53c2\u6570\u7ea6\u675f\u4ee5\u4fdd\u8bc1\u6536\u655b\u3002\u8fd9\u5bfc\u81f4\u5b9e\u9645\u5e94\u7528\u4e2d\u9700\u8981\u8fdb\u884c\u53c2\u6570\u8c03\u4f18\uff0c\u589e\u52a0\u4e86\u590d\u6742\u6027\u3002\u56e0\u6b64\uff0c\u7814\u7a76\u8005\u5e0c\u671b\u8bbe\u8ba1\u4e00\u79cd\u65e0\u9700\u624b\u52a8\u8c03\u53c2\u7684SAM\u53d8\u4f53\uff0c\u8fdb\u4e00\u6b65\u6269\u5c55\u5176\u5e94\u7528\u8303\u56f4\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aLightSAM\u7684\u65b0\u7b97\u6cd5\uff0c\u8be5\u7b97\u6cd5\u91c7\u7528\u4e09\u79cd\u81ea\u9002\u5e94\u4f18\u5316\u5668\uff08AdaGrad-Norm\u3001AdaGrad\u548cAdam\uff09\u5206\u522b\u66ff\u6362SAM\u4e2d\u539f\u6709\u7684SGD\u4f18\u5316\u5668\u7528\u4e8e\u6743\u91cd\u6270\u52a8\u548c\u6a21\u578b\u66f4\u65b0\u3002\u8fd9\u79cd\u65b9\u6cd5\u964d\u4f4e\u4e86\u5bf9\u8d85\u53c2\u6570\uff08\u5982\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\uff09\u7684\u654f\u611f\u6027\uff0c\u4f7f\u5f97\u7b97\u6cd5\u5728\u7406\u8bba\u4e0a\u80fd\u591f\u4ee5\u4efb\u4f55\u53c2\u6570\u9009\u62e9\u5b9e\u73b0\u7406\u60f3\u6536\u655b\uff0c\u8fbe\u5230\u53c2\u6570\u65e0\u5173\u7684\u6548\u679c\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff0c\u5728\u8f83\u5f31\u5047\u8bbe\u6761\u4ef6\u4e0b\uff0cLightSAM\u53ef\u4ee5\u5b9e\u73b0\u7406\u60f3\u6536\u655b\uff0c\u4e14\u5bf9\u6270\u52a8\u534a\u5f84\u548c\u5b66\u4e60\u7387\u7684\u9009\u62e9\u5177\u6709\u9c81\u68d2\u6027\u3002\u521d\u6b65\u5b9e\u9a8c\u7ed3\u679c\u5728\u591a\u4e2a\u6df1\u5ea6\u5b66\u4e60\u4efb\u52a1\u4e0a\u9a8c\u8bc1\u4e86LightSAM\u7684\u6709\u6548\u6027\u3002", "conclusion": "LightSAM\u901a\u8fc7\u5f15\u5165\u81ea\u9002\u5e94\u4f18\u5316\u5668\u89e3\u51b3\u4e86SAM\u5bf9\u8d85\u53c2\u6570\u654f\u611f\u7684\u95ee\u9898\uff0c\u6269\u5927\u4e86SAM\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u826f\u597d\u7684\u6536\u655b\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2505.24403", "pdf": "https://arxiv.org/pdf/2505.24403", "abs": "https://arxiv.org/abs/2505.24403", "authors": ["Giannis Nikolentzos", "Konstantinos Skianis"], "title": "On the Lipschitz Continuity of Set Aggregation Functions and Neural Networks for Sets", "categories": ["cs.LG"], "comment": null, "summary": "The Lipschitz constant of a neural network is connected to several important\nproperties of the network such as its robustness and generalization. It is thus\nuseful in many settings to estimate the Lipschitz constant of a model. Prior\nwork has focused mainly on estimating the Lipschitz constant of multi-layer\nperceptrons and convolutional neural networks. Here we focus on data modeled as\nsets or multisets of vectors and on neural networks that can handle such data.\nThese models typically apply some permutation invariant aggregation function,\nsuch as the sum, mean or max operator, to the input multisets to produce a\nsingle vector for each input sample. In this paper, we investigate whether\nthese aggregation functions are Lipschitz continuous with respect to three\ndistance functions for unordered multisets, and we compute their Lipschitz\nconstants. In the general case, we find that each aggregation function is\nLipschitz continuous with respect to only one of the three distance functions.\nThen, we build on these results to derive upper bounds on the Lipschitz\nconstant of neural networks that can process multisets of vectors, while we\nalso study their stability to perturbations and generalization under\ndistribution shifts. To empirically verify our theoretical analysis, we conduct\na series of experiments on datasets from different domains.", "AI": {"tldr": "This paper explores the Lipschitz continuity of aggregation functions in neural networks designed for set or multiset data, computing their constants and deriving upper bounds for network Lipschitz constants, with empirical validation.", "motivation": "To understand and improve the robustness and generalization of neural networks that process set or multiset data by analyzing the Lipschitz continuity of aggregation functions used in these networks.", "method": "Investigate the Lipschitz continuity of common aggregation functions (sum, mean, max) with respect to three distance functions for unordered multisets. Derive upper bounds on the Lipschitz constant for neural networks processing multisets and study stability and generalization under distribution shifts.", "result": "Found that each aggregation function is Lipschitz continuous with respect to only one of the three distance functions. Derived theoretical upper bounds on the Lipschitz constant of neural networks for multisets and empirically verified these findings through experiments on datasets from various domains.", "conclusion": "Aggregation functions in neural networks for set/multiset data have specific Lipschitz properties depending on the distance metric used. These properties can be leveraged to better understand and enhance the robustness and generalization of such networks."}}
{"id": "2505.24413", "pdf": "https://arxiv.org/pdf/2505.24413", "abs": "https://arxiv.org/abs/2505.24413", "authors": ["Yang Sui", "Qi Xu", "Yang Bai", "Annie Qu"], "title": "Multi-task Learning for Heterogeneous Multi-source Block-Wise Missing Data", "categories": ["cs.LG", "stat.CO"], "comment": null, "summary": "Multi-task learning (MTL) has emerged as an imperative machine learning tool\nto solve multiple learning tasks simultaneously and has been successfully\napplied to healthcare, marketing, and biomedical fields. However, in order to\nborrow information across different tasks effectively, it is essential to\nutilize both homogeneous and heterogeneous information. Among the extensive\nliterature on MTL, various forms of heterogeneity are presented in MTL\nproblems, such as block-wise, distribution, and posterior heterogeneity.\nExisting methods, however, struggle to tackle these forms of heterogeneity\nsimultaneously in a unified framework. In this paper, we propose a two-step\nlearning strategy for MTL which addresses the aforementioned heterogeneity.\nFirst, we impute the missing blocks using shared representations extracted from\nhomogeneous source across different tasks. Next, we disentangle the mappings\nbetween input features and responses into a shared component and a\ntask-specific component, respectively, thereby enabling information borrowing\nthrough the shared component. Our numerical experiments and real-data analysis\nfrom the ADNI database demonstrate the superior MTL performance of the proposed\nmethod compared to other competing methods.", "AI": {"tldr": "The paper proposes a two-step Multi-task learning (MTL) strategy to handle various heterogeneities in MTL problems.", "motivation": "Existing methods for Multi-task learning struggle to address different forms of heterogeneity simultaneously in a unified framework, such as block-wise, distribution, and posterior heterogeneity.", "method": "The method involves imputing missing blocks using shared representations from homogeneous sources across tasks, then disentangling the mappings between input features and responses into a shared component and a task-specific component.", "result": "Numerical experiments and real-data analysis from the ADNI database show that the proposed method performs better than other competing methods in Multi-task learning.", "conclusion": "The proposed two-step learning strategy for Multi-task learning effectively addresses various forms of heterogeneity and shows superior performance."}}
{"id": "2505.24415", "pdf": "https://arxiv.org/pdf/2505.24415", "abs": "https://arxiv.org/abs/2505.24415", "authors": ["Andreas Spilz", "Heiko Oppel", "Michael Munz"], "title": "Boosting Automatic Exercise Evaluation Through Musculoskeletal Simulation-Based IMU Data Augmentation", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Automated evaluation of movement quality holds significant potential for\nenhancing physiotherapeutic treatments and sports training by providing\nobjective, real-time feedback. However, the effectiveness of deep learning\nmodels in assessing movements captured by inertial measurement units (IMUs) is\noften hampered by limited data availability, class imbalance, and label\nambiguity. In this work, we present a novel data augmentation method that\ngenerates realistic IMU data using musculoskeletal simulations integrated with\nsystematic modifications of movement trajectories. Crucially, our approach\nensures biomechanical plausibility and allows for automatic, reliable labeling\nby combining inverse kinematic parameters with a knowledge-based evaluation\nstrategy. Extensive evaluations demonstrate that augmented variants closely\nresembles real-world data, significantly improving the classification accuracy\nand generalization capability of neural network models. Additionally, we\nhighlight the benefits of augmented data for patient-specific fine-tuning\nscenarios, particularly when only limited subject-specific training examples\nare available. Our findings underline the practicality and efficacy of this\naugmentation method in overcoming common challenges faced by deep learning\napplications in physiotherapeutic exercise evaluation.", "AI": {"tldr": "Automated movement evaluation via IMU data is crucial for physiotherapy and sports training. However, deep learning models face challenges like limited data, class imbalance, and label ambiguity. This paper introduces a new data augmentation method that uses musculoskeletal simulations to generate realistic IMU data with biomechanically plausible labels, improving classification accuracy and generalization of neural network models.", "motivation": "To enhance physiotherapeutic treatments and sports training through automated evaluation of movement quality by addressing the limitations faced by deep learning models such as limited data availability, class imbalance, and label ambiguity in IMU data-based movement assessments.", "method": "A novel data augmentation method was developed to generate realistic IMU data using musculoskeletal simulations with systematic modifications of movement trajectories, ensuring biomechanical plausibility and reliable labeling through inverse kinematic parameters and knowledge-based evaluation strategy.", "result": "The augmented data closely resembles real-world data, leading to significant improvements in classification accuracy and generalization capability of neural network models, also proving beneficial for patient-specific fine-tuning when subject-specific training examples are limited.", "conclusion": "The proposed data augmentation method effectively overcomes common challenges in deep learning applications for physiotherapeutic exercise evaluation, demonstrating practicality and efficacy."}}
{"id": "2505.24424", "pdf": "https://arxiv.org/pdf/2505.24424", "abs": "https://arxiv.org/abs/2505.24424", "authors": ["Amit Peleg", "Naman Deep Singh", "Matthias Hein"], "title": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Vision-language models like CLIP have demonstrated remarkable zero-shot\ncapabilities in classification and retrieval. However, these models often\nstruggle with compositional reasoning - the ability to understand the\nrelationships between concepts. A recent benchmark, SugarCrepe++, reveals that\nprevious works on improving compositionality have mainly improved lexical\nsensitivity but neglected semantic understanding. In addition, downstream\nretrieval performance often deteriorates, although one would expect that\nimproving compositionality should enhance retrieval. In this work, we introduce\nCLIC (Compositionally-aware Learning in CLIP), a fine-tuning method based on a\nnovel training technique combining multiple images and their associated\ncaptions. CLIC improves compositionality across architectures as well as\ndifferently pre-trained CLIP models, both in terms of lexical and semantic\nunderstanding, and achieves consistent gains in retrieval performance. This\neven applies to the recent CLIPS, which achieves SOTA retrieval performance.\nNevertheless, the short fine-tuning with CLIC leads to an improvement in\nretrieval and to the best compositional CLIP model on SugarCrepe++. All our\nmodels and code are available at https://clic-compositional-clip.github.io", "AI": {"tldr": "CLIP\u5728\u5206\u7c7b\u548c\u68c0\u7d22\u65b9\u9762\u8868\u73b0\u51fa\u663e\u8457\u7684\u96f6\u6837\u672c\u80fd\u529b\uff0c\u4f46\u5176\u7ec4\u5408\u63a8\u7406\u80fd\u529b\u4ecd\u7136\u4e0d\u8db3\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eCLIP\u7684\u5fae\u8c03\u65b9\u6cd5CLIC\uff0c\u901a\u8fc7\u7ed3\u5408\u591a\u5f20\u56fe\u50cf\u53ca\u5176\u76f8\u5173\u6807\u9898\u7684\u65b0\u9896\u8bad\u7ec3\u6280\u672f\uff0c\u63d0\u9ad8\u6a21\u578b\u7684\u7ec4\u5408\u6027\u3001\u8bcd\u6c47\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u5728\u68c0\u7d22\u6027\u80fd\u4e0a\u53d6\u5f97\u4e00\u81f4\u63d0\u5347\uff0c\u6210\u4e3aSugarCrepe++\u57fa\u51c6\u4e0a\u8868\u73b0\u6700\u4f73\u7684\u7ec4\u5408\u6027CLIP\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08\u5982CLIP\uff09\u867d\u7136\u5728\u5206\u7c7b\u548c\u68c0\u7d22\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u7ec4\u5408\u63a8\u7406\u80fd\u529b\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u7279\u522b\u662f\u5728\u7406\u89e3\u548c\u5904\u7406\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\u65f6\u3002\u6b64\u5916\uff0c\u5c3d\u7ba1\u9884\u671f\u63d0\u9ad8\u7ec4\u5408\u6027\u5e94\u589e\u5f3a\u68c0\u7d22\u6027\u80fd\uff0c\u4f46\u5b9e\u9645\u4e0a\u4e0b\u6e38\u68c0\u7d22\u6027\u80fd\u5f80\u5f80\u4f1a\u4e0b\u964d\u3002", "method": "\u5f15\u5165\u4e86CLIC\uff08Compositionally-aware Learning in CLIP\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8eCLIP\u7684\u5fae\u8c03\u65b9\u6cd5\uff0c\u91c7\u7528\u4e00\u79cd\u65b0\u9896\u7684\u8bad\u7ec3\u6280\u672f\uff0c\u5c06\u591a\u5f20\u56fe\u50cf\u53ca\u5176\u5173\u8054\u7684\u6807\u9898\u7ed3\u5408\u8d77\u6765\u8fdb\u884c\u8bad\u7ec3\u3002\u8be5\u65b9\u6cd5\u4e0d\u4ec5\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u67b6\u6784\u548c\u9884\u8bad\u7ec3CLIP\u6a21\u578b\u4e0a\u7684\u7ec4\u5408\u6027\uff0c\u8fd8\u5728\u8bcd\u6c47\u548c\u8bed\u4e49\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\u3002", "result": "\u901a\u8fc7CLIC\u5fae\u8c03\u540e\u7684\u6a21\u578b\u5728\u68c0\u7d22\u6027\u80fd\u4e0a\u53d6\u5f97\u4e86\u4e00\u81f4\u7684\u63d0\u5347\uff0c\u5c24\u5176\u662f\u5728\u7ec4\u5408\u6027\u65b9\u9762\uff0c\u6210\u4e3a\u4e86SugarCrepe++\u57fa\u51c6\u4e0a\u8868\u73b0\u6700\u4f73\u7684\u7ec4\u5408\u6027CLIP\u6a21\u578b\u3002\u5373\u4f7f\u5bf9\u4e8e\u5df2\u7ecf\u5b9e\u73b0SOTA\u68c0\u7d22\u6027\u80fd\u7684\u6700\u65b0CLIP\u6a21\u578b\uff0cCLIC\u4e5f\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u5176\u68c0\u7d22\u6027\u80fd\u3002", "conclusion": "CLIC\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u6765\u589e\u5f3aCLIP\u6a21\u578b\u7684\u7ec4\u5408\u6027\u3001\u8bcd\u6c47\u548c\u8bed\u4e49\u7406\u89e3\u80fd\u529b\uff0c\u540c\u65f6\u6539\u5584\u4e86\u68c0\u7d22\u6027\u80fd\uff0c\u4e3a\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u7684\u8fdb\u4e00\u6b65\u53d1\u5c55\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.24434", "pdf": "https://arxiv.org/pdf/2505.24434", "abs": "https://arxiv.org/abs/2505.24434", "authors": ["Md Shahriar Rahim Siddiqui", "Moshe Eliasof", "Eldad Haber"], "title": "Graph Flow Matching: Enhancing Image Generation with Neighbor-Aware Flow Fields", "categories": ["cs.LG", "cs.CV"], "comment": null, "summary": "Flow matching casts sample generation as learning a continuous-time velocity\nfield that transports noise to data. Existing flow matching networks typically\npredict each point's velocity independently, considering only its location and\ntime along its flow trajectory, and ignoring neighboring points. However, this\npointwise approach may overlook correlations between points along the\ngeneration trajectory that could enhance velocity predictions, thereby\nimproving downstream generation quality. To address this, we propose Graph Flow\nMatching (GFM), a lightweight enhancement that decomposes the learned velocity\ninto a reaction term -- any standard flow matching network -- and a diffusion\nterm that aggregates neighbor information via a graph neural module. This\nreaction-diffusion formulation retains the scalability of deep flow models\nwhile enriching velocity predictions with local context, all at minimal\nadditional computational cost. Operating in the latent space of a pretrained\nvariational autoencoder, GFM consistently improves Fr\\'echet Inception Distance\n(FID) and recall across five image generation benchmarks (LSUN Church, LSUN\nBedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$), demonstrating its\neffectiveness as a modular enhancement to existing flow matching architectures.", "AI": {"tldr": "Graph Flow Matching (GFM) enhances traditional flow matching by incorporating a diffusion term that considers neighboring point information, improving image generation quality.", "motivation": "Existing flow matching networks predict velocity independently for each point without considering correlations between points along the trajectory, which may limit the quality of downstream generation.", "method": "GFM decomposes the learned velocity into a reaction term (standard flow matching network) and a diffusion term (graph neural module aggregating neighbor information). This approach operates in the latent space of a pretrained variational autoencoder.", "result": "GFM consistently improves Fr\u00e9chet Inception Distance (FID) and recall across five image generation benchmarks (LSUN Church, LSUN Bedroom, FFHQ, AFHQ-Cat, and CelebA-HQ at $256\\times256$).", "conclusion": "GFM is an effective modular enhancement to existing flow matching architectures, enriching velocity predictions with local context while maintaining scalability and minimal additional computational cost."}}
{"id": "2505.24438", "pdf": "https://arxiv.org/pdf/2505.24438", "abs": "https://arxiv.org/abs/2505.24438", "authors": ["Franziska Heeg", "Jonas Sauer", "Petra Mutzel", "Ingo Scholtes"], "title": "Weisfeiler and Leman Follow the Arrow of Time: Expressive Power of Message Passing in Temporal Event Graphs", "categories": ["cs.LG"], "comment": null, "summary": "An important characteristic of temporal graphs is how the directed arrow of\ntime influences their causal topology, i.e., which nodes can possibly influence\neach other causally via time-respecting paths. The resulting patterns are often\nneglected by temporal graph neural networks (TGNNs). To formally analyze the\nexpressive power of TGNNs, we lack a generalization of graph isomorphism to\ntemporal graphs that fully captures their causal topology. Addressing this gap,\nwe introduce the notion of consistent event graph isomorphism, which utilizes a\ntime-unfolded representation of time-respecting paths in temporal graphs. We\ncompare this definition with existing notions of temporal graph isomorphisms.\nWe illustrate and highlight the advantages of our approach and develop a\ntemporal generalization of the Weisfeiler-Leman algorithm to heuristically\ndistinguish non-isomorphic temporal graphs. Building on this theoretical\nfoundation, we derive a novel message passing scheme for temporal graph neural\nnetworks that operates on the event graph representation of temporal graphs. An\nexperimental evaluation shows that our approach performs well in a temporal\ngraph classification experiment.", "AI": {"tldr": "In this paper, researchers address the gap in understanding the causal topology of temporal graphs by introducing a new concept called consistent event graph isomorphism. They also develop a temporal generalization of the Weisfeiler-Leman algorithm and derive a novel message passing scheme for temporal graph neural networks (TGNNs), which performs well in experiments.", "motivation": "The motivation of this paper stems from the observation that an important characteristic of temporal graphs - how the directed arrow of time influences their causal topology - is often neglected by existing temporal graph neural networks (TGNNs). There is a lack of a formal way to analyze the expressive power of TGNNs due to the absence of a generalized graph isomorphism concept applicable to temporal graphs.", "method": "The authors introduce the notion of consistent event graph isomorphism, which uses a time-unfolded representation of time-respecting paths in temporal graphs. They compare this definition with existing notions of temporal graph isomorphisms and develop a temporal generalization of the Weisfeiler-Leman algorithm to distinguish non-isomorphic temporal graphs. Based on this theoretical foundation, they derive a new message passing scheme for TGNNs that operates on the event graph representation of temporal graphs.", "result": "The experimental evaluation indicates that the proposed approach performs well in a temporal graph classification experiment.", "conclusion": "This study provides a novel method to understand and enhance the expressive power of TGNNs through the introduction of consistent event graph isomorphism and a new message passing scheme."}}
{"id": "2505.24445", "pdf": "https://arxiv.org/pdf/2505.24445", "abs": "https://arxiv.org/abs/2505.24445", "authors": ["Xin Chen", "Yarden As", "Andreas Krause"], "title": "Learning Safety Constraints for Large Language Models", "categories": ["cs.LG", "cs.AI"], "comment": "ICML 2025 (Spotlight)", "summary": "Large language models (LLMs) have emerged as powerful tools but pose\nsignificant safety risks through harmful outputs and vulnerability to\nadversarial attacks. We propose SaP, short for Safety Polytope, a geometric\napproach to LLM safety that learns and enforces multiple safety constraints\ndirectly in the model's representation space. We develop a framework that\nidentifies safe and unsafe regions via the polytope's facets, enabling both\ndetection and correction of unsafe outputs through geometric steering. Unlike\nexisting approaches that modify model weights, SaP operates post-hoc in the\nrepresentation space, preserving model capabilities while enforcing safety\nconstraints. Experiments across multiple LLMs demonstrate that our method can\neffectively detect unethical inputs, reduce adversarial attack success rates\nwhile maintaining performance on standard tasks, thus highlighting the\nimportance of having an explicit geometric model for safety. Analysis of the\nlearned polytope facets reveals emergence of specialization in detecting\ndifferent semantic notions of safety, providing interpretable insights into how\nsafety is captured in LLMs' representation space.", "AI": {"tldr": "Large language models (LLMs) have safety risks. The paper proposes SaP, a geometric approach to LLM safety that learns and enforces multiple safety constraints directly in the model's representation space.", "motivation": "To address significant safety risks of LLMs through harmful outputs and vulnerability to adversarial attacks.", "method": "Propose SaP (Safety Polytope), which identifies safe and unsafe regions via the polytope's facets, enabling detection and correction of unsafe outputs through geometric steering. It operates post-hoc in the representation space, not modifying model weights.", "result": "Experiments across multiple LLMs show effective detection of unethical inputs, reduction in adversarial attack success rates while maintaining performance on standard tasks.", "conclusion": "SaP provides an explicit geometric model for safety, with interpretable insights into how safety is captured in LLMs' representation space."}}
{"id": "2505.24452", "pdf": "https://arxiv.org/pdf/2505.24452", "abs": "https://arxiv.org/abs/2505.24452", "authors": ["Anda Tang", "Yiming Dong", "Yutao Zeng", "zhou Xun", "Zhouchen Lin"], "title": "Stepsize anything: A unified learning rate schedule for budgeted-iteration training", "categories": ["cs.LG"], "comment": null, "summary": "The expanding computational costs and limited resources underscore the\ncritical need for budgeted-iteration training, which aims to achieve optimal\nlearning within predetermined iteration budgets.While learning rate schedules\nfundamentally govern the performance of different networks and tasks,\nparticularly in budgeted-iteration scenarios, their design remains largely\nheuristic, lacking theoretical foundations.In addition, the optimal learning\nrate schedule requires extensive trial-and-error selection, making the training\nprocess inefficient.In this work, we propose the Unified Budget-Aware (UBA)\nschedule, a theoretically grounded learning rate schedule that consistently\noutperforms commonly-used schedules among diverse architectures and tasks under\ndifferent constrained training budgets.First, we bridge the gap by constructing\na novel training budget-aware optimization framework, which explicitly accounts\nfor the robustness to landscape curvature variations.From this framework, we\nderive the UBA schedule, controlled by a single hyper-parameter $\\varphi$ that\nprovides a trade-off between flexibility and simplicity, eliminating the need\nfor per-network numerical optimization. Moreover, we establish a theoretical\nconnection between $\\varphi$ and the condition number, adding interpretation\nand justification to our approach. Besides, we prove the convergence for\ndifferent values of $\\varphi$.We offer practical guidelines for its selection\nvia theoretical analysis and empirical results.xtensive experimental results\nshow that UBA \\textit{consistently surpasses} the commonly-used schedules\nacross diverse vision and language tasks, spanning network architectures (e.g.,\nResNet, OLMo) and scales, under different training-iteration budgets.", "AI": {"tldr": "This paper proposes Unified Budget-Aware (UBA) schedule, a theoretically grounded learning rate schedule that outperforms commonly-used schedules among diverse architectures and tasks under different constrained training budgets.", "motivation": "The expanding computational costs and limited resources highlight the need for budgeted-iteration training. Current learning rate schedules lack theoretical foundations and require extensive trial-and-error selection.", "method": "The authors construct a novel training budget-aware optimization framework to derive the UBA schedule, controlled by a single hyper-parameter \u03c6 that balances flexibility and simplicity. They also establish a theoretical connection between \u03c6 and the condition number and prove the convergence for different values of \u03c6.", "result": "Extensive experimental results show that UBA consistently surpasses commonly-used schedules across diverse vision and language tasks, spanning network architectures and scales, under different training-iteration budgets.", "conclusion": "The UBA schedule is a theoretically grounded learning rate schedule that outperforms commonly-used schedules in various scenarios, eliminating the need for per-network numerical optimization."}}
{"id": "2505.23912", "pdf": "https://arxiv.org/pdf/2505.23912", "abs": "https://arxiv.org/abs/2505.23912", "authors": ["Caiqi Zhang", "Xiaochen Zhu", "Chengzu Li", "Nigel Collier", "Andreas Vlachos"], "title": "Reinforcement Learning for Better Verbalized Confidence in Long-Form Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Hallucination remains a major challenge for the safe and trustworthy\ndeployment of large language models (LLMs) in factual content generation. Prior\nwork has explored confidence estimation as an effective approach to\nhallucination detection, but often relies on post-hoc self-consistency methods\nthat require computationally expensive sampling. Verbalized confidence offers a\nmore efficient alternative, but existing approaches are largely limited to\nshort-form question answering (QA) tasks and do not generalize well to\nopen-ended generation. In this paper, we propose LoVeC (Long-form Verbalized\nConfidence), an on-the-fly verbalized confidence estimation method for\nlong-form generation. Specifically, we use reinforcement learning (RL) to train\nLLMs to append numerical confidence scores to each generated statement, serving\nas a direct and interpretable signal of the factuality of generation. Our\nexperiments consider both on-policy and off-policy RL methods, including DPO,\nORPO, and GRPO, to enhance the model calibration. We introduce two novel\nevaluation settings, free-form tagging and iterative tagging, to assess\ndifferent verbalized confidence estimation methods. Experiments on three\nlong-form QA datasets show that our RL-trained models achieve better\ncalibration and generalize robustly across domains. Also, our method is highly\nefficient, as it only requires adding a few tokens to the output being decoded.", "AI": {"tldr": "Hallucination is a challenge for LLMs in factual content generation. Previous methods use confidence estimation but are computationally expensive. This paper proposes LoVeC, an efficient method for long-form verbalized confidence estimation using RL-trained LLMs to append confidence scores. Experiments show better calibration and robust generalization across domains.", "motivation": "To address the issue of hallucination in LLMs during factual content generation and improve upon existing computationally expensive confidence estimation methods.", "method": "Propose LoVeC, which uses reinforcement learning to train LLMs to append numerical confidence scores to each generated statement for long-form generation.", "result": "Experiments on three long-form QA datasets demonstrate better calibration, robust generalization across domains, and high efficiency by only adding a few tokens to the output.", "conclusion": "LoVeC provides an efficient and effective method for verbalized confidence estimation in long-form generation, enhancing model calibration and generalization."}}
{"id": "2505.24461", "pdf": "https://arxiv.org/pdf/2505.24461", "abs": "https://arxiv.org/abs/2505.24461", "authors": ["Jingyao Li", "Senqiao Yang", "Sitong Wu", "Han Shi", "Chuanyang Zheng", "Hong Xu", "Jiaya Jia"], "title": "Logits-Based Finetuning", "categories": ["cs.LG"], "comment": null, "summary": "The core of out-of-distribution (OOD) detection is to learn the\nin-distribution (ID) representation, which is distinguishable from OOD samples.\nPrevious work applied recognition-based methods to learn the ID features, which\ntend to learn shortcuts instead of comprehensive representations. In this work,\nwe find surprisingly that simply using reconstruction-based methods could boost\nthe performance of OOD detection significantly. We deeply explore the main\ncontributors of OOD detection and find that reconstruction-based pretext tasks\nhave the potential to provide a generally applicable and efficacious prior,\nwhich benefits the model in learning intrinsic data distributions of the ID\ndataset. Specifically, we take Masked Image Modeling as a pretext task for our\nOOD detection framework (MOOD). Without bells and whistles, MOOD outperforms\nprevious SOTA of one-class OOD detection by 5.7%, multi-class OOD detection by\n3.0%, and near-distribution OOD detection by 2.1%. It even defeats the\n10-shot-per-class outlier exposure OOD detection, although we do not include\nany OOD samples for our detection. Codes are available at\nhttps://github.com/JulietLJY/MOOD.", "AI": {"tldr": "The paper explores the use of reconstruction-based methods for out-of-distribution (OOD) detection and introduces MOOD, a framework using Masked Image Modeling as a pretext task. It significantly improves OOD detection performance without using any OOD samples.", "motivation": "Current OOD detection methods using recognition-based approaches tend to learn shortcuts rather than comprehensive representations. This motivates the exploration of alternative methods that can provide a more efficacious prior for learning intrinsic data distributions of the in-distribution dataset.", "method": "The method leverages reconstruction-based pretext tasks, specifically Masked Image Modeling, within a framework called MOOD. This approach aims to enhance the model's ability to learn intrinsic data distributions of the in-distribution dataset, improving OOD detection performance.", "result": "MOOD outperforms previous state-of-the-art methods in one-class OOD detection by 5.7%, multi-class OOD detection by 3.0%, and near-distribution OOD detection by 2.1%. It also surpasses 10-shot-per-class outlier exposure OOD detection without including any OOD samples.", "conclusion": "Reconstruction-based methods, particularly Masked Image Modeling, provide a generally applicable and effective prior for OOD detection. The proposed MOOD framework demonstrates significant improvements in OOD detection performance."}}
{"id": "2505.23914", "pdf": "https://arxiv.org/pdf/2505.23914", "abs": "https://arxiv.org/abs/2505.23914", "authors": ["Yuxin Wang", "Botao Yu", "Ivory Yang", "Saeed Hassanpour", "Soroush Vosoughi"], "title": "Probing Association Biases in LLM Moderation Over-Sensitivity", "categories": ["cs.CL", "cs.AI"], "comment": "Under review", "summary": "Large Language Models are widely used for content moderation but often\nmisclassify benign comments as toxic, leading to over-sensitivity. While\nprevious research attributes this issue primarily to the presence of offensive\nterms, we reveal a potential cause beyond token level: LLMs exhibit systematic\ntopic biases in their implicit associations. Inspired by cognitive psychology's\nimplicit association tests, we introduce Topic Association Analysis, a\nsemantic-level approach to quantify how LLMs associate certain topics with\ntoxicity. By prompting LLMs to generate free-form scenario imagination for\nmisclassified benign comments and analyzing their topic amplification levels,\nwe find that more advanced models (e.g., GPT-4 Turbo) demonstrate stronger\ntopic stereotype despite lower overall false positive rates. These biases\nsuggest that LLMs do not merely react to explicit, offensive language but rely\non learned topic associations, shaping their moderation decisions. Our findings\nhighlight the need for refinement beyond keyword-based filtering, providing\ninsights into the underlying mechanisms driving LLM over-sensitivity.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u5b58\u5728\u8fc7\u5ea6\u654f\u611f\u7684\u95ee\u9898\uff0c\u4e0d\u4ec5\u56e0\u4e3a\u8bc6\u522b\u5192\u72af\u6027\u8bcd\u6c47\uff0c\u8fd8\u7531\u4e8e\u7cfb\u7edf\u6027\u7684\u4e3b\u9898\u504f\u89c1\u3002\u901a\u8fc7\u5f15\u5165'\u4e3b\u9898\u5173\u8054\u5206\u6790'\u65b9\u6cd5\uff0c\u7814\u7a76\u53d1\u73b0\u66f4\u5148\u8fdb\u7684\u6a21\u578b\u5c3d\u7ba1\u6574\u4f53\u8bef\u62a5\u7387\u8f83\u4f4e\uff0c\u4f46\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u4e3b\u9898\u523b\u677f\u5370\u8c61\u3002\u8fd9\u8868\u660eLLMs\u4f9d\u8d56\u4e8e\u5b66\u4e60\u5230\u7684\u4e3b\u9898\u5173\u8054\u800c\u975e\u4ec5\u4ec5\u5bf9\u5192\u72af\u6027\u8bed\u8a00\u4f5c\u51fa\u53cd\u5e94\uff0c\u4ece\u800c\u5f71\u54cd\u5176\u5ba1\u6838\u51b3\u7b56\u3002\u7814\u7a76\u5f3a\u8c03\u9700\u8981\u8d85\u8d8a\u57fa\u4e8e\u5173\u952e\u8bcd\u7684\u8fc7\u6ee4\u8fdb\u884c\u6539\u8fdb\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u5185\u5bb9\u5ba1\u6838\u65f6\u7ecf\u5e38\u5c06\u65e0\u5bb3\u8bc4\u8bba\u8bef\u5206\u7c7b\u4e3a\u6709\u6bd2\u8bc4\u8bba\uff0c\u5bfc\u81f4\u8fc7\u5ea6\u654f\u611f\u3002\u867d\u7136\u4ee5\u5f80\u7814\u7a76\u4e3b\u8981\u5f52\u56e0\u4e8e\u5192\u72af\u6027\u8bcd\u6c47\u7684\u5b58\u5728\uff0c\u4f46\u672c\u7814\u7a76\u8bd5\u56fe\u63a2\u7d22\u9664\u8bcd\u6c47\u5c42\u9762\u5916\u53ef\u80fd\u5f15\u53d1\u6b64\u95ee\u9898\u7684\u539f\u56e0\u3002", "method": "\u53d7\u8ba4\u77e5\u5fc3\u7406\u5b66\u9690\u6027\u8054\u60f3\u6d4b\u8bd5\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u8bed\u4e49\u7ea7\u522b\u7684\u65b9\u6cd5\u2014\u2014\u4e3b\u9898\u5173\u8054\u5206\u6790\uff0c\u4ee5\u91cf\u5316LLMs\u5982\u4f55\u5c06\u67d0\u4e9b\u4e3b\u9898\u4e0e\u6bd2\u6027\u76f8\u5173\u8054\u3002\u901a\u8fc7\u5bf9\u88ab\u8bef\u5206\u7c7b\u7684\u65e0\u5bb3\u8bc4\u8bba\u751f\u6210\u81ea\u7531\u5f62\u5f0f\u7684\u60c5\u666f\u60f3\u8c61\uff0c\u5e76\u5206\u6790\u5176\u4e3b\u9898\u653e\u5927\u7a0b\u5ea6\u6765\u63ed\u793a\u6a21\u578b\u7684\u4e3b\u9898\u8054\u60f3\u7279\u6027\u3002", "result": "\u66f4\u5148\u8fdb\u7684\u6a21\u578b\uff08\u5982GPT-4 Turbo\uff09\u5c3d\u7ba1\u6574\u4f53\u8bef\u62a5\u7387\u8f83\u4f4e\uff0c\u4f46\u5728\u4e3b\u9898\u8054\u60f3\u65b9\u9762\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u523b\u677f\u5370\u8c61\uff0c\u8bf4\u660eLLMs\u4e0d\u4ec5\u5bf9\u663e\u5f0f\u7684\u5192\u72af\u6027\u8bed\u8a00\u4f5c\u51fa\u53cd\u5e94\uff0c\u8fd8\u4f9d\u8d56\u4e8e\u6240\u5b66\u7684\u4e3b\u9898\u5173\u8054\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u63ed\u793a\u4e86LLMs\u5728\u5185\u5bb9\u5ba1\u6838\u4e2d\u7684\u8fc7\u5ea6\u654f\u611f\u5e76\u975e\u4ec5\u7531\u5173\u952e\u8bcd\u89e6\u53d1\uff0c\u800c\u662f\u53d7\u5230\u4e3b\u9898\u5173\u8054\u7684\u5f71\u54cd\uff0c\u5f3a\u8c03\u4e86\u9700\u8981\u8fdb\u4e00\u6b65\u6539\u8fdb\uff0c\u8d85\u8d8a\u4f20\u7edf\u7684\u5173\u952e\u8bcd\u8fc7\u6ee4\u673a\u5236\u3002"}}
{"id": "2505.24469", "pdf": "https://arxiv.org/pdf/2505.24469", "abs": "https://arxiv.org/abs/2505.24469", "authors": ["Christina Runkel", "Natacha Kuete Meli", "Jovita Lukasik", "Ander Biguri", "Carola-Bibiane Sch\u00f6nlieb", "Michael Moeller"], "title": "Smooth Model Compression without Fine-Tuning", "categories": ["cs.LG"], "comment": null, "summary": "Compressing and pruning large machine learning models has become a critical\nstep towards their deployment in real-world applications. Standard pruning and\ncompression techniques are typically designed without taking the structure of\nthe network's weights into account, limiting their effectiveness. We explore\nthe impact of smooth regularization on neural network training and model\ncompression. By applying nuclear norm, first- and second-order derivative\npenalties of the weights during training, we encourage structured smoothness\nwhile preserving predictive performance on par with non-smooth models. We find\nthat standard pruning methods often perform better when applied to these smooth\nmodels. Building on this observation, we apply a\nSingular-Value-Decomposition-based compression method that exploits the\nunderlying smooth structure and approximates the model's weight tensors by\nsmaller low-rank tensors. Our approach enables state-of-the-art compression\nwithout any fine-tuning - reaching up to $91\\%$ accuracy on a smooth ResNet-18\non CIFAR-10 with $70\\%$ fewer parameters.", "AI": {"tldr": "\u901a\u8fc7\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u6838\u8303\u6570\u3001\u6743\u91cd\u7684\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570\u60e9\u7f5a\uff0c\u9f13\u52b1\u7ed3\u6784\u5316\u5e73\u6ed1\u6027\uff0c\u4ece\u800c\u63d0\u9ad8\u6a21\u578b\u538b\u7f29\u6548\u679c\uff0c\u4f7f\u7528SVD\u538b\u7f29\u65b9\u6cd5\uff0c\u5728CIFAR-10\u6570\u636e\u96c6\u4e0a\u5bf9ResNet-18\u8fdb\u884c\u538b\u7f29\uff0c\u53c2\u6570\u51cf\u5c1170%\uff0c\u51c6\u786e\u7387\u8fbe\u523091%\u3002", "motivation": "\u5927\u578b\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u538b\u7f29\u548c\u4fee\u526a\u5bf9\u4e8e\u5b9e\u9645\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u4f20\u7edf\u7684\u4fee\u526a\u548c\u538b\u7f29\u6280\u672f\u6ca1\u6709\u8003\u8651\u5230\u7f51\u7edc\u6743\u91cd\u7684\u7ed3\u6784\uff0c\u9650\u5236\u4e86\u5176\u6709\u6548\u6027\u3002\u56e0\u6b64\uff0c\u63a2\u7d22\u5e73\u6ed1\u6b63\u5219\u5316\u5bf9\u795e\u7ecf\u7f51\u7edc\u8bad\u7ec3\u548c\u6a21\u578b\u538b\u7f29\u7684\u5f71\u54cd\u662f\u5fc5\u8981\u7684\u3002", "method": "\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5e94\u7528\u6838\u8303\u6570\u3001\u6743\u91cd\u7684\u4e00\u9636\u548c\u4e8c\u9636\u5bfc\u6570\u60e9\u7f5a\uff0c\u4ee5\u9f13\u52b1\u7ed3\u6784\u5316\u5e73\u6ed1\u6027\uff0c\u5e76\u4fdd\u6301\u9884\u6d4b\u6027\u80fd\u4e0e\u975e\u5e73\u6ed1\u6a21\u578b\u76f8\u5f53\u3002\u7136\u540e\uff0c\u4f7f\u7528\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u4e3a\u57fa\u7840\u7684\u538b\u7f29\u65b9\u6cd5\uff0c\u5229\u7528\u5e95\u5c42\u7684\u5e73\u6ed1\u7ed3\u6784\uff0c\u7528\u8f83\u5c0f\u7684\u4f4e\u79e9\u5f20\u91cf\u8fd1\u4f3c\u6a21\u578b\u7684\u6743\u91cd\u5f20\u91cf\u3002", "result": "\u6807\u51c6\u4fee\u526a\u65b9\u6cd5\u5728\u5e94\u7528\u4e8e\u8fd9\u4e9b\u5e73\u6ed1\u6a21\u578b\u65f6\u901a\u5e38\u8868\u73b0\u66f4\u597d\u3002\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u538b\u7f29\u6548\u679c\uff0c\u65e0\u9700\u4efb\u4f55\u5fae\u8c03\uff0c\u4f8b\u5982\u5728CIFAR-10\u4e0a\u7684\u5e73\u6ed1ResNet-18\u6a21\u578b\u4e2d\uff0c\u53c2\u6570\u51cf\u5c11\u4e8670%\uff0c\u51c6\u786e\u7387\u8fbe\u523091%\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5e73\u6ed1\u6b63\u5219\u5316\u5e76\u7ed3\u5408SVD\u538b\u7f29\u65b9\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u6a21\u578b\u538b\u7f29\u7684\u6548\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u9884\u6d4b\u6027\u80fd\u3002"}}
{"id": "2505.23917", "pdf": "https://arxiv.org/pdf/2505.23917", "abs": "https://arxiv.org/abs/2505.23917", "authors": ["Neehar Kondapaneni", "Oisin Mac Aodha", "Pietro Perona"], "title": "Representational Difference Explanations", "categories": ["cs.CV", "cs.AI", "cs.LG", "q-bio.NC"], "comment": "9 pages, 6 figures, 21 supplementary pages, 14 supp figs", "summary": "We propose a method for discovering and visualizing the differences between\ntwo learned representations, enabling more direct and interpretable model\ncomparisons. We validate our method, which we call Representational Differences\nExplanations (RDX), by using it to compare models with known conceptual\ndifferences and demonstrate that it recovers meaningful distinctions where\nexisting explainable AI (XAI) techniques fail. Applied to state-of-the-art\nmodels on challenging subsets of the ImageNet and iNaturalist datasets, RDX\nreveals both insightful representational differences and subtle patterns in the\ndata. Although comparison is a cornerstone of scientific analysis, current\ntools in machine learning, namely post hoc XAI methods, struggle to support\nmodel comparison effectively. Our work addresses this gap by introducing an\neffective and explainable tool for contrasting model representations.", "AI": {"tldr": "The paper proposes Representational Differences Explanations (RDX), a method for discovering and visualizing differences between two learned representations, facilitating interpretable model comparisons.", "motivation": "Current post hoc explainable AI (XAI) methods in machine learning lack the capability to effectively support model comparison, creating a need for a more effective tool.", "method": "The method, called Representational Differences Explanations (RDX), is designed to discover and visualize the differences between two learned representations. It is validated by comparing models with known conceptual differences.", "result": "RDX successfully recovers meaningful distinctions where existing XAI techniques fail. When applied to state-of-the-art models on subsets of ImageNet and iNaturalist datasets, it reveals insightful representational differences and subtle data patterns.", "conclusion": "RDX addresses the gap in current machine learning tools by providing an effective and explainable method for contrasting model representations."}}
{"id": "2505.24473", "pdf": "https://arxiv.org/pdf/2505.24473", "abs": "https://arxiv.org/abs/2505.24473", "authors": ["Nikita Balagansky", "Yaroslav Aksenov", "Daniil Laptev", "Vadim Kurochkin", "Gleb Gerasimov", "Nikita Koryagin", "Daniil Gavrilov"], "title": "Train One Sparse Autoencoder Across Multiple Sparsity Budgets to Preserve Interpretability and Accuracy", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Sparse Autoencoders (SAEs) have proven to be powerful tools for interpreting\nneural networks by decomposing hidden representations into disentangled,\ninterpretable features via sparsity constraints. However, conventional SAEs are\nconstrained by the fixed sparsity level chosen during training; meeting\ndifferent sparsity requirements therefore demands separate models and increases\nthe computational footprint during both training and evaluation. We introduce a\nnovel training objective, \\emph{HierarchicalTopK}, which trains a single SAE to\noptimise reconstructions across multiple sparsity levels simultaneously.\nExperiments with Gemma-2 2B demonstrate that our approach achieves\nPareto-optimal trade-offs between sparsity and explained variance,\noutperforming traditional SAEs trained at individual sparsity levels. Further\nanalysis shows that HierarchicalTopK preserves high interpretability scores\neven at higher sparsity. The proposed objective thus closes an important gap\nbetween flexibility and interpretability in SAE design.", "AI": {"tldr": "Sparse Autoencoders (SAEs) usually have a fixed sparsity level during training, which leads to the need for separate models to meet different sparsity requirements. This paper introduces HierarchicalTopK, a new training objective that allows a single SAE to optimize reconstructions across multiple sparsity levels simultaneously.", "motivation": "Conventional Sparse Autoencoders are constrained by the fixed sparsity level chosen during training and require separate models to meet different sparsity requirements, increasing computational cost.", "method": "The authors introduce a novel training objective called HierarchicalTopK, which enables a single Sparse Autoencoder to optimize reconstructions across multiple sparsity levels at once.", "result": "Experiments using Gemma-2 2B show that this approach achieves Pareto-optimal trade-offs between sparsity and explained variance, outperforming traditional SAEs trained at individual sparsity levels. Additionally, HierarchicalTopK maintains high interpretability scores even at higher sparsity levels.", "conclusion": "HierarchicalTopK bridges the gap between flexibility and interpretability in Sparse Autoencoder design, allowing for more versatile and efficient models."}}
{"id": "2505.23923", "pdf": "https://arxiv.org/pdf/2505.23923", "abs": "https://arxiv.org/abs/2505.23923", "authors": ["Feiteng Fang", "Ting-En Lin", "Yuchuan Wu", "Xiong Liu", "Xiang Huang", "Dingwei Chen", "Jing Ye", "Haonan Zhang", "Liang Zhu", "Hamid Alinejad-Rokny", "Min Yang", "Fei Huang", "Yongbin Li"], "title": "ChARM: Character-based Act-adaptive Reward Modeling for Advanced Role-Playing Language Agents", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Role-Playing Language Agents (RPLAs) aim to simulate characters for realistic\nand engaging human-computer interactions. However, traditional reward models\noften struggle with scalability and adapting to subjective conversational\npreferences. We propose ChARM, a Character-based Act-adaptive Reward Model,\naddressing these challenges through two innovations: (1) an act-adaptive margin\nthat significantly enhances learning efficiency and generalizability, and (2) a\nself-evolution mechanism leveraging large-scale unlabeled data to improve\ntraining coverage. Additionally, we introduce RoleplayPref, the first\nlarge-scale preference dataset specifically for RPLAs, featuring 1,108\ncharacters, 13 subcategories, and 16,888 bilingual dialogues, alongside\nRoleplayEval, a dedicated evaluation benchmark. Experimental results show a 13%\nimprovement over the conventional Bradley-Terry model in preference rankings.\nFurthermore, applying ChARM-generated rewards to preference learning techniques\n(e.g., direct preference optimization) achieves state-of-the-art results on\nCharacterEval and RoleplayEval. Code and dataset are available at\nhttps://github.com/calubkk/ChARM.", "AI": {"tldr": "The paper introduces ChARM, a Character-based Act-adaptive Reward Model for RPLAs with two innovations and presents RoleplayPref dataset and RoleplayEval benchmark. It shows significant improvements over conventional models and achieves state-of-the-art results.", "motivation": "Traditional reward models for RPLAs lack scalability and struggle to adapt to subjective conversational preferences.", "method": "Propose ChARM with an act-adaptive margin and a self-evolution mechanism. Also introduce RoleplayPref dataset and RoleplayEval benchmark for evaluation.", "result": "13% improvement over the conventional Bradley-Terry model in preference rankings and state-of-the-art results on CharacterEval and RoleplayEval.", "conclusion": "ChARM effectively addresses the limitations of traditional reward models and advances the field of RPLAs."}}
{"id": "2505.24492", "pdf": "https://arxiv.org/pdf/2505.24492", "abs": "https://arxiv.org/abs/2505.24492", "authors": ["David Steinmann", "Wolfgang Stammer", "Antonia W\u00fcst", "Kristian Kersting"], "title": "Object Centric Concept Bottlenecks", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Developing high-performing, yet interpretable models remains a critical\nchallenge in modern AI. Concept-based models (CBMs) attempt to address this by\nextracting human-understandable concepts from a global encoding (e.g., image\nencoding) and then applying a linear classifier on the resulting concept\nactivations, enabling transparent decision-making. However, their reliance on\nholistic image encodings limits their expressiveness in object-centric\nreal-world settings and thus hinders their ability to solve complex vision\ntasks beyond single-label classification. To tackle these challenges, we\nintroduce Object-Centric Concept Bottlenecks (OCB), a framework that combines\nthe strengths of CBMs and pre-trained object-centric foundation models,\nboosting performance and interpretability. We evaluate OCB on complex image\ndatasets and conduct a comprehensive ablation study to analyze key components\nof the framework, such as strategies for aggregating object-concept encodings.\nThe results show that OCB outperforms traditional CBMs and allows one to make\ninterpretable decisions for complex visual tasks.", "AI": {"tldr": "The paper presents Object-Centric Concept Bottlenecks (OCB), a framework that merges concept-based models with pre-trained object-centric foundation models to enhance both performance and interpretability for complex visual tasks.", "motivation": "Current concept-based models (CBMs) are limited in their expressiveness for object-centric real-world settings, which restricts their ability to solve complex vision tasks beyond single-label classification.", "method": "The authors introduce Object-Centric Concept Bottlenecks (OCB), which combines the strengths of CBMs and pre-trained object-centric foundation models. They evaluate OCB on complex image datasets and perform an ablation study on key components like strategies for aggregating object-concept encodings.", "result": "Experiments show that OCB outperforms traditional CBMs and enables interpretable decisions for complex visual tasks.", "conclusion": "OCB is a promising approach to improve both the performance and interpretability of models in complex vision tasks."}}
{"id": "2505.23930", "pdf": "https://arxiv.org/pdf/2505.23930", "abs": "https://arxiv.org/abs/2505.23930", "authors": ["Naomi Omeonga wa Kayembe"], "title": "Exploring Societal Concerns and Perceptions of AI: A Thematic Analysis through the Lens of Problem-Seeking", "categories": ["cs.CY", "cs.AI"], "comment": "48 pages", "summary": "This study introduces a novel conceptual framework distinguishing\nproblem-seeking from problem-solving to clarify the unique features of human\nintelligence in contrast to AI. Problem-seeking refers to the embodied,\nemotionally grounded process by which humans identify and set goals, while\nproblem-solving denotes the execution of strategies aimed at achieving such\npredefined objectives. The framework emphasizes that while AI excels at\nefficiency and optimization, it lacks the orientation derived from experiential\ngrounding and the embodiment flexibility intrinsic to human cognition. To\nempirically explore this distinction, the research analyzes metadata from 157\nYouTube videos discussing AI. Conducting a thematic analysis combining\nqualitative insights with keyword-based quantitative metrics, this\nmixed-methods approach uncovers recurring themes in public discourse, including\nprivacy, job displacement, misinformation, optimism, and ethical concerns. The\nresults reveal a dual sentiment: public fascination with AI's capabilities\ncoexists with anxiety and skepticism about its societal implications. The\ndiscussion critiques the orthogonality thesis, which posits that intelligence\nis separable from goal content, and instead argues that human intelligence\nintegrates goal-setting and goal-pursuit. It underscores the centrality of\nembodied cognition in human reasoning and highlights how AI's limitations come\nfrom its current reliance on computational processing. The study advocates for\nenhancing emotional and digital literacy to foster responsible AI engagement.\nIt calls for reframing public discourse to recognize AI as a tool that augments\n-- rather than replaces -- human intelligence. By positioning problem seeking\nat the core of cognition and as a critical dimension of intelligence, this\nresearch offers new perspectives on ethically aligned and human-centered AI\ndevelopment.", "AI": {"tldr": "\u672c\u7814\u7a76\u901a\u8fc7\u533a\u5206\u95ee\u9898\u5bfb\u6c42\u4e0e\u95ee\u9898\u89e3\u51b3\uff0c\u63a2\u8ba8\u4eba\u7c7b\u667a\u80fd\u4e0eAI\u7684\u72ec\u7279\u7279\u5f81\u3002\u5206\u6790157\u4e2aYouTube\u89c6\u9891\u540e\uff0c\u63ed\u793a\u516c\u4f17\u5bf9AI\u7684\u80fd\u529b\u65e2\u7740\u8ff7\u53c8\u7126\u8651\u3002\u7814\u7a76\u6279\u8bc4\u6b63\u4ea4\u6027\u7406\u8bba\uff0c\u5f3a\u8c03\u4eba\u7c7b\u667a\u80fd\u6574\u5408\u4e86\u76ee\u6807\u8bbe\u5b9a\u548c\u76ee\u6807\u8ffd\u6c42\uff0c\u5e76\u5021\u5bfc\u63d0\u9ad8\u60c5\u611f\u548c\u6570\u5b57\u7d20\u517b\uff0c\u4ee5\u4fc3\u8fdb\u8d1f\u8d23\u4efb\u7684AI\u5e94\u7528\u3002", "motivation": "\u4e3a\u4e86\u660e\u786e\u4eba\u7c7b\u667a\u80fd\u4e0eAI\u7684\u533a\u522b\uff0c\u7279\u522b\u662f\u4eba\u7c7b\u667a\u80fd\u4e2d\u72ec\u7279\u7684\u3001\u57fa\u4e8e\u4f53\u9a8c\u7684\u76ee\u6807\u8bbe\u5b9a\u80fd\u529b\u3002", "method": "\u5f15\u5165\u6982\u5ff5\u6846\u67b6\u533a\u5206\u95ee\u9898\u5bfb\u6c42\u4e0e\u95ee\u9898\u89e3\u51b3\uff1b\u901a\u8fc7\u4e3b\u9898\u5206\u6790\u7ed3\u5408\u5b9a\u6027\u548c\u5b9a\u91cf\u65b9\u6cd5\uff0c\u5206\u6790157\u4e2aYouTube\u89c6\u9891\u7684\u5143\u6570\u636e\u3002", "result": "\u53d1\u73b0\u516c\u4f17\u5bf9AI\u7684\u6001\u5ea6\u5b58\u5728\u53cc\u91cd\u6027\uff1a\u65e2\u6709\u5bf9\u5176\u80fd\u529b\u7684\u7740\u8ff7\uff0c\u4e5f\u6709\u5bf9\u5176\u793e\u4f1a\u5f71\u54cd\u7684\u7126\u8651\u548c\u6000\u7591\u3002", "conclusion": "\u63d0\u51fa\u5e94\u5c06\u95ee\u9898\u5bfb\u6c42\u89c6\u4e3a\u8ba4\u77e5\u7684\u6838\u5fc3\uff0c\u63a8\u52a8\u4ee5\u4eba\u4e3a\u672c\u548c\u7b26\u5408\u4f26\u7406\u7684AI\u53d1\u5c55\uff0c\u540c\u65f6\u589e\u5f3a\u516c\u4f17\u7684\u60c5\u611f\u548c\u6570\u5b57\u7d20\u517b\u3002"}}
{"id": "2505.24498", "pdf": "https://arxiv.org/pdf/2505.24498", "abs": "https://arxiv.org/abs/2505.24498", "authors": ["Andres Fernandez", "Juan Azcarreta", "Cagdas Bilen", "Jesus Monge Alvarez"], "title": "Efficient Neural and Numerical Methods for High-Quality Online Speech Spectrogram Inversion via Gradient Theorem", "categories": ["cs.LG"], "comment": "Accepted at InterSpeech 2025", "summary": "Recent work in online speech spectrogram inversion effectively combines Deep\nLearning with the Gradient Theorem to predict phase derivatives directly from\nmagnitudes. Then, phases are estimated from their derivatives via least\nsquares, resulting in a high quality reconstruction. In this work, we introduce\nthree innovations that drastically reduce computational cost, while maintaining\nhigh quality: Firstly, we introduce a novel neural network architecture with\njust 8k parameters, 30 times smaller than previous state of the art. Secondly,\nincreasing latency by 1 hop size allows us to further halve the cost of the\nneural inference step. Thirdly, we we observe that the least squares problem\nfeatures a tridiagonal matrix and propose a linear-complexity solver for the\nleast squares step that leverages tridiagonality and positive-semidefiniteness,\nachieving a speedup of several orders of magnitude. We release samples online.", "AI": {"tldr": "Recent work in online speech spectrogram inversion effectively combines Deep Learning with the Gradient Theorem to predict phase derivatives directly from magnitudes, while this work introduces three innovations that drastically reduce computational cost while maintaining high quality.", "motivation": "To drastically reduce computational cost of online speech spectrogram inversion while maintaining high quality.", "method": "Firstly, introduce a novel neural network architecture with just 8k parameters; Secondly, increasing latency by 1 hop size allows to further halve the cost of the neural inference step; Thirdly, propose a linear-complexity solver for the least squares step.", "result": "These innovations maintain high quality reconstruction while drastically reducing computational cost.", "conclusion": "The three introduced innovations successfully reduce the computational cost of online speech spectrogram inversion while maintaining high quality."}}
{"id": "2505.23931", "pdf": "https://arxiv.org/pdf/2505.23931", "abs": "https://arxiv.org/abs/2505.23931", "authors": ["Daniel Wurgaft", "Ben Prystawski", "Kanishk Gandhi", "Cedegao E. Zhang", "Joshua B. Tenenbaum", "Noah D. Goodman"], "title": "Scaling up the think-aloud method", "categories": ["cs.CL", "cs.AI"], "comment": "8 pages, 4 figures. Daniel Wurgaft and Ben Prystawski contributed\n  equally", "summary": "The think-aloud method, where participants voice their thoughts as they solve\na task, is a valuable source of rich data about human reasoning processes. Yet,\nit has declined in popularity in contemporary cognitive science, largely\nbecause labor-intensive transcription and annotation preclude large sample\nsizes. Here, we develop methods to automate the transcription and annotation of\nverbal reports of reasoning using natural language processing tools, allowing\nfor large-scale analysis of think-aloud data. In our study, 640 participants\nthought aloud while playing the Game of 24, a mathematical reasoning task. We\nautomatically transcribed the recordings and coded the transcripts as search\ngraphs, finding moderate inter-rater reliability with humans. We analyze these\ngraphs and characterize consistency and variation in human reasoning traces.\nOur work demonstrates the value of think-aloud data at scale and serves as a\nproof of concept for the automated analysis of verbal reports.", "AI": {"tldr": "The paper presents methods to automate transcription and annotation of think-aloud data for large-scale analysis, demonstrating its value through a study on mathematical reasoning.", "motivation": "To revive the think-aloud method in contemporary cognitive science by overcoming the limitation of labor-intensive transcription and annotation.", "method": "Developed methods using natural language processing tools to automate transcription and annotation of verbal reports. Analyzed the data as search graphs.", "result": "Achieved moderate inter-rater reliability with humans and characterized consistency and variation in human reasoning traces.", "conclusion": "Demonstrates the value of think-aloud data at scale and serves as a proof of concept for automated analysis of verbal reports."}}
{"id": "2505.24505", "pdf": "https://arxiv.org/pdf/2505.24505", "abs": "https://arxiv.org/abs/2505.24505", "authors": ["Ignacio Boero", "Santiago Diaz", "Tom\u00e1s V\u00e1zquez", "Enzo Coppes", "Pablo Belzarena", "Federico Larroca"], "title": "Learning to Optimally Dispatch Power: Performance on a Nation-Wide Real-World Dataset", "categories": ["cs.LG", "math.OC"], "comment": null, "summary": "The Optimal Reactive Power Dispatch (ORPD) problem plays a crucial role in\npower system operations, ensuring voltage stability and minimizing power\nlosses. Recent advances in machine learning, particularly within the ``learning\nto optimize'' framework, have enabled fast and efficient approximations of ORPD\nsolutions, typically by training models on precomputed optimization results.\nWhile these approaches have demonstrated promising performance on synthetic\ndatasets, their effectiveness under real-world grid conditions remains largely\nunexplored. This paper makes two key contributions. First, we introduce a\npublicly available power system dataset that includes both the structural\ncharacteristics of Uruguay's electrical grid and nearly two years of real-world\noperational data, encompassing actual demand and generation profiles. Given\nUruguay's high penetration of renewable energy, the ORPD problem has become the\nprimary optimization challenge in its power network. Second, we assess the\nimpact of real-world data on learning-based ORPD solutions, revealing a\nsignificant increase in prediction errors when transitioning from synthetic to\nactual demand and generation inputs. Our results highlight the limitations of\nexisting models in learning under the complex statistical properties of real\ngrid conditions and emphasize the need for more expressive architectures. By\nproviding this dataset, we aim to facilitate further research into robust\nlearning-based optimization techniques for power system management.", "AI": {"tldr": "The paper introduces a publicly available power system dataset from Uruguay and evaluates learning-based ORPD solutions, showing higher prediction errors with real-world data than synthetic data, thus emphasizing the need for more expressive models.", "motivation": "To address the limitations of existing machine learning models in handling the complex statistical properties of real-world grid conditions for Optimal Reactive Power Dispatch (ORPD) problem.", "method": "Introducing a public dataset containing structural and operational data of Uruguay's electrical grid and assessing the impact of real-world data on learning-based ORPD solutions.", "result": "Learning-based ORPD solutions show significantly higher prediction errors with real-world data compared to synthetic data.", "conclusion": "Existing models are limited in handling real grid conditions; there is a need for more expressive architectures, and the provided dataset can help further research."}}
{"id": "2505.24511", "pdf": "https://arxiv.org/pdf/2505.24511", "abs": "https://arxiv.org/abs/2505.24511", "authors": ["Jiahao Wang", "Mingyue Cheng", "Qi Liu"], "title": "Can Slow-thinking LLMs Reason Over Time? Empirical Studies in Time Series Forecasting", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Time series forecasting (TSF) is a fundamental and widely studied task,\nspanning methods from classical statistical approaches to modern deep learning\nand multimodal language modeling. Despite their effectiveness, these methods\noften follow a fast thinking paradigm emphasizing pattern extraction and direct\nvalue mapping, while overlooking explicit reasoning over temporal dynamics and\ncontextual dependencies. Meanwhile, emerging slow-thinking LLMs (e.g.,\nChatGPT-o1, DeepSeek-R1) have demonstrated impressive multi-step reasoning\ncapabilities across diverse domains, suggesting a new opportunity for reframing\nTSF as a structured reasoning task. This motivates a key question: can\nslow-thinking LLMs effectively reason over temporal patterns to support time\nseries forecasting, even in zero-shot manner? To investigate this, in this\npaper, we propose TimeReasoner, an extensive empirical study that formulates\nTSF as a conditional reasoning task. We design a series of prompting strategies\nto elicit inference-time reasoning from pretrained slow-thinking LLMs and\nevaluate their performance across diverse TSF benchmarks. Our findings reveal\nthat slow-thinking LLMs exhibit non-trivial zero-shot forecasting capabilities,\nespecially in capturing high-level trends and contextual shifts. While\npreliminary, our study surfaces important insights into the reasoning behaviors\nof LLMs in temporal domains highlighting both their potential and limitations.\nWe hope this work catalyzes further research into reasoning-based forecasting\nparadigms and paves the way toward more interpretable and generalizable TSF\nframeworks.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u901a\u8fc7\u63d0\u51faTimeReasoner\uff0c\u63a2\u7d22\u4e86\u6162\u601d\u7ef4\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e2d\u7684\u63a8\u7406\u80fd\u529b\u3002\u4ed6\u4eec\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u63d0\u793a\u7b56\u7565\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u4e0a\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u5b83\u4eec\u5177\u6709\u663e\u8457\u7684\u96f6\u6837\u672c\u9884\u6d4b\u80fd\u529b\uff0c\u5c24\u5176\u662f\u5728\u6355\u6349\u9ad8\u5c42\u6b21\u8d8b\u52bf\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u65b9\u9762\u3002\u8fd9\u9879\u521d\u6b65\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u9886\u57df\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u5e76\u6307\u51fa\u4e86\u5176\u6f5c\u529b\u4e0e\u5c40\u9650\u6027\u3002", "motivation": "\u5c3d\u7ba1\u73b0\u6709\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u65b9\u6cd5\u6709\u6548\uff0c\u4f46\u901a\u5e38\u4fa7\u91cd\u4e8e\u5feb\u901f\u601d\u7ef4\u6a21\u5f0f\uff0c\u5f3a\u8c03\u6a21\u5f0f\u63d0\u53d6\u548c\u76f4\u63a5\u503c\u6620\u5c04\uff0c\u800c\u5ffd\u7565\u4e86\u5bf9\u65f6\u95f4\u52a8\u6001\u548c\u4e0a\u4e0b\u6587\u4f9d\u8d56\u6027\u7684\u663e\u5f0f\u63a8\u7406\u3002\u4e0e\u6b64\u540c\u65f6\uff0c\u65b0\u5174\u7684\u6162\u601d\u7ef4\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u793a\u4e86\u8de8\u9886\u57df\u7684\u591a\u6b65\u9aa4\u63a8\u7406\u80fd\u529b\uff0c\u8fd9\u4e3a\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u91cd\u65b0\u5b9a\u4e49\u4e3a\u7ed3\u6784\u5316\u63a8\u7406\u4efb\u52a1\u63d0\u4f9b\u4e86\u65b0\u7684\u673a\u4f1a\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u51fa\u4e86TimeReasoner\uff0c\u4e00\u4e2a\u5e7f\u6cdb\u7684\u5b9e\u8bc1\u7814\u7a76\uff0c\u5c06\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4f5c\u4e3a\u6761\u4ef6\u63a8\u7406\u4efb\u52a1\u3002\u4ed6\u4eec\u8bbe\u8ba1\u4e86\u4e00\u7cfb\u5217\u63d0\u793a\u7b56\u7565\uff0c\u4ee5\u4ece\u9884\u8bad\u7ec3\u7684\u6162\u601d\u7ef4\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u6fc0\u53d1\u63a8\u7406\u65f6\u7684\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u5728\u591a\u4e2a\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u57fa\u51c6\u4e0a\u8bc4\u4f30\u8fd9\u4e9b\u6a21\u578b\u7684\u8868\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6162\u601d\u7ef4\u5927\u8bed\u8a00\u6a21\u578b\u8868\u73b0\u51fa\u975e\u5e73\u51e1\u7684\u96f6\u6837\u672c\u9884\u6d4b\u80fd\u529b\uff0c\u7279\u522b\u662f\u5728\u6355\u6349\u9ad8\u5c42\u6b21\u8d8b\u52bf\u548c\u4e0a\u4e0b\u6587\u53d8\u5316\u65b9\u9762\u3002\u7136\u800c\uff0c\u8fd9\u9879\u7814\u7a76\u4ecd\u5904\u4e8e\u521d\u6b65\u9636\u6bb5\u3002", "conclusion": "\u8fd9\u9879\u7814\u7a76\u63ed\u793a\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u9886\u57df\u4e2d\u7684\u63a8\u7406\u884c\u4e3a\uff0c\u7a81\u663e\u4e86\u5176\u6f5c\u529b\u548c\u5c40\u9650\u6027\u3002\u4f5c\u8005\u5e0c\u671b\u8fd9\u9879\u5de5\u4f5c\u80fd\u591f\u63a8\u52a8\u57fa\u4e8e\u63a8\u7406\u7684\u9884\u6d4b\u8303\u5f0f\u7684\u7814\u7a76\uff0c\u5e76\u4e3a\u66f4\u53ef\u89e3\u91ca\u548c\u901a\u7528\u7684\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u6846\u67b6\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2505.24513", "pdf": "https://arxiv.org/pdf/2505.24513", "abs": "https://arxiv.org/abs/2505.24513", "authors": ["Paritosh Ranjan", "Surajit Majumder", "Prodip Roy"], "title": "Airborne Neural Network", "categories": ["cs.LG", "cs.NE"], "comment": "11 pages, 3 figures", "summary": "Deep Learning, driven by neural networks, has led to groundbreaking\nadvancements in Artificial Intelligence by enabling systems to learn and adapt\nlike the human brain. These models have achieved remarkable results,\nparticularly in data-intensive domains, supported by massive computational\ninfrastructure. However, deploying such systems in Aerospace, where real time\ndata processing and ultra low latency are critical, remains a challenge due to\ninfrastructure limitations. This paper proposes a novel concept: the Airborne\nNeural Network a distributed architecture where multiple airborne devices each\nhost a subset of neural network neurons. These devices compute collaboratively,\nguided by an airborne network controller and layer specific controllers,\nenabling real-time learning and inference during flight. This approach has the\npotential to revolutionize Aerospace applications, including airborne air\ntraffic control, real-time weather and geographical predictions, and dynamic\ngeospatial data processing. By enabling large-scale neural network operations\nin airborne environments, this work lays the foundation for the next generation\nof AI powered Aerospace systems.", "AI": {"tldr": "The paper introduces Airborne Neural Network, a distributed architecture for real-time learning and inference in aerospace systems.", "motivation": "To address the challenge of deploying deep learning systems in aerospace domain where real time data processing and ultra low latency are critical but infrastructure limitations exist.", "method": "Propose Airborne Neural Network, a distributed architecture where multiple airborne devices each host a subset of neural network neurons and compute collaboratively guided by controllers.", "result": "This approach enables large-scale neural network operations in airborne environments which could revolutionize aerospace applications such as air traffic control and geospatial data processing.", "conclusion": "Airborne Neural Network lays the foundation for next generation AI powered aerospace systems."}}
{"id": "2505.23945", "pdf": "https://arxiv.org/pdf/2505.23945", "abs": "https://arxiv.org/abs/2505.23945", "authors": ["Sriram Balasubramanian", "Samyadeep Basu", "Soheil Feizi"], "title": "A Closer Look at Bias and Chain-of-Thought Faithfulness of Large (Vision) Language Models", "categories": ["cs.CL", "cs.AI", "I.2.10; I.2.7"], "comment": "34 pages, 25 figures", "summary": "Chain-of-thought (CoT) reasoning enhances performance of large language\nmodels, but questions remain about whether these reasoning traces faithfully\nreflect the internal processes of the model. We present the first comprehensive\nstudy of CoT faithfulness in large vision-language models (LVLMs),\ninvestigating how both text-based and previously unexplored image-based biases\naffect reasoning and bias articulation. Our work introduces a novel,\nfine-grained evaluation pipeline for categorizing bias articulation patterns,\nenabling significantly more precise analysis of CoT reasoning than previous\nmethods. This framework reveals critical distinctions in how models process and\nrespond to different types of biases, providing new insights into LVLM CoT\nfaithfulness. Our findings reveal that subtle image-based biases are rarely\narticulated compared to explicit text-based ones, even in models specialized\nfor reasoning. Additionally, many models exhibit a previously unidentified\nphenomenon we term ``inconsistent'' reasoning - correctly reasoning before\nabruptly changing answers, serving as a potential canary for detecting biased\nreasoning from unfaithful CoTs. We then apply the same evaluation pipeline to\nrevisit CoT faithfulness in LLMs across various levels of implicit cues. Our\nfindings reveal that current language-only reasoning models continue to\nstruggle with articulating cues that are not overtly stated.", "AI": {"tldr": "Chain-of-thought (CoT) reasoning was studied in large vision-language models (LVLMs) and language models (LLMs). A new evaluation pipeline was introduced to analyze bias articulation patterns. Findings revealed that image-based biases are less articulated than text-based ones, and a phenomenon called 'inconsistent' reasoning was identified.", "motivation": "To investigate the faithfulness of chain-of-thought reasoning in large vision-language models (LVLMs) and understand how both text-based and image-based biases affect reasoning.", "method": "Developed a novel fine-grained evaluation pipeline to categorize bias articulation patterns in LVLMs and LLMs, allowing for more precise analysis of CoT reasoning.", "result": "Discovered that image-based biases are rarely articulated compared to text-based ones, and identified a new phenomenon termed 'inconsistent' reasoning where models correctly reason before suddenly changing answers.", "conclusion": "Current reasoning models struggle with implicit cues that are not explicitly stated, highlighting challenges in achieving faithful CoT reasoning."}}
{"id": "2505.24531", "pdf": "https://arxiv.org/pdf/2505.24531", "abs": "https://arxiv.org/abs/2505.24531", "authors": ["Sagar Ghosh", "Kushal Bose", "Swagatam Das"], "title": "Transformers Are Universally Consistent", "categories": ["cs.LG"], "comment": null, "summary": "Despite their central role in the success of foundational models and\nlarge-scale language modeling, the theoretical foundations governing the\noperation of Transformers remain only partially understood. Contemporary\nresearch has largely focused on their representational capacity for language\ncomprehension and their prowess in in-context learning, frequently under\nidealized assumptions such as linearized attention mechanisms. Initially\nconceived to model sequence-to-sequence transformations, a fundamental and\nunresolved question is whether Transformers can robustly perform functional\nregression over sequences of input tokens. This question assumes heightened\nimportance given the inherently non-Euclidean geometry underlying real-world\ndata distributions. In this work, we establish that Transformers equipped with\nsoftmax-based nonlinear attention are uniformly consistent when tasked with\nexecuting Ordinary Least Squares (OLS) regression, provided both the inputs and\noutputs are embedded in hyperbolic space. We derive deterministic upper bounds\non the empirical error which, in the asymptotic regime, decay at a provable\nrate of $\\mathcal{O}(t^{-1/2d})$, where $t$ denotes the number of input tokens\nand $d$ the embedding dimensionality. Notably, our analysis subsumes the\nEuclidean setting as a special case, recovering analogous convergence\nguarantees parameterized by the intrinsic dimensionality of the data manifold.\nThese theoretical insights are corroborated through empirical evaluations on\nreal-world datasets involving both continuous and categorical response\nvariables.", "AI": {"tldr": "Transformers with softmax-based nonlinear attention can perform OLS regression uniformly consistently in hyperbolic space, with empirical error bounds decreasing at a rate of $\\mathcal{O}(t^{-1/2d})$; results also apply to Euclidean settings.", "motivation": "To determine if Transformers can robustly perform functional regression over sequences of input tokens, especially considering the non-Euclidean geometry of real-world data distributions.", "method": "Analyze Transformers equipped with softmax-based nonlinear attention for their ability to execute OLS regression when inputs and outputs are embedded in hyperbolic space, deriving deterministic upper bounds on empirical error.", "result": "Theoretical analysis shows uniform consistency for OLS regression with error bounds decaying at a rate of $\\mathcal{O}(t^{-1/2d})$, applicable to both hyperbolic and Euclidean spaces.", "conclusion": "Transformers with softmax-based nonlinear attention are capable of performing OLS regression uniformly consistently in hyperbolic space, supported by theoretical guarantees and empirical evaluations."}}
{"id": "2505.24533", "pdf": "https://arxiv.org/pdf/2505.24533", "abs": "https://arxiv.org/abs/2505.24533", "authors": ["Mahesh Godavarti"], "title": "Directional Non-Commutative Monoidal Structures with Interchange Law via Commutative Generators", "categories": ["cs.LG", "cs.AI", "cs.SC", "20-XX, 08A02", "F.4.1; I.2"], "comment": null, "summary": "We introduce a novel framework consisting of a class of algebraic structures\nthat generalize one-dimensional monoidal systems into higher dimensions by\ndefining per-axis composition operators subject to non-commutativity and a\nglobal interchange law. These structures, defined recursively from a base case\nof vector-matrix pairs, model directional composition in multiple dimensions\nwhile preserving structural coherence through commutative linear operators.\n  We show that the framework that unifies several well-known linear transforms\nin signal processing and data analysis. In this framework, data indices are\nembedded into a composite structure that decomposes into simpler components. We\nshow that classic transforms such as the Discrete Fourier Transform (DFT), the\nWalsh transform, and the Hadamard transform are special cases of our algebraic\nstructure. The framework provides a systematic way to derive these transforms\nby appropriately choosing vector and matrix pairs. By subsuming classical\ntransforms within a common structure, the framework also enables the\ndevelopment of learnable transformations tailored to specific data modalities\nand tasks.", "AI": {"tldr": "The paper presents a novel framework generalizing one-dimensional monoidal systems into higher dimensions, unifying several well-known linear transforms and enabling learnable transformations.", "motivation": "To create a systematic way to derive classic transforms such as the Discrete Fourier Transform (DFT), the Walsh transform, and the Hadamard transform by appropriately choosing vector and matrix pairs.", "method": "Introducing a class of algebraic structures that generalize one-dimensional monoidal systems into higher dimensions using per-axis composition operators subject to non-commutativity and a global interchange law. These structures are defined recursively from a base case of vector-matrix pairs.", "result": "Classic transforms are shown to be special cases of this algebraic structure, providing a unified framework for deriving these transforms systematically.", "conclusion": "This framework not only unifies classical transforms but also enables the development of learnable transformations tailored to specific data modalities and tasks."}}
{"id": "2505.24534", "pdf": "https://arxiv.org/pdf/2505.24534", "abs": "https://arxiv.org/abs/2505.24534", "authors": ["Florian Frantzen", "Michael T. Schaub"], "title": "HLSAD: Hodge Laplacian-based Simplicial Anomaly Detection", "categories": ["cs.LG", "cs.SI"], "comment": "Accepted for KDD 2025", "summary": "In this paper, we propose HLSAD, a novel method for detecting anomalies in\ntime-evolving simplicial complexes. While traditional graph anomaly detection\ntechniques have been extensively studied, they often fail to capture changes in\nhigher-order interactions that are crucial for identifying complex structural\nanomalies. These higher-order interactions can arise either directly from the\nunderlying data itself or through graph lifting techniques. Our approach\nleverages the spectral properties of Hodge Laplacians of simplicial complexes\nto effectively model multi-way interactions among data points. By incorporating\nhigher-dimensional simplicial structures into our method, our method enhances\nboth detection accuracy and computational efficiency. Through comprehensive\nexperiments on both synthetic and real-world datasets, we demonstrate that our\napproach outperforms existing graph methods in detecting both events and change\npoints.", "AI": {"tldr": "The paper introduces HLSAD, a new method for detecting anomalies in time-evolving simplicial complexes using Hodge Laplacians.", "motivation": "Traditional graph anomaly detection techniques often fail to capture changes in higher-order interactions that are crucial for identifying complex structural anomalies.", "method": "Leveraging the spectral properties of Hodge Laplacians of simplicial complexes to model multi-way interactions among data points and incorporating higher-dimensional simplicial structures into the method.", "result": "Outperforms existing graph methods in detecting both events and change points through comprehensive experiments on both synthetic and real-world datasets.", "conclusion": "HLSAD enhances both detection accuracy and computational efficiency."}}
{"id": "2505.23953", "pdf": "https://arxiv.org/pdf/2505.23953", "abs": "https://arxiv.org/abs/2505.23953", "authors": ["Melika Sepidband", "Hamed Taherkhani", "Song Wang", "Hadi Hemmati"], "title": "Enhancing LLM-Based Code Generation with Complexity Metrics: A Feedback-Driven Approach", "categories": ["cs.SE", "cs.AI"], "comment": "11 pages, 5 figures. Accepted to COMPSAC 2025", "summary": "Automatic code generation has gained significant momentum with the advent of\nLarge Language Models (LLMs) such as GPT-4. Although many studies focus on\nimproving the effectiveness of LLMs for code generation, very limited work\ntries to understand the generated code's characteristics and leverage that to\nimprove failed cases. In this paper, as the most straightforward characteristic\nof code, we investigate the relationship between code complexity and the\nsuccess of LLM generated code. Using a large set of standard complexity\nmetrics, we first conduct an empirical analysis to explore their correlation\nwith LLM's performance on code generation (i.e., Pass@1). Using logistic\nregression models, we identify which complexity metrics are most predictive of\ncode correctness. Building on these findings, we propose an iterative feedback\nmethod, where LLMs are prompted to generate correct code based on complexity\nmetrics from previous failed outputs. We validate our approach across multiple\nbenchmarks (i.e., HumanEval, MBPP, LeetCode, and BigCodeBench) and various LLMs\n(i.e., GPT-4o, GPT-3.5 Turbo, Llama 3.1, and GPT-o3 mini), comparing the\nresults with two baseline methods: (a) zero-shot generation, and (b) iterative\nexecution-based feedback without our code complexity insights. Experiment\nresults show that our approach makes notable improvements, particularly with a\nsmaller LLM (GPT3.5 Turbo), where, e.g., Pass@1 increased by 35.71% compared to\nthe baseline's improvement of 12.5% on the HumanEval dataset. The study expands\nexperiments to BigCodeBench and integrates the method with the Reflexion code\ngeneration agent, leading to Pass@1 improvements of 20% (GPT-4o) and 23.07%\n(GPT-o3 mini). The results highlight that complexity-aware feedback enhances\nboth direct LLM prompting and agent-based workflows.", "AI": {"tldr": "The paper investigates the relationship between code complexity and success of LLM-generated code, proposing an iterative feedback method based on complexity metrics to improve failed cases.", "motivation": "While many studies focus on improving LLMs for code generation, there's limited work on understanding the characteristics of generated code and leveraging that knowledge to address failures.", "method": "Using standard complexity metrics, the authors conduct an empirical analysis correlating these metrics with LLM performance in code generation. Logistic regression identifies predictive metrics, which inform an iterative feedback loop prompting LLMs to generate correct code based on prior failures.", "result": "Experiments across multiple benchmarks (HumanEval, MBPP, LeetCode, BigCodeBench) and various LLMs show significant improvements, particularly with smaller models like GPT-3.5 Turbo, where Pass@1 increased by 35.71% compared to a baseline improvement of 12.5%. Integrating the method with Reflexion led to further enhancements.", "conclusion": "Complexity-aware feedback improves both direct LLM prompting and agent-based workflows, offering notable performance boosts, especially for smaller models."}}
{"id": "2505.24535", "pdf": "https://arxiv.org/pdf/2505.24535", "abs": "https://arxiv.org/abs/2505.24535", "authors": ["Narmeen Oozeer", "Luke Marks", "Fazl Barez", "Amirali Abdullah"], "title": "Beyond Linear Steering: Unified Multi-Attribute Control for Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Controlling multiple behavioral attributes in large language models (LLMs) at\ninference time is a challenging problem due to interference between attributes\nand the limitations of linear steering methods, which assume additive behavior\nin activation space and require per-attribute tuning. We introduce K-Steering,\na unified and flexible approach that trains a single non-linear multi-label\nclassifier on hidden activations and computes intervention directions via\ngradients at inference time. This avoids linearity assumptions, removes the\nneed for storing and tuning separate attribute vectors, and allows dynamic\ncomposition of behaviors without retraining. To evaluate our method, we propose\ntwo new benchmarks, ToneBank and DebateMix, targeting compositional behavioral\ncontrol. Empirical results across 3 model families, validated by both\nactivation-based classifiers and LLM-based judges, demonstrate that K-Steering\noutperforms strong baselines in accurately steering multiple behaviors.", "AI": {"tldr": "K-Steering\u662f\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u5728\u63a8\u7406\u65f6\u63a7\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\u3002\u5b83\u901a\u8fc7\u8bad\u7ec3\u4e00\u4e2a\u5355\u4e00\u7684\u975e\u7ebf\u6027\u591a\u6807\u7b7e\u5206\u7c7b\u5668\u6765\u907f\u514d\u7ebf\u6027\u5047\u8bbe\uff0c\u79fb\u9664\u5b58\u50a8\u548c\u8c03\u6574\u5355\u72ec\u5c5e\u6027\u5411\u91cf\u7684\u9700\u6c42\uff0c\u5e76\u5141\u8bb8\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u52a8\u6001\u7ec4\u5408\u884c\u4e3a\u3002\u5728ToneBank\u548cDebateMix\u4e24\u4e2a\u65b0\u57fa\u51c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0cK-Steering\u5728\u51c6\u786e\u5f15\u5bfc\u591a\u79cd\u884c\u4e3a\u65b9\u9762\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u3002", "motivation": "\u63a7\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\u662f\u4e00\u4e2a\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u56e0\u4e3a\u5c5e\u6027\u4e4b\u95f4\u5b58\u5728\u5e72\u6270\uff0c\u800c\u4e14\u7ebf\u6027\u5f15\u5bfc\u65b9\u6cd5\u5047\u8bbe\u6fc0\u6d3b\u7a7a\u95f4\u4e2d\u7684\u52a0\u6cd5\u884c\u4e3a\u5e76\u9700\u8981\u6bcf\u5c5e\u6027\u8c03\u6574\u3002", "method": "\u5f15\u5165\u4e86K-Steering\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u85cf\u6fc0\u6d3b\u4e0a\u8bad\u7ec3\u4e00\u4e2a\u5355\u4e00\u7684\u975e\u7ebf\u6027\u591a\u6807\u7b7e\u5206\u7c7b\u5668\uff0c\u5e76\u901a\u8fc7\u68af\u5ea6\u8ba1\u7b97\u5e72\u9884\u65b9\u5411\u3002\u8fd9\u907f\u514d\u4e86\u7ebf\u6027\u5047\u8bbe\uff0c\u79fb\u9664\u4e86\u5b58\u50a8\u548c\u8c03\u6574\u5355\u72ec\u5c5e\u6027\u5411\u91cf\u7684\u9700\u6c42\uff0c\u5e76\u5141\u8bb8\u5728\u4e0d\u91cd\u65b0\u8bad\u7ec3\u7684\u60c5\u51b5\u4e0b\u52a8\u6001\u7ec4\u5408\u884c\u4e3a\u3002", "result": "\u57283\u4e2a\u6a21\u578b\u5bb6\u65cf\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\uff0c\u901a\u8fc7\u6fc0\u6d3b\u57fa\u7840\u5206\u7c7b\u5668\u548cLLM\u57fa\u7840\u6cd5\u5b98\u9a8c\u8bc1\uff0c\u8868\u660eK-Steering\u5728\u51c6\u786e\u5f15\u5bfc\u591a\u79cd\u884c\u4e3a\u65b9\u9762\u4f18\u4e8e\u5f3a\u5927\u7684\u57fa\u7ebf\u3002", "conclusion": "K-Steering\u63d0\u4f9b\u4e86\u4e00\u79cd\u7edf\u4e00\u4e14\u7075\u6d3b\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u63a7\u5236\u5927\u578b\u8bed\u8a00\u6a21\u578b\u591a\u4e2a\u884c\u4e3a\u5c5e\u6027\u7684\u6311\u6218\u3002"}}
{"id": "2505.24578", "pdf": "https://arxiv.org/pdf/2505.24578", "abs": "https://arxiv.org/abs/2505.24578", "authors": ["Abhishek Chandra", "Taniya Kapoor", "Mitrofan Curti", "Koen Tiels", "Elena A. Lomonova"], "title": "Neuro-Symbolic Operator for Interpretable and Generalizable Characterization of Complex Piezoelectric Systems", "categories": ["cs.LG"], "comment": null, "summary": "Complex piezoelectric systems are foundational in industrial applications.\nTheir performance, however, is challenged by the nonlinear voltage-displacement\nhysteretic relationships. Efficient characterization methods are, therefore,\nessential for reliable design, monitoring, and maintenance. Recently proposed\nneural operator methods serve as surrogates for system characterization but\nface two pressing issues: interpretability and generalizability.\nState-of-the-art (SOTA) neural operators are black-boxes, providing little\ninsight into the learned operator. Additionally, generalizing them to novel\nvoltages and predicting displacement profiles beyond the training domain is\nchallenging, limiting their practical use. To address these limitations, this\npaper proposes a neuro-symbolic operator (NSO) framework that derives the\nanalytical operators governing hysteretic relationships. NSO first learns a\nFourier neural operator mapping voltage fields to displacement profiles,\nfollowed by a library-based sparse model discovery method, generating white-box\nparsimonious models governing the underlying hysteresis. These models enable\naccurate and interpretable prediction of displacement profiles across varying\nand out-of-distribution voltage fields, facilitating generalizability. The\npotential of NSO is demonstrated by accurately predicting voltage-displacement\nhysteresis, including butterfly-shaped relationships. Moreover, NSO predicts\ndisplacement profiles even for noisy and low-fidelity voltage data, emphasizing\nits robustness. The results highlight the advantages of NSO compared to SOTA\nneural operators and model discovery methods on several evaluation metrics.\nConsequently, NSO contributes to characterizing complex piezoelectric systems\nwhile improving the interpretability and generalizability of neural operators,\nessential for design, monitoring, maintenance, and other real-world scenarios.", "AI": {"tldr": "Neuro-symbolic operator (NSO) framework is proposed to derive analytical operators governing hysteretic relationships in complex piezoelectric systems. It combines a Fourier neural operator and a sparse model discovery method, enabling accurate, interpretable predictions of displacement profiles even for noisy data or out-of-distribution voltages.", "motivation": "Current neural operator methods used for characterizing complex piezoelectric systems suffer from issues related to interpretability and generalizability. State-of-the-art neural operators are black-boxes that do not provide insights into the learned operator and struggle with predicting displacement profiles beyond their training domain.", "method": "The NSO framework first uses a Fourier neural operator to learn a mapping from voltage fields to displacement profiles. Then it applies a library-based sparse model discovery method to generate white-box parsimonious models governing the underlying hysteresis.", "result": "NSO accurately predicts voltage-displacement hysteresis, including butterfly-shaped relationships, and can handle noisy and low-fidelity voltage data, showing robustness. It outperforms state-of-the-art neural operators and model discovery methods on several evaluation metrics.", "conclusion": "The NSO contributes significantly to the characterization of complex piezoelectric systems by enhancing both interpretability and generalizability of neural operators, which is crucial for various real-world applications such as design, monitoring, and maintenance."}}
{"id": "2505.24579", "pdf": "https://arxiv.org/pdf/2505.24579", "abs": "https://arxiv.org/abs/2505.24579", "authors": ["Chaoyu Liu", "Yangming Li", "Zhongying Deng", "Chris Budd", "Carola-Bibiane Sch\u00f6nlieb"], "title": "Conservation-preserved Fourier Neural Operator through Adaptive Correction", "categories": ["cs.LG"], "comment": null, "summary": "Fourier Neural Operators (FNOs) have recently emerged as a promising and\nefficient approach for learning the numerical solutions to partial differential\nequations (PDEs) from data. However, standard FNO often fails to preserve key\nconservation laws, such as mass conservation, momentum conservation, norm\nconservation, etc., which are crucial for accurately modeling physical systems.\nExisting methods for incorporating these conservation laws into Fourier neural\noperators are achieved by designing related loss function or incorporating\npost-processing method at the training time. None of them can both exactly and\nadaptively correct the outputs to satisfy conservation laws, and our\nexperiments show that these methods can lead to inferior performance while\npreserving conservation laws. In this work, we propose a novel adaptive\ncorrection approach to ensure the conservation of fundamental quantities. Our\nmethod introduces a learnable matrix to adaptively adjust the solution to\nsatisfy the conservation law during training. It ensures that the outputs\nexactly satisfy the goal conservation law and allow for more flexibility and\nadaptivity for the model to correct the outputs. We theoretically show that\napplying our adaptive correction to an unconstrained FNO yields a solution with\ndata loss no worse than that of the best conservation-satisfying FNO. We\ncompare our approach with existing methods on a range of representative PDEs.\nExperiment results show that our method consistently outperform other methods.", "AI": {"tldr": "\u4e3a\u4e86\u89e3\u51b3\u6807\u51c6\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50(FNOs)\u65e0\u6cd5\u5f88\u597d\u5730\u9075\u5faa\u7269\u7406\u5b88\u6052\u5b9a\u5f8b\u7684\u95ee\u9898\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u6821\u6b63\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u5b66\u4e60\u77e9\u9635\u6765\u8c03\u6574\u89e3\u4ee5\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u504f\u5fae\u5206\u65b9\u7a0b(PDEs)\u4e0a\u8868\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c3d\u7ba1\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50(FNOs)\u5728\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u504f\u5fae\u5206\u65b9\u7a0b(PDEs)\u7684\u6570\u503c\u89e3\u65b9\u9762\u663e\u793a\u51fa\u5e0c\u671b\u548c\u6548\u7387\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u65e0\u6cd5\u4fdd\u7559\u5173\u952e\u7684\u5b88\u6052\u5b9a\u5f8b\uff08\u5982\u8d28\u91cf\u5b88\u6052\u3001\u52a8\u91cf\u5b88\u6052\u7b49\uff09\uff0c\u8fd9\u5728\u51c6\u786e\u5efa\u6a21\u7269\u7406\u7cfb\u7edf\u65f6\u662f\u81f3\u5173\u91cd\u8981\u7684\u3002\u73b0\u6709\u7684\u5c06\u8fd9\u4e9b\u5b88\u6052\u5b9a\u5f8b\u7eb3\u5165\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u7684\u65b9\u6cd5\u8981\u4e48\u8bbe\u8ba1\u76f8\u5173\u635f\u5931\u51fd\u6570\uff0c\u8981\u4e48\u5728\u8bad\u7ec3\u65f6\u91c7\u7528\u540e\u5904\u7406\u65b9\u6cd5\uff0c\u4f46\u8fd9\u4e9b\u65b9\u6cd5\u4e0d\u80fd\u7cbe\u786e\u4e14\u81ea\u9002\u5e94\u5730\u6821\u6b63\u8f93\u51fa\u4ee5\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\uff0c\u5e76\u53ef\u80fd\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u81ea\u9002\u5e94\u6821\u6b63\u65b9\u6cd5\uff0c\u901a\u8fc7\u5f15\u5165\u4e00\u4e2a\u53ef\u5b66\u4e60\u77e9\u9635\uff0c\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u81ea\u9002\u5e94\u5730\u8c03\u6574\u89e3\u4ee5\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\u3002\u8fd9\u79cd\u65b9\u6cd5\u786e\u4fdd\u4e86\u8f93\u51fa\u5b8c\u5168\u7b26\u5408\u76ee\u6807\u5b88\u6052\u5b9a\u5f8b\uff0c\u540c\u65f6\u4e3a\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u591a\u7684\u7075\u6d3b\u6027\u548c\u81ea\u9002\u5e94\u6027\u4ee5\u6821\u6b63\u8f93\u51fa\u3002\u7406\u8bba\u4e0a\u8bc1\u660e\uff0c\u5c06\u6b64\u81ea\u9002\u5e94\u6821\u6b63\u5e94\u7528\u4e8e\u65e0\u7ea6\u675f\u7684FNO\u53ef\u4ee5\u5f97\u5230\u4e00\u4e2a\u6570\u636e\u635f\u5931\u4e0d\u6bd4\u6700\u4f73\u5b88\u6052\u6ee1\u8db3\u578bFNO\u5dee\u7684\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u4e00\u7cfb\u5217\u5177\u6709\u4ee3\u8868\u6027\u7684PDEs\u4e0a\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u6821\u6b63\u65b9\u6cd5\u6709\u6548\u5730\u89e3\u51b3\u4e86FNO\u65e0\u6cd5\u7cbe\u786e\u6ee1\u8db3\u5b88\u6052\u5b9a\u5f8b\u7684\u95ee\u9898\uff0c\u4e3a\u6570\u503c\u6c42\u89e3PDE\u63d0\u4f9b\u4e86\u4e00\u4e2a\u66f4\u7cbe\u786e\u548c\u7075\u6d3b\u7684\u5de5\u5177\u3002"}}
{"id": "2505.23977", "pdf": "https://arxiv.org/pdf/2505.23977", "abs": "https://arxiv.org/abs/2505.23977", "authors": ["Yichen Feng", "Zhangchen Xu", "Fengqing Jiang", "Yuetai Li", "Bhaskar Ramasubramanian", "Luyao Niu", "Bill Yuchen Lin", "Radha Poovendran"], "title": "VisualSphinx: Large-Scale Synthetic Vision Logic Puzzles for RL", "categories": ["cs.CV", "cs.AI", "cs.LG"], "comment": "Project page at https://visualsphinx.github.io/", "summary": "Vision language models (VLMs) are expected to perform effective multimodal\nreasoning and make logically coherent decisions, which is critical to tasks\nsuch as diagram understanding and spatial problem solving. However, current VLM\nreasoning lacks large-scale and well-structured training datasets. To bridge\nthis gap, we propose VisualSphinx, a first-of-its-kind large-scale synthetic\nvisual logical reasoning training data. To tackle the challenge of image\nsynthesis with grounding answers, we propose a rule-to-image synthesis\npipeline, which extracts and expands puzzle rules from seed questions and\ngenerates the code of grounding synthesis image synthesis for puzzle sample\nassembly. Experiments demonstrate that VLM trained using GRPO on VisualSphinx\nbenefit from logical coherence and readability of our dataset and exhibit\nimproved performance on logical reasoning tasks. The enhanced reasoning\ncapabilities developed from VisualSphinx also benefit other reasoning tasks\nsuch as algebraic reasoning, arithmetic reasoning and geometry reasoning.", "AI": {"tldr": "The paper presents VisualSphinx, a large-scale synthetic visual logical reasoning training data for vision language models (VLMs), enhancing their logical reasoning capabilities.", "motivation": "Vision language models need effective multimodal reasoning and logical coherence which is essential for tasks like diagram understanding but lack appropriate training datasets.", "method": "Proposes VisualSphinx, a large-scale synthetic visual logical reasoning training data created through a rule-to-image synthesis pipeline that extracts and expands puzzle rules from seed questions to generate grounded synthesis images.", "result": "VLMs trained with VisualSphinx show improved performance in logical reasoning tasks and also benefit other reasoning tasks such as algebraic, arithmetic, and geometry reasoning.", "conclusion": "VisualSphinx enhances VLM's reasoning capabilities significantly."}}
{"id": "2505.24584", "pdf": "https://arxiv.org/pdf/2505.24584", "abs": "https://arxiv.org/abs/2505.24584", "authors": ["Sakhinana Sagar Srinivas", "Shivam Gupta", "Venkataramana Runkana"], "title": "AutoChemSchematic AI: A Closed-Loop, Physics-Aware Agentic Framework for Auto-Generating Chemical Process and Instrumentation Diagrams", "categories": ["cs.LG", "cs.AI", "cs.IR"], "comment": null, "summary": "Recent advancements in generative AI have accelerated the discovery of novel\nchemicals and materials; however, transitioning these discoveries to\nindustrial-scale production remains a critical bottleneck, as it requires the\ndevelopment of entirely new chemical manufacturing processes. Current AI\nmethods cannot auto-generate PFDs or PIDs, despite their critical role in\nscaling chemical processes, while adhering to engineering constraints. We\npresent a closed loop, physics aware framework for the automated generation of\nindustrially viable PFDs and PIDs. The framework integrates domain specialized\nsmall scale language models (SLMs) (trained for chemical process QA tasks) with\nfirst principles simulation, leveraging three key components: (1) a\nhierarchical knowledge graph of process flow and instrumentation descriptions\nfor 1,020+ chemicals, (2) a multi-stage training pipeline that fine tunes\ndomain specialized SLMs on synthetic datasets via Supervised Fine-Tuning (SFT),\nDirect Preference Optimization (DPO), and Retrieval-Augmented Instruction\nTuning (RAIT), and (3) DWSIM based simulator in the loop validation to ensure\nfeasibility. To improve both runtime efficiency and model compactness, the\nframework incorporates advanced inference time optimizations including\nFlashAttention, Lookahead Decoding, PagedAttention with KV-cache quantization,\nand Test Time Inference Scaling and independently applies structural pruning\ntechniques (width and depth) guided by importance heuristics to reduce model\nsize with minimal accuracy loss. Experiments demonstrate that the framework\ngenerates simulator-validated process descriptions with high fidelity,\noutperforms baseline methods in correctness, and generalizes to unseen\nchemicals. By bridging AI-driven design with industrial-scale feasibility, this\nwork significantly reduces R&D timelines from lab discovery to plant\ndeployment.", "AI": {"tldr": "Recent advancements in generative AI have accelerated chemical and material discovery, but transitioning to industrial-scale production is still a challenge. This paper presents a closed-loop, physics-aware framework that automates the generation of process flow diagrams (PFDs) and piping and instrumentation diagrams (PIDs), which are crucial for scaling chemical processes. The framework integrates specialized small language models with first-principles simulation, and it includes a hierarchical knowledge graph, multi-stage training pipeline, and DWSIM-based validation. Advanced inference optimizations and structural pruning techniques are also applied to improve efficiency and compactness.", "motivation": "The motivation behind this work is to address the critical bottleneck of transitioning AI-discovered chemicals and materials into industrial-scale production by developing new chemical manufacturing processes. Current AI methods lack the capability to auto-generate PFDs or PIDs while considering engineering constraints.", "method": "The method involves creating a closed loop, physics aware framework for automated generation of industrially viable PFDs and PIDs. It integrates domain specialized small scale language models with first principles simulation. Key components include: a hierarchical knowledge graph of process flow and instrumentation descriptions for over 1020 chemicals; a multi-stage training pipeline using Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Retrieval-Augmented Instruction Tuning (RAIT); and DWSIM based simulator in the loop validation. Additionally, advanced inference time optimizations and structural pruning techniques are incorporated to enhance runtime efficiency and model compactness.", "result": "Experiments show that the framework generates simulator-validated process descriptions with high fidelity, outperforms baseline methods in correctness, and generalizes well to unseen chemicals.", "conclusion": "This work bridges AI-driven design with industrial-scale feasibility, significantly reducing R&D timelines from lab discovery to plant deployment."}}
{"id": "2505.24592", "pdf": "https://arxiv.org/pdf/2505.24592", "abs": "https://arxiv.org/abs/2505.24592", "authors": ["Weebum Yoo", "Sung Whan Yoon"], "title": "A Flat Minima Perspective on Understanding Augmentations and Model Robustness", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Model robustness indicates a model's capability to generalize well on\nunforeseen distributional shifts, including data corruption, adversarial\nattacks, and domain shifts. Data augmentation is one of the prevalent and\neffective ways to enhance robustness. Despite the great success of\naugmentations in different fields, a general theoretical understanding of their\nefficacy in improving model robustness is lacking. We offer a unified\ntheoretical framework to clarify how augmentations can enhance model robustness\nthrough the lens of loss surface flatness and PAC generalization bound. Our\nwork diverges from prior studies in that our analysis i) broadly encompasses\nmuch of the existing augmentation methods, and ii) is not limited to specific\ntypes of distribution shifts like adversarial attacks. We confirm our theories\nthrough simulations on the existing common corruption and adversarial\nrobustness benchmarks based on the CIFAR and ImageNet datasets, as well as\ndomain generalization benchmarks including PACS and OfficeHome.", "AI": {"tldr": "The paper presents a unified theoretical framework explaining how data augmentations enhance model robustness, using loss surface flatness and PAC generalization bound, with confirmation via simulations on various benchmarks.", "motivation": "To provide a comprehensive theoretical understanding of why and how data augmentations improve model robustness across different types of distributional shifts.", "method": "A unified theoretical framework analyzing the role of data augmentations in enhancing model robustness by considering loss surface flatness and PAC generalization bound. This method covers a wide range of existing augmentation techniques and is not restricted to specific distribution shifts.", "result": "The theories proposed in the paper are validated through simulations on common corruption and adversarial robustness benchmarks (CIFAR, ImageNet) and domain generalization benchmarks (PACS, OfficeHome).", "conclusion": "This work offers a broad and inclusive theoretical analysis of the efficacy of data augmentations in improving model robustness, beyond specific types of distributional shifts."}}
{"id": "2505.23996", "pdf": "https://arxiv.org/pdf/2505.23996", "abs": "https://arxiv.org/abs/2505.23996", "authors": ["Yinong Oliver Wang", "Nivedha Sivakumar", "Falaah Arif Khan", "Rin Metcalf Susa", "Adam Golinski", "Natalie Mackraz", "Barry-John Theobald", "Luca Zappella", "Nicholas Apostoloff"], "title": "Is Your Model Fairly Certain? Uncertainty-Aware Fairness Evaluation for LLMs", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "9 pages, 8 figures, and 1 table in main paper. Supplementary appendix\n  attached. Accepted at ICML 2025", "summary": "The recent rapid adoption of large language models (LLMs) highlights the\ncritical need for benchmarking their fairness. Conventional fairness metrics,\nwhich focus on discrete accuracy-based evaluations (i.e., prediction\ncorrectness), fail to capture the implicit impact of model uncertainty (e.g.,\nhigher model confidence about one group over another despite similar accuracy).\nTo address this limitation, we propose an uncertainty-aware fairness metric,\nUCerF, to enable a fine-grained evaluation of model fairness that is more\nreflective of the internal bias in model decisions compared to conventional\nfairness measures. Furthermore, observing data size, diversity, and clarity\nissues in current datasets, we introduce a new gender-occupation fairness\nevaluation dataset with 31,756 samples for co-reference resolution, offering a\nmore diverse and suitable dataset for evaluating modern LLMs. We establish a\nbenchmark, using our metric and dataset, and apply it to evaluate the behavior\nof ten open-source LLMs. For example, Mistral-7B exhibits suboptimal fairness\ndue to high confidence in incorrect predictions, a detail overlooked by\nEqualized Odds but captured by UCerF. Overall, our proposed LLM benchmark,\nwhich evaluates fairness with uncertainty awareness, paves the way for\ndeveloping more transparent and accountable AI systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u516c\u5e73\u6027\u5ea6\u91cfUCerF\uff0c\u5e76\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b31,756\u4e2a\u6837\u672c\u7684\u65b0\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u73b0\u4ee3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6027\u522b-\u804c\u4e1a\u516c\u5e73\u6027\u3002\u4f7f\u7528\u8be5\u5ea6\u91cf\u548c\u6570\u636e\u96c6\u5bf9\u5341\u4e2a\u5f00\u6e90LLM\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u63ed\u793a\u4e86\u4f20\u7edf\u65b9\u6cd5\u672a\u80fd\u53d1\u73b0\u7684\u6a21\u578b\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7684\u5feb\u901f\u666e\u53ca\u5f3a\u8c03\u4e86\u5bf9\u5176\u516c\u5e73\u6027\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\u7684\u91cd\u8981\u6027\u3002\u4f20\u7edf\u7684\u516c\u5e73\u6027\u6307\u6807\u4ec5\u5173\u6ce8\u79bb\u6563\u7684\u51c6\u786e\u6027\u8bc4\u4f30\uff0c\u65e0\u6cd5\u53cd\u6620\u6a21\u578b\u5728\u4e0d\u540c\u7fa4\u4f53\u95f4\u7684\u4e0d\u786e\u5b9a\u6027\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u4e86\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u516c\u5e73\u6027\u5ea6\u91cfUCerF\uff0c\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b31,756\u4e2a\u6837\u672c\u7684\u65b0\u6570\u636e\u96c6\u7528\u4e8e\u5171\u6307\u89e3\u6790\u7684\u6027\u522b-\u804c\u4e1a\u516c\u5e73\u6027\u8bc4\u4f30\uff0c\u5e76\u4f7f\u7528\u8fd9\u4e9b\u5de5\u5177\u5bf9\u5341\u4e2a\u5f00\u6e90LLM\u8fdb\u884c\u4e86\u57fa\u51c6\u6d4b\u8bd5\u3002", "result": "\u901a\u8fc7UCerF\u5ea6\u91cf\u53d1\u73b0\u4e86\u5982Mistral-7B\u7b49\u6a21\u578b\u5728\u9519\u8bef\u9884\u6d4b\u4e0a\u8868\u73b0\u51fa\u8fc7\u9ad8\u7f6e\u4fe1\u5ea6\u7684\u95ee\u9898\uff0c\u8fd9\u662f\u4f20\u7edfEqualized Odds\u65b9\u6cd5\u672a\u80fd\u6355\u6349\u5230\u7684\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684LLM\u57fa\u51c6\u6d4b\u8bd5\u65b9\u6cd5\u80fd\u591f\u66f4\u5168\u9762\u5730\u8bc4\u4f30\u6a21\u578b\u516c\u5e73\u6027\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u52a0\u900f\u660e\u548c\u8d1f\u8d23\u4efb\u7684AI\u7cfb\u7edf\u3002"}}
{"id": "2505.24595", "pdf": "https://arxiv.org/pdf/2505.24595", "abs": "https://arxiv.org/abs/2505.24595", "authors": ["Andrei Chernov", "Vitaliy Pozdnyakov", "Ilya Makarov"], "title": "Binary Cumulative Encoding meets Time Series Forecasting", "categories": ["cs.LG", "cs.AI", "stat.ML"], "comment": null, "summary": "Recent studies in time series forecasting have explored formulating\nregression via classification task. By discretizing the continuous target space\ninto bins and predicting over a fixed set of classes, these approaches benefit\nfrom stable training, robust uncertainty modeling, and compatibility with\nmodern deep learning architectures. However, most existing methods rely on\none-hot encoding that ignores the inherent ordinal structure of the underlying\nvalues. As a result, they fail to provide information about the relative\ndistance between predicted and true values during training. In this paper, we\npropose to address this limitation by introducing binary cumulative encoding\n(BCE), that represents scalar targets into monotonic binary vectors. This\nencoding implicitly preserves order and magnitude information, allowing the\nmodel to learn distance-aware representations while still operating within a\nclassification framework. We propose a convolutional neural network\narchitecture specifically designed for BCE, incorporating residual and dilated\nconvolutions to enable fast and expressive temporal modeling. Through extensive\nexperiments on benchmark forecasting datasets, we show that our approach\noutperforms widely used methods in both point and probabilistic forecasting,\nwhile requiring fewer parameters and enabling faster training.", "AI": {"tldr": "The paper proposes Binary Cumulative Encoding (BCE) for time series forecasting that retains order and magnitude info, outperforming existing methods with fewer parameters.", "motivation": "Existing time series forecasting methods using classification tasks lack the ability to convey relative distance between predicted and true values due to reliance on one-hot encoding which ignores ordinal structure of values.", "method": "Introduced Binary Cumulative Encoding (BCE) that transforms scalar targets into monotonic binary vectors preserving order and magnitude information. Also proposed a specific convolutional neural network architecture incorporating residual and dilated convolutions for effective temporal modeling within the BCE framework.", "result": "Experiments on benchmark datasets demonstrate superior performance in both point and probabilistic forecasting compared to widely used methods, along with reduced parameter count and faster training.", "conclusion": "Binary Cumulative Encoding coupled with the proposed CNN architecture provides an efficient and effective approach for time series forecasting, advancing the state-of-the-art in this domain."}}
{"id": "2505.24001", "pdf": "https://arxiv.org/pdf/2505.24001", "abs": "https://arxiv.org/abs/2505.24001", "authors": ["Wonjun Yi", "Wonho Jung", "Kangmin Jang", "Yong-Hwa Park"], "title": "Multi-output Classification using a Cross-talk Architecture for Compound Fault Diagnosis of Motors in Partially Labeled Condition", "categories": ["eess.SP", "cs.AI"], "comment": "Submitted to Mechanical Systems and Signal Processing on May 9th,\n  2025", "summary": "The increasing complexity of rotating machinery and the diversity of\noperating conditions, such as rotating speed and varying torques, have\namplified the challenges in fault diagnosis in scenarios requiring domain\nadaptation, particularly involving compound faults. This study addresses these\nchallenges by introducing a novel multi-output classification (MOC) framework\ntailored for domain adaptation in partially labeled (PL) target datasets.\nUnlike conventional multi-class classification (MCC) approaches, the proposed\nMOC framework classifies the severity levels of compound faults simultaneously.\nFurthermore, we explore various single-task and multi-task architectures\napplicable to the MOC formulation-including shared trunk and cross-talk-based\ndesigns-for compound fault diagnosis under PL conditions. Based on this\ninvestigation, we propose a novel cross-talk layer structure that enables\nselective information sharing across diagnostic tasks, effectively enhancing\nclassification performance in compound fault scenarios. In addition,\nfrequency-layer normalization was incorporated to improve domain adaptation\nperformance on motor vibration data. Compound fault conditions were implemented\nusing a motor-based test setup, and the proposed model was evaluated across six\ndomain adaptation scenarios. The experimental results demonstrate its superior\nmacro F1 performance compared to baseline models. We further showed that the\nproposed mode's structural advantage is more pronounced in compound fault\nsettings through a single-fault comparison. We also found that frequency-layer\nnormalization fits the fault diagnosis task better than conventional methods.\nLastly, we discuss that this improvement primarily stems from the model's\nstructural ability to leverage inter-fault classification task interactions,\nrather than from a simple increase in model parameters.", "AI": {"tldr": "The paper proposes a novel multi-output classification (MOC) framework for domain adaptation in fault diagnosis of rotating machinery with partially labeled target datasets, focusing on compound faults. It introduces a cross-talk layer structure and frequency-layer normalization to enhance classification performance.", "motivation": "The increasing complexity of rotating machinery and the diversity of operating conditions have made fault diagnosis more challenging, especially in scenarios requiring domain adaptation and involving compound faults.", "method": "The study develops a MOC framework tailored for domain adaptation in partially labeled target datasets. It explores various single-task and multi-task architectures applicable to the MOC formulation, including shared trunk and cross-talk-based designs. A novel cross-talk layer structure is proposed to enable selective information sharing across diagnostic tasks. Frequency-layer normalization is incorporated to improve domain adaptation performance on motor vibration data.", "result": "The experimental results demonstrate superior macro F1 performance compared to baseline models across six domain adaptation scenarios. The proposed model's structural advantage is more pronounced in compound fault settings compared to single-fault conditions. Frequency-layer normalization fits the fault diagnosis task better than conventional methods.", "conclusion": "The improvement in fault diagnosis primarily stems from the model's structural ability to leverage inter-fault classification task interactions, rather than simply increasing model parameters."}}
{"id": "2505.24603", "pdf": "https://arxiv.org/pdf/2505.24603", "abs": "https://arxiv.org/abs/2505.24603", "authors": ["Omri Lev", "Vishwak Srinivasan", "Moshe Shenfeld", "Katrina Ligett", "Ayush Sekhari", "Ashia C. Wilson"], "title": "The Gaussian Mixing Mechanism: Renyi Differential Privacy via Gaussian Sketches", "categories": ["cs.LG"], "comment": null, "summary": "Gaussian sketching, which consists of pre-multiplying the data with a random\nGaussian matrix, is a widely used technique for multiple problems in data\nscience and machine learning, with applications spanning computationally\nefficient optimization, coded computing, and federated learning. This operation\nalso provides differential privacy guarantees due to its inherent randomness.\nIn this work, we revisit this operation through the lens of Renyi Differential\nPrivacy (RDP), providing a refined privacy analysis that yields significantly\ntighter bounds than prior results. We then demonstrate how this improved\nanalysis leads to performance improvement in different linear regression\nsettings, establishing theoretical utility guarantees. Empirically, our methods\nimprove performance across multiple datasets and, in several cases, reduce\nruntime.", "AI": {"tldr": "The paper revisits Gaussian sketching through the lens of Renyi Differential Privacy (RDP), providing tighter privacy bounds and demonstrating performance improvements in linear regression settings.", "motivation": "Gaussian sketching, which involves pre-multiplying data with a random Gaussian matrix, is a widely used technique in data science and machine learning. It also inherently provides differential privacy guarantees. The motivation is to refine the privacy analysis of this operation using RDP to obtain significantly tighter privacy bounds than prior results.", "method": "The authors conduct a refined privacy analysis of Gaussian sketching using Renyi Differential Privacy (RDP). This approach yields significantly tighter privacy bounds compared to previous analyses. They then apply this improved analysis to different linear regression settings.", "result": "The improved privacy analysis leads to performance improvements in various linear regression settings. Theoretical utility guarantees are established, and empirical results show that the methods improve performance across multiple datasets, sometimes also reducing runtime.", "conclusion": "Gaussian sketching, when analyzed through the lens of RDP, offers significantly tighter privacy bounds. This refined analysis improves performance in linear regression tasks, both theoretically and empirically."}}
{"id": "2505.24612", "pdf": "https://arxiv.org/pdf/2505.24612", "abs": "https://arxiv.org/abs/2505.24612", "authors": ["Sujoy Chatterjee", "Everton Romanzini Colombo", "Marcos Medeiros Raimundo"], "title": "Multi-criteria Rank-based Aggregation for Explainable AI", "categories": ["cs.LG"], "comment": "Accepted at the 2025 International Joint Conference on Neural\n  Networks (IJCNN)", "summary": "Explainability is crucial for improving the transparency of black-box machine\nlearning models. With the advancement of explanation methods such as LIME and\nSHAP, various XAI performance metrics have been developed to evaluate the\nquality of explanations. However, different explainers can provide contrasting\nexplanations for the same prediction, introducing trade-offs across conflicting\nquality metrics. Although available aggregation approaches improve robustness,\nreducing explanations' variability, very limited research employed a\nmulti-criteria decision-making approach. To address this gap, this paper\nintroduces a multi-criteria rank-based weighted aggregation method that\nbalances multiple quality metrics simultaneously to produce an ensemble of\nexplanation models. Furthermore, we propose rank-based versions of existing XAI\nmetrics (complexity, faithfulness and stability) to better evaluate ranked\nfeature importance explanations. Extensive experiments on publicly available\ndatasets demonstrate the robustness of the proposed model across these metrics.\nComparative analyses of various multi-criteria decision-making and rank\naggregation algorithms showed that TOPSIS and WSUM are the best candidates for\nthis use case.", "AI": {"tldr": "Explainability is crucial for machine learning models. This paper introduces a multi-criteria rank-based weighted aggregation method to balance multiple quality metrics and produce an ensemble of explanation models, also proposing rank-based versions of XAI metrics.", "motivation": "Explainability is important in machine learning models and different explainers can provide contrasting explanations for the same prediction, introducing trade-offs across conflicting quality metrics. Although available aggregation approaches improve robustness, reducing explanations' variability, very limited research employed a multi-criteria decision-making approach.", "method": "This paper introduces a multi-criteria rank-based weighted aggregation method that balances multiple quality metrics simultaneously to produce an ensemble of explanation models. It also proposes rank-based versions of existing XAI metrics (complexity, faithfulness and stability) to better evaluate ranked feature importance explanations.", "result": "Extensive experiments on publicly available datasets demonstrate the robustness of the proposed model across these metrics. Comparative analyses showed that TOPSIS and WSUM are the best candidates for this use case.", "conclusion": "A multi-criteria rank-based weighted aggregation method was introduced which successfully balances multiple quality metrics simultaneously to produce an ensemble of explanation models. Rank-based versions of XAI metrics were also proposed and proved effective."}}
{"id": "2505.24009", "pdf": "https://arxiv.org/pdf/2505.24009", "abs": "https://arxiv.org/abs/2505.24009", "authors": ["Hidetaka Kamigaito", "Ying Zhang", "Jingun Kwon", "Katsuhiko Hayashi", "Manabu Okumura", "Taro Watanabe"], "title": "Diversity of Transformer Layers: One Aspect of Parameter Scaling Laws", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Transformers deliver outstanding performance across a wide range of tasks and\nare now a dominant backbone architecture for large language models (LLMs).\nTheir task-solving performance is improved by increasing parameter size, as\nshown in the recent studies on parameter scaling laws. Although recent\nmechanistic-interpretability studies have deepened our understanding of the\ninternal behavior of Transformers by analyzing their residual stream, the\nrelationship between these internal mechanisms and the parameter scaling laws\nremains unclear. To bridge this gap, we focus on layers and their size, which\nmainly decide the parameter size of Transformers. For this purpose, we first\ntheoretically investigate the layers within the residual stream through a\nbias-diversity decomposition. The decomposition separates (i) bias, the error\nof each layer's output from the ground truth, and (ii) diversity, which\nindicates how much the outputs of each layer differ from each other. Analyzing\nTransformers under this theory reveals that performance improves when\nindividual layers make predictions close to the correct answer and remain\nmutually diverse. We show that diversity becomes especially critical when\nindividual layers' outputs are far from the ground truth. Finally, we introduce\nan information-theoretic diversity and show our main findings that adding\nlayers enhances performance only when those layers behave differently, i.e.,\nare diverse. We also reveal the performance gains from increasing the number of\nlayers exhibit submodularity: marginal improvements diminish as additional\nlayers increase, mirroring the logarithmic convergence predicted by the\nparameter scaling laws. Experiments on multiple semantic-understanding tasks\nwith various LLMs empirically confirm the theoretical properties derived in\nthis study.", "AI": {"tldr": "Transformers\u6027\u80fd\u968f\u53c2\u6570\u89c4\u6a21\u589e\u52a0\u800c\u63d0\u5347\uff0c\u4f46\u5185\u90e8\u673a\u5236\u4e0e\u53c2\u6570\u7f29\u653e\u89c4\u5f8b\u7684\u5173\u7cfb\u5c1a\u4e0d\u660e\u786e\u3002\u672c\u6587\u901a\u8fc7\u504f\u5dee-\u591a\u6837\u6027\u5206\u89e3\u7814\u7a76\u6b8b\u5dee\u6d41\u4e2d\u7684\u5c42\uff0c\u53d1\u73b0\u589e\u52a0\u5c42\u80fd\u63d0\u9ad8\u6027\u80fd\u662f\u56e0\u4e3a\u5b83\u4eec\u7684\u884c\u4e3a\u4e0d\u540c\uff08\u5373\u591a\u6837\u6027\uff09\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u589e\u52a0\u5c42\u6570\u7684\u6027\u80fd\u589e\u76ca\u8868\u73b0\u51fa\u6b21\u6a21\u6027\uff0c\u8fb9\u9645\u6539\u8fdb\u968f\u7740\u5c42\u6570\u589e\u52a0\u800c\u51cf\u5c11\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u77e5Transformer\u6027\u80fd\u53ef\u901a\u8fc7\u589e\u5927\u53c2\u6570\u89c4\u6a21\u6765\u6539\u5584\uff0c\u4f46\u5176\u5185\u90e8\u673a\u5236\u4e0e\u53c2\u6570\u7f29\u653e\u89c4\u5f8b\u4e4b\u95f4\u7684\u5173\u7cfb\u4ecd\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\u9700\u8981\u7814\u7a76\u5c42\u548c\u5176\u89c4\u6a21\u5982\u4f55\u5f71\u54cd\u6027\u80fd\u3002", "method": "\u901a\u8fc7\u504f\u5dee-\u591a\u6837\u6027\u5206\u89e3\u5206\u6790\u6b8b\u5dee\u6d41\u4e2d\u7684\u5c42\uff0c\u5c06\u8bef\u5dee\u5206\u4e3a\u504f\u5dee\uff08\u5c42\u8f93\u51fa\u4e0e\u771f\u5b9e\u503c\u7684\u8bef\u5dee\uff09\u548c\u591a\u6837\u6027\uff08\u5c42\u8f93\u51fa\u4e4b\u95f4\u7684\u5dee\u5f02\uff09\u3002\u63a5\u7740\u5f15\u5165\u4fe1\u606f\u8bba\u591a\u6837\u6027\uff0c\u5e76\u7814\u7a76\u589e\u52a0\u5c42\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u5f53\u5404\u5c42\u9884\u6d4b\u63a5\u8fd1\u6b63\u786e\u7b54\u6848\u4e14\u4fdd\u6301\u76f8\u4e92\u591a\u6837\u6027\u65f6\u6027\u80fd\u66f4\u4f18\uff1b\u5f53\u5c42\u8f93\u51fa\u8fdc\u79bb\u771f\u5b9e\u503c\u65f6\uff0c\u591a\u6837\u6027\u5c24\u4e3a\u91cd\u8981\u3002\u589e\u52a0\u5c42\u4ec5\u5728\u5c42\u884c\u4e3a\u4e0d\u540c\u65f6\u624d\u589e\u5f3a\u6027\u80fd\uff0c\u4e14\u6027\u80fd\u589e\u76ca\u8868\u73b0\u51fa\u6b21\u6a21\u6027\u3002", "conclusion": "\u589e\u52a0\u5c42\u7684\u591a\u6837\u6027\u662f\u63d0\u5347Transformer\u6027\u80fd\u7684\u5173\u952e\uff0c\u4e14\u6027\u80fd\u589e\u76ca\u968f\u5c42\u6570\u589e\u52a0\u5448\u73b0\u9012\u51cf\u8d8b\u52bf\uff0c\u4e0e\u53c2\u6570\u7f29\u653e\u89c4\u5f8b\u4e00\u81f4\u3002"}}
{"id": "2505.24623", "pdf": "https://arxiv.org/pdf/2505.24623", "abs": "https://arxiv.org/abs/2505.24623", "authors": ["Wenyuan Li", "Guang Li", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "title": "Hyperbolic Dataset Distillation", "categories": ["cs.LG", "cs.AI", "cs.CV"], "comment": null, "summary": "To address the computational and storage challenges posed by large-scale\ndatasets in deep learning, dataset distillation has been proposed to synthesize\na compact dataset that replaces the original while maintaining comparable model\nperformance. Unlike optimization-based approaches that require costly bi-level\noptimization, distribution matching (DM) methods improve efficiency by aligning\nthe distributions of synthetic and original data, thereby eliminating nested\noptimization. DM achieves high computational efficiency and has emerged as a\npromising solution. However, existing DM methods, constrained to Euclidean\nspace, treat data as independent and identically distributed points,\noverlooking complex geometric and hierarchical relationships. To overcome this\nlimitation, we propose a novel hyperbolic dataset distillation method, termed\nHDD. Hyperbolic space, characterized by negative curvature and exponential\nvolume growth with distance, naturally models hierarchical and tree-like\nstructures. HDD embeds features extracted by a shallow network into the Lorentz\nhyperbolic space, where the discrepancy between synthetic and original data is\nmeasured by the hyperbolic (geodesic) distance between their centroids. By\noptimizing this distance, the hierarchical structure is explicitly integrated\ninto the distillation process, guiding synthetic samples to gravitate towards\nthe root-centric regions of the original data distribution while preserving\ntheir underlying geometric characteristics. Furthermore, we find that pruning\nin hyperbolic space requires only 20% of the distilled core set to retain model\nperformance, while significantly improving training stability. Notably, HDD is\nseamlessly compatible with most existing DM methods, and extensive experiments\non different datasets validate its effectiveness.", "AI": {"tldr": "The paper proposes Hyperbolic Dataset Distillation (HDD), a novel method that uses hyperbolic space to preserve hierarchical and geometric relationships in dataset distillation. HDD improves upon existing distribution matching methods by embedding features into hyperbolic space, enhancing efficiency and performance.", "motivation": "Current distribution matching (DM) methods for dataset distillation operate within Euclidean space, treating data points as independent and identically distributed without considering complex geometric or hierarchical relationships. This limitation motivates the need for an approach that can better capture such structures.", "method": "The proposed method, Hyperbolic Dataset Distillation (HDD), embeds features extracted from a shallow network into the Lorentz hyperbolic space. The discrepancy between synthetic and original data distributions is measured using the hyperbolic distance between their centroids. By optimizing this distance, the method integrates hierarchical structure into the distillation process. Additionally, pruning in hyperbolic space shows that only 20% of the distilled core set is needed to maintain model performance.", "result": "Experiments on various datasets demonstrate that HDD effectively captures hierarchical and geometric characteristics of data, leading to improved training stability and comparable model performance with significantly reduced dataset size. It also shows compatibility with most existing DM methods.", "conclusion": "HDD offers a promising solution for dataset distillation by leveraging hyperbolic space to address limitations of current DM methods. It achieves high computational efficiency while preserving important data characteristics."}}
{"id": "2505.24012", "pdf": "https://arxiv.org/pdf/2505.24012", "abs": "https://arxiv.org/abs/2505.24012", "authors": ["Alexandre Bonlarron", "Florian R\u00e9gin", "Elisabetta De Maria", "Jean-Charles R\u00e9gin"], "title": "Large Language Model Meets Constraint Propagation", "categories": ["cs.CL", "cs.AI"], "comment": "To appear in the Proceedings of the Thirty-Fourth International Joint\n  Conference on Artificial Intelligence (IJCAI 2025)", "summary": "Large Language Models (LLMs) excel at generating fluent text but struggle to\nenforce external constraints because they generate tokens sequentially without\nexplicit control mechanisms. GenCP addresses this limitation by combining LLM\npredictions with Constraint Programming (CP) reasoning, formulating text\ngeneration as a Constraint Satisfaction Problem (CSP). In this paper, we\nimprove GenCP by integrating Masked Language Models (MLMs) for domain\ngeneration, which allows bidirectional constraint propagation that leverages\nboth past and future tokens. This integration bridges the gap between\ntoken-level prediction and structured constraint enforcement, leading to more\nreliable and constraint-aware text generation. Our evaluation on COLLIE\nbenchmarks demonstrates that incorporating domain preview via MLM calls\nsignificantly improves GenCP's performance. Although this approach incurs\nadditional MLM calls and, in some cases, increased backtracking, the overall\neffect is a more efficient use of LLM inferences and an enhanced ability to\ngenerate feasible and meaningful solutions, particularly in tasks with strict\ncontent constraints.", "AI": {"tldr": "Large Language Models (LLMs) lack the ability to enforce external constraints due to sequential token generation without explicit control mechanisms. GenCP resolves this by merging LLM predictions with Constraint Programming (CP) reasoning, formulating text generation as a Constraint Satisfaction Problem (CSP). This paper enhances GenCP through integrating Masked Language Models (MLMs) for domain generation, enabling bidirectional constraint propagation and bridging the gap between token-level prediction and structured constraint enforcement. Evaluation on COLLIE benchmarks shows that incorporating domain preview via MLM calls significantly boosts GenCP's performance, making LLM inferences more efficient and improving the generation of feasible and meaningful solutions.", "motivation": "The motivation behind this research is the limitation of Large Language Models (LLMs) in enforcing external constraints during text generation due to their sequential token generation process without explicit control mechanisms. This limitation necessitates a solution that can better handle structured constraints while maintaining fluent text generation.", "method": "The method involves enhancing the GenCP system by integrating Masked Language Models (MLMs) for domain generation. This integration allows bidirectional constraint propagation, leveraging both past and future tokens. By formulating text generation as a Constraint Satisfaction Problem (CSP) and combining it with CP reasoning, the approach bridges the gap between token-level prediction and structured constraint enforcement.", "result": "The evaluation on COLLIE benchmarks indicates that incorporating domain preview via MLM calls significantly improves GenCP's performance. Despite additional MLM calls and increased backtracking in some cases, the overall effect is a more efficient use of LLM inferences and an enhanced ability to generate feasible and meaningful solutions, particularly in tasks with strict content constraints.", "conclusion": "The conclusion is that the integration of Masked Language Models (MLMs) into the GenCP system leads to more reliable and constraint-aware text generation. This advancement makes LLM inferences more efficient and enhances the system's ability to generate feasible and meaningful solutions, especially in tasks requiring strict content constraints."}}
{"id": "2505.24627", "pdf": "https://arxiv.org/pdf/2505.24627", "abs": "https://arxiv.org/abs/2505.24627", "authors": ["Fu Luo", "Yaoxin Wu", "Zhi Zheng", "Zhenkun Wang"], "title": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees", "categories": ["cs.LG"], "comment": null, "summary": "Recent neural combinatorial optimization (NCO) methods have shown promising\nproblem-solving ability without requiring domain-specific expertise. Most\nexisting NCO methods use training and testing data with a fixed constraint\nvalue and lack research on the effect of constraint tightness on the\nperformance of NCO methods. This paper takes the capacity-constrained vehicle\nrouting problem (CVRP) as an example to empirically analyze the NCO performance\nunder different tightness degrees of the capacity constraint. Our analysis\nreveals that existing NCO methods overfit the capacity constraint, and they can\nonly perform satisfactorily on a small range of the constraint values but\npoorly on other values. To tackle this drawback of existing NCO methods, we\ndevelop an efficient training scheme that explicitly considers varying degrees\nof constraint tightness and proposes a multi-expert module to learn a generally\nadaptable solving strategy. Experimental results show that the proposed method\ncan effectively overcome the overfitting issue, demonstrating superior\nperformances on the CVRP and CVRP with time windows (CVRPTW) with various\nconstraint tightness degrees.", "AI": {"tldr": "Recent neural combinatorial optimization (NCO) methods show promise but overfit to specific constraint values. This paper addresses this issue by developing a training scheme and multi-expert module for the CVRP, improving performance across varying constraint tightness degrees.", "motivation": "To understand and improve the performance of NCO methods under different constraint tightness levels, using CVRP as an example.", "method": "Empirical analysis of existing NCO methods on CVRP reveals overfitting to capacity constraints. A new training scheme and multi-expert module are proposed to address this.", "result": "The proposed method effectively overcomes the overfitting issue, showing superior performances on CVRP and CVRPTW with various constraint tightness degrees.", "conclusion": "The developed training scheme and multi-expert module enhance the adaptability of NCO methods to different constraint values."}}
{"id": "2505.24629", "pdf": "https://arxiv.org/pdf/2505.24629", "abs": "https://arxiv.org/abs/2505.24629", "authors": ["Lotte Bransen", "Tim Janssen", "Jesse Davis"], "title": "Stop Guessing: Optimizing Goalkeeper Policies for Soccer Penalty Kicks", "categories": ["cs.LG", "cs.GT"], "comment": "24 pages, 7 figures", "summary": "Penalties are fraught and game-changing moments in soccer games that teams\nexplicitly prepare for. Consequently, there has been substantial interest in\nanalyzing them in order to provide advice to practitioners. From a data science\nperspective, such analyses suffer from a significant limitation: they make the\nunrealistic simplifying assumption that goalkeepers and takers select their\naction -- where to dive and where to the place the kick -- independently of\neach other. In reality, the choices that some goalkeepers make depend on the\ntaker's movements and vice-versa. This adds substantial complexity to the\nproblem because not all players have the same action capacities, that is, only\nsome players are capable of basing their decisions on their opponent's\nmovements. However, the small sample sizes on the player level mean that one\nmay have limited insights into a specific opponent's capacities. We address\nthese challenges by developing a player-agnostic simulation framework that can\nevaluate the efficacy of different goalkeeper strategies. It considers a rich\nset of choices and incorporates information about a goalkeeper's skills. Our\nwork is grounded in a large dataset of penalties that were annotated by penalty\nexperts and include aspects of both kicker and goalkeeper strategies. We show\nhow our framework can be used to optimize goalkeeper policies in real-world\nsituations.", "AI": {"tldr": "\u5728\u8db3\u7403\u70b9\u7403\u5206\u6790\u4e2d\uff0c\u73b0\u6709\u7684\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u5b88\u95e8\u5458\u548c\u8e22\u7403\u8005\u72ec\u7acb\u9009\u62e9\u884c\u52a8\uff0c\u8fd9\u4e0e\u5b9e\u9645\u60c5\u51b5\u4e0d\u7b26\u3002\u672c\u6587\u901a\u8fc7\u6784\u5efa\u4e00\u4e2a\u4e0e\u7403\u5458\u65e0\u5173\u7684\u6a21\u62df\u6846\u67b6\uff0c\u5229\u7528\u5927\u91cf\u7531\u4e13\u5bb6\u6807\u6ce8\u7684\u70b9\u7403\u6570\u636e\u96c6\uff0c\u8bc4\u4f30\u4e0d\u540c\u5b88\u95e8\u5458\u7b56\u7565\u7684\u6548\u679c\uff0c\u5e76\u4f18\u5316\u5b88\u95e8\u5458\u5728\u5b9e\u9645\u6bd4\u8d5b\u4e2d\u7684\u51b3\u7b56\u653f\u7b56\u3002", "motivation": "\u73b0\u6709\u7684\u70b9\u7403\u5206\u6790\u65b9\u6cd5\u5047\u8bbe\u5b88\u95e8\u5458\u548c\u8e22\u7403\u8005\u7684\u52a8\u4f5c\u9009\u62e9\u76f8\u4e92\u72ec\u7acb\uff0c\u4f46\u73b0\u5b9e\u4e2d\u4e24\u8005\u7684\u9009\u62e9\u4f1a\u4e92\u76f8\u5f71\u54cd\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u6837\u672c\u91cf\u5c0f\uff0c\u96be\u4ee5\u6df1\u5165\u4e86\u89e3\u7279\u5b9a\u5bf9\u624b\u7684\u80fd\u529b\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u7684\u65b9\u6cd5\u6765\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u4e0e\u7403\u5458\u65e0\u5173\u7684\u6a21\u62df\u6846\u67b6\uff0c\u8be5\u6846\u67b6\u57fa\u4e8e\u4e00\u4e2a\u5927\u578b\u70b9\u7403\u6570\u636e\u96c6\uff08\u7531\u70b9\u7403\u4e13\u5bb6\u6807\u6ce8\uff09\uff0c\u8003\u8651\u4e86\u4e30\u5bcc\u7684\u52a8\u4f5c\u9009\u62e9\u5e76\u7ed3\u5408\u4e86\u5b88\u95e8\u5458\u6280\u80fd\u4fe1\u606f\uff0c\u7528\u4e8e\u8bc4\u4f30\u4e0d\u540c\u5b88\u95e8\u5458\u7b56\u7565\u7684\u6548\u679c\u3002", "result": "\u8be5\u6846\u67b6\u80fd\u591f\u6709\u6548\u8bc4\u4f30\u5404\u79cd\u5b88\u95e8\u5458\u7b56\u7565\uff0c\u5e76\u4e3a\u5b9e\u9645\u6bd4\u8d5b\u4e2d\u7684\u5b88\u95e8\u5458\u51b3\u7b56\u63d0\u4f9b\u4f18\u5316\u65b9\u6848\u3002", "conclusion": "\u901a\u8fc7\u63d0\u51fa\u7684\u6a21\u62df\u6846\u67b6\uff0c\u53ef\u4ee5\u66f4\u597d\u5730\u7406\u89e3\u70b9\u7403\u4e2d\u7684\u590d\u6742\u4e92\u52a8\uff0c\u5e76\u4e3a\u5b88\u95e8\u5458\u63d0\u4f9b\u66f4\u4f18\u7684\u7b56\u7565\u5efa\u8bae\u3002"}}
{"id": "2505.24023", "pdf": "https://arxiv.org/pdf/2505.24023", "abs": "https://arxiv.org/abs/2505.24023", "authors": ["Sangwon Jung", "Alex Oesterling", "Claudio Mayrink Verdun", "Sajani Vithana", "Taesup Moon", "Flavio P. Calmon"], "title": "Multi-Group Proportional Representation for Text-to-Image Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Text-to-image (T2I) generative models can create vivid, realistic images from\ntextual descriptions. As these models proliferate, they expose new concerns\nabout their ability to represent diverse demographic groups, propagate\nstereotypes, and efface minority populations. Despite growing attention to the\n\"safe\" and \"responsible\" design of artificial intelligence (AI), there is no\nestablished methodology to systematically measure and control representational\nharms in image generation. This paper introduces a novel framework to measure\nthe representation of intersectional groups in images generated by T2I models\nby applying the Multi-Group Proportional Representation (MPR) metric. MPR\nevaluates the worst-case deviation of representation statistics across given\npopulation groups in images produced by a generative model, allowing for\nflexible and context-specific measurements based on user requirements. We also\ndevelop an algorithm to optimize T2I models for this metric. Through\nexperiments, we demonstrate that MPR can effectively measure representation\nstatistics across multiple intersectional groups and, when used as a training\nobjective, can guide models toward a more balanced generation across\ndemographic groups while maintaining generation quality.", "AI": {"tldr": "This paper proposes a novel framework using the Multi-Group Proportional Representation (MPR) metric to measure and optimize the representation of intersectional groups in images generated by text-to-image models, promoting balanced demographic representation while preserving generation quality.", "motivation": "There is an increasing concern about the ability of text-to-image generative models to represent diverse demographic groups fairly and responsibly. Current AI design lacks a systematic methodology to measure and control representational harms in image generation.", "method": "The paper introduces the MPR metric to evaluate the worst-case deviation of representation statistics across population groups in generated images. It also develops an optimization algorithm that uses MPR as a training objective to guide T2I models towards more balanced generation.", "result": "Experiments show that MPR can effectively measure representation statistics across multiple intersectional groups and, when used during training, leads to more balanced image generation across demographic groups without compromising quality.", "conclusion": "The proposed framework provides a systematic way to assess and improve the fairness of representation in text-to-image models, contributing to the responsible design of AI systems."}}
{"id": "2505.24642", "pdf": "https://arxiv.org/pdf/2505.24642", "abs": "https://arxiv.org/abs/2505.24642", "authors": ["Masahiro Negishi", "Thomas G\u00e4rtner", "Pascal Welke"], "title": "WILTing Trees: Interpreting the Distance Between MPNN Embeddings", "categories": ["cs.LG", "I.2.6"], "comment": "25 pages, 10 figures. Accepted to ICML 2025. See\n  https://github.com/masahiro-negishi/wilt for code", "summary": "We investigate the distance function learned by message passing neural\nnetworks (MPNNs) in specific tasks, aiming to capture the functional distance\nbetween prediction targets that MPNNs implicitly learn. This contrasts with\nprevious work, which links MPNN distances on arbitrary tasks to structural\ndistances on graphs that ignore task-specific information. To address this gap,\nwe distill the distance between MPNN embeddings into an interpretable graph\ndistance. Our method uses optimal transport on the Weisfeiler Leman Labeling\nTree (WILT), where the edge weights reveal subgraphs that strongly influence\nthe distance between embeddings. This approach generalizes two well-known graph\nkernels and can be computed in linear time. Through extensive experiments, we\ndemonstrate that MPNNs define the relative position of embeddings by focusing\non a small set of subgraphs that are known to be functionally important in the\ndomain.", "AI": {"tldr": "The paper explores how MPNNs learn functional distances between prediction targets and proposes a method using optimal transport on WILT to interpret these distances.", "motivation": "To understand the functional distance between prediction targets that MPNNs implicitly learn, unlike previous work that links MPNN distances to structural graph distances without considering task-specific information.", "method": "Distill the distance between MPNN embeddings into an interpretable graph distance using optimal transport on the Weisfeiler Leman Labeling Tree (WILT), where edge weights reveal influential subgraphs.", "result": "Through experiments, it is shown that MPNNs define the relative position of embeddings by focusing on a small set of functionally important subgraphs.", "conclusion": "MPNNs focus on specific subgraphs to determine embedding distances, and the proposed method provides an interpretable way to understand these distances."}}
{"id": "2505.24025", "pdf": "https://arxiv.org/pdf/2505.24025", "abs": "https://arxiv.org/abs/2505.24025", "authors": ["Chenbin Pan", "Wenbin He", "Zhengzhong Tu", "Liu Ren"], "title": "DINO-R1: Incentivizing Reasoning Capability in Vision Foundation Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The recent explosive interest in the reasoning capabilities of large language\nmodels, such as DeepSeek-R1, has demonstrated remarkable success through\nreinforcement learning-based fine-tuning frameworks, exemplified by methods\nlike Group Relative Policy Optimization (GRPO). However, such reasoning\nabilities remain underexplored and notably absent in vision foundation models,\nincluding representation models like the DINO series. In this work, we propose\n\\textbf{DINO-R1}, the first such attempt to incentivize visual in-context\nreasoning capabilities of vision foundation models using reinforcement\nlearning. Specifically, DINO-R1 introduces \\textbf{Group Relative Query\nOptimization (GRQO)}, a novel reinforcement-style training strategy explicitly\ndesigned for query-based representation models, which computes query-level\nrewards based on group-normalized alignment quality. We also apply\nKL-regularization to stabilize the objectness distribution to reduce the\ntraining instability. This joint optimization enables dense and expressive\nsupervision across queries while mitigating overfitting and distributional\ndrift. Building upon Grounding-DINO, we train a series of DINO-R1 family models\nthat integrate a visual prompt encoder and a visual-guided query selection\nmechanism. Extensive experiments on COCO, LVIS, and ODinW demonstrate that\nDINO-R1 significantly outperforms supervised fine-tuning baselines, achieving\nstrong generalization in both open-vocabulary and closed-set visual prompting\nscenarios.", "AI": {"tldr": "DINO-R1 is the first attempt to enhance visual in-context reasoning of vision foundation models via reinforcement learning, introducing GRQO and KL-regularization methods.", "motivation": "Reasoning capabilities have been successfully explored in large language models but are underexplored in vision foundation models.", "method": "Propose DINO-R1 with Group Relative Query Optimization (GRQO) and KL-regularization, building upon Grounding-DINO for training a series of models.", "result": "DINO-R1 outperforms supervised fine-tuning baselines on COCO, LVIS, and ODinW datasets, showing strong generalization in various visual prompting scenarios.", "conclusion": "DINO-R1 significantly improves visual in-context reasoning through reinforcement learning, setting a new approach for vision foundation models."}}
{"id": "2505.24664", "pdf": "https://arxiv.org/pdf/2505.24664", "abs": "https://arxiv.org/abs/2505.24664", "authors": ["Daniel Severo", "Brian Karrer", "Niklas Nolte"], "title": "Learning Distributions over Permutations and Rankings with Factorized Representations", "categories": ["cs.LG"], "comment": null, "summary": "Learning distributions over permutations is a fundamental problem in machine\nlearning, with applications in ranking, combinatorial optimization, structured\nprediction, and data association. Existing methods rely on mixtures of\nparametric families or neural networks with expensive variational inference\nprocedures. In this work, we propose a novel approach that leverages\nalternative representations for permutations, including Lehmer codes,\nFisher-Yates draws, and Insertion-Vectors. These representations form a\nbijection with the symmetric group, allowing for unconstrained learning using\nconventional deep learning techniques, and can represent any probability\ndistribution over permutations. Our approach enables a trade-off between\nexpressivity of the model family and computational requirements. In the least\nexpressive and most computationally efficient case, our method subsumes\nprevious families of well established probabilistic models over permutations,\nincluding Mallow's and the Repeated Insertion Model. Experiments indicate our\nmethod significantly outperforms current approaches on the jigsaw puzzle\nbenchmark, a common task for permutation learning. However, we argue this\nbenchmark is limited in its ability to assess learning probability\ndistributions, as the target is a delta distribution (i.e., a single correct\nsolution exists). We therefore propose two additional benchmarks: learning\ncyclic permutations and re-ranking movies based on user preference. We show\nthat our method learns non-trivial distributions even in the least expressive\nmode, while traditional models fail to even generate valid permutations in this\nsetting.", "AI": {"tldr": "The paper proposes a new approach to learning distributions over permutations using alternative representations such as Lehmer codes, Fisher-Yates draws, and Insertion-Vectors.", "motivation": "Existing methods for learning distributions over permutations rely on mixtures of parametric families or neural networks with expensive variational inference procedures. The authors aim to develop a more efficient and flexible method.", "method": "The proposed method leverages alternative representations for permutations including Lehmer codes, Fisher-Yates draws, and Insertion-Vectors. These representations form a bijection with the symmetric group, allowing for unconstrained learning using conventional deep learning techniques.", "result": "Experiments show that the proposed method significantly outperforms current approaches on the jigsaw puzzle benchmark. Additionally, the method learns non-trivial distributions even in the least expressive mode on two new benchmarks: learning cyclic permutations and re-ranking movies based on user preference.", "conclusion": "The novel approach enables a trade-off between expressivity of the model family and computational requirements, and subsumes previous families of probabilistic models over permutations."}}
{"id": "2505.24026", "pdf": "https://arxiv.org/pdf/2505.24026", "abs": "https://arxiv.org/abs/2505.24026", "authors": ["Numair Nadeem", "Muhammad Hamza Asad", "Saeed Anwar", "Abdul Bais"], "title": "MaskAdapt: Unsupervised Geometry-Aware Domain Adaptation Using Multimodal Contextual Learning and RGB-Depth Masking", "categories": ["cs.CV", "cs.AI"], "comment": "11 pages, 5 figures, presented at the IEEE/CVF Conference on Computer\n  Vision and Pattern Recognition (CVPR) 2025. Reviewer comments available upon\n  request", "summary": "Semantic segmentation of crops and weeds is crucial for site-specific farm\nmanagement; however, most existing methods depend on labor intensive\npixel-level annotations. A further challenge arises when models trained on one\nfield (source domain) fail to generalize to new fields (target domain) due to\ndomain shifts, such as variations in lighting, camera setups, soil composition,\nand crop growth stages. Unsupervised Domain Adaptation (UDA) addresses this by\nenabling adaptation without target-domain labels, but current UDA methods\nstruggle with occlusions and visual blending between crops and weeds, leading\nto misclassifications in real-world conditions. To overcome these limitations,\nwe introduce MaskAdapt, a novel approach that enhances segmentation accuracy\nthrough multimodal contextual learning by integrating RGB images with features\nderived from depth data. By computing depth gradients from depth maps, our\nmethod captures spatial transitions that help resolve texture ambiguities.\nThese gradients, through a cross-attention mechanism, refines RGB feature\nrepresentations, resulting in sharper boundary delineation. In addition, we\npropose a geometry-aware masking strategy that applies horizontal, vertical,\nand stochastic masks during training. This encourages the model to focus on the\nbroader spatial context for robust visual recognition. Evaluations on real\nagricultural datasets demonstrate that MaskAdapt consistently outperforms\nexisting State-of-the-Art (SOTA) UDA methods, achieving improved segmentation\nmean Intersection over Union (mIOU) across diverse field conditions.", "AI": {"tldr": "The paper presents MaskAdapt, a novel approach for crop and weed semantic segmentation that enhances accuracy through multimodal contextual learning using RGB images and depth data gradients. It introduces geometry-aware masking and cross-attention mechanisms to address occlusions and texture ambiguities, outperforming SOTA UDA methods in diverse agricultural conditions.", "motivation": "Existing methods for crop and weed segmentation rely heavily on pixel-level annotations and struggle with domain shifts and real-world challenges such as occlusions and visual blending between crops and weeds.", "method": "MaskAdapt integrates RGB images with depth data gradients through a cross-attention mechanism to refine feature representations and improve boundary delineation. A geometry-aware masking strategy is also proposed, applying horizontal, vertical, and stochastic masks during training to enhance spatial context understanding.", "result": "Evaluations on real agricultural datasets show MaskAdapt consistently surpasses existing SOTA UDA methods, achieving higher segmentation mean Intersection over Union (mIOU) across various field conditions.", "conclusion": "MaskAdapt demonstrates significant improvements in semantic segmentation accuracy for crops and weeds under diverse agricultural scenarios, addressing limitations of current UDA methods."}}
{"id": "2505.24665", "pdf": "https://arxiv.org/pdf/2505.24665", "abs": "https://arxiv.org/abs/2505.24665", "authors": ["Hanlin Yu", "S\u00f8ren Hauberg", "Marcelo Hartmann", "Arto Klami", "Georgios Arvanitidis"], "title": "Learning geometry and topology via multi-chart flows", "categories": ["cs.LG"], "comment": null, "summary": "Real world data often lie on low-dimensional Riemannian manifolds embedded in\nhigh-dimensional spaces. This motivates learning degenerate normalizing flows\nthat map between the ambient space and a low-dimensional latent space. However,\nif the manifold has a non-trivial topology, it can never be correctly learned\nusing a single flow. Instead multiple flows must be `glued together'. In this\npaper, we first propose the general training scheme for learning such a\ncollection of flows, and secondly we develop the first numerical algorithms for\ncomputing geodesics on such manifolds. Empirically, we demonstrate that this\nleads to highly significant improvements in topology estimation.", "AI": {"tldr": "\u901a\u8fc7\u5b66\u4e60\u591a\u4e2a\u7c98\u5408\u5728\u4e00\u8d77\u7684\u6d41\u5e76\u5f00\u53d1\u8ba1\u7b97\u6d4b\u5730\u7ebf\u7684\u6570\u503c\u7b97\u6cd5\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u9ad8\u62d3\u6251\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u7684\u6570\u636e\u901a\u5e38\u4f4d\u4e8e\u5d4c\u5165\u9ad8\u7ef4\u7a7a\u95f4\u7684\u4f4e\u7ef4\u9ece\u66fc\u6d41\u5f62\u4e0a\uff0c\u8fd9\u4fc3\u4f7f\u6211\u4eec\u5b66\u4e60\u9000\u5316\u7684\u5f52\u4e00\u5316\u6d41\uff0c\u8fd9\u4e9b\u6d41\u5728\u73af\u5883\u7a7a\u95f4\u548c\u4f4e\u7ef4\u6f5c\u5728\u7a7a\u95f4\u4e4b\u95f4\u6620\u5c04\u3002\u7136\u800c\uff0c\u5982\u679c\u6d41\u5f62\u5177\u6709\u975e\u5e73\u51e1\u7684\u62d3\u6251\u7ed3\u6784\uff0c\u5219\u4f7f\u7528\u5355\u4e00\u6d41\u65e0\u6cd5\u6b63\u786e\u5b66\u4e60\u5b83\u3002", "method": "\u9996\u5148\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5b66\u4e60\u6b64\u7c7b\u6d41\u96c6\u5408\u7684\u4e00\u822c\u8bad\u7ec3\u65b9\u6848\uff1b\u5176\u6b21\u5f00\u53d1\u4e86\u7b2c\u4e00\u4e2a\u7528\u4e8e\u5728\u8fd9\u4e9b\u6d41\u5f62\u4e0a\u8ba1\u7b97\u6d4b\u5730\u7ebf\u7684\u6570\u503c\u7b97\u6cd5\u3002", "result": "\u7ecf\u9a8c\u4e0a\uff0c\u8bc1\u660e\u8fd9\u79cd\u65b9\u6cd5\u5bfc\u81f4\u62d3\u6251\u4f30\u8ba1\u6709\u9ad8\u5ea6\u663e\u8457\u7684\u6539\u8fdb\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u591a\u6d41\u7ec4\u5408\u548c\u6d4b\u5730\u7ebf\u8ba1\u7b97\u63d0\u9ad8\u4e86\u62d3\u6251\u4f30\u8ba1\u7684\u6548\u679c\u3002"}}
{"id": "2505.24676", "pdf": "https://arxiv.org/pdf/2505.24676", "abs": "https://arxiv.org/abs/2505.24676", "authors": ["Mihir Bhaskar", "Jun Tao Luo", "Zihan Geng", "Asmita Hajra", "Junia Howell", "Matthew R. Gormley"], "title": "Predicting the Past: Estimating Historical Appraisals with OCR and Machine Learning", "categories": ["cs.LG"], "comment": "Accepted to COMPASS 2025", "summary": "Despite well-documented consequences of the U.S. government's 1930s housing\npolicies on racial wealth disparities, scholars have struggled to quantify its\nprecise financial effects due to the inaccessibility of historical property\nappraisal records. Many counties still store these records in physical formats,\nmaking large-scale quantitative analysis difficult. We present an approach\nscholars can use to digitize historical housing assessment data, applying it to\nbuild and release a dataset for one county. Starting from publicly available\nscanned documents, we manually annotated property cards for over 12,000\nproperties to train and validate our methods. We use OCR to label data for an\nadditional 50,000 properties, based on our two-stage approach combining\nclassical computer vision techniques with deep learning-based OCR. For cases\nwhere OCR cannot be applied, such as when scanned documents are not available,\nwe show how a regression model based on building feature data can estimate the\nhistorical values, and test the generalizability of this model to other\ncounties. With these cost-effective tools, scholars, community activists, and\npolicy makers can better analyze and understand the historical impacts of\nredlining.", "AI": {"tldr": "\u5b66\u8005\u4eec\u56e0\u5386\u53f2\u623f\u4ea7\u8bc4\u4f30\u8bb0\u5f55\u7684\u96be\u4ee5\u83b7\u53d6\uff0c\u96be\u4ee5\u91cf\u5316\u7f8e\u56fd\u653f\u5e9c20\u4e16\u7eaa30\u5e74\u4ee3\u4f4f\u623f\u653f\u7b56\u5bf9\u79cd\u65cf\u8d22\u5bcc\u5dee\u5f02\u7684\u786e\u5207\u91d1\u878d\u5f71\u54cd\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u5b57\u5316\u5386\u53f2\u4f4f\u623f\u8bc4\u4f30\u6570\u636e\u7684\u65b9\u6cd5\uff0c\u5e76\u5efa\u7acb\u4e86\u4e00\u4e2a\u53bf\u7684\u6570\u636e\u96c6\u3002\u901a\u8fc7\u624b\u52a8\u6807\u6ce8\u3001OCR\u6280\u672f\u548c\u56de\u5f52\u6a21\u578b\u7b49\u624b\u6bb5\uff0c\u4f7f\u5f97\u5b66\u8005\u3001\u793e\u533a\u6d3b\u52a8\u5bb6\u548c\u653f\u7b56\u5236\u5b9a\u8005\u80fd\u66f4\u597d\u5730\u5206\u6790\u548c\u7406\u89e3\u7ea2\u7ebf\u5212\u5b9a\u7684\u5386\u53f2\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u6709\u5145\u5206\u8bb0\u5f55\u663e\u793a\u7f8e\u56fd\u653f\u5e9c20\u4e16\u7eaa30\u5e74\u4ee3\u7684\u4f4f\u623f\u653f\u7b56\u5bf9\u79cd\u65cf\u8d22\u5bcc\u5dee\u5f02\u4ea7\u751f\u4e86\u6df1\u8fdc\u5f71\u54cd\uff0c\u4f46\u7531\u4e8e\u5386\u53f2\u623f\u4ea7\u8bc4\u4f30\u8bb0\u5f55\u7684\u96be\u4ee5\u83b7\u53d6\uff0c\u5b66\u8005\u4eec\u96be\u4ee5\u91cf\u5316\u5176\u786e\u5207\u91d1\u878d\u5f71\u54cd\u3002", "method": "\u4ece\u516c\u5f00\u53ef\u5f97\u7684\u626b\u63cf\u6587\u6863\u5f00\u59cb\uff0c\u624b\u52a8\u6807\u6ce8\u8d85\u8fc712,000\u4e2a\u623f\u4ea7\u5361\u7247\u4ee5\u8bad\u7ec3\u548c\u9a8c\u8bc1\u65b9\u6cd5\uff1b\u4f7f\u7528OCR\u6280\u672f\u4e3a\u989d\u591650,000\u4e2a\u623f\u4ea7\u6807\u6ce8\u6570\u636e\uff0c\u91c7\u7528\u7ed3\u5408\u7ecf\u5178\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u4e8eOCR\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1b\u5bf9\u4e8e\u65e0\u6cd5\u5e94\u7528OCR\u7684\u60c5\u51b5\uff08\u5982\u626b\u63cf\u6587\u6863\u4e0d\u53ef\u7528\uff09\uff0c\u5c55\u793a\u5982\u4f55\u57fa\u4e8e\u5efa\u7b51\u7279\u5f81\u6570\u636e\u7684\u56de\u5f52\u6a21\u578b\u6765\u4f30\u8ba1\u5386\u53f2\u4ef7\u503c\uff0c\u5e76\u6d4b\u8bd5\u8be5\u6a21\u578b\u5728\u5176\u4ed6\u53bf\u7684\u901a\u7528\u6027\u3002", "result": "\u6210\u529f\u6784\u5efa\u4e86\u4e00\u4e2a\u53bf\u7684\u5386\u53f2\u4f4f\u623f\u8bc4\u4f30\u6570\u636e\u96c6\uff0c\u4e14\u8bc1\u660e\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684\u5de5\u5177\u548c\u6280\u672f\u53ef\u4ee5\u7528\u4e8e\u66f4\u5927\u8303\u56f4\u7684\u7814\u7a76\u3002", "conclusion": "\u901a\u8fc7\u672c\u6587\u63d0\u51fa\u7684\u6570\u5b57\u5316\u65b9\u6cd5\u548c\u6a21\u578b\uff0c\u5b66\u8005\u3001\u793e\u533a\u6d3b\u52a8\u5bb6\u548c\u653f\u7b56\u5236\u5b9a\u8005\u80fd\u591f\u66f4\u597d\u5730\u5206\u6790\u548c\u7406\u89e3\u7ea2\u7ebf\u5212\u5b9a\u7684\u5386\u53f2\u5f71\u54cd\u3002"}}
{"id": "2505.24684", "pdf": "https://arxiv.org/pdf/2505.24684", "abs": "https://arxiv.org/abs/2505.24684", "authors": ["Zihao Chen", "Yu Xiang", "Wenyong Wang"], "title": "Disentangling Granularity: An Implicit Inductive Bias in Factorized VAEs", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Despite the success in learning semantically meaningful, unsupervised\ndisentangled representations, variational autoencoders (VAEs) and their\nvariants face a fundamental theoretical challenge: substantial evidence\nindicates that unsupervised disentanglement is unattainable without implicit\ninductive bias, yet such bias remains elusive. In this work, we focus on\nexploring the implicit inductive bias that drive disentanglement in VAEs with\nfactorization priors. By analyzing the total correlation in \\b{eta}-TCVAE, we\nuncover a crucial implicit inductive bias called disentangling granularity,\nwhich leads to the discovery of an interesting \"V\"-shaped optimal Evidence\nLower Bound (ELBO) trajectory within the parameter space. This finding is\nvalidated through over 100K experiments using factorized VAEs and our newly\nproposed model, \\b{eta}-STCVAE. Notably, experimental results reveal that\nconventional factorized VAEs, constrained by fixed disentangling granularity,\ninherently tend to disentangle low-complexity feature. Whereas, appropriately\ntuning disentangling granularity, as enabled by \\b{eta}-STCVAE, broadens the\nrange of disentangled representations, allowing for the disentanglement of\nhigh-complexity features. Our findings unveil that disentangling granularity as\nan implicit inductive bias in factorized VAEs influence both disentanglement\nperformance and the inference of the ELBO, offering fresh insights into the\ninterpretability and inherent biases of VAEs.", "AI": {"tldr": "\u901a\u8fc7\u5206\u6790\u03b7-TCVAE\u4e2d\u7684\u603b\u76f8\u5173\u6027\uff0c\u53d1\u73b0\u4e86\u89e3\u7ea0\u7f20\u7c92\u5ea6\u8fd9\u4e00\u5173\u952e\u7684\u9690\u5f0f\u5f52\u7eb3\u504f\u5dee\uff0c\u5e76\u63ed\u793a\u4e86\u53c2\u6570\u7a7a\u95f4\u4e2d\u6700\u4f73ELBO\u8f68\u8ff9\u7684\u6709\u8da3\u201cV\u201d\u5f62\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4f20\u7edf\u56e0\u5b50\u5206\u89e3VAE\u53d7\u9650\u4e8e\u56fa\u5b9a\u7684\u89e3\u7ea0\u7f20\u7c92\u5ea6\uff0c\u503e\u5411\u4e8e\u89e3\u7ea0\u7f20\u4f4e\u590d\u6742\u5ea6\u7279\u5f81\uff0c\u800c\u03b7-STCVAE\u80fd\u591f\u901a\u8fc7\u8c03\u6574\u89e3\u7ea0\u7f20\u7c92\u5ea6\u6765\u6269\u5c55\u53ef\u89e3\u7ea0\u7f20\u8868\u793a\u7684\u8303\u56f4\uff0c\u5141\u8bb8\u89e3\u7ea0\u7f20\u9ad8\u590d\u6742\u5ea6\u7279\u5f81\u3002", "motivation": "\u53d8\u5206\u81ea\u7f16\u7801\u5668\uff08VAEs\uff09\u53ca\u5176\u53d8\u4f53\u5728\u5b66\u4e60\u8bed\u4e49\u4e0a\u6709\u610f\u4e49\u7684\u65e0\u76d1\u7763\u89e3\u7ea0\u7f20\u8868\u793a\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u9762\u4e34\u7740\u4e00\u4e2a\u57fa\u672c\u7684\u7406\u8bba\u6311\u6218\uff1a\u6ca1\u6709\u9690\u5f0f\u7684\u5f52\u7eb3\u504f\u5dee\uff0c\u65e0\u76d1\u7763\u89e3\u7ea0\u7f20\u662f\u65e0\u6cd5\u5b9e\u73b0\u7684\uff0c\u7136\u800c\u8fd9\u79cd\u504f\u5dee\u4ecd\u7136\u96be\u4ee5\u6349\u6478\u3002", "method": "\u7814\u7a76\u8005\u4e13\u6ce8\u4e8e\u63a2\u7d22\u5e26\u6709\u56e0\u5b50\u5316\u5148\u9a8c\u7684VAEs\u4e2d\u9a71\u52a8\u89e3\u7ea0\u7f20\u7684\u9690\u5f0f\u5f52\u7eb3\u504f\u5dee\u3002\u901a\u8fc7\u5206\u6790\u03b7-TCVAE\u4e2d\u7684\u603b\u76f8\u5173\u6027\uff0c\u53d1\u73b0\u4e86\u79f0\u4e3a\u89e3\u7ea0\u7f20\u7c92\u5ea6\u7684\u5173\u952e\u9690\u5f0f\u5f52\u7eb3\u504f\u5dee\u3002\u5e76\u63d0\u51fa\u4e86\u65b0\u7684\u6a21\u578b\u03b7-STCVAE\uff0c\u901a\u8fc7\u8d85\u8fc710\u4e07\u6b21\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u53d1\u73b0\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4f20\u7edf\u7684\u56e0\u5b50\u5206\u89e3VAE\u53d7\u56fa\u5b9a\u89e3\u7ea0\u7f20\u7c92\u5ea6\u7684\u9650\u5236\uff0c\u5185\u5728\u5730\u503e\u5411\u4e8e\u89e3\u7ea0\u7f20\u4f4e\u590d\u6742\u5ea6\u7279\u5f81\u3002\u800c\u901a\u8fc7\u03b7-STCVAE\u9002\u5f53\u5730\u8c03\u6574\u89e3\u7ea0\u7f20\u7c92\u5ea6\uff0c\u53ef\u4ee5\u6269\u5927\u89e3\u7ea0\u7f20\u8868\u793a\u7684\u8303\u56f4\uff0c\u5141\u8bb8\u89e3\u7ea0\u7f20\u9ad8\u590d\u6742\u5ea6\u7279\u5f81\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u89e3\u7ea0\u7f20\u7c92\u5ea6\u4f5c\u4e3a\u4e00\u79cd\u9690\u5f0f\u5f52\u7eb3\u504f\u5dee\u5f71\u54cd\u4e86\u89e3\u7ea0\u7f20\u6027\u80fd\u548cELBO\u7684\u63a8\u7406\uff0c\u4e3aVAEs\u7684\u53ef\u89e3\u91ca\u6027\u548c\u56fa\u6709\u504f\u5dee\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002"}}
{"id": "2505.24040", "pdf": "https://arxiv.org/pdf/2505.24040", "abs": "https://arxiv.org/abs/2505.24040", "authors": ["Yuexing Hao", "Kumail Alhamoud", "Hyewon Jeong", "Haoran Zhang", "Isha Puri", "Philip Torr", "Mike Schaekermann", "Ariel D. Stern", "Marzyeh Ghassemi"], "title": "MedPAIR: Measuring Physicians and AI Relevance Alignment in Medical Question Answering", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large Language Models (LLMs) have demonstrated remarkable performance on\nvarious medical question-answering (QA) benchmarks, including standardized\nmedical exams. However, correct answers alone do not ensure correct logic, and\nmodels may reach accurate conclusions through flawed processes. In this study,\nwe introduce the MedPAIR (Medical Dataset Comparing Physicians and AI Relevance\nEstimation and Question Answering) dataset to evaluate how physician trainees\nand LLMs prioritize relevant information when answering QA questions. We obtain\nannotations on 1,300 QA pairs from 36 physician trainees, labeling each\nsentence within the question components for relevance. We compare these\nrelevance estimates to those for LLMs, and further evaluate the impact of these\n\"relevant\" subsets on downstream task performance for both physician trainees\nand LLMs. We find that LLMs are frequently not aligned with the content\nrelevance estimates of physician trainees. After filtering out physician\ntrainee-labeled irrelevant sentences, accuracy improves for both the trainees\nand the LLMs. All LLM and physician trainee-labeled data are available at:\nhttp://medpair.csail.mit.edu/.", "AI": {"tldr": "The paper introduces MedPAIR dataset to compare how physician trainees and LLMs prioritize information in medical QA, finding LLMs often misaligned with human relevance estimates. Filtering irrelevant sentences improves accuracy for both groups.", "motivation": "To evaluate and compare the prioritization of relevant information in medical question-answering between physician trainees and large language models.", "method": "Creation of the MedPAIR dataset with annotations from 36 physician trainees on 1,300 QA pairs, assessing sentence relevance within questions and comparing these estimates to those of LLMs.", "result": "LLMs show frequent misalignment with the relevance assessments of physician trainees. Removing irrelevant sentences as labeled by trainees enhances accuracy for both groups.", "conclusion": "The study highlights the importance of content relevance in medical QA and provides a resource (MedPAIR dataset) for further research in aligning LLMs with human relevance judgments."}}
{"id": "2505.24692", "pdf": "https://arxiv.org/pdf/2505.24692", "abs": "https://arxiv.org/abs/2505.24692", "authors": ["Derek Everett", "Fred Lu", "Edward Raff", "Fernando Camacho", "James Holt"], "title": "Quick-Draw Bandits: Quickly Optimizing in Nonstationary Environments with Extremely Many Arms", "categories": ["cs.LG", "stat.ML"], "comment": "KDD 2025, Research Track", "summary": "Canonical algorithms for multi-armed bandits typically assume a stationary\nreward environment where the size of the action space (number of arms) is\nsmall. More recently developed methods typically relax only one of these\nassumptions: existing non-stationary bandit policies are designed for a small\nnumber of arms, while Lipschitz, linear, and Gaussian process bandit policies\nare designed to handle a large (or infinite) number of arms in stationary\nreward environments under constraints on the reward function. In this\nmanuscript, we propose a novel policy to learn reward environments over a\ncontinuous space using Gaussian interpolation. We show that our method\nefficiently learns continuous Lipschitz reward functions with\n$\\mathcal{O}^*(\\sqrt{T})$ cumulative regret. Furthermore, our method naturally\nextends to non-stationary problems with a simple modification. We finally\ndemonstrate that our method is computationally favorable (100-10000x faster)\nand experimentally outperforms sliding Gaussian process policies on datasets\nwith non-stationarity and an extremely large number of arms.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\uff0c\u4f7f\u7528\u9ad8\u65af\u63d2\u503c\u5728\u8fde\u7eed\u7a7a\u95f4\u4e2d\u5b66\u4e60\u5956\u52b1\u73af\u5883\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5b66\u4e60\u8fde\u7eed\u7684Lipschitz\u5956\u52b1\u51fd\u6570\uff0c\u5e76\u81ea\u7136\u6269\u5c55\u5230\u975e\u5e73\u7a33\u95ee\u9898\uff0c\u540c\u65f6\u8ba1\u7b97\u4e0a\u66f4\u4f18\uff08100-10000\u500d\u66f4\u5feb\uff09\uff0c\u5e76\u5728\u5b9e\u9a8c\u4e2d\u4f18\u4e8e\u6ed1\u52a8\u9ad8\u65af\u8fc7\u7a0b\u7b56\u7565\u3002", "motivation": "\u7ecf\u5178\u7684\u591a\u81c2\u8d4c\u535a\u673a\u7b97\u6cd5\u901a\u5e38\u5047\u8bbe\u5956\u52b1\u73af\u5883\u662f\u5e73\u7a33\u7684\u4e14\u52a8\u4f5c\u7a7a\u95f4\u8f83\u5c0f\u3002\u8fd1\u671f\u7684\u53d1\u5c55\u901a\u5e38\u53ea\u653e\u677e\u5176\u4e2d\u4e00\u4e2a\u5047\u8bbe\uff1a\u73b0\u6709\u7684\u975e\u5e73\u7a33\u8d4c\u535a\u673a\u7b56\u7565\u9002\u7528\u4e8e\u5c11\u91cf\u624b\u81c2\uff0c\u800cLipschitz\u3001\u7ebf\u6027\u548c\u9ad8\u65af\u8fc7\u7a0b\u8d4c\u535a\u673a\u7b56\u7565\u5219\u7528\u4e8e\u5904\u7406\u5e73\u7a33\u5956\u52b1\u73af\u5883\u4e0b\u5927\u91cf\u7684\u624b\u81c2\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u5728\u4e00\u4e2a\u8fde\u7eed\u7a7a\u95f4\u5185\u5b66\u4e60\u5956\u52b1\u73af\u5883\u7684\u95ee\u9898\uff0c\u540c\u65f6\u8003\u8651\u975e\u5e73\u7a33\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7b56\u7565\uff0c\u4f7f\u7528\u9ad8\u65af\u63d2\u503c\u6765\u5b66\u4e60\u8fde\u7eed\u7a7a\u95f4\u4e2d\u7684\u5956\u52b1\u73af\u5883\u3002\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5$\\mathcal{O}^*(\\sqrt{T})$\u7684\u7d2f\u79ef\u9057\u61be\u6709\u6548\u5730\u5b66\u4e60\u8fde\u7eed\u7684Lipschitz\u5956\u52b1\u51fd\u6570\u3002\u901a\u8fc7\u7b80\u5355\u7684\u4fee\u6539\uff0c\u8be5\u65b9\u6cd5\u53ef\u4ee5\u81ea\u7136\u5730\u6269\u5c55\u5230\u975e\u5e73\u7a33\u95ee\u9898\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u8ba1\u7b97\u4e0a\u5177\u6709\u4f18\u52bf\uff08\u6bd4\u73b0\u6709\u65b9\u6cd5\u5feb100-10000\u500d\uff09\uff0c\u5e76\u4e14\u5728\u5177\u6709\u975e\u5e73\u7a33\u6027\u548c\u6781\u5927\u91cf\u624b\u81c2\u7684\u6570\u636e\u96c6\u4e0a\uff0c\u5b9e\u9a8c\u8868\u73b0\u4f18\u4e8e\u6ed1\u52a8\u9ad8\u65af\u8fc7\u7a0b\u7b56\u7565\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7b56\u7565\u4e0d\u4ec5\u5728\u7406\u8bba\u4e0a\u4fdd\u8bc1\u4e86\u5bf9\u8fde\u7eedLipschitz\u5956\u52b1\u51fd\u6570\u7684\u6709\u6548\u5b66\u4e60\uff0c\u8fd8\u5c55\u793a\u4e86\u5176\u5728\u975e\u5e73\u7a33\u95ee\u9898\u4e0a\u7684\u9002\u7528\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002"}}
{"id": "2505.24709", "pdf": "https://arxiv.org/pdf/2505.24709", "abs": "https://arxiv.org/abs/2505.24709", "authors": ["Soichiro Nishimori", "Yu-Jie Zhang", "Thanawat Lodkaew", "Masashi Sugiyama"], "title": "On Symmetric Losses for Robust Policy Optimization with Noisy Preferences", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Optimizing policies based on human preferences is key to aligning language\nmodels with human intent. This work focuses on reward modeling, a core\ncomponent in reinforcement learning from human feedback (RLHF), and offline\npreference optimization, such as direct preference optimization. Conventional\napproaches typically assume accurate annotations. However, real-world\npreference data often contains noise due to human errors or biases. We propose\na principled framework for robust policy optimization under noisy preferences,\nviewing reward modeling as a classification problem. This allows us to leverage\nsymmetric losses, known for their robustness to label noise in classification,\nleading to our Symmetric Preference Optimization (SymPO) method. We prove that\nsymmetric losses enable successful policy optimization even under noisy labels,\nas the resulting reward remains rank-preserving -- a property sufficient for\npolicy improvement. Experiments on synthetic and real-world tasks demonstrate\nthe effectiveness of SymPO.", "AI": {"tldr": "This paper proposes Symmetric Preference Optimization (SymPO), a method that uses symmetric losses for robust policy optimization in language models even with noisy preference data, proving its effectiveness through various experiments.", "motivation": "Current methods for optimizing policies based on human preferences assume accurate annotations, but real-world data often contains noise due to human errors or biases.", "method": "The authors propose treating reward modeling as a classification problem and applying symmetric losses, which are robust to label noise, leading to the development of the Symmetric Preference Optimization (SymPO) method.", "result": "Experiments conducted on both synthetic and real-world tasks show that SymPO is effective in optimizing policies under noisy conditions while maintaining rank-preserving rewards.", "conclusion": "SymPO enables successful policy optimization even when labels are noisy, providing a robust framework for reinforcement learning from human feedback."}}
{"id": "2505.24710", "pdf": "https://arxiv.org/pdf/2505.24710", "abs": "https://arxiv.org/abs/2505.24710", "authors": ["Wei Chen", "Jiahao Zhang", "Haipeng Zhu", "Boyan Xu", "Zhifeng Hao", "Keli Zhang", "Junjian Ye", "Ruichu Cai"], "title": "Causal-aware Large Language Models: Enhancing Decision-Making Through Learning, Adapting and Acting", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "Accepted by IJCAI 2025", "summary": "Large language models (LLMs) have shown great potential in decision-making\ndue to the vast amount of knowledge stored within the models. However, these\npre-trained models are prone to lack reasoning abilities and are difficult to\nadapt to new environments, further hindering their application to complex\nreal-world tasks. To address these challenges, inspired by the human cognitive\nprocess, we propose Causal-aware LLMs, which integrate the structural causal\nmodel (SCM) into the decision-making process to model, update, and utilize\nstructured knowledge of the environment in a ``learning-adapting-acting\"\nparadigm. Specifically, in the learning stage, we first utilize an LLM to\nextract the environment-specific causal entities and their causal relations to\ninitialize a structured causal model of the environment. Subsequently,in the\nadapting stage, we update the structured causal model through external feedback\nabout the environment, via an idea of causal intervention. Finally, in the\nacting stage, Causal-aware LLMs exploit structured causal knowledge for more\nefficient policy-making through the reinforcement learning agent. The above\nprocesses are performed iteratively to learn causal knowledge, ultimately\nenabling the causal-aware LLMs to achieve a more accurate understanding of the\nenvironment and make more efficient decisions. Experimental results across 22\ndiverse tasks within the open-world game ``Crafter\" validate the effectiveness\nof our proposed method.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.24090", "pdf": "https://arxiv.org/pdf/2505.24090", "abs": "https://arxiv.org/abs/2505.24090", "authors": ["Karan Hanswadkar", "Anika Kanchi", "Shivani Tripathi", "Shi Qiao", "Rony Chatterjee", "Alekh Jindal"], "title": "Searching Clinical Data Using Generative AI", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "Artificial Intelligence (AI) is making a major impact on healthcare,\nparticularly through its application in natural language processing (NLP) and\npredictive analytics. The healthcare sector has increasingly adopted AI for\ntasks such as clinical data analysis and medical code assignment. However,\nsearching for clinical information in large and often unorganized datasets\nremains a manual and error-prone process. Assisting this process with\nautomations can help physicians improve their operational productivity\nsignificantly.\n  In this paper, we present a generative AI approach, coined SearchAI, to\nenhance the accuracy and efficiency of searching clinical data. Unlike\ntraditional code assignment, which is a one-to-one problem, clinical data\nsearch is a one-to-many problem, i.e., a given search query can map to a family\nof codes. Healthcare professionals typically search for groups of related\ndiseases, drugs, or conditions that map to many codes, and therefore, they need\nsearch tools that can handle keyword synonyms, semantic variants, and broad\nopen-ended queries. SearchAI employs a hierarchical model that respects the\ncoding hierarchy and improves the traversal of relationships from parent to\nchild nodes. SearchAI navigates these hierarchies predictively and ensures that\nall paths are reachable without losing any relevant nodes.\n  To evaluate the effectiveness of SearchAI, we conducted a series of\nexperiments using both public and production datasets. Our results show that\nSearchAI outperforms default hierarchical traversals across several metrics,\nincluding accuracy, robustness, performance, and scalability. SearchAI can help\nmake clinical data more accessible, leading to streamlined workflows, reduced\nadministrative burden, and enhanced coding and diagnostic accuracy.", "AI": {"tldr": "The paper introduces SearchAI, a generative AI approach that enhances clinical data search accuracy and efficiency through a hierarchical model. It outperforms traditional methods in metrics like accuracy and scalability.", "motivation": "Clinical data search in large datasets is still manual and error-prone, creating a need for automation to improve physicians' operational productivity.", "method": "SearchAI uses a hierarchical model respecting the coding hierarchy to handle one-to-many search problems, ensuring all paths are reachable without losing relevant nodes.", "result": "Experiments on public and production datasets show SearchAI outperforms default hierarchical traversals in accuracy, robustness, performance, and scalability.", "conclusion": "SearchAI can make clinical data more accessible, streamlining workflows, reducing administrative burden, and enhancing coding and diagnostic accuracy."}}
{"id": "2505.24715", "pdf": "https://arxiv.org/pdf/2505.24715", "abs": "https://arxiv.org/abs/2505.24715", "authors": ["Fabio Fehr", "Prabhu Teja Sivaprasad", "Luca Franceschi", "Giovanni Zappella"], "title": "CoRet: Improved Retriever for Code Editing", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "ACL 2025", "summary": "In this paper, we introduce CoRet, a dense retrieval model designed for\ncode-editing tasks that integrates code semantics, repository structure, and\ncall graph dependencies. The model focuses on retrieving relevant portions of a\ncode repository based on natural language queries such as requests to implement\nnew features or fix bugs. These retrieved code chunks can then be presented to\na user or to a second code-editing model or agent. To train CoRet, we propose a\nloss function explicitly designed for repository-level retrieval. On SWE-bench\nand Long Code Arena's bug localisation datasets, we show that our model\nsubstantially improves retrieval recall by at least 15 percentage points over\nexisting models, and ablate the design choices to show their importance in\nachieving these results.", "AI": {"tldr": "This paper introduces CoRet, a dense retrieval model for code-editing tasks which improves retrieval recall by at least 15 percentage points over existing models.", "motivation": "To develop a model that integrates code semantics, repository structure, and call graph dependencies for enhancing code repository retrieval based on natural language queries.", "method": "The model, CoRet, is designed for code-editing tasks and uses a loss function explicitly designed for repository-level retrieval. It focuses on retrieving relevant portions of a code repository based on natural language queries.", "result": "CoRet substantially improves retrieval recall by at least 15 percentage points over existing models on SWE-bench and Long Code Arena's bug localisation datasets.", "conclusion": "CoRet shows significant improvements in retrieval performance and the importance of its design choices."}}
{"id": "2505.24099", "pdf": "https://arxiv.org/pdf/2505.24099", "abs": "https://arxiv.org/abs/2505.24099", "authors": ["Mohammad Shah Alam", "William Ott", "Ilya Timofeyev"], "title": "Attractor learning for spatiotemporally chaotic dynamical systems using echo state networks with transfer learning", "categories": ["math.DS", "cs.AI", "cs.LG", "nlin.CD", "stat.ML", "37N99, 68T30"], "comment": null, "summary": "In this paper, we explore the predictive capabilities of echo state networks\n(ESNs) for the generalized Kuramoto-Sivashinsky (gKS) equation, an archetypal\nnonlinear PDE that exhibits spatiotemporal chaos. We introduce a novel\nmethodology that integrates ESNs with transfer learning, aiming to enhance\npredictive performance across various parameter regimes of the gKS model. Our\nresearch focuses on predicting changes in long-term statistical patterns of the\ngKS model that result from varying the dispersion relation or the length of the\nspatial domain. We use transfer learning to adapt ESNs to different parameter\nsettings and successfully capture changes in the underlying chaotic attractor.", "AI": {"tldr": "This paper investigates the use of echo state networks (ESNs) with transfer learning to predict changes in long-term statistical patterns of the generalized Kuramoto-Sivashinsky (gKS) equation when parameters such as dispersion relation or spatial domain length vary.", "motivation": "To improve the predictive capabilities of ESNs for complex systems like the gKS model that exhibits spatiotemporal chaos, especially across different parameter regimes.", "method": "Integrate ESNs with transfer learning to adapt them to various parameter settings of the gKS model, allowing prediction of changes in long-term statistical patterns and chaotic attractors.", "result": "Successfully captured changes in the underlying chaotic attractor of the gKS model when varying parameters like dispersion relation or spatial domain length.", "conclusion": "The combination of ESNs and transfer learning shows promise for predicting complex dynamical behaviors in nonlinear systems."}}
{"id": "2505.24717", "pdf": "https://arxiv.org/pdf/2505.24717", "abs": "https://arxiv.org/abs/2505.24717", "authors": ["Benjamin Holzschuh", "Qiang Liu", "Georg Kohl", "Nils Thuerey"], "title": "PDE-Transformer: Efficient and Versatile Transformers for Physics Simulations", "categories": ["cs.LG"], "comment": "ICML 2025. Code available at\n  https://github.com/tum-pbs/pde-transformer", "summary": "We introduce PDE-Transformer, an improved transformer-based architecture for\nsurrogate modeling of physics simulations on regular grids. We combine recent\narchitectural improvements of diffusion transformers with adjustments specific\nfor large-scale simulations to yield a more scalable and versatile\ngeneral-purpose transformer architecture, which can be used as the backbone for\nbuilding large-scale foundation models in physical sciences. We demonstrate\nthat our proposed architecture outperforms state-of-the-art transformer\narchitectures for computer vision on a large dataset of 16 different types of\nPDEs. We propose to embed different physical channels individually as\nspatio-temporal tokens, which interact via channel-wise self-attention. This\nhelps to maintain a consistent information density of tokens when learning\nmultiple types of PDEs simultaneously. We demonstrate that our pre-trained\nmodels achieve improved performance on several challenging downstream tasks\ncompared to training from scratch and also beat other foundation model\narchitectures for physics simulations.", "AI": {"tldr": "The paper presents PDE-Transformer, an advanced transformer-based architecture for physics simulations on regular grids, which surpasses existing models in performance and scalability.", "motivation": "To create a more scalable and versatile general-purpose transformer architecture for building large-scale foundation models in physical sciences.", "method": "Combining recent architectural improvements of diffusion transformers with specific adjustments for large-scale simulations, embedding different physical channels individually as spatio-temporal tokens that interact via channel-wise self-attention.", "result": "Outperforms state-of-the-art transformer architectures for computer vision on a large dataset of 16 different types of PDEs and achieves improved performance on several challenging downstream tasks compared to training from scratch.", "conclusion": "PDE-Transformer is a successful architecture that can be used as the backbone for building large-scale foundation models in physical sciences, beating other foundation model architectures for physics simulations."}}
{"id": "2505.24120", "pdf": "https://arxiv.org/pdf/2505.24120", "abs": "https://arxiv.org/abs/2505.24120", "authors": ["Ai Jian", "Weijie Qiu", "Xiaokun Wang", "Peiyu Wang", "Yunzhuo Hao", "Jiangbo Pei", "Yichen Wei", "Yi Peng", "Xuchen Song"], "title": "CSVQA: A Chinese Multimodal Benchmark for Evaluating STEM Reasoning Capabilities of VLMs", "categories": ["cs.CV", "cs.AI"], "comment": "36 pages", "summary": "Vision-Language Models (VLMs) have demonstrated remarkable progress in\nmultimodal understanding, yet their capabilities for scientific reasoning\nremains inadequately assessed. Current multimodal benchmarks predominantly\nevaluate generic image comprehension or text-driven reasoning, lacking\nauthentic scientific contexts that require domain-specific knowledge\nintegration with visual evidence analysis. To fill this gap, we present CSVQA,\na diagnostic multimodal benchmark specifically designed for evaluating\nscientific reasoning through domain-grounded visual question answering.Our\nbenchmark features 1,378 carefully constructed question-answer pairs spanning\ndiverse STEM disciplines, each demanding domain knowledge, integration of\nvisual evidence, and higher-order reasoning. Compared to prior multimodal\nbenchmarks, CSVQA places greater emphasis on real-world scientific content and\ncomplex reasoning.We additionally propose a rigorous evaluation protocol to\nsystematically assess whether model predictions are substantiated by valid\nintermediate reasoning steps based on curated explanations. Our comprehensive\nevaluation of 15 VLMs on this benchmark reveals notable performance\ndisparities, as even the top-ranked proprietary model attains only 49.6\\%\naccuracy.This empirical evidence underscores the pressing need for advancing\nscientific reasoning capabilities in VLMs. Our CSVQA is released at\nhttps://huggingface.co/datasets/Skywork/CSVQA.", "AI": {"tldr": "Vision-Language Models (VLMs) lack adequate scientific reasoning abilities. The study introduces CSVQA, a benchmark with 1,378 question-answer pairs across STEM disciplines to evaluate scientific reasoning in VLMs. A rigorous evaluation protocol is also proposed, revealing significant performance disparities among 15 VLMs tested.", "motivation": "To address the inadequately assessed scientific reasoning capabilities of Vision-Language Models and the lack of authentic scientific contexts in current multimodal benchmarks.", "method": "Creation of CSVQA, a diagnostic multimodal benchmark featuring 1,378 question-answer pairs spanning diverse STEM disciplines, demanding domain knowledge, visual evidence integration, and higher-order reasoning. Proposal of a rigorous evaluation protocol based on curated explanations.", "result": "Evaluation of 15 VLMs on the CSVQA benchmark reveals notable performance disparities, with even the top-ranked model achieving only 49.6% accuracy.", "conclusion": "There is an urgent need to enhance scientific reasoning capabilities in VLMs."}}
{"id": "2505.24721", "pdf": "https://arxiv.org/pdf/2505.24721", "abs": "https://arxiv.org/abs/2505.24721", "authors": ["Nick Rossenbach", "Benedikt Hilmes", "Leon Brackmann", "Moritz Gunz", "Ralf Schl\u00fcter"], "title": "Running Conventional Automatic Speech Recognition on Memristor Hardware: A Simulated Approach", "categories": ["cs.LG", "cs.AR", "cs.ET"], "comment": "Accepted for the Blue Sky track at Interspeech 2025", "summary": "Memristor-based hardware offers new possibilities for energy-efficient\nmachine learning (ML) by providing analog in-memory matrix multiplication.\nCurrent hardware prototypes cannot fit large neural networks, and related\nliterature covers only small ML models for tasks like MNIST or single word\nrecognition. Simulation can be used to explore how hardware properties affect\nlarger models, but existing software assumes simplified hardware. We propose a\nPyTorch-based library based on \"Synaptogen\" to simulate neural network\nexecution with accurately captured memristor hardware properties. For the first\ntime, we show how an ML system with millions of parameters would behave on\nmemristor hardware, using a Conformer trained on the speech recognition task\nTED-LIUMv2 as example. With adjusted quantization-aware training, we limit the\nrelative degradation in word error rate to 25% when using a 3-bit weight\nprecision to execute linear operations via simulated analog computation.", "AI": {"tldr": "This paper proposes a PyTorch-based library called Synaptogen to simulate neural network execution with accurately captured memristor hardware properties, demonstrating its effectiveness on a Conformer trained on TED-LIUMv2.", "motivation": "Current memristor-based hardware prototypes cannot fit large neural networks and existing software for simulation assumes simplified hardware. There is a need for more accurate simulation tools to explore the behavior of larger ML models on memristor hardware.", "method": "The authors developed a PyTorch-based library named Synaptogen which simulates neural network execution using detailed memristor hardware properties. They applied this tool to study the performance of a Conformer model with millions of parameters trained on the speech recognition task TED-LIUMv2.", "result": "Using Synaptogen, they found that with adjusted quantization-aware training, the relative degradation in word error rate could be limited to 25% when employing a 3-bit weight precision for linear operations via simulated analog computation.", "conclusion": "The proposed Synaptogen library allows for the accurate simulation of large ML models on memristor hardware, providing insights into system behavior under realistic hardware constraints."}}
{"id": "2505.24133", "pdf": "https://arxiv.org/pdf/2505.24133", "abs": "https://arxiv.org/abs/2505.24133", "authors": ["Zefan Cai", "Wen Xiao", "Hanshi Sun", "Cheng Luo", "Yikai Zhang", "Ke Wan", "Yucheng Li", "Yeyang Zhou", "Li-Wen Chang", "Jiuxiang Gu", "Zhen Dong", "Anima Anandkumar", "Abedelkadir Asi", "Junjie Hu"], "title": "R-KV: Redundancy-aware KV Cache Compression for Training-Free Reasoning Models Acceleration", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Reasoning models have demonstrated impressive performance in self-reflection\nand chain-of-thought reasoning. However, they often produce excessively long\noutputs, leading to prohibitively large key-value (KV) caches during inference.\nWhile chain-of-thought inference significantly improves performance on complex\nreasoning tasks, it can also lead to reasoning failures when deployed with\nexisting KV cache compression approaches. To address this, we propose\nRedundancy-aware KV Cache Compression for Reasoning models (R-KV), a novel\nmethod specifically targeting redundant tokens in reasoning models. Our method\npreserves nearly 100% of the full KV cache performance using only 10% of the KV\ncache, substantially outperforming existing KV cache baselines, which reach\nonly 60% of the performance. Remarkably, R-KV even achieves 105% of full KV\ncache performance with 16% of the KV cache. This KV-cache reduction also leads\nto a 90% memory saving and a 6.6X throughput over standard chain-of-thought\nreasoning inference. Experimental results show that R-KV consistently\noutperforms existing KV cache compression baselines across two mathematical\nreasoning datasets.", "AI": {"tldr": "The paper introduces Redundancy-aware KV Cache Compression for Reasoning models (R-KV), which reduces cache size while maintaining or improving performance in reasoning tasks, offering significant memory savings and throughput improvements.", "motivation": "Reasoning models, despite their strong performance in complex tasks, suffer from excessive output length leading to large key-value (KV) caches. Existing KV cache compression methods cause reasoning failures when used with chain-of-thought inference.", "method": "Proposes R-KV, a method that targets redundant tokens in reasoning models to compress KV caches effectively without losing performance.", "result": "R-KV preserves nearly 100% of full KV cache performance using only 10% of the cache, achieves 105% performance with 16% cache, offers 90% memory saving, and 6.6X throughput compared to standard methods. It consistently outperforms existing baselines on two mathematical reasoning datasets.", "conclusion": "R-KV provides an effective solution for reducing KV cache size in reasoning models without sacrificing performance, resulting in substantial memory savings and improved throughput."}}
{"id": "2505.24722", "pdf": "https://arxiv.org/pdf/2505.24722", "abs": "https://arxiv.org/abs/2505.24722", "authors": ["Neil He", "Rishabh Anand", "Hiren Madhu", "Ali Maatouk", "Smita Krishnaswamy", "Leandros Tassiulas", "Menglin Yang", "Rex Ying"], "title": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have shown great success in text modeling tasks\nacross domains. However, natural language exhibits inherent semantic\nhierarchies and nuanced geometric structure, which current LLMs do not capture\ncompletely owing to their reliance on Euclidean operations. Recent studies have\nalso shown that not respecting the geometry of token embeddings leads to\ntraining instabilities and degradation of generative capabilities. These\nfindings suggest that shifting to non-Euclidean geometries can better align\nlanguage models with the underlying geometry of text. We thus propose to\noperate fully in Hyperbolic space, known for its expansive, scale-free, and\nlow-distortion properties. We thus introduce HELM, a family of HypErbolic Large\nLanguage Models, offering a geometric rethinking of the Transformer-based LLM\nthat addresses the representational inflexibility, missing set of necessary\noperations, and poor scalability of existing hyperbolic LMs. We additionally\nintroduce a Mixture-of-Curvature Experts model, HELM-MICE, where each expert\noperates in a distinct curvature space to encode more fine-grained geometric\nstructure from text, as well as a dense model, HELM-D. For HELM-MICE, we\nfurther develop hyperbolic Multi-Head Latent Attention (HMLA) for efficient,\nreduced-KV-cache training and inference. For both models, we develop essential\nhyperbolic equivalents of rotary positional encodings and RMS normalization. We\nare the first to train fully hyperbolic LLMs at billion-parameter scale, and\nevaluate them on well-known benchmarks such as MMLU and ARC, spanning STEM\nproblem-solving, general knowledge, and commonsense reasoning. Our results show\nconsistent gains from our HELM architectures -- up to 4% -- over popular\nEuclidean architectures used in LLaMA and DeepSeek, highlighting the efficacy\nand enhanced reasoning afforded by hyperbolic geometry in large-scale LM\npretraining.", "AI": {"tldr": "\u63d0\u51fa\u4e86HELM\u7cfb\u5217\u6a21\u578b\uff0c\u57fa\u4e8e\u53cc\u66f2\u7a7a\u95f4\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u5305\u542bHELM-MICE\u548cHELM-D\u4e24\u79cd\u6a21\u578b\u3002\u901a\u8fc7\u5f15\u5165\u53cc\u66f2\u51e0\u4f55\uff0c\u6539\u5584\u4e86\u8bed\u8a00\u6a21\u578b\u5728\u6587\u672c\u5efa\u6a21\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "motivation": "\u5f53\u524d\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u4f9d\u8d56\u6b27\u51e0\u91cc\u5f97\u64cd\u4f5c\uff0c\u65e0\u6cd5\u5b8c\u5168\u6355\u6349\u81ea\u7136\u8bed\u8a00\u4e2d\u56fa\u6709\u7684\u8bed\u4e49\u5c42\u6b21\u548c\u51e0\u4f55\u7ed3\u6784\uff0c\u5bfc\u81f4\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u548c\u751f\u6210\u80fd\u529b\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5168\u65b0\u7684\u53cc\u66f2\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08HELM\uff09\uff0c\u5305\u62ecMixture-of-Curvature Experts\u6a21\u578b\uff08HELM-MICE\uff09\u548c\u5bc6\u96c6\u6a21\u578b\uff08HELM-D\uff09\u3002\u5f00\u53d1\u4e86\u53cc\u66f2\u591a\u5934\u6f5c\u5728\u6ce8\u610f\u529b\uff08HMLA\uff09\u3001\u53cc\u66f2\u65cb\u8f6c\u4f4d\u7f6e\u7f16\u7801\u548cRMS\u5f52\u4e00\u5316\u7b49\u6280\u672f\u3002", "result": "\u5728MMLU\u548cARC\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cHELM\u67b6\u6784\u76f8\u8f83\u4e8e\u6d41\u884c\u7684\u6b27\u51e0\u91cc\u5f97\u67b6\u6784\uff08\u5982LLaMA\u548cDeepSeek\uff09\u8868\u73b0\u51fa\u4e00\u81f4\u7684\u63d0\u5347\uff0c\u6700\u9ad8\u53ef\u8fbe4%\u3002", "conclusion": "\u53cc\u66f2\u51e0\u4f55\u5728\u5927\u89c4\u6a21\u8bed\u8a00\u6a21\u578b\u9884\u8bad\u7ec3\u4e2d\u5c55\u73b0\u51fa\u6709\u6548\u6027\u548c\u589e\u5f3a\u63a8\u7406\u80fd\u529b\uff0c\u4e3a\u672a\u6765\u8bed\u8a00\u6a21\u578b\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2505.24136", "pdf": "https://arxiv.org/pdf/2505.24136", "abs": "https://arxiv.org/abs/2505.24136", "authors": ["Ya\u015far Utku Al\u00e7alar", "Mehmet Ak\u00e7akaya"], "title": "Sparsity-Driven Parallel Imaging Consistency for Improved Self-Supervised MRI Reconstruction", "categories": ["eess.IV", "cs.AI", "cs.CV", "cs.LG", "physics.med-ph"], "comment": "IEEE International Conference on Image Processing (ICIP), 2025", "summary": "Physics-driven deep learning (PD-DL) models have proven to be a powerful\napproach for improved reconstruction of rapid MRI scans. In order to train\nthese models in scenarios where fully-sampled reference data is unavailable,\nself-supervised learning has gained prominence. However, its application at\nhigh acceleration rates frequently introduces artifacts, compromising image\nfidelity. To mitigate this shortcoming, we propose a novel way to train PD-DL\nnetworks via carefully-designed perturbations. In particular, we enhance the\nk-space masking idea of conventional self-supervised learning with a novel\nconsistency term that assesses the model's ability to accurately predict the\nadded perturbations in a sparse domain, leading to more reliable and\nartifact-free reconstructions. The results obtained from the fastMRI knee and\nbrain datasets show that the proposed training strategy effectively reduces\naliasing artifacts and mitigates noise amplification at high acceleration\nrates, outperforming state-of-the-art self-supervised methods both visually and\nquantitatively.", "AI": {"tldr": "In order to address the issue of artifacts in high acceleration rate MRI reconstructions when fully-sampled reference data is unavailable, this paper proposes a new training method for physics-driven deep learning (PD-DL) networks that uses carefully-designed perturbations. This approach enhances conventional self-supervised learning and leads to more reliable, artifact-free reconstructions.", "motivation": "Self-supervised learning is crucial for training PD-DL models when fully-sampled reference data is not available. However, at high acceleration rates, it often introduces artifacts that compromise image fidelity. Thus, there is a need for an improved method to reduce these artifacts and improve reconstruction quality.", "method": "The authors propose a novel training strategy for PD-DL networks that incorporates a consistency term assessing the model's ability to predict added perturbations in a sparse domain. This builds upon the k-space masking idea used in conventional self-supervised learning.", "result": "The proposed method effectively reduces aliasing artifacts and mitigates noise amplification at high acceleration rates. It outperforms state-of-the-art self-supervised methods both visually and quantitatively on the fastMRI knee and brain datasets.", "conclusion": "The novel training strategy for PD-DL networks using carefully-designed perturbations improves MRI reconstruction quality at high acceleration rates, surpassing existing self-supervised techniques."}}
{"id": "2505.24728", "pdf": "https://arxiv.org/pdf/2505.24728", "abs": "https://arxiv.org/abs/2505.24728", "authors": ["Dongzi Jin", "Yong Xiao", "Yingyu Li"], "title": "Robust Federated Learning against Model Perturbation in Edge Networks", "categories": ["cs.LG", "cs.DC"], "comment": "Accepted by IEEE ICC 2025", "summary": "Federated Learning (FL) is a promising paradigm for realizing edge\nintelligence, allowing collaborative learning among distributed edge devices by\nsharing models instead of raw data. However, the shared models are often\nassumed to be ideal, which would be inevitably violated in practice due to\nvarious perturbations, leading to significant performance degradation. To\novercome this challenge, we propose a novel method, termed Sharpness-Aware\nMinimization-based Robust Federated Learning (SMRFL), which aims to improve\nmodel robustness against perturbations by exploring the geometrical property of\nthe model landscape. Specifically, SMRFL solves a min-max optimization problem\nthat promotes model convergence towards a flat minimum by minimizing the\nmaximum loss within a neighborhood of the model parameters. In this way, model\nsensitivity to perturbations is reduced, and robustness is enhanced since\nmodels in the neighborhood of the flat minimum also enjoy low loss values. The\ntheoretical result proves that SMRFL can converge at the same rate as FL\nwithout perturbations. Extensive experimental results show that SMRFL\nsignificantly enhances robustness against perturbations compared to three\nbaseline methods on two real-world datasets under three perturbation scenarios.", "AI": {"tldr": "In this paper, the authors address the issue of performance degradation in Federated Learning (FL) caused by perturbations in shared models. They propose a method called Sharpness-Aware Minimization-based Robust Federated Learning (SMRFL). This method improves model robustness against perturbations by exploring the geometrical property of the model landscape and solving a min-max optimization problem. Theoretical analysis proves that SMRFL converges at the same rate as FL without perturbations. Experimental results demonstrate that SMRFL significantly enhances robustness compared to baseline methods under various perturbation scenarios.", "motivation": "The motivation of this paper is to overcome the challenge of significant performance degradation in Federated Learning when shared models are exposed to various perturbations in practical scenarios.", "method": "The proposed method, Sharpness-Aware Minimization-based Robust Federated Learning (SMRFL), aims to improve model robustness against perturbations. It solves a min-max optimization problem that promotes model convergence towards a flat minimum by minimizing the maximum loss within a neighborhood of the model parameters.", "result": "The theoretical result proves that SMRFL can converge at the same rate as FL without perturbations. Extensive experimental results show that SMRFL significantly enhances robustness against perturbations compared to three baseline methods on two real-world datasets under three perturbation scenarios.", "conclusion": "SMRFL effectively reduces model sensitivity to perturbations and enhances robustness, making it a promising approach for improving the reliability of Federated Learning in practical applications."}}
{"id": "2505.24729", "pdf": "https://arxiv.org/pdf/2505.24729", "abs": "https://arxiv.org/abs/2505.24729", "authors": ["Magamed Taimeskhanov", "Damien Garreau"], "title": "Feature Attribution from First Principles", "categories": ["cs.LG"], "comment": "30 pages, 3 figures", "summary": "Feature attribution methods are a popular approach to explain the behavior of\nmachine learning models. They assign importance scores to each input feature,\nquantifying their influence on the model's prediction. However, evaluating\nthese methods empirically remains a significant challenge. To bypass this\nshortcoming, several prior works have proposed axiomatic frameworks that any\nfeature attribution method should satisfy. In this work, we argue that such\naxioms are often too restrictive, and propose in response a new feature\nattribution framework, built from the ground up. Rather than imposing axioms,\nwe start by defining attributions for the simplest possible models, i.e.,\nindicator functions, and use these as building blocks for more complex models.\nWe then show that one recovers several existing attribution methods, depending\non the choice of atomic attribution. Subsequently, we derive closed-form\nexpressions for attribution of deep ReLU networks, and take a step toward the\noptimization of evaluation metrics with respect to feature attributions.", "AI": {"tldr": "The paper proposes a new feature attribution framework for machine learning models, which starts by defining attributions for simple models and uses these as building blocks for complex models. It also derives expressions for deep ReLU networks and steps towards optimizing evaluation metrics.", "motivation": "Existing axiomatic frameworks for feature attribution methods in machine learning are too restrictive, making it difficult to evaluate these methods empirically.", "method": "The method involves starting with the simplest models (indicator functions) to define attributions and using these as building blocks for more complex models. This approach bypasses the need for restrictive axioms.", "result": "This approach recovers several existing attribution methods depending on the choice of atomic attribution and derives closed-form expressions for deep ReLU networks.", "conclusion": "The proposed framework offers a novel way to understand feature attributions without restrictive axioms and takes a step forward in optimizing evaluation metrics related to feature attributions."}}
{"id": "2505.24139", "pdf": "https://arxiv.org/pdf/2505.24139", "abs": "https://arxiv.org/abs/2505.24139", "authors": ["Yichen Xie", "Runsheng Xu", "Tong He", "Jyh-Jing Hwang", "Katie Luo", "Jingwei Ji", "Hubert Lin", "Letian Chen", "Yiren Lu", "Zhaoqi Leng", "Dragomir Anguelov", "Mingxing Tan"], "title": "S4-Driver: Scalable Self-Supervised Driving Multimodal Large Language Modelwith Spatio-Temporal Visual Representation", "categories": ["cs.CV", "cs.AI"], "comment": "Accepted by CVPR2025", "summary": "The latest advancements in multi-modal large language models (MLLMs) have\nspurred a strong renewed interest in end-to-end motion planning approaches for\nautonomous driving. Many end-to-end approaches rely on human annotations to\nlearn intermediate perception and prediction tasks, while purely\nself-supervised approaches--which directly learn from sensor inputs to generate\nplanning trajectories without human annotations often underperform the state of\nthe art. We observe a key gap in the input representation space: end-to-end\napproaches built on MLLMs are often pretrained with reasoning tasks in 2D image\nspace rather than the native 3D space in which autonomous vehicles plan. To\nthis end, we propose S4-Driver, a scalable self-supervised motion planning\nalgorithm with spatio-temporal visual representation, based on the popular PaLI\nmultimodal large language model. S4-Driver uses a novel sparse volume strategy\nto seamlessly transform the strong visual representation of MLLMs from\nperspective view to 3D space without the need to finetune the vision encoder.\nThis representation aggregates multi-view and multi-frame visual inputs and\nenables better prediction of planning trajectories in 3D space. To validate our\nmethod, we run experiments on both nuScenes and Waymo Open Motion Dataset (with\nin-house camera data). Results show that S4-Driver performs favorably against\nexisting supervised multi-task approaches while requiring no human annotations.\nIt also demonstrates great scalability when pretrained on large volumes of\nunannotated driving logs.", "AI": {"tldr": "S4-Driver is a scalable self-supervised motion planning algorithm with spatio-temporal visual representation based on the PaLI multimodal large language model. It transforms MLLMs' visual representation from 2D to 3D space via a novel sparse volume strategy without finetuning the vision encoder, showing competitive performance against supervised multi-task approaches and great scalability.", "motivation": "The key gap in the input representation space for end-to-end autonomous driving approaches built on MLLMs is that they are often pretrained with reasoning tasks in 2D image space rather than the native 3D space where autonomous vehicles plan.", "method": "S4-Driver uses a novel sparse volume strategy to transform MLLMs' strong visual representation from perspective view to 3D space without the need to finetune the vision encoder, aggregating multi-view and multi-frame visual inputs for better prediction of planning trajectories in 3D space.", "result": "S4-Driver performs favorably against existing supervised multi-task approaches while requiring no human annotations and demonstrates great scalability when pretrained on large volumes of unannotated driving logs.", "conclusion": "S4-Driver shows competitive performance against supervised multi-task approaches and great scalability, advancing the state-of-the-art in self-supervised motion planning algorithms."}}
{"id": "2505.24737", "pdf": "https://arxiv.org/pdf/2505.24737", "abs": "https://arxiv.org/abs/2505.24737", "authors": ["Erchi Wang", "Yuqing Zhu", "Yu-Xiang Wang"], "title": "Adapting to Linear Separable Subsets with Large-Margin in Differentially Private Learning", "categories": ["cs.LG", "stat.ML"], "comment": null, "summary": "This paper studies the problem of differentially private empirical risk\nminimization (DP-ERM) for binary linear classification. We obtain an efficient\n$(\\varepsilon,\\delta)$-DP algorithm with an empirical zero-one risk bound of\n$\\tilde{O}\\left(\\frac{1}{\\gamma^2\\varepsilon n} +\n\\frac{|S_{\\mathrm{out}}|}{\\gamma n}\\right)$ where $n$ is the number of data\npoints, $S_{\\mathrm{out}}$ is an arbitrary subset of data one can remove and\n$\\gamma$ is the margin of linear separation of the remaining data points (after\n$S_{\\mathrm{out}}$ is removed). Here, $\\tilde{O}(\\cdot)$ hides only logarithmic\nterms. In the agnostic case, we improve the existing results when the number of\noutliers is small. Our algorithm is highly adaptive because it does not require\nknowing the margin parameter $\\gamma$ or outlier subset $S_{\\mathrm{out}}$. We\nalso derive a utility bound for the advanced private hyperparameter tuning\nalgorithm.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.24141", "pdf": "https://arxiv.org/pdf/2505.24141", "abs": "https://arxiv.org/abs/2505.24141", "authors": ["Jiashuai Liu", "Yingjia Shang", "Yingkang Zhan", "Di Zhang", "Yi Niu", "Dong Wei", "Xian Wu", "Zeyu Gao", "Chen Li", "Yefeng Zheng"], "title": "The Butterfly Effect in Pathology: Exploring Security in Pathology Foundation Models", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "With the widespread adoption of pathology foundation models in both research\nand clinical decision support systems, exploring their security has become a\ncritical concern. However, despite their growing impact, the vulnerability of\nthese models to adversarial attacks remains largely unexplored. In this work,\nwe present the first systematic investigation into the security of pathology\nfoundation models for whole slide image~(WSI) analysis against adversarial\nattacks. Specifically, we introduce the principle of \\textit{local perturbation\nwith global impact} and propose a label-free attack framework that operates\nwithout requiring access to downstream task labels. Under this attack\nframework, we revise four classical white-box attack methods and redefine the\nperturbation budget based on the characteristics of WSI. We conduct\ncomprehensive experiments on three representative pathology foundation models\nacross five datasets and six downstream tasks. Despite modifying only 0.1\\% of\npatches per slide with imperceptible noise, our attack leads to downstream\naccuracy degradation that can reach up to 20\\% in the worst cases. Furthermore,\nwe analyze key factors that influence attack success, explore the relationship\nbetween patch-level vulnerability and semantic content, and conduct a\npreliminary investigation into potential defence strategies. These findings lay\nthe groundwork for future research on the adversarial robustness and reliable\ndeployment of pathology foundation models. Our code is publicly available at:\nhttps://github.com/Jiashuai-Liu-hmos/Attack-WSI-pathology-foundation-models.", "AI": {"tldr": "\u5c3d\u7ba1\u75c5\u7406\u57fa\u7840\u6a21\u578b\u5728\u7814\u7a76\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u7cfb\u7edf\u4e2d\u88ab\u5e7f\u6cdb\u91c7\u7528\uff0c\u4f46\u5176\u5bf9\u6297\u6027\u653b\u51fb\u7684\u8106\u5f31\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002\u672c\u6587\u9996\u6b21\u7cfb\u7edf\u5730\u7814\u7a76\u4e86\u5168\u5207\u7247\u56fe\u50cf\u5206\u6790\u4e2d\u7684\u75c5\u7406\u57fa\u7840\u6a21\u578b\u5b89\u5168\u6027\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6807\u7b7e\u653b\u51fb\u6846\u67b6\uff0c\u80fd\u591f\u5728\u4fee\u6539\u5c11\u91cf\u56fe\u50cf\u5757\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u964d\u4f4e\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u6027\u3002", "motivation": "\u75c5\u7406\u57fa\u7840\u6a21\u578b\u7684\u5b89\u5168\u6027\u95ee\u9898\u65e5\u76ca\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u5bf9\u5176\u5bf9\u6297\u6027\u653b\u51fb\u7684\u8106\u5f31\u6027\u7814\u7a76\u8f83\u5c11\u3002", "method": "\u5f15\u5165\u4e86\u201c\u5c40\u90e8\u6270\u52a8\uff0c\u5168\u5c40\u5f71\u54cd\u201d\u7684\u539f\u5219\uff0c\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u8bbf\u95ee\u4e0b\u6e38\u4efb\u52a1\u6807\u7b7e\u7684\u65e0\u6807\u7b7e\u653b\u51fb\u6846\u67b6\uff0c\u4fee\u8ba2\u4e86\u56db\u79cd\u7ecf\u5178\u7684\u767d\u76d2\u653b\u51fb\u65b9\u6cd5\uff0c\u5e76\u6839\u636e\u5168\u5207\u7247\u56fe\u50cf\u7684\u7279\u6027\u91cd\u65b0\u5b9a\u4e49\u4e86\u6270\u52a8\u9884\u7b97\u3002", "result": "\u901a\u8fc7\u4ec5\u4fee\u6539\u6bcf\u5f20\u5e7b\u706f\u72470.1%\u7684\u8865\u4e01\u5e76\u6dfb\u52a0\u4e0d\u53ef\u5bdf\u89c9\u7684\u566a\u58f0\uff0c\u653b\u51fb\u5bfc\u81f4\u67d0\u4e9b\u60c5\u51b5\u4e0b\u4e0b\u6e38\u4efb\u52a1\u51c6\u786e\u7387\u4e0b\u964d\u9ad8\u8fbe20%\u3002\u6b64\u5916\uff0c\u8fd8\u5206\u6790\u4e86\u5f71\u54cd\u653b\u51fb\u6210\u529f\u7684\u56e0\u7d20\u3001\u56fe\u50cf\u5757\u7ea7\u6f0f\u6d1e\u4e0e\u8bed\u4e49\u5185\u5bb9\u7684\u5173\u7cfb\uff0c\u5e76\u521d\u6b65\u63a2\u8ba8\u4e86\u9632\u5fa1\u7b56\u7565\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u672a\u6765\u5173\u4e8e\u75c5\u7406\u57fa\u7840\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u548c\u53ef\u9760\u90e8\u7f72\u7684\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2505.24749", "pdf": "https://arxiv.org/pdf/2505.24749", "abs": "https://arxiv.org/abs/2505.24749", "authors": ["Yehonathan Refael", "Guy Smorodinsky", "Tom Tirer", "Ofir Lindenbaum"], "title": "SUMO: Subspace-Aware Moment-Orthogonalization for Accelerating Memory-Efficient LLM Training", "categories": ["cs.LG", "cs.CL", "math.OC"], "comment": null, "summary": "Low-rank gradient-based optimization methods have significantly improved\nmemory efficiency during the training of large language models (LLMs), enabling\noperations within constrained hardware without sacrificing performance.\nHowever, these methods primarily emphasize memory savings, often overlooking\npotential acceleration in convergence due to their reliance on standard\nisotropic steepest descent techniques, which can perform suboptimally in the\nhighly anisotropic landscapes typical of deep networks, particularly LLMs. In\nthis paper, we propose SUMO (Subspace-Aware Moment-Orthogonalization), an\noptimizer that employs exact singular value decomposition (SVD) for moment\northogonalization within a dynamically adapted low-dimensional subspace,\nenabling norm-inducing steepest descent optimization steps. By explicitly\naligning optimization steps with the spectral characteristics of the loss\nlandscape, SUMO effectively mitigates approximation errors associated with\ncommonly used methods like Newton-Schulz orthogonalization approximation. We\ntheoretically establish an upper bound on these approximation errors, proving\ntheir dependence on the condition numbers of moments, conditions we\nanalytically demonstrate are encountered during LLM training. Furthermore, we\nboth theoretically and empirically illustrate that exact orthogonalization via\nSVD substantially improves convergence rates while reducing overall complexity.\nEmpirical evaluations confirm that SUMO accelerates convergence, enhances\nstability, improves performance, and reduces memory requirements by up to 20%\ncompared to state-of-the-art methods.", "AI": {"tldr": "SUMO\u662f\u4e00\u79cd\u65b0\u7684\u4f18\u5316\u5668\uff0c\u901a\u8fc7\u5728\u52a8\u6001\u8c03\u6574\u7684\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u4e2d\u4f7f\u7528\u7cbe\u786e\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u8fdb\u884c\u52a8\u91cf\u6b63\u4ea4\u5316\uff0c\u80fd\u591f\u663e\u8457\u52a0\u901f\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u6536\u655b\u901f\u5ea6\uff0c\u5e76\u63d0\u9ad8\u7a33\u5b9a\u6027\u548c\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u5c3d\u7ba1\u4f4e\u79e9\u68af\u5ea6\u4f18\u5316\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u5185\u5b58\u6548\u7387\uff0c\u4f46\u5b83\u4eec\u901a\u5e38\u4f9d\u8d56\u4e8e\u6807\u51c6\u7684\u5404\u5411\u540c\u6027\u6700\u9661\u4e0b\u964d\u6280\u672f\uff0c\u8fd9\u5728\u6df1\u5ea6\u7f51\u7edc\uff08\u7279\u522b\u662f\u5927\u8bed\u8a00\u6a21\u578b\uff09\u7684\u9ad8\u5ea6\u5404\u5411\u5f02\u6027\u635f\u5931\u666f\u89c2\u4e2d\u53ef\u80fd\u8868\u73b0\u4e0d\u4f73\uff0c\u9650\u5236\u4e86\u6536\u655b\u901f\u5ea6\u7684\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSUMO\u7684\u4f18\u5316\u5668\uff0c\u5b83\u5229\u7528\u7cbe\u786e\u7684\u5947\u5f02\u503c\u5206\u89e3\uff08SVD\uff09\u5728\u52a8\u6001\u8c03\u6574\u7684\u4f4e\u7ef4\u5b50\u7a7a\u95f4\u5185\u8fdb\u884c\u52a8\u91cf\u6b63\u4ea4\u5316\uff0c\u4ece\u800c\u5b9e\u73b0\u4e0e\u635f\u5931\u666f\u89c2\u7684\u8c31\u7279\u6027\u5bf9\u9f50\u7684\u8303\u6570\u8bf1\u5bfc\u6700\u9661\u4e0b\u964d\u4f18\u5316\u6b65\u9aa4\u3002\u6b64\u5916\uff0c\u8fd8\u7406\u8bba\u63a8\u5bfc\u4e86\u8fd1\u4f3c\u8bef\u5dee\u7684\u4e0a\u9650\uff0c\u5e76\u8bc1\u660e\u5176\u4e0e\u77e9\u7684\u6761\u4ef6\u6570\u76f8\u5173\uff0c\u8fd9\u4e9b\u6761\u4ef6\u5728\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u4e2d\u7ecf\u5e38\u51fa\u73b0\u3002", "result": "\u7406\u8bba\u4e0a\u548c\u5b9e\u8bc1\u4e0a\u90fd\u8868\u660e\uff0c\u901a\u8fc7SVD\u8fdb\u884c\u7cbe\u786e\u6b63\u4ea4\u5316\u53ef\u4ee5\u5927\u5e45\u63d0\u9ad8\u6536\u655b\u7387\uff0c\u540c\u65f6\u964d\u4f4e\u6574\u4f53\u590d\u6742\u5ea6\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cSUMO\u76f8\u8f83\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u52a0\u901f\u4e86\u6536\u655b\uff0c\u8fd8\u63d0\u5347\u4e86\u7a33\u5b9a\u6027\u3001\u6027\u80fd\uff0c\u5e76\u5c06\u5185\u5b58\u9700\u6c42\u51cf\u5c11\u4e86\u591a\u8fbe20%\u3002", "conclusion": "SUMO\u4f5c\u4e3a\u4e00\u79cd\u521b\u65b0\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u5728\u4e0d\u727a\u7272\u6027\u80fd\u7684\u524d\u63d0\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u8bed\u8a00\u6a21\u578b\u8bad\u7ec3\u7684\u6548\u7387\u548c\u7a33\u5b9a\u6027\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u5185\u5b58\u6d88\u8017\u3002"}}
{"id": "2505.24760", "pdf": "https://arxiv.org/pdf/2505.24760", "abs": "https://arxiv.org/abs/2505.24760", "authors": ["Zafir Stojanovski", "Oliver Stanley", "Joe Sharratt", "Richard Jones", "Abdulhakeem Adefioye", "Jean Kaddour", "Andreas K\u00f6pf"], "title": "REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": "For code, see https://github.com/open-thought/reasoning-gym", "summary": "We introduce Reasoning Gym (RG), a library of reasoning environments for\nreinforcement learning with verifiable rewards. It provides over 100 data\ngenerators and verifiers spanning multiple domains including algebra,\narithmetic, computation, cognition, geometry, graph theory, logic, and various\ncommon games. Its key innovation is the ability to generate virtually infinite\ntraining data with adjustable complexity, unlike most previous reasoning\ndatasets, which are typically fixed. This procedural generation approach allows\nfor continuous evaluation across varying difficulty levels. Our experimental\nresults demonstrate the efficacy of RG in both evaluating and reinforcement\nlearning of reasoning models.", "AI": {"tldr": "The paper introduces Reasoning Gym (RG), a library for reinforcement learning that offers over 100 data generators and verifiers across multiple domains. Its key innovation is the ability to generate virtually infinite training data with adjustable complexity.", "motivation": "To create a library of reasoning environments for reinforcement learning with verifiable rewards, addressing the limitation of fixed datasets in previous reasoning datasets.", "method": "Developed Reasoning Gym (RG) which includes data generators and verifiers spanning various domains and utilizes procedural generation to create virtually infinite training data with adjustable complexity.", "result": "Experimental results show the efficacy of RG in both evaluating and reinforcement learning of reasoning models.", "conclusion": "Reasoning Gym provides a valuable tool for continuous evaluation across varying difficulty levels in reinforcement learning."}}
{"id": "2505.24773", "pdf": "https://arxiv.org/pdf/2505.24773", "abs": "https://arxiv.org/abs/2505.24773", "authors": ["Yajie Zhou", "Xiaoyi Pang", "Zhibo Wang"], "title": "AFLoRA: Adaptive Federated Fine-Tuning of Large Language Models with Resource-Aware Low-Rank Adaption", "categories": ["cs.LG"], "comment": null, "summary": "Federated fine-tuning has emerged as a promising approach to adapt foundation\nmodels to downstream tasks using decentralized data. However, real-world\ndeployment remains challenging due to the high computational and communication\ndemands of fine-tuning Large Language Models (LLMs) on clients with data and\nsystem resources that are heterogeneous and constrained. In such settings, the\nglobal model's performance is often bottlenecked by the weakest clients and\nfurther degraded by the non-IID nature of local data. Although existing methods\nleverage parameter-efficient techniques such as Low-Rank Adaptation (LoRA) to\nreduce communication and computation overhead, they often fail to\nsimultaneously ensure accurate aggregation of low-rank updates and maintain low\nsystem costs, thereby hindering overall performance. To address these\nchallenges, we propose AFLoRA, an adaptive and lightweight federated\nfine-tuning framework for LLMs. AFLoRA decouples shared and client-specific\nupdates to reduce overhead and improve aggregation accuracy, incorporates\ndiagonal matrix-based rank pruning to better utilize local resources, and\nemploys rank-aware aggregation with public data refinement to strengthen\ngeneralization under data heterogeneity. Extensive experiments demonstrate that\nAFLoRA outperforms state-of-the-art methods in both accuracy and efficiency,\nproviding a practical solution for efficient LLM adaptation in heterogeneous\nenvironments in the real world.", "AI": {"tldr": "AFLoRA\u662f\u4e00\u79cd\u4e3a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8bbe\u8ba1\u7684\u81ea\u9002\u5e94\u8f7b\u91cf\u7ea7\u8054\u90a6\u5fae\u8c03\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u79bb\u5171\u4eab\u548c\u5ba2\u6237\u7aef\u7279\u5b9a\u66f4\u65b0\u3001\u4f7f\u7528\u5bf9\u89d2\u77e9\u9635\u79e9\u526a\u679d\u548c\u57fa\u4e8e\u516c\u5171\u6570\u636e\u4f18\u5316\u7684\u79e9\u611f\u77e5\u805a\u5408\u7b49\u65b9\u6cd5\uff0c\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u4e0a\u8d85\u8d8a\u73b0\u6709\u6280\u672f\u3002", "motivation": "\u73b0\u6709\u7684\u8054\u90a6\u5fae\u8c03\u65b9\u6cd5\u5728\u5904\u7406\u5f02\u6784\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\uff0c\u9762\u4e34\u8ba1\u7b97\u4e0e\u901a\u4fe1\u9700\u6c42\u9ad8\u3001\u6027\u80fd\u53d7\u6700\u5f31\u5ba2\u6237\u7aef\u9650\u5236\u4ee5\u53ca\u975e\u72ec\u7acb\u540c\u5206\u5e03\u6570\u636e\u5f71\u54cd\u7b49\u95ee\u9898\uff0c\u540c\u65f6\u96be\u4ee5\u517c\u987e\u4f4e\u79e9\u66f4\u65b0\u7684\u7cbe\u786e\u805a\u5408\u548c\u7cfb\u7edf\u6210\u672c\u3002", "method": "AFLoRA\u6846\u67b6\u4e3b\u8981\u91c7\u7528\u4ee5\u4e0b\u7b56\u7565\uff1a1) \u5206\u79bb\u5171\u4eab\u548c\u5ba2\u6237\u7aef\u7279\u5b9a\u66f4\u65b0\u4ee5\u964d\u4f4e\u5f00\u9500\u5e76\u63d0\u9ad8\u805a\u5408\u7cbe\u5ea6\uff1b2) \u5f15\u5165\u57fa\u4e8e\u5bf9\u89d2\u77e9\u9635\u7684\u79e9\u526a\u679d\u4ee5\u66f4\u6709\u6548\u5730\u5229\u7528\u672c\u5730\u8d44\u6e90\uff1b3) \u4f7f\u7528\u5177\u6709\u516c\u5171\u6570\u636e\u4f18\u5316\u7684\u79e9\u611f\u77e5\u805a\u5408\u6765\u589e\u5f3a\u6570\u636e\u5f02\u8d28\u6027\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0cAFLoRA\u5728\u51c6\u786e\u6027\u548c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u6280\u672f\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u4e2d\u5f02\u6784\u73af\u5883\u4e0b\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u6709\u6548\u9002\u914d\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "AFLoRA\u901a\u8fc7\u521b\u65b0\u7684\u6280\u672f\u624b\u6bb5\u89e3\u51b3\u4e86\u8054\u90a6\u5fae\u8c03\u5927\u578b\u8bed\u8a00\u6a21\u578b\u65f6\u9047\u5230\u7684\u6027\u80fd\u74f6\u9888\u95ee\u9898\uff0c\u5e76\u5728\u5f02\u6784\u73af\u5883\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u7cbe\u51c6\u7684\u6a21\u578b\u9002\u914d\u3002"}}
{"id": "2505.24163", "pdf": "https://arxiv.org/pdf/2505.24163", "abs": "https://arxiv.org/abs/2505.24163", "authors": ["Jiaqi Sun", "Shiyou Qian", "Zhangchi Han", "Wei Li", "Zelin Qian", "Dingyu Yang", "Jian Cao", "Guangtao Xue"], "title": "LKD-KGC: Domain-Specific KG Construction via LLM-driven Knowledge Dependency Parsing", "categories": ["cs.CL", "cs.AI"], "comment": "Submitting to EDBT 2026", "summary": "Knowledge Graphs (KGs) structure real-world entities and their relationships\ninto triples, enhancing machine reasoning for various tasks. While\ndomain-specific KGs offer substantial benefits, their manual construction is\noften inefficient and requires specialized knowledge. Recent approaches for\nknowledge graph construction (KGC) based on large language models (LLMs), such\nas schema-guided KGC and reference knowledge integration, have proven\nefficient. However, these methods are constrained by their reliance on manually\ndefined schema, single-document processing, and public-domain references,\nmaking them less effective for domain-specific corpora that exhibit complex\nknowledge dependencies and specificity, as well as limited reference knowledge.\nTo address these challenges, we propose LKD-KGC, a novel framework for\nunsupervised domain-specific KG construction. LKD-KGC autonomously analyzes\ndocument repositories to infer knowledge dependencies, determines optimal\nprocessing sequences via LLM driven prioritization, and autoregressively\ngenerates entity schema by integrating hierarchical inter-document contexts.\nThis schema guides the unsupervised extraction of entities and relationships,\neliminating reliance on predefined structures or external knowledge. Extensive\nexperiments show that compared with state-of-the-art baselines, LKD-KGC\ngenerally achieves improvements of 10% to 20% in both precision and recall\nrate, demonstrating its potential in constructing high-quality domain-specific\nKGs.", "AI": {"tldr": "The paper introduces LKD-KGC, an unsupervised framework for constructing domain-specific knowledge graphs (KGs) from document repositories. It autonomously infers knowledge dependencies, determines processing sequences, and generates entity schema without relying on predefined structures or external knowledge. Experiments show improvements of 10%-20% in precision and recall compared to state-of-the-art baselines.", "motivation": "Existing methods for knowledge graph construction (KGC) using large language models (LLMs) are constrained by manually defined schemas, single-document processing, and public-domain references, which limits their effectiveness for domain-specific corpora with complex knowledge dependencies and limited reference knowledge.", "method": "LKD-KGC autonomously analyzes document repositories to infer knowledge dependencies, determines optimal processing sequences via LLM driven prioritization, and autoregressively generates entity schema by integrating hierarchical inter-document contexts. This schema then guides the unsupervised extraction of entities and relationships.", "result": "Extensive experiments demonstrate that LKD-KGC achieves improvements of 10% to 20% in both precision and recall rate compared to state-of-the-art baselines.", "conclusion": "LKD-KGC shows potential in constructing high-quality domain-specific KGs without relying on predefined structures or external knowledge."}}
{"id": "2505.24776", "pdf": "https://arxiv.org/pdf/2505.24776", "abs": "https://arxiv.org/abs/2505.24776", "authors": ["Zachary Bastiani", "Robert M. Kirby", "Jacob Hochhalter", "Shandian Zhe"], "title": "Diffusion-Based Symbolic Regression", "categories": ["cs.LG"], "comment": null, "summary": "Diffusion has emerged as a powerful framework for generative modeling,\nachieving remarkable success in applications such as image and audio synthesis.\nEnlightened by this progress, we propose a novel diffusion-based approach for\nsymbolic regression. We construct a random mask-based diffusion and denoising\nprocess to generate diverse and high-quality equations. We integrate this\ngenerative processes with a token-wise Group Relative Policy Optimization\n(GRPO) method to conduct efficient reinforcement learning on the given\nmeasurement dataset. In addition, we introduce a long short-term risk-seeking\npolicy to expand the pool of top-performing candidates, further enhancing\nperformance. Extensive experiments and ablation studies have demonstrated the\neffectiveness of our approach.", "AI": {"tldr": "Diffusion is used for symbolic regression, with a novel approach that combines random mask-based diffusion, denoising, and reinforcement learning to generate high-quality equations.", "motivation": "Symbolic regression needs a powerful generative modeling framework like diffusion, which has been successful in other fields such as image and audio synthesis.", "method": "A random mask-based diffusion and denoising process is constructed to generate diverse and high-quality equations. This is integrated with token-wise Group Relative Policy Optimization (GRPO) for efficient reinforcement learning on measurement datasets. Additionally, a long short-term risk-seeking policy is introduced to expand the pool of top-performing candidates.", "result": "Extensive experiments and ablation studies have shown the effectiveness of the proposed approach.", "conclusion": "The novel diffusion-based approach for symbolic regression successfully generates high-quality equations and performs efficiently."}}
{"id": "2505.24779", "pdf": "https://arxiv.org/pdf/2505.24779", "abs": "https://arxiv.org/abs/2505.24779", "authors": ["Yidong Luo", "Chenguang Wang", "Jiahao Yang", "Fanzeng Xia", "Tianshu Yu"], "title": "EVA-MILP: Towards Standardized Evaluation of MILP Instance Generation", "categories": ["cs.LG"], "comment": "The code is available in\n  \\url{https://github.com/anonymous-neurips-submission-2025/EVA-MILP}", "summary": "Mixed-Integer Linear Programming (MILP) is fundamental to solving complex\ndecision-making problems. The proliferation of MILP instance generation\nmethods, driven by machine learning's demand for diverse optimization datasets\nand the limitations of static benchmarks, has significantly outpaced\nstandardized evaluation techniques. Consequently, assessing the fidelity and\nutility of synthetic MILP instances remains a critical, multifaceted challenge.\nThis paper introduces a comprehensive benchmark framework designed for the\nsystematic and objective evaluation of MILP instance generation methods. Our\nframework provides a unified and extensible methodology, assessing instance\nquality across crucial dimensions: mathematical validity, structural\nsimilarity, computational hardness, and utility in downstream machine learning\ntasks. A key innovation is its in-depth analysis of solver-internal features --\nparticularly by comparing distributions of key solver outputs including root\nnode gap, heuristic success rates, and cut plane usage -- leveraging the\nsolver's dynamic solution behavior as an `expert assessment' to reveal nuanced\ncomputational resemblances. By offering a structured approach with clearly\ndefined solver-independent and solver-dependent metrics, our benchmark aims to\nfacilitate robust comparisons among diverse generation techniques, spur the\ndevelopment of higher-quality instance generators, and ultimately enhance the\nreliability of research reliant on synthetic MILP data. The framework's\neffectiveness in systematically comparing the fidelity of instance sets is\ndemonstrated using contemporary generative models.", "AI": {"tldr": "The paper introduces a benchmark framework for evaluating Mixed-Integer Linear Programming (MILP) instance generation methods across crucial dimensions, using solver-internal features as 'expert assessments' to enhance the reliability of synthetic MILP data.", "motivation": "Driven by the lack of standardized evaluation techniques for assessing the fidelity and utility of synthetic MILP instances amidst the proliferation of generation methods.", "method": "The method involves a comprehensive benchmark framework that evaluates MILP instance quality across mathematical validity, structural similarity, computational hardness, and utility in machine learning tasks. It analyzes solver-internal features such as root node gap, heuristic success rates, and cut plane usage.", "result": "The framework effectively facilitates robust comparisons among diverse generation techniques, spurring development of higher-quality instance generators.", "conclusion": "This benchmark aims to enhance the reliability of research reliant on synthetic MILP data through systematic comparison of instance set fidelity."}}
{"id": "2505.24780", "pdf": "https://arxiv.org/pdf/2505.24780", "abs": "https://arxiv.org/abs/2505.24780", "authors": ["Run-Ze He", "Jun-Jian Su", "Su-Juan Qin", "Zheng-Ping Jin", "Fei Gao"], "title": "QGAN-based data augmentation for hybrid quantum-classical neural networks", "categories": ["cs.LG", "quant-ph"], "comment": null, "summary": "Quantum neural networks converge faster and achieve higher accuracy than\nclassical models. However, data augmentation in quantum machine learning\nremains underexplored. To tackle data scarcity, we integrate quantum generative\nadversarial networks (QGANs) with hybrid quantum-classical neural networks\n(HQCNNs) to develop an augmentation framework. We propose two strategies: a\ngeneral approach to enhance data processing and classification across HQCNNs,\nand a customized strategy that dynamically generates samples tailored to the\nHQCNN's performance on specific data categories, improving its ability to learn\nfrom complex datasets. Simulation experiments on the MNIST dataset demonstrate\nthat QGAN outperforms traditional data augmentation methods and classical GANs.\nCompared to baseline DCGAN, QGAN achieves comparable performance with half the\nparameters, balancing efficiency and effectiveness. This suggests that QGANs\ncan simplify models and generate high-quality data, enhancing HQCNN accuracy\nand performance. These findings pave the way for applying quantum data\naugmentation techniques in machine learning.", "AI": {"tldr": "The paper explores the use of Quantum Generative Adversarial Networks (QGANs) with Hybrid Quantum-Classical Neural Networks (HQCNNs) for data augmentation, showing improved performance and efficiency compared to classical methods.", "motivation": "Data augmentation in quantum machine learning is underexplored, particularly in addressing data scarcity issues.", "method": "Integrate QGANs with HQCNNs to create an augmentation framework with two strategies: a general approach for enhancing data processing and classification across HQCNNs, and a customized strategy that dynamically generates samples based on HQCNN's performance.", "result": "Simulation experiments on MNIST dataset show QGAN outperforms traditional data augmentation methods and classical GANs. It achieves comparable performance with half the parameters of DCGAN, indicating higher efficiency and effectiveness.", "conclusion": "QGANs can simplify models, generate high-quality data, and enhance HQCNN accuracy and performance, paving the way for applying quantum data augmentation techniques in machine learning."}}
{"id": "2505.24182", "pdf": "https://arxiv.org/pdf/2505.24182", "abs": "https://arxiv.org/abs/2505.24182", "authors": ["Zhuobai Dong", "Junchao Yi", "Ziyuan Zheng", "Haochen Han", "Xiangxi Zheng", "Alex Jinpeng Wang", "Fangming Liu", "Linjie Li"], "title": "Seeing is Not Reasoning: MVPBench for Graph-based Evaluation of Multi-path Visual Physical CoT", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Understanding the physical world - governed by laws of motion, spatial\nrelations, and causality - poses a fundamental challenge for multimodal large\nlanguage models (MLLMs). While recent advances such as OpenAI o3 and GPT-4o\ndemonstrate impressive perceptual and reasoning capabilities, our investigation\nreveals these models struggle profoundly with visual physical reasoning,\nfailing to grasp basic physical laws, spatial interactions, and causal effects\nin complex scenes. More importantly, they often fail to follow coherent\nreasoning chains grounded in visual evidence, especially when multiple steps\nare needed to arrive at the correct answer. To rigorously evaluate this\ncapability, we introduce MVPBench, a curated benchmark designed to rigorously\nevaluate visual physical reasoning through the lens of visual chain-of-thought\n(CoT). Each example features interleaved multi-image inputs and demands not\nonly the correct final answer but also a coherent, step-by-step reasoning path\ngrounded in evolving visual cues. This setup mirrors how humans reason through\nreal-world physical processes over time. To ensure fine-grained evaluation, we\nintroduce a graph-based CoT consistency metric that verifies whether the\nreasoning path of model adheres to valid physical logic. Additionally, we\nminimize shortcut exploitation from text priors, encouraging models to rely on\nvisual understanding. Experimental results reveal a concerning trend: even\ncutting-edge MLLMs exhibit poor visual reasoning accuracy and weak image-text\nalignment in physical domains. Surprisingly, RL-based post-training alignment -\ncommonly believed to improve visual reasoning performance - often harms spatial\nreasoning, suggesting a need to rethink current fine-tuning practices.", "AI": {"tldr": "\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u7269\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u663e\u8457\u4e0d\u8db3\uff0c\u5c24\u5176\u5728\u590d\u6742\u573a\u666f\u4e2d\u7684\u7269\u7406\u89c4\u5f8b\u3001\u7a7a\u95f4\u4ea4\u4e92\u548c\u56e0\u679c\u5173\u7cfb\u4e0a\u8868\u73b0\u4e0d\u4f73\u3002\u4e3a\u8bc4\u4f30\u6b64\u80fd\u529b\uff0c\u7814\u7a76\u63d0\u51faMVPBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u56fe\u7684CoT\u4e00\u81f4\u6027\u5ea6\u91cf\u65b9\u6cd5\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u5373\u4f7f\u662f\u6700\u5148\u8fdb\u7684\u6a21\u578b\u4e5f\u8868\u73b0\u51fa\u8f83\u5dee\u7684\u89c6\u89c9\u63a8\u7406\u51c6\u786e\u6027\u548c\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\u80fd\u529b\uff0c\u800cRL-based\u540e\u8bad\u7ec3\u5bf9\u9f50\u751a\u81f3\u53ef\u80fd\u635f\u5bb3\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5728\u611f\u77e5\u548c\u63a8\u7406\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u89c6\u89c9\u7269\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u660e\u663e\u7f3a\u9677\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u573a\u666f\u4e2d\u7684\u57fa\u672c\u7269\u7406\u5b9a\u5f8b\u3001\u7a7a\u95f4\u4e92\u52a8\u548c\u56e0\u679c\u6548\u5e94\u65f6\u3002\u6b64\u5916\uff0c\u8fd9\u4e9b\u6a21\u578b\u5f80\u5f80\u65e0\u6cd5\u6839\u636e\u89c6\u89c9\u8bc1\u636e\u8fdb\u884c\u8fde\u8d2f\u7684\u63a8\u7406\u94fe\u6761\uff0c\u5c24\u5176\u662f\u5728\u9700\u8981\u591a\u6b65\u9aa4\u624d\u80fd\u5f97\u51fa\u6b63\u786e\u7b54\u6848\u7684\u60c5\u51b5\u4e0b\u3002", "method": "\u63d0\u51fa\u4e86MVPBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u901a\u8fc7\u89c6\u89c9\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u7684\u89d2\u5ea6\u4e25\u683c\u8bc4\u4f30\u89c6\u89c9\u7269\u7406\u63a8\u7406\u80fd\u529b\u3002\u6bcf\u4e2a\u793a\u4f8b\u5305\u542b\u4ea4\u9519\u7684\u591a\u56fe\u50cf\u8f93\u5165\uff0c\u8981\u6c42\u4e0d\u4ec5\u63d0\u4f9b\u6b63\u786e\u7684\u6700\u7ec8\u7b54\u6848\uff0c\u8fd8\u9700\u8981\u4e00\u4e2a\u57fa\u4e8e\u9010\u6b65\u53d8\u5316\u89c6\u89c9\u7ebf\u7d22\u7684\u8fde\u8d2f\u63a8\u7406\u8def\u5f84\u3002\u540c\u65f6\uff0c\u5f15\u5165\u4e86\u57fa\u4e8e\u56fe\u7684CoT\u4e00\u81f4\u6027\u5ea6\u91cf\u6765\u9a8c\u8bc1\u6a21\u578b\u7684\u63a8\u7406\u8def\u5f84\u662f\u5426\u7b26\u5408\u6709\u6548\u7684\u7269\u7406\u903b\u8f91\u3002\u5e76\u901a\u8fc7\u51cf\u5c11\u6587\u672c\u5148\u9a8c\u7684\u4f7f\u7528\uff0c\u9f13\u52b1\u6a21\u578b\u4f9d\u8d56\u4e8e\u89c6\u89c9\u7406\u89e3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u63ed\u793a\u4e86\u4e00\u4e2a\u4ee4\u4eba\u62c5\u5fe7\u7684\u8d8b\u52bf\uff1a\u5373\u4f7f\u662f\u524d\u6cbf\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u7269\u7406\u9886\u57df\u4e2d\u4e5f\u663e\u793a\u51fa\u8f83\u5dee\u7684\u89c6\u89c9\u63a8\u7406\u51c6\u786e\u6027\u548c\u5f31\u56fe\u50cf-\u6587\u672c\u5bf9\u9f50\u80fd\u529b\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\uff08RL\uff09\u7684\u540e\u8bad\u7ec3\u5bf9\u9f50\u65b9\u6cd5\u901a\u5e38\u88ab\u8ba4\u4e3a\u53ef\u4ee5\u63d0\u9ad8\u89c6\u89c9\u63a8\u7406\u6027\u80fd\uff0c\u4f46\u4e8b\u5b9e\u8868\u660e\u5b83\u5f80\u5f80\u4f1a\u635f\u5bb3\u7a7a\u95f4\u63a8\u7406\u80fd\u529b\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u76ee\u524d\u6700\u5148\u8fdb\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u5728\u89c6\u89c9\u7269\u7406\u63a8\u7406\u65b9\u9762\u5b58\u5728\u91cd\u5927\u6311\u6218\u3002\u8fd9\u63d0\u793a\u6211\u4eec\u9700\u8981\u91cd\u65b0\u601d\u8003\u5f53\u524d\u7684\u5fae\u8c03\u5b9e\u8df5\uff0c\u7279\u522b\u662f\u4e0e\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u5bf9\u9f50\u65b9\u6cd5\u76f8\u5173\u7684\u5185\u5bb9\u3002"}}
{"id": "2505.24791", "pdf": "https://arxiv.org/pdf/2505.24791", "abs": "https://arxiv.org/abs/2505.24791", "authors": ["Jiaru Zhang", "Juanwu Lu", "Ziran Wang", "Ruqi Zhang"], "title": "Inference Acceleration of Autoregressive Normalizing Flows by Selective Jacobi Decoding", "categories": ["cs.LG", "cs.AI"], "comment": null, "summary": "Normalizing flows are promising generative models with advantages such as\ntheoretical rigor, analytical log-likelihood computation, and end-to-end\ntraining. However, the architectural constraints to ensure invertibility and\ntractable Jacobian computation limit their expressive power and practical\nusability. Recent advancements utilize autoregressive modeling, significantly\nenhancing expressive power and generation quality. However, such sequential\nmodeling inherently restricts parallel computation during inference, leading to\nslow generation that impedes practical deployment. In this paper, we first\nidentify that strict sequential dependency in inference is unnecessary to\ngenerate high-quality samples. We observe that patches in sequential modeling\ncan also be approximated without strictly conditioning on all preceding\npatches. Moreover, the models tend to exhibit low dependency redundancy in the\ninitial layer and higher redundancy in subsequent layers. Leveraging these\nobservations, we propose a selective Jacobi decoding (SeJD) strategy that\naccelerates autoregressive inference through parallel iterative optimization.\nTheoretical analyses demonstrate the method's superlinear convergence rate and\nguarantee that the number of iterations required is no greater than the\noriginal sequential approach. Empirical evaluations across multiple datasets\nvalidate the generality and effectiveness of our acceleration technique.\nExperiments demonstrate substantial speed improvements up to 4.7 times faster\ninference while keeping the generation quality and fidelity.", "AI": {"tldr": "The paper proposes Selective Jacobi Decoding (SeJD), a strategy to accelerate autoregressive inference in normalizing flows by parallel iterative optimization, achieving up to 4.7 times faster inference without compromising generation quality.", "motivation": "Normalizing flows are powerful generative models but face challenges such as limited expressive power due to architectural constraints and slow generation during inference due to sequential modeling.", "method": "The authors propose SeJD, which leverages observations that strict sequential dependency is unnecessary for high-quality sample generation and that there is low dependency redundancy in the initial layer and higher redundancy in subsequent layers. SeJD accelerates autoregressive inference through parallel iterative optimization.", "result": "Empirical evaluations demonstrate substantial speed improvements up to 4.7 times faster inference while maintaining generation quality and fidelity.", "conclusion": "SeJD provides a general and effective technique to accelerate autoregressive inference in normalizing flows."}}
{"id": "2505.24802", "pdf": "https://arxiv.org/pdf/2505.24802", "abs": "https://arxiv.org/abs/2505.24802", "authors": ["Marc Gonz\u00e1lez", "Rachid Guerraoui", "Rafael Pinot", "Geovani Rizk", "John Stephan", "Fran\u00e7ois Ta\u00efani"], "title": "ByzFL: Research Framework for Robust Federated Learning", "categories": ["cs.LG"], "comment": null, "summary": "We present ByzFL, an open-source Python library for developing and\nbenchmarking robust federated learning (FL) algorithms. ByzFL provides a\nunified and extensible framework that includes implementations of\nstate-of-the-art robust aggregators, a suite of configurable attacks, and tools\nfor simulating a variety of FL scenarios, including heterogeneous data\ndistributions, multiple training algorithms, and adversarial threat models. The\nlibrary enables systematic experimentation via a single JSON-based\nconfiguration file and includes built-in utilities for result visualization.\nCompatible with PyTorch tensors and NumPy arrays, ByzFL is designed to\nfacilitate reproducible research and rapid prototyping of robust FL solutions.\nByzFL is available at https://byzfl.epfl.ch/, with source code hosted on\nGitHub: https://github.com/LPD-EPFL/byzfl.", "AI": {"tldr": "An open-source Python library named ByzFL is presented for developing and benchmarking robust federated learning algorithms. It provides a unified framework, including state-of-the-art robust aggregators, configurable attacks, and FL scenario simulations. ByzFL supports systematic experimentation through a JSON-based configuration file and result visualization utilities.", "motivation": "To address the need for a comprehensive and flexible tool to develop and evaluate robust federated learning algorithms in the presence of various adversarial threat models and heterogeneous data distributions.", "method": "ByzFL provides a unified and extensible framework with implementations of state-of-the-art robust aggregators, a suite of configurable attacks, and tools for simulating FL scenarios such as heterogeneous data distributions, multiple training algorithms, and adversarial threat models. Experimentation is enabled via a single JSON-based configuration file.", "result": "The library facilitates reproducible research and rapid prototyping of robust FL solutions, compatible with PyTorch tensors and NumPy arrays.", "conclusion": "ByzFL is an open-source Python library that enables the development and benchmarking of robust federated learning algorithms, available at https://byzfl.epfl.ch/ and on GitHub."}}
{"id": "2505.24823", "pdf": "https://arxiv.org/pdf/2505.24823", "abs": "https://arxiv.org/abs/2505.24823", "authors": ["Yinggan Xu", "Yue Liu", "Zhiqiang Gao", "Changnan Peng", "Di Luo"], "title": "PhySense: Principle-Based Physics Reasoning Benchmarking for Large Language Models", "categories": ["cs.LG", "cs.AI", "cs.CL"], "comment": null, "summary": "Large language models (LLMs) have rapidly advanced and are increasingly\ncapable of tackling complex scientific problems, including those in physics.\nDespite this progress, current LLMs often fail to emulate the concise,\nprinciple-based reasoning characteristic of human experts, instead generating\nlengthy and opaque solutions. This discrepancy highlights a crucial gap in\ntheir ability to apply core physical principles for efficient and interpretable\nproblem solving. To systematically investigate this limitation, we introduce\nPhySense, a novel principle-based physics reasoning benchmark designed to be\neasily solvable by experts using guiding principles, yet deceptively difficult\nfor LLMs without principle-first reasoning. Our evaluation across multiple\nstate-of-the-art LLMs and prompt types reveals a consistent failure to align\nwith expert-like reasoning paths, providing insights for developing AI systems\nwith efficient, robust and interpretable principle-based scientific reasoning.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89e3\u51b3\u590d\u6742\u79d1\u5b66\u95ee\u9898\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u5f80\u5f80\u65e0\u6cd5\u6a21\u62df\u4eba\u7c7b\u4e13\u5bb6\u57fa\u4e8e\u539f\u5219\u7684\u7b80\u6d01\u63a8\u7406\uff0c\u800c\u662f\u751f\u6210\u5197\u957f\u4e14\u4e0d\u900f\u660e\u7684\u89e3\u51b3\u65b9\u6848\u3002\u4e3a\u7814\u7a76\u6b64\u9650\u5236\uff0c\u6211\u4eec\u5f15\u5165\u4e86PhySense\uff0c\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u539f\u5219\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8bc4\u4f30\u663e\u793a\uff0c\u591a\u4e2a\u6700\u5148\u8fdb\u7684LLM\u672a\u80fd\u4e0e\u4e13\u5bb6\u7684\u63a8\u7406\u8def\u5f84\u4e00\u81f4\uff0c\u8fd9\u4e3a\u5f00\u53d1\u9ad8\u6548\u3001\u7a33\u5065\u548c\u53ef\u89e3\u91ca\u7684\u539f\u5219\u57fa\u7840\u79d1\u5b66\u63a8\u7406AI\u7cfb\u7edf\u63d0\u4f9b\u4e86\u89c1\u89e3\u3002", "motivation": "\u5f53\u524d\u7684\u5927\u8bed\u8a00\u6a21\u578b\u867d\u7136\u80fd\u591f\u89e3\u51b3\u590d\u6742\u7684\u79d1\u5b66\u95ee\u9898\uff0c\u4f46\u5176\u63a8\u7406\u65b9\u5f0f\u4e0e\u4eba\u7c7b\u4e13\u5bb6\u76f8\u6bd4\u5b58\u5728\u5dee\u8ddd\uff0c\u7279\u522b\u662f\u5728\u57fa\u4e8e\u6838\u5fc3\u7269\u7406\u539f\u5219\u8fdb\u884c\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u7684\u95ee\u9898\u89e3\u51b3\u65b9\u9762\u3002", "method": "\u901a\u8fc7\u8bbe\u8ba1PhySense\u8fd9\u4e00\u65b0\u578b\u57fa\u4e8e\u7269\u7406\u539f\u5219\u63a8\u7406\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8be5\u6d4b\u8bd5\u5bf9\u4e13\u5bb6\u6765\u8bf4\u5bb9\u6613\u89e3\u51b3\uff0c\u4f46\u5bf9\u7f3a\u4e4f\u539f\u5219\u4f18\u5148\u63a8\u7406\u7684LLM\u6765\u8bf4\u5177\u6709\u6311\u6218\u6027\u3002\u7136\u540e\u4f7f\u7528\u591a\u79cd\u6700\u5148\u8fdb\u7684LLM\u548c\u63d0\u793a\u7c7b\u578b\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u8bc4\u4f30\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9bLLM\u4e00\u81f4\u5730\u672a\u80fd\u9075\u5faa\u7c7b\u4f3c\u4e8e\u4e13\u5bb6\u7684\u63a8\u7406\u8def\u5f84\u3002", "conclusion": "\u9700\u8981\u8fdb\u4e00\u6b65\u53d1\u5c55AI\u7cfb\u7edf\u4ee5\u5b9e\u73b0\u9ad8\u6548\u3001\u7a33\u5065\u548c\u53ef\u89e3\u91ca\u7684\u539f\u5219\u57fa\u7840\u79d1\u5b66\u63a8\u7406\u3002"}}
{"id": "2505.24214", "pdf": "https://arxiv.org/pdf/2505.24214", "abs": "https://arxiv.org/abs/2505.24214", "authors": ["Redwan Sony", "Parisa Farmanifard", "Hamzeh Alzwairy", "Nitish Shukla", "Arun Ross"], "title": "Benchmarking Foundation Models for Zero-Shot Biometric Tasks", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "The advent of foundation models, particularly Vision-Language Models (VLMs)\nand Multi-modal Large Language Models (MLLMs), has redefined the frontiers of\nartificial intelligence, enabling remarkable generalization across diverse\ntasks with minimal or no supervision. Yet, their potential in biometric\nrecognition and analysis remains relatively underexplored. In this work, we\nintroduce a comprehensive benchmark that evaluates the zero-shot and few-shot\nperformance of state-of-the-art publicly available VLMs and MLLMs across six\nbiometric tasks spanning the face and iris modalities: face verification, soft\nbiometric attribute prediction (gender and race), iris recognition,\npresentation attack detection (PAD), and face manipulation detection (morphs\nand deepfakes). A total of 41 VLMs were used in this evaluation. Experiments\nshow that embeddings from these foundation models can be used for diverse\nbiometric tasks with varying degrees of success. For example, in the case of\nface verification, a True Match Rate (TMR) of 96.77 percent was obtained at a\nFalse Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW)\ndataset, without any fine-tuning. In the case of iris recognition, the TMR at 1\npercent FMR on the IITD-R-Full dataset was 97.55 percent without any\nfine-tuning. Further, we show that applying a simple classifier head to these\nembeddings can help perform DeepFake detection for faces, Presentation Attack\nDetection (PAD) for irides, and extract soft biometric attributes like gender\nand ethnicity from faces with reasonably high accuracy. This work reiterates\nthe potential of pretrained models in achieving the long-term vision of\nArtificial General Intelligence.", "AI": {"tldr": "Foundation models, especially Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), show potential in biometric recognition tasks.", "motivation": "To explore the potential of foundation models, specifically VLMs and MLLMs, in biometric recognition and analysis which remains relatively underexplored.", "method": "A comprehensive benchmark was introduced to evaluate the zero-shot and few-shot performance of 41 publicly available VLMs across six biometric tasks related to face and iris modalities.", "result": "Experiments demonstrated that embeddings from these foundation models can be effectively used for various biometric tasks without fine-tuning. Notable results include a True Match Rate (TMR) of 96.77% at a False Match Rate (FMR) of 1% for face verification on LFW dataset, and a TMR of 97.55% at 1% FMR for iris recognition on IITD-R-Full dataset. Simple classifier heads applied to these embeddings also showed high accuracy in tasks like DeepFake detection, Presentation Attack Detection (PAD), and soft biometric attribute prediction.", "conclusion": "This work highlights the potential of pretrained models in achieving Artificial General Intelligence by demonstrating their effectiveness in diverse biometric tasks."}}
{"id": "2505.24835", "pdf": "https://arxiv.org/pdf/2505.24835", "abs": "https://arxiv.org/abs/2505.24835", "authors": ["Fuyuan Lyu", "Linfeng Du", "Yunpeng Weng", "Qiufang Ying", "Zhiyan Xu", "Wen Zou", "Haolun Wu", "Xiuqiang He", "Xing Tang"], "title": "Timing is important: Risk-aware Fund Allocation based on Time-Series Forecasting", "categories": ["cs.LG"], "comment": "Accepted by KDD 2025 ADS Track", "summary": "Fund allocation has been an increasingly important problem in the financial\ndomain. In reality, we aim to allocate the funds to buy certain assets within a\ncertain future period. Naive solutions such as prediction-only or\nPredict-then-Optimize approaches suffer from goal mismatch. Additionally, the\nintroduction of the SOTA time series forecasting model inevitably introduces\nadditional uncertainty in the predicted result. To solve both problems\nmentioned above, we introduce a Risk-aware Time-Series Predict-and-Allocate\n(RTS-PnO) framework, which holds no prior assumption on the forecasting models.\nSuch a framework contains three features: (i) end-to-end training with\nobjective alignment measurement, (ii) adaptive forecasting uncertainty\ncalibration, and (iii) agnostic towards forecasting models. The evaluation of\nRTS-PnO is conducted over both online and offline experiments. For offline\nexperiments, eight datasets from three categories of financial applications are\nused: Currency, Stock, and Cryptos. RTS-PnO consistently outperforms other\ncompetitive baselines. The online experiment is conducted on the Cross-Border\nPayment business at FiT, Tencent, and an 8.4\\% decrease in regret is witnessed\nwhen compared with the product-line approach. The code for the offline\nexperiment is available at https://github.com/fuyuanlyu/RTS-PnO.", "AI": {"tldr": "\u5728\u8d44\u91d1\u5206\u914d\u95ee\u9898\u4e2d\uff0c\u4f20\u7edf\u7684\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u5339\u914d\u548c\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u6a21\u578b\u5047\u8bbe\u7684\u98ce\u9669\u611f\u77e5\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u4e0e\u5206\u914d\u6846\u67b6\uff08RTS-PnO\uff09\uff0c\u5177\u6709\u7aef\u5230\u7aef\u8bad\u7ec3\u3001\u81ea\u9002\u5e94\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\u548c\u5bf9\u9884\u6d4b\u6a21\u578b\u4e0d\u53ef\u77e5\u7684\u7279\u70b9\u3002\u8be5\u6846\u67b6\u5728\u79bb\u7ebf\u5b9e\u9a8c\u4e2d\u4f7f\u7528\u516b\u4e2a\u6570\u636e\u96c6\uff0c\u5728\u5728\u7ebf\u5b9e\u9a8c\u4e2d\u5e94\u7528\u4e8e\u817e\u8bafFiT\u7684\u8de8\u5883\u652f\u4ed8\u4e1a\u52a1\uff0c\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u8d44\u91d1\u5206\u914d\u662f\u91d1\u878d\u9886\u57df\u7684\u91cd\u8981\u95ee\u9898\uff0c\u73b0\u6709\u7684\u7b80\u5355\u9884\u6d4b\u6216\u9884\u6d4b\u540e\u4f18\u5316\u65b9\u6cd5\u5b58\u5728\u76ee\u6807\u4e0d\u5339\u914d\u7684\u95ee\u9898\uff0c\u540c\u65f6\u6700\u5148\u8fdb\u7684\u65f6\u5e8f\u9884\u6d4b\u6a21\u578b\u5f15\u5165\u4e86\u989d\u5916\u7684\u4e0d\u786e\u5b9a\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRTS-PnO\u7684\u6846\u67b6\uff0c\u5176\u7279\u70b9\u5305\u62ec\uff1a(i) \u7aef\u5230\u7aef\u8bad\u7ec3\u5e76\u4f7f\u7528\u76ee\u6807\u4e00\u81f4\u6027\u5ea6\u91cf\uff0c(ii) \u81ea\u9002\u5e94\u9884\u6d4b\u4e0d\u786e\u5b9a\u6027\u6821\u51c6\uff0c(iii) \u5bf9\u9884\u6d4b\u6a21\u578b\u4e0d\u53ef\u77e5\u3002", "result": "\u5728\u79bb\u7ebf\u5b9e\u9a8c\u4e2d\uff0c\u4f7f\u7528\u6765\u81ea\u4e09\u79cd\u91d1\u878d\u5e94\u7528\u7c7b\u522b\u7684\u516b\u4e2a\u6570\u636e\u96c6\uff0cRTS-PnO\u59cb\u7ec8\u4f18\u4e8e\u5176\u4ed6\u7ade\u4e89\u57fa\u7ebf\u3002\u5728\u5728\u7ebf\u5b9e\u9a8c\u4e2d\uff0c\u4e0e\u4ea7\u54c1\u7ebf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u540e\u6094\u503c\u51cf\u5c11\u4e868.4%\u3002", "conclusion": "RTS-PnO\u6846\u67b6\u89e3\u51b3\u4e86\u76ee\u6807\u4e0d\u5339\u914d\u548c\u9884\u6d4b\u7ed3\u679c\u4e0d\u786e\u5b9a\u6027\u7684\u95ee\u9898\uff0c\u5c55\u793a\u4e86\u5728\u591a\u79cd\u91d1\u878d\u5e94\u7528\u573a\u666f\u4e2d\u7684\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2505.24225", "pdf": "https://arxiv.org/pdf/2505.24225", "abs": "https://arxiv.org/abs/2505.24225", "authors": ["Haibo Jin", "Peiyan Zhang", "Man Luo", "Haohan Wang"], "title": "Reasoning Can Hurt the Inductive Abilities of Large Language Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": "26 pages", "summary": "Large Language Models (LLMs) have shown remarkable progress across domains,\nyet their ability to perform inductive reasoning - inferring latent rules from\nsparse examples - remains limited. It is often assumed that chain-of-thought\n(CoT) prompting, as used in Large Reasoning Models (LRMs), enhances such\nreasoning. We investigate this assumption with creating four controlled,\ndiagnostic game-based tasks - chess, Texas Hold'em, dice games, and blackjack -\nwith hidden human-defined rules. We find that CoT reasoning can degrade\ninductive performance, with LRMs often underperforming their non-reasoning\ncounterparts.\n  To explain this, we present a theoretical framework that reveals how\nreasoning steps can amplify error through three failure modes: incorrect\nsub-task decomposition, incorrect sub-task solving, and incorrect final answer\nsummarization. Based on our theoretical and empirical analysis, we introduce\nstructured interventions that adapt CoT generation according to our identified\nfailure types. These interventions improve inductive accuracy without\nretraining. Our findings suggest that effective (CoT) reasoning depends not\nonly on taking more steps but also on ensuring those steps are well-structured.", "AI": {"tldr": "\u5c3d\u7ba1\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u88ab\u5e7f\u6cdb\u7528\u4e8e\u589e\u5f3a\u5927\u578b\u63a8\u7406\u6a21\u578b\uff08LRMs\uff09\u7684\u5f52\u7eb3\u63a8\u7406\u80fd\u529b\uff0c\u4f46\u7814\u7a76\u8868\u660e\uff0c\u5b83\u53ef\u80fd\u4f1a\u964d\u4f4e\u5f52\u7eb3\u6027\u80fd\u3002\u672c\u6587\u901a\u8fc7\u56db\u4e2a\u53d7\u63a7\u8bca\u65ad\u4efb\u52a1\u63ed\u793a\u4e86CoT\u63a8\u7406\u53ef\u80fd\u56e0\u4e09\u79cd\u9519\u8bef\u6a21\u5f0f\u653e\u5927\u9519\u8bef\uff0c\u5e76\u63d0\u51fa\u4e86\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u6539\u8fdb\u5f52\u7eb3\u51c6\u786e\u6027\u7684\u7ed3\u6784\u5316\u5e72\u9884\u63aa\u65bd\u3002\u8fd9\u8868\u660e\u6709\u6548\u7684\u63a8\u7406\u4e0d\u4ec5\u53d6\u51b3\u4e8e\u6b65\u9aa4\u6570\u91cf\uff0c\u8fd8\u53d6\u51b3\u4e8e\u6b65\u9aa4\u7684\u8d28\u91cf\u548c\u7ed3\u6784\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5f52\u7eb3\u63a8\u7406\u65b9\u9762\u8868\u73b0\u6709\u9650\uff0c\u800c\u94fe\u5f0f\u601d\u7ef4\uff08CoT\uff09\u63d0\u793a\u88ab\u8ba4\u4e3a\u80fd\u63d0\u5347\u8fd9\u79cd\u80fd\u529b\u3002\u7136\u800c\uff0c\u5176\u5b9e\u9645\u6548\u679c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u9a8c\u8bc1\u3002", "method": "\u8bbe\u8ba1\u4e86\u56db\u4e2a\u57fa\u4e8e\u6e38\u620f\u7684\u53d7\u63a7\u8bca\u65ad\u4efb\u52a1\uff08\u56fd\u9645\u8c61\u68cb\u3001\u5fb7\u5dde\u6251\u514b\u3001\u9ab0\u5b50\u6e38\u620f\u548c\u4e8c\u5341\u4e00\u70b9\uff09\uff0c\u8fd9\u4e9b\u4efb\u52a1\u5305\u542b\u9690\u85cf\u7684\u4eba\u7c7b\u5b9a\u4e49\u89c4\u5219\u3002\u901a\u8fc7\u7406\u8bba\u6846\u67b6\u5206\u6790\u4e86CoT\u63a8\u7406\u4e2d\u53ef\u80fd\u5bfc\u81f4\u9519\u8bef\u7684\u4e09\u4e2a\u6a21\u5f0f\uff1a\u5b50\u4efb\u52a1\u5206\u89e3\u9519\u8bef\u3001\u5b50\u4efb\u52a1\u89e3\u51b3\u9519\u8bef\u548c\u6700\u7ec8\u7b54\u6848\u603b\u7ed3\u9519\u8bef\u3002\u6839\u636e\u5206\u6790\u7ed3\u679c\uff0c\u63d0\u51fa\u4e86\u9002\u5e94\u4e0d\u540c\u9519\u8bef\u7c7b\u578b\u7684\u7ed3\u6784\u5316\u5e72\u9884\u63aa\u65bd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cCoT\u63a8\u7406\u53ef\u80fd\u4f1a\u964d\u4f4e\u5f52\u7eb3\u63a8\u7406\u7684\u8868\u73b0\uff0c\u5927\u578b\u63a8\u7406\u6a21\u578b\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u4e0d\u5982\u4e0d\u4f7f\u7528\u63a8\u7406\u7684\u6a21\u578b\u3002\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u5e72\u9884\u63aa\u65bd\u663e\u8457\u63d0\u9ad8\u4e86\u5f52\u7eb3\u63a8\u7406\u7684\u51c6\u786e\u6027\uff0c\u4e14\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u6a21\u578b\u3002", "conclusion": "\u6709\u6548\u7684\u63a8\u7406\u4e0d\u4ec5\u9700\u8981\u589e\u52a0\u63a8\u7406\u6b65\u9aa4\u7684\u6570\u91cf\uff0c\u8fd8\u9700\u8981\u786e\u4fdd\u63a8\u7406\u6b65\u9aa4\u7684\u7ed3\u6784\u5408\u7406\u3002\u7ed3\u6784\u5316\u5e72\u9884\u53ef\u4ee5\u6539\u5584\u6a21\u578b\u7684\u5f52\u7eb3\u63a8\u7406\u80fd\u529b\u3002"}}
{"id": "2505.24842", "pdf": "https://arxiv.org/pdf/2505.24842", "abs": "https://arxiv.org/abs/2505.24842", "authors": ["Harsh Chaudhari", "Jamie Hayes", "Matthew Jagielski", "Ilia Shumailov", "Milad Nasr", "Alina Oprea"], "title": "Cascading Adversarial Bias from Injection to Distillation in Language Models", "categories": ["cs.LG"], "comment": null, "summary": "Model distillation has become essential for creating smaller, deployable\nlanguage models that retain larger system capabilities. However, widespread\ndeployment raises concerns about resilience to adversarial manipulation. This\npaper investigates vulnerability of distilled models to adversarial injection\nof biased content during training. We demonstrate that adversaries can inject\nsubtle biases into teacher models through minimal data poisoning, which\npropagates to student models and becomes significantly amplified. We propose\ntwo propagation modes: Untargeted Propagation, where bias affects multiple\ntasks, and Targeted Propagation, focusing on specific tasks while maintaining\nnormal behavior elsewhere. With only 25 poisoned samples (0.25% poisoning\nrate), student models generate biased responses 76.9% of the time in targeted\nscenarios - higher than 69.4% in teacher models. For untargeted propagation,\nadversarial bias appears 6x-29x more frequently in student models on unseen\ntasks. We validate findings across six bias types (targeted advertisements,\nphishing links, narrative manipulations, insecure coding practices), various\ndistillation methods, and different modalities spanning text and code\ngeneration. Our evaluation reveals shortcomings in current defenses -\nperplexity filtering, bias detection systems, and LLM-based autorater\nframeworks - against these attacks. Results expose significant security\nvulnerabilities in distilled models, highlighting need for specialized\nsafeguards. We propose practical design principles for building effective\nadversarial bias mitigation strategies.", "AI": {"tldr": "\u6a21\u578b\u84b8\u998f\u867d\u7136\u6709\u52a9\u4e8e\u521b\u5efa\u66f4\u5c0f\u3001\u53ef\u90e8\u7f72\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u5bb9\u6613\u53d7\u5230\u5bf9\u6297\u6027\u504f\u5dee\u6ce8\u5165\u7684\u653b\u51fb\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u901a\u8fc7\u5c11\u91cf\u6570\u636e\u6295\u6bd2\u5373\u53ef\u5728\u6559\u5e08\u6a21\u578b\u4e2d\u6ce8\u5165\u7ec6\u5fae\u504f\u5dee\uff0c\u8fd9\u4e9b\u504f\u5dee\u4f1a\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u663e\u8457\u653e\u5927\u3002\u63d0\u51fa\u4e86\u975e\u76ee\u6807\u4f20\u64ad\u548c\u76ee\u6807\u4f20\u64ad\u4e24\u79cd\u6a21\u5f0f\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u79cd\u504f\u5dee\u7c7b\u578b\u3001\u84b8\u998f\u65b9\u6cd5\u548c\u6a21\u6001\u4e2d\u7684\u6709\u6548\u6027\u3002\u5f53\u524d\u9632\u5fa1\u63aa\u65bd\u5bf9\u6b64\u7c7b\u653b\u51fb\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u63aa\u65bd\u3002", "motivation": "\u5c3d\u7ba1\u6a21\u578b\u84b8\u998f\u53ef\u4ee5\u751f\u6210\u66f4\u5c0f\u4e14\u529f\u80fd\u5f3a\u5927\u7684\u8bed\u8a00\u6a21\u578b\uff0c\u4f46\u5176\u5728\u5e7f\u6cdb\u90e8\u7f72\u65f6\u9762\u4e34\u5bf9\u6297\u6027\u64cd\u4f5c\u7684\u98ce\u9669\uff0c\u7279\u522b\u662f\u5728\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u53ef\u80fd\u88ab\u6ce8\u5165\u6709\u504f\u5185\u5bb9\u3002", "method": "\u901a\u8fc7\u5728\u6559\u5e08\u6a21\u578b\u4e2d\u8fdb\u884c\u5c11\u91cf\u6570\u636e\u6295\u6bd2\u6ce8\u5165\u504f\u5dee\uff0c\u5e76\u5206\u6790\u8fd9\u4e9b\u504f\u5dee\u5982\u4f55\u5728\u5b66\u751f\u6a21\u578b\u4e2d\u4f20\u64ad\u548c\u653e\u5927\u3002\u63d0\u51fa\u975e\u76ee\u6807\u4f20\u64ad\u548c\u76ee\u6807\u4f20\u64ad\u4e24\u79cd\u6a21\u5f0f\uff0c\u5206\u522b\u5f71\u54cd\u591a\u4e2a\u4efb\u52a1\u548c\u7279\u5b9a\u4efb\u52a1\u3002\u4f7f\u7528\u4e0d\u540c\u7684\u504f\u5dee\u7c7b\u578b\u3001\u84b8\u998f\u65b9\u6cd5\u548c\u6a21\u6001\u9a8c\u8bc1\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002", "result": "\u4ec5\u752825\u4e2a\u6295\u6bd2\u6837\u672c\uff080.25%\u6295\u6bd2\u7387\uff09\uff0c\u5b66\u751f\u6a21\u578b\u5728\u76ee\u6807\u573a\u666f\u4e2d\u751f\u6210\u6709\u504f\u54cd\u5e94\u7684\u6982\u7387\u4e3a76.9%\uff0c\u9ad8\u4e8e\u6559\u5e08\u6a21\u578b\u768469.4%\u3002\u5bf9\u4e8e\u975e\u76ee\u6807\u4f20\u64ad\uff0c\u5bf9\u6297\u6027\u504f\u5dee\u5728\u672a\u89c1\u4efb\u52a1\u4e2d\u7684\u5b66\u751f\u6a21\u578b\u4e2d\u51fa\u73b0\u9891\u7387\u9ad8\u51fa6\u500d\u81f329\u500d\u3002", "conclusion": "\u5f53\u524d\u9632\u5fa1\u63aa\u65bd\u5bf9\u8fd9\u7c7b\u653b\u51fb\u6548\u679c\u6709\u9650\uff0c\u84b8\u998f\u6a21\u578b\u5b58\u5728\u91cd\u5927\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u3002\u63d0\u51fa\u4e86\u6784\u5efa\u6709\u6548\u7684\u5bf9\u6297\u6027\u504f\u5dee\u7f13\u89e3\u7b56\u7565\u7684\u5b9e\u9645\u8bbe\u8ba1\u539f\u5219\u3002"}}
{"id": "2505.24843", "pdf": "https://arxiv.org/pdf/2505.24843", "abs": "https://arxiv.org/abs/2505.24843", "authors": ["Ruqi Bai", "Yao Ji", "Zeyu Zhou", "David I. Inouye"], "title": "From Invariant Representations to Invariant Data: Provable Robustness to Spurious Correlations via Noisy Counterfactual Matching", "categories": ["cs.LG"], "comment": null, "summary": "Spurious correlations can cause model performance to degrade in new\nenvironments. Prior causality-inspired works aim to learn invariant\nrepresentations (e.g., IRM) but typically underperform empirical risk\nminimization (ERM). Recent alternatives improve robustness by leveraging\ntest-time data, but such data may be unavailable in practice. To address these\nissues, we take a data-centric approach by leveraging invariant data pairs,\npairs of samples that would have the same prediction with the optimally robust\nclassifier. We prove that certain counterfactual pairs will naturally satisfy\nthis invariance property and introduce noisy counterfactual matching (NCM), a\nsimple constraint-based method for leveraging invariant pairs for enhanced\nrobustness, even with a small set of noisy pairs-in the ideal case, each pair\ncan eliminate one spurious feature. For linear causal models, we prove that the\ntest domain error can be upper bounded by the in-domain error and a term that\ndepends on the counterfactuals' diversity and quality. We validate on a\nsynthetic dataset and demonstrate on real-world benchmarks that linear probing\non a pretrained backbone improves robustness.", "AI": {"tldr": "Spurious correlations can degrade model performance in new environments. Previous methods either underperform or require test-time data. This paper proposes a data-centric approach, Noisy Counterfactual Matching (NCM), that uses invariant data pairs to enhance robustness without needing test-time data. The method can eliminate spurious features and is validated on both synthetic and real-world datasets.", "motivation": "To address the issue of model performance degradation due to spurious correlations in new environments, while avoiding the pitfalls of prior methods such as underperformance or reliance on test-time data.", "method": "The paper introduces Noisy Counterfactual Matching (NCM), a constraint-based method leveraging invariant data pairs. These are pairs of samples that would have the same prediction with an optimally robust classifier. NCM can function effectively even with a small set of noisy pairs, potentially eliminating one spurious feature per pair. Additionally, for linear causal models, the test domain error is shown to be upper bounded by the in-domain error and a term depending on counterfactual diversity and quality.", "result": "NCM is proven effective in enhancing robustness. Theoretical results show that using counterfactual pairs can reduce reliance on spurious features. Empirical validation on a synthetic dataset and real-world benchmarks demonstrates that linear probing on a pretrained backbone improves robustness.", "conclusion": "Noisy Counterfactual Matching offers a promising data-centric solution to improve model robustness against spurious correlations without requiring test-time data, supported by both theoretical analysis and experimental results."}}
{"id": "2505.24232", "pdf": "https://arxiv.org/pdf/2505.24232", "abs": "https://arxiv.org/abs/2505.24232", "authors": ["Haibo Jin", "Peiyan Zhang", "Peiran Wang", "Man Luo", "Haohan Wang"], "title": "From Hallucinations to Jailbreaks: Rethinking the Vulnerability of Large Foundation Models", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Large foundation models (LFMs) are susceptible to two distinct\nvulnerabilities: hallucinations and jailbreak attacks. While typically studied\nin isolation, we observe that defenses targeting one often affect the other,\nhinting at a deeper connection.\n  We propose a unified theoretical framework that models jailbreaks as\ntoken-level optimization and hallucinations as attention-level optimization.\nWithin this framework, we establish two key propositions: (1) \\textit{Similar\nLoss Convergence} - the loss functions for both vulnerabilities converge\nsimilarly when optimizing for target-specific outputs; and (2) \\textit{Gradient\nConsistency in Attention Redistribution} - both exhibit consistent gradient\nbehavior driven by shared attention dynamics.\n  We validate these propositions empirically on LLaVA-1.5 and MiniGPT-4,\nshowing consistent optimization trends and aligned gradients. Leveraging this\nconnection, we demonstrate that mitigation techniques for hallucinations can\nreduce jailbreak success rates, and vice versa. Our findings reveal a shared\nfailure mode in LFMs and suggest that robustness strategies should jointly\naddress both vulnerabilities.", "AI": {"tldr": "Large foundation models (LFMs) are vulnerable to hallucinations and jailbreak attacks. This paper proposes a unified theoretical framework for understanding these vulnerabilities, validates it empirically on LLaVA-1.5 and MiniGPT-4, and suggests that robustness strategies should jointly address both issues.", "motivation": "To understand the connection between two distinct vulnerabilities in large foundation models: hallucinations and jailbreak attacks, and to develop more effective defense mechanisms.", "method": "Propose a unified theoretical framework modeling jailbreaks as token-level optimization and hallucinations as attention-level optimization. Establish two key propositions: Similar Loss Convergence and Gradient Consistency in Attention Redistribution.", "result": "Empirical validation of the propositions on LLaVA-1.5 and MiniGPT-4 shows consistent optimization trends and aligned gradients. Mitigation techniques for one vulnerability can reduce the success rate of the other.", "conclusion": "There is a shared failure mode in LFMs regarding hallucinations and jailbreak attacks, suggesting that robustness strategies should be developed to jointly address both vulnerabilities."}}
{"id": "2505.24844", "pdf": "https://arxiv.org/pdf/2505.24844", "abs": "https://arxiv.org/abs/2505.24844", "authors": ["Wanyun Xie", "Francesco Tonin", "Volkan Cevher"], "title": "Chameleon: A Flexible Data-mixing Framework for Language Model Pretraining and Finetuning", "categories": ["cs.LG", "cs.CL"], "comment": "ICML 2025", "summary": "Training data mixtures greatly impact the generalization performance of large\nlanguage models. Existing domain reweighting methods often rely on costly\nweight computations and require retraining when new data is introduced. To this\nend, we introduce a flexible and efficient data mixing framework, Chameleon,\nthat employs leverage scores to quantify domain importance within a learned\nembedding space. We first construct a domain affinity matrix over domain\nembeddings. The induced leverage scores determine a mixture that upweights\ndomains sharing common representations in embedding space. This formulation\nallows direct transfer to new data by computing the new domain embeddings. In\nexperiments, we demonstrate improvements over three key scenarios: (i) our\ncomputed weights improve performance on pretraining domains with a fraction of\nthe compute of existing methods; (ii) Chameleon can adapt to data changes\nwithout proxy retraining, boosting few-shot reasoning accuracies when\ntransferred to new data; (iii) our method enables efficient domain reweighting\nin finetuning, consistently improving test perplexity on all finetuning domains\nover uniform mixture. Our code is available at\nhttps://github.com/LIONS-EPFL/Chameleon.", "AI": {"tldr": "Chameleon\u662f\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u6570\u636e\u6df7\u5408\u6846\u67b6\uff0c\u5229\u7528leverage scores\u91cf\u5316\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u9886\u57df\u91cd\u8981\u6027\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u8bed\u8a00\u6a21\u578b\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u7684\u8868\u73b0\u3002", "motivation": "\u73b0\u6709\u7684\u9886\u57df\u91cd\u52a0\u6743\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u4e8e\u6602\u8d35\u7684\u6743\u91cd\u8ba1\u7b97\uff0c\u5e76\u4e14\u5728\u5f15\u5165\u65b0\u6570\u636e\u65f6\u9700\u8981\u91cd\u65b0\u8bad\u7ec3\uff0c\u56e0\u6b64\u7814\u7a76\u8005\u4eec\u5e0c\u671b\u627e\u5230\u4e00\u79cd\u66f4\u7075\u6d3b\u3001\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u901a\u8fc7\u6784\u5efa\u9886\u57df\u4eb2\u548c\u529b\u77e9\u9635\u6765\u786e\u5b9a\u9886\u57df\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u5171\u540c\u8868\u793a\uff0c\u5e76\u4f7f\u7528leverage scores\u8ba1\u7b97\u6570\u636e\u6df7\u5408\u6743\u91cd\uff0c\u4ece\u800c\u5b9e\u73b0\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u65b0\u6570\u636e\u7684\u80fd\u529b\u3002", "result": "(i) \u5728\u9884\u8bad\u7ec3\u9886\u57df\u4e2d\uff0c\u8ba1\u7b97\u51fa\u7684\u6743\u91cd\u4ec5\u7528\u4e00\u5c0f\u90e8\u5206\u8ba1\u7b97\u91cf\u5c31\u63d0\u9ad8\u4e86\u6027\u80fd\uff1b(ii) Chameleon\u53ef\u4ee5\u9002\u5e94\u6570\u636e\u53d8\u5316\uff0c\u63d0\u9ad8\u5c11\u6837\u672c\u63a8\u7406\u51c6\u786e\u6027\uff1b(iii) \u5728\u5fae\u8c03\u8fc7\u7a0b\u4e2d\uff0c\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6539\u5584\u6240\u6709\u5fae\u8c03\u9886\u57df\u7684\u6d4b\u8bd5\u56f0\u60d1\u5ea6\u3002", "conclusion": "Chameleon\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u65b9\u6cd5\u6765\u8fdb\u884c\u6570\u636e\u6df7\u5408\uff0c\u51cf\u5c11\u4e86\u8ba1\u7b97\u6210\u672c\u5e76\u63d0\u9ad8\u4e86\u6a21\u578b\u5728\u5404\u79cd\u573a\u666f\u4e0b\u7684\u6cdb\u5316\u6027\u80fd\u3002"}}
{"id": "2505.24239", "pdf": "https://arxiv.org/pdf/2505.24239", "abs": "https://arxiv.org/abs/2505.24239", "authors": ["Sana Ebrahimi", "Mohsen Dehghankar", "Abolfazl Asudeh"], "title": "An Adversary-Resistant Multi-Agent LLM System via Credibility Scoring", "categories": ["cs.MA", "cs.AI", "cs.CL", "cs.LG"], "comment": null, "summary": "While multi-agent LLM systems show strong capabilities in various domains,\nthey are highly vulnerable to adversarial and low-performing agents. To resolve\nthis issue, in this paper, we introduce a general and adversary-resistant\nmulti-agent LLM framework based on credibility scoring. We model the\ncollaborative query-answering process as an iterative game, where the agents\ncommunicate and contribute to a final system output. Our system associates a\ncredibility score that is used when aggregating the team outputs. The\ncredibility scores are learned gradually based on the past contributions of\neach agent in query answering. Our experiments across multiple tasks and\nsettings demonstrate our system's effectiveness in mitigating adversarial\ninfluence and enhancing the resilience of multi-agent cooperation, even in the\nadversary-majority settings.", "AI": {"tldr": "A new multi-agent LLM framework with credibility scoring is introduced to reduce vulnerability to adversarial agents.", "motivation": "Multi-agent LLM systems are vulnerable to adversarial and low-performing agents.", "method": "Model the collaborative query-answering process as an iterative game, associating credibility scores for each agent based on past contributions.", "result": "Experiments show effectiveness in reducing adversarial influence and enhancing resilience in multi-agent cooperation, even when adversaries are in the majority.", "conclusion": "The introduced framework improves multi-agent system resilience against adversarial agents."}}
{"id": "2505.24850", "pdf": "https://arxiv.org/pdf/2505.24850", "abs": "https://arxiv.org/abs/2505.24850", "authors": ["Shuyao Xu", "Cheng Peng", "Jiangxuan Long", "Weidi Xu", "Wei Chu", "Yuan Qi"], "title": "Harnessing Negative Signals: Reinforcement Distillation from Teacher Data for LLM Reasoning", "categories": ["cs.LG", "cs.AI", "cs.CL", "I.2.6; I.2.7"], "comment": "27 pages, 10 figures. Code available at\n  https://github.com/Tim-Siu/reinforcement-distillation", "summary": "Recent advances in model distillation demonstrate that data from advanced\nreasoning models (e.g., DeepSeek-R1, OpenAI's o1) can effectively transfer\ncomplex reasoning abilities to smaller, efficient student models. However,\nstandard practices employ rejection sampling, discarding incorrect reasoning\nexamples -- valuable, yet often underutilized data. This paper addresses the\ncritical question: How can both positive and negative distilled reasoning\ntraces be effectively leveraged to maximize LLM reasoning performance in an\noffline setting? To this end, We propose Reinforcement Distillation (REDI), a\ntwo-stage framework. Stage 1 learns from positive traces via Supervised\nFine-Tuning (SFT). Stage 2 further refines the model using both positive and\nnegative traces through our proposed REDI objective. This novel objective is a\nsimple, reference-free loss function that outperforms established methods like\nDPO and SimPO in this distillation context. Our empirical evaluations\ndemonstrate REDI's superiority over baseline Rejection Sampling SFT or SFT\ncombined with DPO/SimPO on mathematical reasoning tasks. Notably, the\nQwen-REDI-1.5B model, post-trained on just 131k positive and negative examples\nfrom the open Open-R1 dataset, achieves an 83.1% score on MATH-500 (pass@1).\nIts performance matches or surpasses that of DeepSeek-R1-Distill-Qwen-1.5B (a\nmodel post-trained on 800k proprietary data) across various mathematical\nreasoning benchmarks, establishing a new state-of-the-art for 1.5B models\npost-trained offline with openly available data.", "AI": {"tldr": "Recent advances in model distillation show that complex reasoning abilities can be transferred to smaller models. This paper proposes REDI, a two-stage framework that leverages both positive and negative distilled reasoning traces to maximize LLM reasoning performance in an offline setting. Empirical evaluations demonstrate REDI's superiority over other methods.", "motivation": "Standard practices in model distillation discard incorrect reasoning examples, which are valuable yet underutilized data. The paper aims to address how both positive and negative distilled reasoning traces can be effectively used to improve LLM reasoning performance.", "method": "The proposed method is called Reinforcement Distillation (REDI), a two-stage framework. Stage 1 involves learning from positive traces via Supervised Fine-Tuning (SFT). Stage 2 refines the model using both positive and negative traces through the REDI objective, a novel reference-free loss function.", "result": "Empirical evaluations show that REDI outperforms baseline methods like Rejection Sampling SFT or SFT combined with DPO/SimPO on mathematical reasoning tasks. Notably, the Qwen-REDI-1.5B model achieves an 83.1% score on MATH-500 and matches or surpasses other models across various benchmarks.", "conclusion": "REDI establishes a new state-of-the-art for 1.5B models post-trained offline with openly available data, demonstrating its effectiveness in leveraging both positive and negative reasoning traces."}}
{"id": "2505.24245", "pdf": "https://arxiv.org/pdf/2505.24245", "abs": "https://arxiv.org/abs/2505.24245", "authors": ["Xin Kang", "Zihan Zheng", "Lei Chu", "Yue Gao", "Jiahao Li", "Hao Pan", "Xuejin Chen", "Yan Lu"], "title": "LTM3D: Bridging Token Spaces for Conditional 3D Generation with Auto-Regressive Diffusion Framework", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "We present LTM3D, a Latent Token space Modeling framework for conditional 3D\nshape generation that integrates the strengths of diffusion and auto-regressive\n(AR) models. While diffusion-based methods effectively model continuous latent\nspaces and AR models excel at capturing inter-token dependencies, combining\nthese paradigms for 3D shape generation remains a challenge. To address this,\nLTM3D features a Conditional Distribution Modeling backbone, leveraging a\nmasked autoencoder and a diffusion model to enhance token dependency learning.\nAdditionally, we introduce Prefix Learning, which aligns condition tokens with\nshape latent tokens during generation, improving flexibility across modalities.\nWe further propose a Latent Token Reconstruction module with\nReconstruction-Guided Sampling to reduce uncertainty and enhance structural\nfidelity in generated shapes. Our approach operates in token space, enabling\nsupport for multiple 3D representations, including signed distance fields,\npoint clouds, meshes, and 3D Gaussian Splatting. Extensive experiments on\nimage- and text-conditioned shape generation tasks demonstrate that LTM3D\noutperforms existing methods in prompt fidelity and structural accuracy while\noffering a generalizable framework for multi-modal, multi-representation 3D\ngeneration.", "AI": {"tldr": "The paper introduces LTM3D, a framework combining diffusion and AR models for conditional 3D shape generation, featuring Conditional Distribution Modeling, Prefix Learning, and Latent Token Reconstruction to enhance token dependency learning, align condition tokens, and reduce uncertainty respectively. It operates in token space supporting multiple 3D representations and outperforms existing methods.", "motivation": "To integrate the strengths of diffusion and auto-regressive models for conditional 3D shape generation, addressing the challenge of combining these paradigms effectively.", "method": "LTM3D uses a Conditional Distribution Modeling backbone with a masked autoencoder and a diffusion model to improve token dependency learning. It also includes Prefix Learning to align condition tokens with shape latent tokens, and a Latent Token Reconstruction module with Reconstruction-Guided Sampling to reduce uncertainty and enhance structural fidelity.", "result": "Extensive experiments show that LTM3D surpasses existing methods in prompt fidelity and structural accuracy for image- and text-conditioned shape generation tasks, while providing a generalizable framework for multi-modal, multi-representation 3D generation.", "conclusion": "LTM3D successfully combines diffusion and AR models for conditional 3D shape generation, offering superior performance and a flexible framework for various 3D representations."}}
{"id": "2505.24857", "pdf": "https://arxiv.org/pdf/2505.24857", "abs": "https://arxiv.org/abs/2505.24857", "authors": ["Heli Ben-Hamu", "Itai Gat", "Daniel Severo", "Niklas Nolte", "Brian Karrer"], "title": "Accelerated Sampling from Masked Diffusion Models via Entropy Bounded Unmasking", "categories": ["cs.LG"], "comment": null, "summary": "Recent masked diffusion models (MDMs) have shown competitive performance\ncompared to autoregressive models (ARMs) for language modeling. While most\nliterature has focused on performance enhancing sampling procedures, efficient\nsampling from MDMs has been scarcely explored. We make the observation that\noften a given sequence of partially masked tokens determines the values of\nmultiple unknown tokens deterministically, meaning that a single prediction of\na masked model holds additional information unused by standard sampling\nprocedures. Based on this observation, we introduce EB-Sampler, a simple\ndrop-in replacement for existing samplers, utilizing an Entropy Bounded\nunmasking procedure that dynamically unmasks multiple tokens in one function\nevaluation with predefined approximate error tolerance. We formulate the\nEB-Sampler as part of a broad family of adaptive samplers for which we provide\nan error analysis that motivates our algorithmic choices. EB-Sampler\naccelerates sampling from current state of the art MDMs by roughly 2-3x on\nstandard coding and math reasoning benchmarks without loss in performance. We\nalso validate the same procedure works well on smaller reasoning tasks\nincluding maze navigation and Sudoku, tasks ARMs often struggle with.", "AI": {"tldr": "EB-Sampler\u662f\u4e00\u79cd\u65b0\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u80fd\u52a0\u901f\u5f53\u524d\u6700\u5148\u8fdb\u7684MDMs\u7684\u91c7\u6837\u8fc7\u7a0b\u7ea62-3\u500d\uff0c\u5728\u6807\u51c6\u7f16\u7801\u548c\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u4e0d\u635f\u5931\u6027\u80fd\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5728\u5c0f\u578b\u63a8\u7406\u4efb\u52a1\uff08\u5982\u8ff7\u5bab\u5bfc\u822a\u548c\u6570\u72ec\uff09\u4e2d\u4e5f\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u5c3d\u7ba1\u5927\u591a\u6570\u6587\u732e\u96c6\u4e2d\u4e8e\u63d0\u5347\u91c7\u6837\u7a0b\u5e8f\u7684\u6027\u80fd\uff0c\u4f46\u5bf9MDMs\u7684\u6709\u6548\u91c7\u6837\u63a2\u7d22\u8f83\u5c11\u3002\u7814\u7a76\u8005\u89c2\u5bdf\u5230\u90e8\u5206\u88ab\u63a9\u76d6\u7684\u4ee4\u724c\u5e8f\u5217\u901a\u5e38\u53ef\u4ee5\u786e\u5b9a\u6027\u5730\u51b3\u5b9a\u591a\u4e2a\u672a\u77e5\u4ee4\u724c\u7684\u503c\uff0c\u8fd9\u610f\u5473\u7740\u5355\u4e00\u7684\u9884\u6d4b\u6a21\u578b\u5305\u542b\u672a\u88ab\u6807\u51c6\u91c7\u6837\u8fc7\u7a0b\u5145\u5206\u5229\u7528\u7684\u989d\u5916\u4fe1\u606f\u3002", "method": "\u57fa\u4e8e\u4e0a\u8ff0\u89c2\u5bdf\uff0c\u7814\u7a76\u8005\u5f15\u5165\u4e86EB-Sampler\uff0c\u8fd9\u662f\u73b0\u6709\u91c7\u6837\u5668\u7684\u4e00\u4e2a\u7b80\u5355\u66ff\u4ee3\u65b9\u6848\uff0c\u91c7\u7528\u71b5\u7ea6\u675f\u89e3\u7801\u8fc7\u7a0b\uff0c\u80fd\u591f\u5728\u4e00\u6b21\u51fd\u6570\u8bc4\u4f30\u4e2d\u52a8\u6001\u89e3\u7801\u591a\u4e2a\u4ee4\u724c\uff0c\u5e76\u5177\u6709\u9884\u5b9a\u4e49\u7684\u8fd1\u4f3c\u8bef\u5dee\u5bb9\u9650\u3002\u6b64\u5916\uff0c\u7814\u7a76\u8005\u5c06EB-Sampler\u4f5c\u4e3a\u4e00\u4e2a\u5e7f\u6cdb\u7684\u81ea\u9002\u5e94\u91c7\u6837\u5668\u5bb6\u65cf\u7684\u4e00\u90e8\u5206\u8fdb\u884c\u516c\u5f0f\u5316\uff0c\u5e76\u63d0\u4f9b\u4e86\u9519\u8bef\u5206\u6790\u4ee5\u652f\u6301\u5176\u7b97\u6cd5\u9009\u62e9\u3002", "result": "EB-Sampler\u80fd\u591f\u5c06\u5f53\u524d\u6700\u5148\u8fdb\u7684MDMs\u7684\u91c7\u6837\u901f\u5ea6\u63d0\u9ad8\u7ea62-3\u500d\uff0c\u5728\u6807\u51c6\u7f16\u7801\u548c\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u4e0a\u4e0d\u635f\u5931\u6027\u80fd\u3002\u5e76\u4e14\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u5728\u8f83\u5c0f\u7684\u63a8\u7406\u4efb\u52a1\uff08\u5305\u62ec\u8ff7\u5bab\u5bfc\u822a\u548c\u6570\u72ec\uff09\u4e2d\u4e5f\u8868\u73b0\u826f\u597d\uff0c\u800c\u8fd9\u4e9b\u4efb\u52a1\u5f80\u5f80\u662fARMs\u96be\u4ee5\u5904\u7406\u7684\u3002", "conclusion": "EB-Sampler\u4e3aMDMs\u63d0\u4f9b\u4e86\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u91c7\u6837\u65b9\u6cd5\uff0c\u4e0d\u4ec5\u663e\u8457\u63d0\u9ad8\u4e86\u91c7\u6837\u901f\u5ea6\uff0c\u800c\u4e14\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u4fdd\u6301\u751a\u81f3\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u5176\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u548c\u5176\u4ed6\u63a8\u7406\u4efb\u52a1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.24859", "pdf": "https://arxiv.org/pdf/2505.24859", "abs": "https://arxiv.org/abs/2505.24859", "authors": ["Joschka Braun", "Carsten Eickhoff", "Seyed Ali Bahrainian"], "title": "Beyond Multiple Choice: Evaluating Steering Vectors for Adaptive Free-Form Summarization", "categories": ["cs.LG", "cs.CL"], "comment": "29 pages, 21 figures, preprint", "summary": "Steering vectors are a lightweight method for controlling text properties by\nadding a learned bias to language model activations at inference time. So far,\nsteering vectors have predominantly been evaluated in multiple-choice settings,\nwhile their effectiveness in free-form generation tasks remains understudied.\nMoving \"Beyond Multiple Choice,\" we thoroughly evaluate the effectiveness of\nsteering vectors in adaptively controlling topical focus, sentiment, toxicity,\nand readability in abstractive summaries of the NEWTS dataset. We find that\nsteering effectively controls the targeted summary properties, but high\nsteering strengths consistently degrade both intrinsic and extrinsic text\nquality. Compared to steering, prompting offers weaker control, while\npreserving text quality. Combining steering and prompting yields the strongest\ncontrol over text properties and offers the most favorable efficacy-quality\ntrade-off at moderate steering strengths. Our results underscore the practical\ntrade-off between control strength and text quality preservation when applying\nsteering vectors to free-form generation tasks.", "AI": {"tldr": "Steering vectors can control text properties in free-form generation tasks, but high steering strengths degrade text quality. Combining steering and prompting offers the best trade-off.", "motivation": "To evaluate the effectiveness of steering vectors in free-form generation tasks beyond multiple-choice settings, focusing on adaptively controlling topical focus, sentiment, toxicity, and readability in abstractive summaries.", "method": "Evaluate steering vectors' ability to control targeted summary properties in abstractive summaries of the NEWTS dataset, comparing their performance with prompting and combining both methods.", "result": "Steering vectors effectively control targeted summary properties but degrade text quality at high strengths. Prompting offers weaker control while preserving quality. Combining steering and prompting yields the strongest control with a favorable efficacy-quality trade-off.", "conclusion": "There is a practical trade-off between control strength and text quality preservation when using steering vectors for free-form generation tasks."}}
{"id": "2505.24253", "pdf": "https://arxiv.org/pdf/2505.24253", "abs": "https://arxiv.org/abs/2505.24253", "authors": ["Ishaan Rawal", "Suryansh Kumar"], "title": "Interactive Video Generation via Domain Adaptation", "categories": ["cs.CV", "cs.AI", "cs.MM"], "comment": "Preprint. Under Review", "summary": "Text-conditioned diffusion models have emerged as powerful tools for\nhigh-quality video generation. However, enabling Interactive Video Generation\n(IVG), where users control motion elements such as object trajectory, remains\nchallenging. Recent training-free approaches introduce attention masking to\nguide trajectory, but this often degrades perceptual quality. We identify two\nkey failure modes in these methods, both of which we interpret as domain shift\nproblems, and propose solutions inspired by domain adaptation. First, we\nattribute the perceptual degradation to internal covariate shift induced by\nattention masking, as pretrained models are not trained to handle masked\nattention. To address this, we propose mask normalization, a pre-normalization\nlayer designed to mitigate this shift via distribution matching. Second, we\naddress initialization gap, where the randomly sampled initial noise does not\nalign with IVG conditioning, by introducing a temporal intrinsic diffusion\nprior that enforces spatio-temporal consistency at each denoising step.\nExtensive qualitative and quantitative evaluations demonstrate that mask\nnormalization and temporal intrinsic denoising improve both perceptual quality\nand trajectory control over the existing state-of-the-art IVG techniques.", "AI": {"tldr": "Text-conditioned diffusion models are strong for video generation, but Interactive Video Generation (IVG) with good quality is hard. Recent methods using attention masking have issues. This paper identifies two problems: perceptual degradation and initialization gap, proposing mask normalization and temporal intrinsic diffusion prior to solve them. These solutions improve both quality and trajectory control.", "motivation": "To enable high-quality Interactive Video Generation where users can control motion elements without degrading the perceptual quality.", "method": "Identified two failure modes in current IVG methods as domain shift problems. Proposed mask normalization to mitigate internal covariate shift caused by attention masking and a temporal intrinsic diffusion prior to address the initialization gap.", "result": "Extensive evaluations show that the proposed mask normalization and temporal intrinsic denoising enhance both perceptual quality and trajectory control compared to existing IVG techniques.", "conclusion": "The solutions of mask normalization and temporal intrinsic diffusion prior effectively improve the perceptual quality and trajectory control in Interactive Video Generation."}}
{"id": "2505.24874", "pdf": "https://arxiv.org/pdf/2505.24874", "abs": "https://arxiv.org/abs/2505.24874", "authors": ["Adam Stein", "Aaditya Naik", "Neelay Velingker", "Mayur Naik", "Eric Wong"], "title": "The Road to Generalizable Neuro-Symbolic Learning Should be Paved with Foundation Models", "categories": ["cs.LG"], "comment": "19 pages, 11 figures", "summary": "Neuro-symbolic learning was proposed to address challenges with training\nneural networks for complex reasoning tasks with the added benefits of\ninterpretability, reliability, and efficiency. Neuro-symbolic learning methods\ntraditionally train neural models in conjunction with symbolic programs, but\nthey face significant challenges that limit them to simplistic problems. On the\nother hand, purely-neural foundation models now reach state-of-the-art\nperformance through prompting rather than training, but they are often\nunreliable and lack interpretability. Supplementing foundation models with\nsymbolic programs, which we call neuro-symbolic prompting, provides a way to\nuse these models for complex reasoning tasks. Doing so raises the question:\nWhat role does specialized model training as part of neuro-symbolic learning\nhave in the age of foundation models? To explore this question, we highlight\nthree pitfalls of traditional neuro-symbolic learning with respect to the\ncompute, data, and programs leading to generalization problems. This position\npaper argues that foundation models enable generalizable neuro-symbolic\nsolutions, offering a path towards achieving the original goals of\nneuro-symbolic learning without the downsides of training from scratch.", "AI": {"tldr": "Neuro-symbolic learning combines neural networks with symbolic programs for complex reasoning tasks. While traditional neuro-symbolic methods face challenges, foundation models offer a promising alternative through neuro-symbolic prompting.", "motivation": "To address the limitations of traditional neuro-symbolic learning and explore the potential of foundation models in achieving the goals of neuro-symbolic learning without the downsides of training from scratch.", "method": "Highlighting three pitfalls of traditional neuro-symbolic learning and arguing that foundation models enable generalizable neuro-symbolic solutions.", "result": "Foundation models can be used for complex reasoning tasks through neuro-symbolic prompting, offering a path towards achieving the original goals of neuro-symbolic learning.", "conclusion": "Foundation models provide a way to achieve the benefits of neuro-symbolic learning, such as interpretability and reliability, without the challenges associated with traditional training methods."}}
{"id": "2505.24255", "pdf": "https://arxiv.org/pdf/2505.24255", "abs": "https://arxiv.org/abs/2505.24255", "authors": ["Neemesh Yadav", "Palakorn Achananuparp", "Jing Jiang", "Ee-Peng Lim"], "title": "Effects of Theory of Mind and Prosocial Beliefs on Steering Human-Aligned Behaviors of LLMs in Ultimatum Games", "categories": ["cs.CL", "cs.AI", "cs.HC"], "comment": "17 pages, 1 figure, 6 tables", "summary": "Large Language Models (LLMs) have shown potential in simulating human\nbehaviors and performing theory-of-mind (ToM) reasoning, a crucial skill for\ncomplex social interactions. In this study, we investigate the role of ToM\nreasoning in aligning agentic behaviors with human norms in negotiation tasks,\nusing the ultimatum game as a controlled environment. We initialized LLM agents\nwith different prosocial beliefs (including Greedy, Fair, and Selfless) and\nreasoning methods like chain-of-thought (CoT) and varying ToM levels, and\nexamined their decision-making processes across diverse LLMs, including\nreasoning models like o3-mini and DeepSeek-R1 Distilled Qwen 32B. Results from\n2,700 simulations indicated that ToM reasoning enhances behavior alignment,\ndecision-making consistency, and negotiation outcomes. Consistent with previous\nfindings, reasoning models exhibit limited capability compared to models with\nToM reasoning, different roles of the game benefits with different orders of\nToM reasoning. Our findings contribute to the understanding of ToM's role in\nenhancing human-AI interaction and cooperative decision-making. The code used\nfor our experiments can be found at https://github.com/Stealth-py/UltimatumToM.", "AI": {"tldr": "The study explores how Theory-of-Mind (ToM) reasoning in Large Language Models (LLMs) can align agentic behaviors with human norms during negotiation tasks, using the ultimatum game. LLM agents with different prosocial beliefs and ToM levels were initialized and tested across various models. Results from 2,700 simulations showed that ToM reasoning improves behavior alignment, decision-making consistency, and negotiation outcomes.", "motivation": "To investigate the role of Theory-of-Mind (ToM) reasoning in aligning agentic behaviors with human norms in negotiation tasks, specifically using the ultimatum game as a controlled environment.", "method": "LLM agents were initialized with different prosocial beliefs (Greedy, Fair, Selfless) and reasoning methods (chain-of-thought). They were examined across diverse LLMs including o3-mini, DeepSeek-R1 Distilled Qwen 32B. The study used 2,700 simulations to evaluate their decision-making processes.", "result": "ToM reasoning enhances behavior alignment, decision-making consistency, and negotiation outcomes. Reasoning models without ToM reasoning show limited capabilities compared to those with it.", "conclusion": "This research contributes to understanding the role of ToM in enhancing human-AI interaction and cooperative decision-making."}}
{"id": "2411.14207", "pdf": "https://arxiv.org/pdf/2411.14207", "abs": "https://arxiv.org/abs/2411.14207", "authors": ["Shivam Saini", "J\u00fcrgen Peissig"], "title": "HARP: A Large-Scale Higher-Order Ambisonic Room Impulse Response Dataset", "categories": ["cs.SD", "cs.AI", "cs.LG", "cs.MM", "eess.AS"], "comment": "Accepted at ICASSP 2025 Workshop. Code to generate uploaded at:\n  https://github.com/whojavumusic/HARP", "summary": "This contribution introduces a dataset of 7th-order Ambisonic Room Impulse\nResponses (HOA-RIRs), created using the Image Source Method. By employing\nhigher-order Ambisonics, our dataset enables precise spatial audio\nreproduction, a critical requirement for realistic immersive audio\napplications. Leveraging the virtual simulation, we present a unique microphone\nconfiguration, based on the superposition principle, designed to optimize sound\nfield coverage while addressing the limitations of traditional microphone\narrays. The presented 64-microphone configuration allows us to capture RIRs\ndirectly in the Spherical Harmonics domain. The dataset features a wide range\nof room configurations, encompassing variations in room geometry, acoustic\nabsorption materials, and source-receiver distances. A detailed description of\nthe simulation setup is provided alongside for an accurate reproduction. The\ndataset serves as a vital resource for researchers working on spatial audio,\nparticularly in applications involving machine learning to improve room\nacoustics modeling and sound field synthesis. It further provides a very high\nlevel of spatial resolution and realism crucial for tasks such as source\nlocalization, reverberation prediction, and immersive sound reproduction.", "AI": {"tldr": "The paper introduces a 7th-order Ambisonic Room Impulse Responses (HOA-RIRs) dataset created via the Image Source Method, featuring a unique 64-microphone configuration for precise spatial audio reproduction and serving as a resource for spatial audio researchers.", "motivation": "To provide a comprehensive and high-resolution dataset for spatial audio research, overcoming limitations of traditional microphone arrays.", "method": "Using the Image Source Method to generate a dataset of 7th-order Ambisonic Room Impulse Responses with a unique 64-microphone configuration based on the superposition principle, allowing direct capture in the Spherical Harmonics domain.", "result": "A versatile dataset covering various room configurations, offering high spatial resolution and realism for tasks like source localization, reverberation prediction, and immersive sound reproduction.", "conclusion": "This dataset is an important contribution to spatial audio research, particularly beneficial for machine learning applications in room acoustics modeling and sound field synthesis."}}
{"id": "2505.24264", "pdf": "https://arxiv.org/pdf/2505.24264", "abs": "https://arxiv.org/abs/2505.24264", "authors": ["Xin Quan", "Marco Valentino", "Louise A. Dennis", "Andr\u00e9 Freitas"], "title": "Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations", "categories": ["cs.CL", "cs.AI"], "comment": "Camera-ready for ACL 2025", "summary": "Natural language explanations play a fundamental role in Natural Language\nInference (NLI) by revealing how premises logically entail hypotheses. Recent\nwork has shown that the interaction of large language models (LLMs) with\ntheorem provers (TPs) can help verify and improve the validity of NLI\nexplanations. However, TPs require translating natural language into\nmachine-verifiable formal representations, a process that introduces the risk\nof semantic information loss and unfaithful interpretation, an issue compounded\nby LLMs' challenges in capturing critical logical structures with sufficient\nprecision. Moreover, LLMs are still limited in their capacity for rigorous and\nrobust proof construction within formal verification frameworks. To mitigate\nissues related to faithfulness and robustness, this paper investigates\nstrategies to (1) alleviate semantic loss during autoformalisation, (2)\nefficiently identify and correct syntactic errors in logical representations,\n(3) explicitly use logical expressions to guide LLMs in generating structured\nproof sketches, and (4) increase LLMs' capacity of interpreting TP's feedback\nfor iterative refinement. Our empirical results on e-SNLI, QASC and WorldTree\nusing different LLMs demonstrate that the proposed strategies yield significant\nimprovements in autoformalisation (+18.46%, +34.2%, +39.77%) and explanation\nrefinement (+29.5%, +51.5%, +41.25%) over the state-of-the-art model. Moreover,\nwe show that specific interventions on the hybrid LLM-TP architecture can\nsubstantially improve efficiency, drastically reducing the number of iterations\nrequired for successful verification.", "AI": {"tldr": "\u901a\u8fc7\u7814\u7a76\u7b56\u7565\u63d0\u5347\u81ea\u7136\u8bed\u8a00\u63a8\u7406\u4e2d\u89e3\u91ca\u7684\u6709\u6548\u6027\uff0c\u5305\u62ec\u51cf\u5c11\u8bed\u4e49\u635f\u5931\u3001\u7ea0\u6b63\u8bed\u6cd5\u9519\u8bef\u3001\u5f15\u5bfc\u6a21\u578b\u751f\u6210\u8bc1\u660e\u8349\u56fe\u548c\u63d0\u9ad8\u5bf9\u53cd\u9988\u7684\u89e3\u8bfb\u80fd\u529b\u3002\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8fd9\u4e9b\u7b56\u7565\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u5347\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u548c\u89e3\u91ca\u6539\u8fdb\u7684\u6548\u679c\uff0c\u5e76\u51cf\u5c11\u4e86\u9a8c\u8bc1\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u3002", "motivation": "\u81ea\u7136\u8bed\u8a00\u89e3\u91ca\u5728\u81ea\u7136\u8bed\u8a00\u63a8\u7406\uff08NLI\uff09\u4e2d\u8d77\u7740\u5173\u952e\u4f5c\u7528\uff0c\u7136\u800c\u5f53\u524d\u65b9\u6cd5\u5728\u5c06\u81ea\u7136\u8bed\u8a00\u8f6c\u6362\u4e3a\u673a\u5668\u53ef\u9a8c\u8bc1\u7684\u5f62\u5f0f\u8868\u793a\u65f6\u5b58\u5728\u8bed\u4e49\u4fe1\u606f\u4e22\u5931\u548c\u4e0d\u51c6\u786e\u89e3\u91ca\u7684\u95ee\u9898\uff0c\u540c\u65f6\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u6355\u6349\u903b\u8f91\u7ed3\u6784\u548c\u6784\u5efa\u4e25\u8c28\u8bc1\u660e\u65b9\u9762\u4ecd\u6709\u9650\u5236\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u7b56\u7565\uff1a1) \u51cf\u5c11\u81ea\u52a8\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u635f\u5931\uff1b2) \u6709\u6548\u8bc6\u522b\u548c\u7ea0\u6b63\u903b\u8f91\u8868\u793a\u4e2d\u7684\u8bed\u6cd5\u9519\u8bef\uff1b3) \u4f7f\u7528\u903b\u8f91\u8868\u8fbe\u5f0f\u6307\u5bfcLLMs\u751f\u6210\u7ed3\u6784\u5316\u7684\u8bc1\u660e\u8349\u56fe\uff1b4) \u63d0\u9ad8LLMs\u5bf9TP\u53cd\u9988\u7684\u89e3\u8bfb\u80fd\u529b\u4ee5\u8fdb\u884c\u8fed\u4ee3\u6539\u8fdb\u3002\u6b64\u5916\uff0c\u8fd8\u7814\u7a76\u4e86\u6df7\u5408LLM-TP\u67b6\u6784\u4e2d\u7684\u7279\u5b9a\u5e72\u9884\u63aa\u65bd\u4ee5\u63d0\u9ad8\u6548\u7387\u3002", "result": "\u5728e-SNLI\u3001QASC\u548cWorldTree\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u8bc1\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u7b56\u7565\u5728\u81ea\u52a8\u5f62\u5f0f\u5316\u65b9\u9762\u5206\u522b\u63d0\u9ad8\u4e86+18.46%\u3001+34.2%\u3001+39.77%\uff0c\u5728\u89e3\u91ca\u6539\u8fdb\u65b9\u9762\u5206\u522b\u63d0\u9ad8\u4e86+29.5%\u3001+51.5%\u3001+41.25%\u3002\u6b64\u5916\uff0c\u7279\u5b9a\u5e72\u9884\u63aa\u65bd\u663e\u8457\u63d0\u9ad8\u4e86\u9a8c\u8bc1\u6548\u7387\uff0c\u5927\u5e45\u51cf\u5c11\u4e86\u6210\u529f\u9a8c\u8bc1\u6240\u9700\u7684\u8fed\u4ee3\u6b21\u6570\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684\u7b56\u7565\u6709\u6548\u5730\u7f13\u89e3\u4e86\u81ea\u52a8\u5f62\u5f0f\u5316\u8fc7\u7a0b\u4e2d\u7684\u8bed\u4e49\u635f\u5931\u95ee\u9898\uff0c\u63d0\u9ad8\u4e86LLMs\u5728\u751f\u6210\u7ed3\u6784\u5316\u8bc1\u660e\u8349\u56fe\u548c\u89e3\u8bfbTP\u53cd\u9988\u65b9\u9762\u7684\u80fd\u529b\uff0c\u4ece\u800c\u663e\u8457\u6539\u8fdb\u4e86NLI\u89e3\u91ca\u7684\u8d28\u91cf\u548c\u9a8c\u8bc1\u6548\u7387\u3002"}}
{"id": "2505.05880", "pdf": "https://arxiv.org/pdf/2505.05880", "abs": "https://arxiv.org/abs/2505.05880", "authors": ["Bettina Fazzinga", "Sergio Flesca", "Filippo Furfaro", "Luigi Pontieri", "Francesco Scala"], "title": "Combining Abstract Argumentation and Machine Learning for Efficiently Analyzing Low-Level Process Event Streams", "categories": ["cs.AI", "cs.LG"], "comment": null, "summary": "Monitoring and analyzing process traces is a critical task for modern\ncompanies and organizations. In scenarios where there is a gap between trace\nevents and reference business activities, this entails an interpretation\nproblem, amounting to translating each event of any ongoing trace into the\ncorresponding step of the activity instance. Building on a recent approach that\nframes the interpretation problem as an acceptance problem within an Abstract\nArgumentation Framework (AAF), one can elegantly analyze plausible event\ninterpretations (possibly in an aggregated form), as well as offer explanations\nfor those that conflict with prior process knowledge. Since, in settings where\nevent-to-activity mapping is highly uncertain (or simply under-specified) this\nreasoning-based approach may yield lowly-informative results and heavy\ncomputation, one can think of discovering a sequencetagging model, trained to\nsuggest highly-probable candidate event interpretations in a context-aware way.\nHowever, training such a model optimally may require using a large amount of\nmanually-annotated example traces. Considering the urgent need of developing\nGreen AI solutions enabling environmental and societal sustainability (with\nreduced labor/computational costs and carbon footprint), we propose a\ndata/computation-efficient neuro-symbolic approach to the problem, where the\ncandidate interpretations returned by the example-driven sequence tagger is\nrefined by the AAF-based reasoner. This allows us to also leverage prior\nknowledge to compensate for the scarcity of example data, as confirmed by\nexperimental results; clearly, this property is particularly useful in settings\nwhere data annotation and model optimization costs are subject to stringent\nconstraints.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e/\u8ba1\u7b97\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u793a\u4f8b\u9a71\u52a8\u7684\u5e8f\u5217\u6807\u8bb0\u5668\u548c\u57fa\u4e8eAAF\u7684\u63a8\u7406\u5668\u6765\u89e3\u51b3\u4e8b\u4ef6\u89e3\u91ca\u95ee\u9898\uff0c\u51cf\u5c11\u6570\u636e\u6807\u6ce8\u548c\u6a21\u578b\u4f18\u5316\u6210\u672c\uff0c\u540c\u65f6\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u5f25\u8865\u793a\u4f8b\u6570\u636e\u7684\u4e0d\u8db3\u3002", "motivation": "\u5728\u4e8b\u4ef6\u4e0e\u6d3b\u52a8\u6620\u5c04\u9ad8\u5ea6\u4e0d\u786e\u5b9a\u6216\u672a\u660e\u786e\u6307\u5b9a\u7684\u60c5\u51b5\u4e0b\uff0c\u73b0\u6709\u7684\u57fa\u4e8e\u63a8\u7406\u7684\u65b9\u6cd5\u53ef\u80fd\u4f1a\u4ea7\u751f\u4fe1\u606f\u91cf\u4f4e\u7684\u7ed3\u679c\u548c\u7e41\u91cd\u7684\u8ba1\u7b97\u3002\u6b64\u5916\uff0c\u8bad\u7ec3\u4e00\u4e2a\u5e8f\u5217\u6807\u8bb0\u6a21\u578b\u9700\u8981\u5927\u91cf\u624b\u52a8\u6807\u6ce8\u7684\u793a\u4f8b\u75d5\u8ff9\uff0c\u8fd9\u4e0d\u7b26\u5408\u5f00\u53d1\u7eff\u8272AI\u89e3\u51b3\u65b9\u6848\u7684\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e/\u8ba1\u7b97\u9ad8\u6548\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\uff0c\u5c06\u793a\u4f8b\u9a71\u52a8\u7684\u5e8f\u5217\u6807\u8bb0\u5668\u751f\u6210\u7684\u5019\u9009\u89e3\u91ca\u4ea4\u7ed9\u57fa\u4e8eAAF\u7684\u63a8\u7406\u5668\u8fdb\u884c\u7ec6\u5316\uff0c\u4ece\u800c\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\u5f25\u8865\u793a\u4f8b\u6570\u636e\u7684\u7a00\u7f3a\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5229\u7528\u5148\u9a8c\u77e5\u8bc6\uff0c\u5728\u6570\u636e\u6807\u6ce8\u548c\u6a21\u578b\u4f18\u5316\u6210\u672c\u53d7\u5230\u4e25\u683c\u9650\u5236\u7684\u60c5\u51b5\u4e0b\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u795e\u7ecf\u7b26\u53f7\u65b9\u6cd5\u4e3a\u4e8b\u4ef6\u89e3\u91ca\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u4e2a\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u51cf\u5c11\u52b3\u52a8/\u8ba1\u7b97\u6210\u672c\u548c\u78b3\u8db3\u8ff9\u7684\u540c\u65f6\uff0c\u5e94\u5bf9\u6570\u636e\u7a00\u7f3a\u6027\u7684\u6311\u6218\u3002"}}
{"id": "2505.24269", "pdf": "https://arxiv.org/pdf/2505.24269", "abs": "https://arxiv.org/abs/2505.24269", "authors": ["Aleksandr Algazinov", "Joydeep Chandra", "Matt Laing"], "title": "INSIGHT: A Survey of In-Network Systems for Intelligent, High-Efficiency AI and Topology Optimization", "categories": ["cs.NI", "cs.AI"], "comment": null, "summary": "In-network computation represents a transformative approach to addressing the\nescalating demands of Artificial Intelligence (AI) workloads on network\ninfrastructure. By leveraging the processing capabilities of network devices\nsuch as switches, routers, and Network Interface Cards (NICs), this paradigm\nenables AI computations to be performed directly within the network fabric,\nsignificantly reducing latency, enhancing throughput, and optimizing resource\nutilization. This paper provides a comprehensive analysis of optimizing\nin-network computation for AI, exploring the evolution of programmable network\narchitectures, such as Software-Defined Networking (SDN) and Programmable Data\nPlanes (PDPs), and their convergence with AI. It examines methodologies for\nmapping AI models onto resource-constrained network devices, addressing\nchallenges like limited memory and computational capabilities through efficient\nalgorithm design and model compression techniques. The paper also highlights\nadvancements in distributed learning, particularly in-network aggregation, and\nthe potential of federated learning to enhance privacy and scalability.\nFrameworks like Planter and Quark are discussed for simplifying development,\nalongside key applications such as intelligent network monitoring, intrusion\ndetection, traffic management, and Edge AI. Future research directions,\nincluding runtime programmability, standardized benchmarks, and new\napplications paradigms, are proposed to advance this rapidly evolving field.\nThis survey underscores the potential of in-network AI to create intelligent,\nefficient, and responsive networks capable of meeting the demands of\nnext-generation AI applications.", "AI": {"tldr": "In-network computation can significantly improve AI workloads by reducing latency, enhancing throughput and optimizing resource utilization. This paper analyzes the optimization of in-network computation for AI, including programmable network architectures, mapping AI models onto network devices, distributed learning, and future research directions.", "motivation": "The escalating demands of AI workloads on network infrastructure necessitate a transformative approach to processing data within the network itself, rather than relying solely on traditional computing resources.", "method": "Exploration of programmable network architectures (SDN, PDPs), methodologies for mapping AI models onto network devices, advancements in distributed learning (in-network aggregation, federated learning), frameworks (Planter, Quark) for development simplification, and key applications (intelligent network monitoring, intrusion detection, traffic management, Edge AI).", "result": "Reduced latency, enhanced throughput, optimized resource utilization, and potential for intelligent, efficient, and responsive networks capable of meeting next-generation AI application demands.", "conclusion": "In-network AI holds significant potential to revolutionize network infrastructure, creating more intelligent, efficient, and responsive systems for handling AI workloads."}}
{"id": "2505.24291", "pdf": "https://arxiv.org/pdf/2505.24291", "abs": "https://arxiv.org/abs/2505.24291", "authors": ["Kaidi Wang", "Wenhao Guan", "Ziyue Jiang", "Hukai Huang", "Peijie Chen", "Weijie Wu", "Qingyang Hong", "Lin Li"], "title": "Discl-VC: Disentangled Discrete Tokens and In-Context Learning for Controllable Zero-Shot Voice Conversion", "categories": ["cs.SD", "cs.AI", "eess.AS"], "comment": null, "summary": "Currently, zero-shot voice conversion systems are capable of synthesizing the\nvoice of unseen speakers. However, most existing approaches struggle to\naccurately replicate the speaking style of the source speaker or mimic the\ndistinctive speaking style of the target speaker, thereby limiting the\ncontrollability of voice conversion. In this work, we propose Discl-VC, a novel\nvoice conversion framework that disentangles content and prosody information\nfrom self-supervised speech representations and synthesizes the target\nspeaker's voice through in-context learning with a flow matching transformer.\nTo enable precise control over the prosody of generated speech, we introduce a\nmask generative transformer that predicts discrete prosody tokens in a\nnon-autoregressive manner based on prompts. Experimental results demonstrate\nthe superior performance of Discl-VC in zero-shot voice conversion and its\nremarkable accuracy in prosody control for synthesized speech.", "AI": {"tldr": "Discl-VC is a new voice conversion framework that separates content and prosody info, enabling better control over speaking styles in zero-shot scenarios.", "motivation": "Current zero-shot voice conversion systems have trouble accurately replicating speaking styles, limiting controllability.", "method": "Propose Discl-VC which disentangles content and prosody from self-supervised speech representations using in-context learning with a flow matching transformer. Also introduce a mask generative transformer for non-autoregressive prediction of discrete prosody tokens based on prompts.", "result": "Experimental results show superior performance in zero-shot voice conversion and remarkable accuracy in prosody control.", "conclusion": "Discl-VC offers significant improvements in both voice conversion quality and prosody control."}}
{"id": "2505.23774", "pdf": "https://arxiv.org/pdf/2505.23774", "abs": "https://arxiv.org/abs/2505.23774", "authors": ["Zeki Doruk Erden", "Boi Faltings"], "title": "On the Parallels Between Evolutionary Theory and the State of AI", "categories": ["q-bio.NC", "cs.LG", "cs.NE", "nlin.AO"], "comment": "Published at the Evolving Self-Organization Workshop in GECCO 2025", "summary": "This article critically examines the foundational principles of contemporary\nAI methods, exploring the limitations that hinder its potential. We draw\nparallels between the modern AI landscape and the 20th-century Modern Synthesis\nin evolutionary biology, and highlight how advancements in evolutionary theory\nthat augmented the Modern Synthesis, particularly those of Evolutionary\nDevelopmental Biology, offer insights that can inform a new design paradigm for\nAI. By synthesizing findings across AI and evolutionary theory, we propose a\npathway to overcome existing limitations, enabling AI to achieve its\naspirational goals.", "AI": {"tldr": "The paper draws parallels between AI and evolutionary biology, proposing a new design paradigm for AI inspired by advancements in evolutionary theory.", "motivation": "To critically examine the foundational principles of contemporary AI methods and explore their limitations while seeking insights from evolutionary biology to inform a new design paradigm for AI.", "method": "Drawing parallels between the modern AI landscape and the 20th-century Modern Synthesis in evolutionary biology, and highlighting how advancements in evolutionary theory offer insights that can inform a new design paradigm for AI.", "result": "A pathway is proposed to overcome existing limitations in AI, enabling it to achieve its aspirational goals by synthesizing findings across AI and evolutionary theory.", "conclusion": "Advancements in evolutionary theory, particularly those of Evolutionary Developmental Biology, can offer insights that inform a new design paradigm for AI."}}
{"id": "2505.23781", "pdf": "https://arxiv.org/pdf/2505.23781", "abs": "https://arxiv.org/abs/2505.23781", "authors": ["Hamideh Khaleghpour", "Brett McKinney"], "title": "Unified AI for Accurate Audio Anomaly Detection", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "6 pages, 14 figures. Based on original research. Submitted to arXiv\n  for public preprint", "summary": "This paper presents a unified AI framework for high-accuracy audio anomaly\ndetection by integrating advanced noise reduction, feature extraction, and\nmachine learning modeling techniques. The approach combines spectral\nsubtraction and adaptive filtering to enhance audio quality, followed by\nfeature extraction using traditional methods like MFCCs and deep embeddings\nfrom pre-trained models such as OpenL3. The modeling pipeline incorporates\nclassical models (SVM, Random Forest), deep learning architectures (CNNs), and\nensemble methods to boost robustness and accuracy. Evaluated on benchmark\ndatasets including TORGO and LibriSpeech, the proposed framework demonstrates\nsuperior performance in precision, recall, and classification of slurred vs.\nnormal speech. This work addresses challenges in noisy environments and\nreal-time applications and provides a scalable solution for audio-based anomaly\ndetection.", "AI": {"tldr": "The paper proposes a unified AI framework for high-accuracy audio anomaly detection using noise reduction, feature extraction, and machine learning techniques.", "motivation": "To address challenges in noisy environments and real-time applications for audio-based anomaly detection.", "method": "Combining spectral subtraction and adaptive filtering for noise reduction, traditional methods (MFCCs) and deep embeddings (OpenL3) for feature extraction, and classical models (SVM, Random Forest), deep learning architectures (CNNs), and ensemble methods for modeling.", "result": "Superior performance in precision, recall, and classification of slurred vs. normal speech on benchmark datasets like TORGO and LibriSpeech.", "conclusion": "This work provides a scalable solution for audio-based anomaly detection."}}
{"id": "2505.24336", "pdf": "https://arxiv.org/pdf/2505.24336", "abs": "https://arxiv.org/abs/2505.24336", "authors": ["Minsu Kang", "Seolhee Lee", "Choonghyeon Lee", "Namhyun Cho"], "title": "When Humans Growl and Birds Speak: High-Fidelity Voice Conversion from Human to Animal and Designed Sounds", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD", "eess.SP"], "comment": "INTERSPEECH 2025 accepted", "summary": "Human to non-human voice conversion (H2NH-VC) transforms human speech into\nanimal or designed vocalizations. Unlike prior studies focused on dog-sounds\nand 16 or 22.05kHz audio transformation, this work addresses a broader range of\nnon-speech sounds, including natural sounds (lion-roars, birdsongs) and\ndesigned voice (synthetic growls). To accomodate generation of diverse\nnon-speech sounds and 44.1kHz high-quality audio transformation, we introduce a\npreprocessing pipeline and an improved CVAE-based H2NH-VC model, both optimized\nfor human and non-human voices. Experimental results showed that the proposed\nmethod outperformed baselines in quality, naturalness, and similarity MOS,\nachieving effective voice conversion across diverse non-human timbres. Demo\nsamples are available at\nhttps://nc-ai.github.io/speech/publications/nonhuman-vc/", "AI": {"tldr": "This paper introduces a preprocessing pipeline and an improved CVAE-based H2NH-VC model for transforming human speech into a broader range of non-speech sounds, including natural sounds and designed voice, with high-quality audio transformation at 44.1kHz.", "motivation": "To address the limitations of prior studies that focused on dog-sounds and lower quality audio transformation, and to accommodate generation of diverse non-speech sounds and high-quality audio transformation.", "method": "Introduced a preprocessing pipeline and an improved CVAE-based H2NH-VC model optimized for both human and non-human voices.", "result": "The proposed method outperformed baselines in quality, naturalness, and similarity MOS, achieving effective voice conversion across diverse non-human timbres.", "conclusion": "The introduced preprocessing pipeline and improved CVAE-based H2NH-VC model successfully transform human speech into a broader range of non-speech sounds with high-quality audio."}}
{"id": "2505.23784", "pdf": "https://arxiv.org/pdf/2505.23784", "abs": "https://arxiv.org/abs/2505.23784", "authors": ["Shayan Dadman", "Bernt Arild Bremdal", "B\u00f8rre Bang", "Rune Dalmo"], "title": "Learning Normal Patterns in Musical Loops", "categories": ["cs.SD", "cs.IR", "cs.LG", "cs.MM", "eess.AS"], "comment": "27 pages, 10 figures", "summary": "This paper introduces an unsupervised framework for detecting audio patterns\nin musical samples (loops) through anomaly detection techniques, addressing\nchallenges in music information retrieval (MIR). Existing methods are often\nconstrained by reliance on handcrafted features, domain-specific limitations,\nor dependence on iterative user interaction. We address these limitations\nthrough an architecture combining deep feature extraction with unsupervised\nanomaly detection. Our approach leverages a pre-trained Hierarchical\nToken-semantic Audio Transformer (HTS-AT), paired with a Feature Fusion\nMechanism (FFM), to generate representations from variable-length audio loops.\nThese embeddings are processed using one-class Deep Support Vector Data\nDescription (Deep SVDD), which learns normative audio patterns by mapping them\nto a compact latent hypersphere. Evaluations on curated bass and guitar\ndatasets compare standard and residual autoencoder variants against baselines\nlike Isolation Forest (IF) and and principle component analysis (PCA) methods.\nResults show our Deep SVDD models, especially the residual autoencoder variant,\ndeliver improved anomaly separation, particularly for larger variations. This\nresearch contributes a flexible, fully unsupervised solution for processing\ndiverse audio samples, overcoming previous structural and input limitations\nwhile enabling effective pattern identification through distance-based latent\nspace scoring.", "AI": {"tldr": "This paper presents an unsupervised framework using deep feature extraction and anomaly detection for identifying audio patterns in music samples, showing improved performance over traditional methods.", "motivation": "To overcome the limitations of existing music information retrieval methods that rely on handcrafted features, have domain-specific constraints, or require iterative user interaction.", "method": "The method uses a pre-trained Hierarchical Token-semantic Audio Transformer (HTS-AT) with a Feature Fusion Mechanism (FFM) to generate audio loop representations. These are processed by one-class Deep Support Vector Data Description (Deep SVDD) to detect anomalies through mapping normative patterns to a compact latent hypersphere.", "result": "The Deep SVDD models, particularly the residual autoencoder variant, demonstrate enhanced anomaly separation compared to standard methods like Isolation Forest and PCA, especially for larger variations.", "conclusion": "This research offers a fully unsupervised, flexible solution for effective pattern identification in diverse audio samples, overcoming previous structural and input limitations."}}
{"id": "2505.24341", "pdf": "https://arxiv.org/pdf/2505.24341", "abs": "https://arxiv.org/abs/2505.24341", "authors": ["Shujian Yang", "Shiyao Cui", "Chuanrui Hu", "Haicheng Wang", "Tianwei Zhang", "Minlie Huang", "Jialiang Lu", "Han Qiu"], "title": "Exploring Multimodal Challenges in Toxic Chinese Detection: Taxonomy, Benchmark, and Findings", "categories": ["cs.CL", "cs.AI", "cs.CY"], "comment": "Accepted to ACL 2025 (Findings). Camera-ready version", "summary": "Detecting toxic content using language models is important but challenging.\nWhile large language models (LLMs) have demonstrated strong performance in\nunderstanding Chinese, recent studies show that simple character substitutions\nin toxic Chinese text can easily confuse the state-of-the-art (SOTA) LLMs. In\nthis paper, we highlight the multimodal nature of Chinese language as a key\nchallenge for deploying LLMs in toxic Chinese detection. First, we propose a\ntaxonomy of 3 perturbation strategies and 8 specific approaches in toxic\nChinese content. Then, we curate a dataset based on this taxonomy, and\nbenchmark 9 SOTA LLMs (from both the US and China) to assess if they can detect\nperturbed toxic Chinese text. Additionally, we explore cost-effective\nenhancement solutions like in-context learning (ICL) and supervised fine-tuning\n(SFT). Our results reveal two important findings. (1) LLMs are less capable of\ndetecting perturbed multimodal Chinese toxic contents. (2) ICL or SFT with a\nsmall number of perturbed examples may cause the LLMs \"overcorrect'':\nmisidentify many normal Chinese contents as toxic.", "AI": {"tldr": "Detecting toxic Chinese content via LLMs is challenging due to multimodal nature and character perturbations. A taxonomy of 3 strategies/8 approaches, a curated dataset, and benchmarking of 9 SOTA LLMs reveal that these models struggle with perturbed toxic content and may 'overcorrect' when using ICL or SFT.", "motivation": "Toxic content detection in Chinese language poses unique challenges for LLMs due to the multimodal characteristics of Chinese and the ease with which simple character substitutions can confuse models.", "method": "Proposed a taxonomy of perturbation strategies/approaches for toxic Chinese content; curated a dataset based on this taxonomy; benchmarked 9 SOTA LLMs for detecting perturbed toxic Chinese text; explored enhancement solutions like ICL and SFT.", "result": "LLMs show weakness in detecting perturbed multimodal Chinese toxic contents. Enhancement methods such as ICL or SFT with few perturbed examples can cause 'overcorrection', misidentifying normal contents as toxic.", "conclusion": "Detection of perturbed toxic Chinese content by LLMs needs improvement. Caution should be exercised with ICL and SFT approaches to avoid overcorrection."}}
{"id": "2505.23789", "pdf": "https://arxiv.org/pdf/2505.23789", "abs": "https://arxiv.org/abs/2505.23789", "authors": ["Mingyu Huang", "Shasha Zhou", "Yuxuan Chen", "Ke Li"], "title": "Conversational Exploration of Literature Landscape with LitChat", "categories": ["cs.CL", "cs.IR", "cs.LG"], "comment": null, "summary": "We are living in an era of \"big literature\", where the volume of digital\nscientific publications is growing exponentially. While offering new\nopportunities, this also poses challenges for understanding literature\nlandscapes, as traditional manual reviewing is no longer feasible. Recent large\nlanguage models (LLMs) have shown strong capabilities for literature\ncomprehension, yet they are incapable of offering \"comprehensive, objective,\nopen and transparent\" views desired by systematic reviews due to their limited\ncontext windows and trust issues like hallucinations. Here we present LitChat,\nan end-to-end, interactive and conversational literature agent that augments\nLLM agents with data-driven discovery tools to facilitate literature\nexploration. LitChat automatically interprets user queries, retrieves relevant\nsources, constructs knowledge graphs, and employs diverse data-mining\ntechniques to generate evidence-based insights addressing user needs. We\nillustrate the effectiveness of LitChat via a case study on AI4Health,\nhighlighting its capacity to quickly navigate the users through large-scale\nliterature landscape with data-based evidence that is otherwise infeasible with\ntraditional means.", "AI": {"tldr": "In the era of 'big literature', where digital scientific publications are exponentially increasing, traditional manual reviewing is no longer feasible. Recent LLMs have shown strong capabilities for literature comprehension but cannot offer systematic reviews due to limited context windows and trust issues. This paper presents LitChat, an interactive literature agent that augments LLM agents with data-driven discovery tools, automatically interprets user queries, retrieves relevant sources, constructs knowledge graphs, and employs diverse data-mining techniques. A case study on AI4Health illustrates its effectiveness.", "motivation": "To address the challenges posed by the exponential growth in digital scientific publications and the limitations of current LLMs in providing comprehensive, objective, open, and transparent views desired by systematic reviews.", "method": "LitChat is an end-to-end, interactive, and conversational literature agent that augments LLM agents with data-driven discovery tools. It automatically interprets user queries, retrieves relevant sources, constructs knowledge graphs, and employs diverse data-mining techniques to generate evidence-based insights addressing user needs.", "result": "A case study on AI4Health demonstrates the effectiveness of LitChat in quickly navigating users through a large-scale literature landscape with data-based evidence, which would be infeasible with traditional means.", "conclusion": "LitChat offers a novel solution to navigate through the vast landscape of scientific literature by combining the strengths of LLMs with data-driven discovery tools, enabling more efficient and insightful literature exploration."}}
{"id": "2505.24371", "pdf": "https://arxiv.org/pdf/2505.24371", "abs": "https://arxiv.org/abs/2505.24371", "authors": ["Md Intisar Chowdhury", "Kittinun Aukkapinyo", "Hiroshi Fujimura", "Joo Ann Woo", "Wasu Wasusatein", "Fadoua Ghourabi"], "title": "Grid-LOGAT: Grid Based Local and Global Area Transcription for Video Question Answering", "categories": ["cs.CV", "cs.AI"], "comment": "\\c{opyright} 2025 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "summary": "In this paper, we propose a Grid-based Local and Global Area Transcription\n(Grid-LoGAT) system for Video Question Answering (VideoQA). The system operates\nin two phases. First, extracting text transcripts from video frames using a\nVision-Language Model (VLM). Next, processing questions using these transcripts\nto generate answers through a Large Language Model (LLM). This design ensures\nimage privacy by deploying the VLM on edge devices and the LLM in the cloud. To\nimprove transcript quality, we propose grid-based visual prompting, which\nextracts intricate local details from each grid cell and integrates them with\nglobal information. Evaluation results show that Grid-LoGAT, using the\nopen-source VLM (LLaVA-1.6-7B) and LLM (Llama-3.1-8B), outperforms\nstate-of-the-art methods with similar baseline models on NExT-QA and STAR-QA\ndatasets with an accuracy of 65.9% and 50.11% respectively. Additionally, our\nmethod surpasses the non-grid version by 24 points on localization-based\nquestions we created using NExT-QA.", "AI": {"tldr": "The paper presents Grid-LoGAT, a VideoQA system using grid-based visual prompting to extract local and global details from video frames with VLM on edge devices for privacy, and answers questions via LLM in the cloud. It outperforms state-of-the-art methods on NExT-QA and STAR-QA datasets.", "motivation": "To create a VideoQA system that ensures image privacy while improving transcript quality by extracting intricate local details from video frames and integrating them with global information.", "method": "Grid-LoGAT operates in two phases: extracting text transcripts from video frames using VLM and processing questions using these transcripts through LLM. Grid-based visual prompting is used to improve transcript quality.", "result": "Grid-LoGAT outperforms state-of-the-art methods with similar baseline models on NExT-QA (65.9%) and STAR-QA (50.11%) datasets. It surpasses the non-grid version by 24 points on localization-based questions created using NExT-QA.", "conclusion": "Grid-LoGAT effectively ensures image privacy and improves transcript quality for VideoQA tasks."}}
{"id": "2505.24380", "pdf": "https://arxiv.org/pdf/2505.24380", "abs": "https://arxiv.org/abs/2505.24380", "authors": ["Zheng Wang"], "title": "SASP: Strip-Aware Spatial Perception for Fine-Grained Bird Image Classification", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Fine-grained bird image classification (FBIC) is not only of great\nsignificance for ecological monitoring and species identification, but also\nholds broad research value in the fields of image recognition and fine-grained\nvisual modeling. Compared with general image classification tasks, FBIC poses\nmore formidable challenges: 1) the differences in species size and imaging\ndistance result in the varying sizes of birds presented in the images; 2)\ncomplex natural habitats often introduce strong background interference; 3) and\nhighly flexible poses such as flying, perching, or foraging result in\nsubstantial intra-class variability. These factors collectively make it\ndifficult for traditional methods to stably extract discriminative features,\nthereby limiting the generalizability and interpretability of models in\nreal-world applications. To address these challenges, this paper proposes a\nfine-grained bird classification framework based on strip-aware spatial\nperception, which aims to capture long-range spatial dependencies across entire\nrows or columns in bird images, thereby enhancing the model's robustness and\ninterpretability. The proposed method incorporates two novel modules:\nextensional perception aggregator (EPA) and channel semantic weaving (CSW).\nSpecifically, EPA integrates local texture details with global structural cues\nby aggregating information across horizontal and vertical spatial directions.\nCSW further refines the semantic representations by adaptively fusing\nlong-range and short-range information along the channel dimension. Built upon\na ResNet-50 backbone, the model enables jump-wise connection of extended\nstructural features across the spatial domain. Experimental results on the\nCUB-200-2011 dataset demonstrate that our framework achieves significant\nperformance improvements while maintaining architectural efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u5e26\u611f\u77e5\u7a7a\u95f4\u7684\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u56fe\u50cf\u5206\u7c7b\u6846\u67b6\uff0c\u5305\u542bEPA\u548cCSW\u4e24\u4e2a\u6a21\u5757\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u6846\u67b6\u6027\u80fd\u663e\u8457\u63d0\u5347\u4e14\u67b6\u6784\u9ad8\u6548\u3002", "motivation": "\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u56fe\u50cf\u5206\u7c7b\u5bf9\u4e8e\u751f\u6001\u76d1\u6d4b\u548c\u7269\u79cd\u8bc6\u522b\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u5e76\u5728\u56fe\u50cf\u8bc6\u522b\u548c\u7ec6\u7c92\u5ea6\u89c6\u89c9\u5efa\u6a21\u9886\u57df\u5177\u6709\u5e7f\u6cdb\u7814\u7a76\u4ef7\u503c\u3002\u7136\u800c\uff0c\u4e0e\u4e00\u822c\u56fe\u50cf\u5206\u7c7b\u4efb\u52a1\u76f8\u6bd4\uff0cFBIC\u9762\u4e34\u66f4\u591a\u6311\u6218\uff0c\u5982\u9e1f\u7c7b\u5927\u5c0f\u53d8\u5316\u3001\u80cc\u666f\u5e72\u6270\u4ee5\u53ca\u59ff\u6001\u591a\u6837\u6027\u7b49\u95ee\u9898\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86\u4f20\u7edf\u65b9\u6cd5\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6cdb\u5316\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u5e26\u611f\u77e5\u7a7a\u95f4\u7684\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u5206\u7c7b\u6846\u67b6\uff0c\u5176\u4e2d\u5305\u542b\u6269\u5c55\u611f\u77e5\u805a\u5408\u5668\uff08EPA\uff09\u548c\u901a\u9053\u8bed\u4e49\u7f16\u7ec7\uff08CSW\uff09\u4e24\u4e2a\u6a21\u5757\u3002EPA\u901a\u8fc7\u6574\u5408\u6c34\u5e73\u548c\u5782\u76f4\u7a7a\u95f4\u65b9\u5411\u7684\u4fe1\u606f\u6765\u878d\u5408\u5c40\u90e8\u7eb9\u7406\u7ec6\u8282\u4e0e\u5168\u5c40\u7ed3\u6784\u63d0\u793a\uff1bCSW\u5219\u901a\u8fc7\u6cbf\u901a\u9053\u7ef4\u5ea6\u81ea\u9002\u5e94\u878d\u5408\u957f\u8ddd\u79bb\u548c\u77ed\u8ddd\u79bb\u4fe1\u606f\u8fdb\u4e00\u6b65\u7ec6\u5316\u8bed\u4e49\u8868\u793a\u3002\u6a21\u578b\u5efa\u7acb\u5728ResNet-50\u4e3b\u5e72\u7f51\u7edc\u4e4b\u4e0a\uff0c\u652f\u6301\u8de8\u7a7a\u95f4\u57df\u6269\u5c55\u7ed3\u6784\u7279\u5f81\u7684\u8df3\u8dc3\u8fde\u63a5\u3002", "result": "\u5728CUB-200-2011\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u6846\u67b6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u6539\u8fdb\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u67b6\u6784\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u57fa\u4e8e\u6761\u5e26\u611f\u77e5\u7a7a\u95f4\u7684\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u5206\u7c7b\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u7ec6\u7c92\u5ea6\u9e1f\u7c7b\u56fe\u50cf\u5206\u7c7b\u4e2d\u7684\u6311\u6218\uff0c\u63d0\u9ad8\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u9ad8\u6548\u7684\u67b6\u6784\u8bbe\u8ba1\u3002"}}
{"id": "2505.24409", "pdf": "https://arxiv.org/pdf/2505.24409", "abs": "https://arxiv.org/abs/2505.24409", "authors": ["Eojin Kang", "Juae Kim"], "title": "LLMs Are Globally Multilingual Yet Locally Monolingual: Exploring Knowledge Transfer via Language and Thought Theory", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Multilingual large language models (LLMs) open up new possibilities for\nleveraging information across languages, but their factual knowledge recall\nremains inconsistent depending on the input language. While previous studies\nhave attempted to address this issue through English-based prompting and\nevaluation, we explore non-English to English transfer via Language and Thought\nTheory. This perspective allows us to examine language-thought binding in LLMs\nand uncover why factual knowledge often fails to transfer effectively. We\npropose the Language-to-Thought (L2T) prompting strategy, which analyzes the\nrelationship between input language, internal cognitive processes, and\nknowledge. Experimental results challenge the assumption that English-based\napproaches consistently outperform other languages and offer a novel insight\nthat aligning the model's internal thought with the knowledge required for the\ntask is critical for successful cross-lingual transfer. Furthermore, we show\nthat applying L2T during training can alleviate LLMs' reliance on the input\nlanguage and facilitate cross-linguistic knowledge integration without\ntranslation-based learning. Code and datasets will be available.", "AI": {"tldr": "Multilingual LLMs have inconsistent factual knowledge recall depending on the input language. This paper explores non-English to English transfer via Language and Thought Theory, proposes the Language-to-Thought (L2T) prompting strategy, and shows that applying L2T during training can facilitate cross-linguistic knowledge integration without translation-based learning.", "motivation": "To address the inconsistency of factual knowledge recall in multilingual LLMs based on the input language and explore non-English to English transfer via Language and Thought Theory.", "method": "Propose the Language-to-Thought (L2T) prompting strategy which analyzes the relationship between input language, internal cognitive processes, and knowledge. Apply L2T during training to alleviate LLMs' reliance on the input language.", "result": "Experimental results challenge the assumption that English-based approaches consistently outperform other languages and show that aligning the model's internal thought with the knowledge required for the task is critical for successful cross-lingual transfer.", "conclusion": "Applying L2T during training can alleviate LLMs' reliance on the input language and facilitate cross-linguistic knowledge integration without translation-based learning."}}
{"id": "2505.24429", "pdf": "https://arxiv.org/pdf/2505.24429", "abs": "https://arxiv.org/abs/2505.24429", "authors": ["Giovanny C-Londo\u00f1o", "Javier S\u00e1nchez", "\u00c1ngel Rodr\u00edguez-Santana"], "title": "Deep Learning Weather Models for Subregional Ocean Forecasting: A Case Study on the Canary Current Upwelling System", "categories": ["physics.ao-ph", "cs.AI", "cs.LG"], "comment": "28 pages, 8 figures", "summary": "Oceanographic forecasting impacts various sectors of society by supporting\nenvironmental conservation and economic activities. Based on global circulation\nmodels, traditional forecasting methods are computationally expensive and slow,\nlimiting their ability to provide rapid forecasts. Recent advances in deep\nlearning offer faster and more accurate predictions, although these data-driven\nmodels are often trained with global data from numerical simulations, which may\nnot reflect reality. The emergence of such models presents great potential for\nimproving ocean prediction at a subregional domain. However, their ability to\npredict fine-scale ocean processes, like mesoscale structures, remains largely\nunknown. This work aims to adapt a graph neural network initially developed for\nglobal weather forecasting to improve subregional ocean prediction,\nspecifically focusing on the Canary Current upwelling system. The model is\ntrained with satellite data and compared to state-of-the-art physical ocean\nmodels to assess its performance in capturing ocean dynamics. Our results show\nthat the deep learning model surpasses traditional methods in precision despite\nsome challenges in upwelling areas. It demonstrated superior performance in\nreducing RMSE errors compared to ConvLSTM and the GLORYS reanalysis,\nparticularly in regions with complex oceanic dynamics such as Cape Ghir, Cape\nBojador, and Cape Blanc. The model achieved improvements of up to 26.5%\nrelative to ConvLSTM and error reductions of up to 76% in 5-day forecasts\ncompared to the GLORYS reanalysis at these critical locations, highlighting its\nenhanced capability to capture spatial variability and improve predictive\naccuracy in complex areas. These findings suggest the viability of adapting\nmeteorological data-driven models for improving subregional medium-term ocean\nforecasting.", "AI": {"tldr": "\u901a\u8fc7\u9002\u5e94\u6700\u521d\u4e3a\u5168\u7403\u5929\u6c14\u9884\u62a5\u5f00\u53d1\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u672c\u7814\u7a76\u63d0\u9ad8\u4e86\u6b21\u533a\u57df\u6d77\u6d0b\u9884\u6d4b\u7684\u51c6\u786e\u6027\uff0c\u7279\u522b\u662f\u5728\u52a0\u90a3\u5229\u6d0b\u6d41\u6d8c\u5347\u7cfb\u7edf\u4e2d\u3002\u5c3d\u7ba1\u5728\u6d8c\u5347\u533a\u5b58\u5728\u4e00\u4e9b\u6311\u6218\uff0c\u4f46\u8be5\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u964d\u4f4eRMSE\u8bef\u5dee\u65b9\u9762\u4f18\u4e8eConvLSTM\u548cGLORYS\u518d\u5206\u6790\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6d77\u6d0b\u52a8\u529b\u5b66\u533a\u57df\uff08\u5982Ghir\u6d77\u89d2\u3001Bojador\u6d77\u89d2\u548cBlanc\u6d77\u89d2\uff09\u3002\u8be5\u6a21\u578b\u57285\u5929\u9884\u6d4b\u4e2d\u5b9e\u73b0\u4e86\u9ad8\u8fbe26.5%\u7684\u6539\u8fdb\u548c\u9ad8\u8fbe76%\u7684\u8bef\u5dee\u51cf\u5c11\uff0c\u8bc1\u660e\u4e86\u5c06\u6c14\u8c61\u6570\u636e\u9a71\u52a8\u6a21\u578b\u7528\u4e8e\u6539\u8fdb\u6b21\u533a\u57df\u4e2d\u671f\u6d77\u6d0b\u9884\u62a5\u7684\u53ef\u884c\u6027\u3002", "motivation": "\u4f20\u7edf\u7684\u57fa\u4e8e\u5168\u7403\u5faa\u73af\u6a21\u578b\u7684\u6d77\u6d0b\u9884\u6d4b\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\uff0c\u9650\u5236\u4e86\u5feb\u901f\u9884\u6d4b\u7684\u80fd\u529b\u3002\u867d\u7136\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u4e86\u66f4\u5feb\u3001\u66f4\u51c6\u786e\u7684\u9884\u6d4b\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u9a71\u52a8\u6a21\u578b\u901a\u5e38\u4f7f\u7528\u6765\u81ea\u6570\u503c\u6a21\u62df\u7684\u5168\u7403\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u53ef\u80fd\u65e0\u6cd5\u53cd\u6620\u73b0\u5b9e\u3002\u6b64\u5916\uff0c\u5b83\u4eec\u5bf9\u7ec6\u5c3a\u5ea6\u6d77\u6d0b\u8fc7\u7a0b\uff08\u5982\u4e2d\u5c3a\u5ea6\u7ed3\u6784\uff09\u7684\u9884\u6d4b\u80fd\u529b\u5c1a\u4e0d\u6e05\u695a\u3002\u56e0\u6b64\uff0c\u6709\u5fc5\u8981\u63a2\u7d22\u5e76\u6539\u8fdb\u9002\u7528\u4e8e\u6b21\u533a\u57df\u6d77\u6d0b\u9884\u6d4b\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3002", "method": "\u672c\u7814\u7a76\u91c7\u7528\u4e86\u4e00\u79cd\u6700\u521d\u4e3a\u5168\u7403\u5929\u6c14\u9884\u62a5\u5f00\u53d1\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u6b21\u533a\u57df\u6d77\u6d0b\u9884\u6d4b\uff0c\u7279\u522b\u662f\u52a0\u90a3\u5229\u6d0b\u6d41\u6d8c\u5347\u7cfb\u7edf\u3002\u6a21\u578b\u4f7f\u7528\u536b\u661f\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\uff0c\u5e76\u4e0e\u6700\u5148\u8fdb\u7684\u7269\u7406\u6d77\u6d0b\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\uff0c\u4ee5\u8bc4\u4f30\u5176\u6355\u6349\u6d77\u6d0b\u52a8\u529b\u5b66\u7684\u80fd\u529b\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5728\u7cbe\u5ea6\u4e0a\u8d85\u8fc7\u4e86\u4f20\u7edf\u65b9\u6cd5\uff0c\u5c3d\u7ba1\u5728\u6d8c\u5347\u533a\u5b58\u5728\u4e00\u4e9b\u6311\u6218\u3002\u8be5\u6a21\u578b\u5728\u964d\u4f4e\u5747\u65b9\u6839\u8bef\u5dee\uff08RMSE\uff09\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u7279\u522b\u662f\u5728\u590d\u6742\u6d77\u6d0b\u52a8\u529b\u5b66\u533a\u57df\uff08\u5982Ghir\u6d77\u89d2\u3001Bojador\u6d77\u89d2\u548cBlanc\u6d77\u89d2\uff09\uff0c\u76f8\u5bf9ConvLSTM\u7684\u6539\u8fdb\u9ad8\u8fbe26.5%\uff0c\u76f8\u5bf9\u4e8eGLORYS\u518d\u5206\u6790\u7684\u8bef\u5dee\u51cf\u5c11\u9ad8\u8fbe76%\uff085\u5929\u9884\u6d4b\uff09\u3002", "conclusion": "\u672c\u7814\u7a76\u8bc1\u660e\u4e86\u9002\u5e94\u6c14\u8c61\u6570\u636e\u9a71\u52a8\u6a21\u578b\u4ee5\u6539\u5584\u6b21\u533a\u57df\u4e2d\u671f\u6d77\u6d0b\u9884\u62a5\u7684\u53ef\u884c\u6027\u3002\u8fd9\u79cd\u56fe\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u590d\u6742\u6d77\u6d0b\u52a8\u529b\u5b66\u533a\u57df\u663e\u793a\u51fa\u589e\u5f3a\u7684\u7a7a\u95f4\u53d8\u5f02\u6027\u6355\u6349\u80fd\u529b\u548c\u66f4\u9ad8\u7684\u9884\u6d4b\u51c6\u786e\u6027\u3002"}}
{"id": "2505.23815", "pdf": "https://arxiv.org/pdf/2505.23815", "abs": "https://arxiv.org/abs/2505.23815", "authors": ["St\u00e9phane Aroca-Ouellette", "Natalie Mackraz", "Barry-John Theobald", "Katherine Metcalf"], "title": "Aligning LLMs by Predicting Preferences from User Writing Samples", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ICML 2025. 32 pages total: 9 main, 2 references, 21\n  appendix. arXiv admin note: substantial text overlap with arXiv:2410.06273", "summary": "Accommodating human preferences is essential for creating aligned LLM agents\nthat deliver personalized and effective interactions. Recent work has shown the\npotential for LLMs acting as writing agents to infer a description of user\npreferences. Agent alignment then comes from conditioning on the inferred\npreference description. However, existing methods often produce generic\npreference descriptions that fail to capture the unique and individualized\nnature of human preferences. This paper introduces PROSE, a method designed to\nenhance the precision of preference descriptions inferred from user writing\nsamples. PROSE incorporates two key elements: (1) iterative refinement of\ninferred preferences, and (2) verification of inferred preferences across\nmultiple user writing samples. We evaluate PROSE with several LLMs (i.e.,\nQwen2.5 7B and 72B Instruct, GPT-mini, and GPT-4o) on a summarization and an\nemail writing task. We find that PROSE more accurately infers nuanced human\npreferences, improving the quality of the writing agent's generations over\nCIPHER (a state-of-the-art method for inferring preferences) by 33\\%. Lastly,\nwe demonstrate that ICL and PROSE are complementary methods, and combining them\nprovides up to a 9\\% improvement over ICL alone.", "AI": {"tldr": "The paper presents PROSE, a method for enhancing the precision of inferred human preferences in LLM writing agents. It uses iterative refinement and verification across multiple user samples. Evaluated with several LLMs on summarization and email writing tasks, PROSE outperforms CIPHER by 33%. Combining PROSE with ICL offers up to 9% improvement over ICL alone.", "motivation": "Existing methods for inferring human preferences often produce generic descriptions that fail to capture the unique nature of individual preferences.", "method": "PROSE incorporates two key elements: (1) iterative refinement of inferred preferences, and (2) verification of inferred preferences across multiple user writing samples.", "result": "PROSE more accurately infers nuanced human preferences, improving the quality of the writing agent's generations over CIPHER by 33%. Combining PROSE with ICL provides up to a 9% improvement over ICL alone.", "conclusion": "PROSE enhances the precision of preference descriptions inferred from user writing samples, leading to improved performance in personalized interactions."}}
{"id": "2505.23816", "pdf": "https://arxiv.org/pdf/2505.23816", "abs": "https://arxiv.org/abs/2505.23816", "authors": ["Trenton Chang", "Tobias Schnabel", "Adith Swaminathan", "Jenna Wiens"], "title": "A Course Correction in Steerability Evaluation: Revealing Miscalibration and Side Effects in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": "10 pages, 8 figures. 26 pages of references and supplementary\n  material, 20 additional figures", "summary": "Despite advances in large language models (LLMs) on reasoning and\ninstruction-following benchmarks, it remains unclear whether they can reliably\nproduce outputs aligned with a broad variety of user goals, a concept we refer\nto as steerability. The abundance of methods proposed to modify LLM behavior\nmakes it unclear whether current LLMs are already steerable, or require further\nintervention. In particular, LLMs may exhibit (i) poor coverage, where rare\nuser goals are underrepresented; (ii) miscalibration, where models overshoot\nrequests; and (iii) side effects, where changes to one dimension of text\ninadvertently affect others. To systematically evaluate these failures, we\nintroduce a framework based on a multi-dimensional goal space that models user\ngoals and LLM outputs as vectors with dimensions corresponding to text\nattributes (e.g., reading difficulty). Applied to a text-rewriting task, we\nfind that current LLMs struggle with steerability, as side effects are\npersistent. Interventions to improve steerability, such as prompt engineering,\nbest-of-$N$ sampling, and reinforcement learning fine-tuning, have varying\neffectiveness, yet side effects remain problematic. Our findings suggest that\neven strong LLMs struggle with steerability, and existing alignment strategies\nmay be insufficient. We open-source our steerability evaluation framework at\nhttps://github.com/MLD3/steerability.", "AI": {"tldr": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u63a8\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5b83\u4eec\u662f\u5426\u80fd\u53ef\u9760\u5730\u4ea7\u751f\u4e0e\u5e7f\u6cdb\u7528\u6237\u76ee\u6807\u4e00\u81f4\u7684\u8f93\u51fa\u4ecd\u4e0d\u6e05\u695a\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u7ef4\u76ee\u6807\u7a7a\u95f4\u7684\u6846\u67b6\uff0c\u4ee5\u7cfb\u7edf\u8bc4\u4f30LLMs\u5728\u6587\u672c\u91cd\u5199\u4efb\u52a1\u4e2d\u7684\u53ef\u63a7\u6027\u95ee\u9898\uff0c\u5e76\u53d1\u73b0\u73b0\u6709\u7b56\u7565\u53ef\u80fd\u4e0d\u8db3\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "motivation": "\u5c3d\u7ba1\u5927\u8bed\u8a00\u6a21\u578b\u5728\u5404\u79cd\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5176\u8f93\u51fa\u662f\u5426\u80fd\u53ef\u9760\u5730\u4e0e\u5e7f\u6cdb\u7684\u7528\u6237\u76ee\u6807\u5bf9\u9f50\u5c1a\u4e0d\u660e\u786e\uff0c\u5373\u5b58\u5728\u6240\u8c13\u7684\u201c\u53ef\u63a7\u6027\u201d\u95ee\u9898\u3002\u6b64\u5916\uff0c\u591a\u79cd\u65b9\u6cd5\u88ab\u63d0\u51fa\u4ee5\u4fee\u6539LLM\u884c\u4e3a\uff0c\u4f46\u4e0d\u786e\u5b9a\u8fd9\u4e9b\u65b9\u6cd5\u662f\u5426\u8db3\u4ee5\u63d0\u5347LLM\u7684\u53ef\u63a7\u6027\u3002", "method": "\u4f5c\u8005\u5f15\u5165\u4e86\u4e00\u4e2a\u57fa\u4e8e\u591a\u7ef4\u76ee\u6807\u7a7a\u95f4\u7684\u6846\u67b6\uff0c\u5c06\u7528\u6237\u76ee\u6807\u548cLLM\u8f93\u51fa\u5efa\u6a21\u4e3a\u5411\u91cf\uff0c\u5411\u91cf\u7684\u7ef4\u5ea6\u5bf9\u5e94\u4e8e\u6587\u672c\u5c5e\u6027\uff08\u5982\u9605\u8bfb\u96be\u5ea6\uff09\u3002\u8be5\u6846\u67b6\u5e94\u7528\u4e8e\u6587\u672c\u91cd\u5199\u4efb\u52a1\uff0c\u7528\u4ee5\u7cfb\u7edf\u8bc4\u4f30LLM\u5728\u53ef\u63a7\u6027\u65b9\u9762\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5305\u62ec\u8986\u76d6\u4e0d\u8db3\u3001\u6821\u51c6\u4e0d\u5f53\u548c\u526f\u4f5c\u7528\u7b49\u95ee\u9898\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u5f53\u524dLLM\u5728\u53ef\u63a7\u6027\u65b9\u9762\u5b58\u5728\u56f0\u96be\uff0c\u5c24\u5176\u662f\u526f\u4f5c\u7528\u95ee\u9898\u6301\u7eed\u5b58\u5728\u3002\u901a\u8fc7\u5e72\u9884\u63aa\u65bd\uff08\u5982\u63d0\u793a\u5de5\u7a0b\u3001\u6700\u4f73N\u91c7\u6837\u548c\u5f3a\u5316\u5b66\u4e60\u5fae\u8c03\uff09\u867d\u7136\u53ef\u4ee5\u90e8\u5206\u6539\u5584\u53ef\u63a7\u6027\uff0c\u4f46\u526f\u4f5c\u7528\u4ecd\u7136\u96be\u4ee5\u5b8c\u5168\u6d88\u9664\u3002", "conclusion": "\u5373\u4f7f\u662f\u6700\u5f3a\u5927\u7684LLM\uff0c\u5728\u53ef\u63a7\u6027\u65b9\u9762\u4e5f\u9762\u4e34\u6311\u6218\uff0c\u73b0\u6709\u7684\u5bf9\u9f50\u7b56\u7565\u53ef\u80fd\u4e0d\u8db3\u4ee5\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002\u56e0\u6b64\uff0c\u4f5c\u8005\u5f00\u6e90\u4e86\u4ed6\u4eec\u7684\u53ef\u63a7\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u4ee5\u4fbf\u8fdb\u4e00\u6b65\u7814\u7a76\u548c\u6539\u8fdb\u3002"}}
{"id": "2505.23834", "pdf": "https://arxiv.org/pdf/2505.23834", "abs": "https://arxiv.org/abs/2505.23834", "authors": ["Seung Gyu Jeong", "Seong Eun Kim"], "title": "Patient-Aware Feature Alignment for Robust Lung Sound Classification:Cohesion-Separation and Global Alignment Losses", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "Accepted INTERSPEECH 2025", "summary": "Lung sound classification is vital for early diagnosis of respiratory\ndiseases. However, biomedical signals often exhibit inter-patient variability\neven among patients with the same symptoms, requiring a learning approach that\nconsiders individual differences. We propose a Patient-Aware Feature Alignment\n(PAFA) framework with two novel losses, Patient Cohesion-Separation Loss (PCSL)\nand Global Patient Alignment Loss (GPAL). PCSL clusters features of the same\npatient while separating those from other patients to capture patient\nvariability, whereas GPAL draws each patient's centroid toward a global center,\npreventing feature space fragmentation. Our method achieves outstanding results\non the ICBHI dataset with a score of 64.84\\% for four-class and 72.08\\% for\ntwo-class classification. These findings highlight PAFA's ability to capture\nindividualized patterns and demonstrate performance gains in distinct patient\nclusters, offering broader applications for patient-centered healthcare.", "AI": {"tldr": "The paper proposes a Patient-Aware Feature Alignment (PAFA) framework with two novel losses, PCSL and GPAL, for lung sound classification. It achieves excellent results on the ICBHI dataset.", "motivation": "Biomedical signals exhibit inter-patient variability even among patients with the same symptoms, necessitating a learning approach that considers individual differences.", "method": "The PAFA framework includes two novel losses: Patient Cohesion-Separation Loss (PCSL) and Global Patient Alignment Loss (GPAL). PCSL clusters features of the same patient while separating those from other patients to capture patient variability. GPAL draws each patient's centroid toward a global center, preventing feature space fragmentation.", "result": "The method achieved scores of 64.84% for four-class and 72.08% for two-class classification on the ICBHI dataset.", "conclusion": "The findings highlight PAFA's ability to capture individualized patterns and demonstrate performance gains in distinct patient clusters, offering broader applications for patient-centered healthcare."}}
{"id": "2505.24472", "pdf": "https://arxiv.org/pdf/2505.24472", "abs": "https://arxiv.org/abs/2505.24472", "authors": ["Hieu Tran", "Phuong-Anh Nguyen-Le", "Huy Nghiem", "Quang-Nhan Nguyen", "Wei Ai", "Marine Carpuat"], "title": "VietMix: A Naturally Occurring Vietnamese-English Code-Mixed Corpus with Iterative Augmentation for Machine Translation", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": null, "summary": "Machine translation systems fail when processing code-mixed inputs for\nlow-resource languages. We address this challenge by curating VietMix, a\nparallel corpus of naturally occurring code-mixed Vietnamese text paired with\nexpert English translations. Augmenting this resource, we developed a\ncomplementary synthetic data generation pipeline. This pipeline incorporates\nfiltering mechanisms to ensure syntactic plausibility and pragmatic\nappropriateness in code-mixing patterns. Experimental validation shows our\nnaturalistic and complementary synthetic data boost models' performance,\nmeasured by translation quality estimation scores, of up to 71.84 on COMETkiwi\nand 81.77 on XCOMET. Triangulating positive results with LLM-based assessments,\naugmented models are favored over seed fine-tuned counterparts in approximately\n49% of judgments (54-56% excluding ties). VietMix and our augmentation\nmethodology advance ecological validity in neural MT evaluations and establish\na framework for addressing code-mixed translation challenges across other\nlow-resource pairs.", "AI": {"tldr": "This paper presents VietMix, a parallel corpus of code-mixed Vietnamese-English text, and a synthetic data generation pipeline to improve machine translation for low-resource languages. The methods significantly boost translation quality scores and are preferred in LLM-based assessments.", "motivation": "Machine translation systems struggle with code-mixed inputs for low-resource languages, leading to the need for a specialized corpus and data generation method to address this challenge.", "method": "The researchers created VietMix, a parallel corpus of naturally occurring code-mixed Vietnamese text with expert English translations. They also developed a synthetic data generation pipeline with filtering mechanisms to ensure syntactic plausibility and pragmatic appropriateness in code-mixing patterns.", "result": "Experimental validation shows that naturalistic and synthetic data improved models' performance, achieving scores of up to 71.84 on COMETkiwi and 81.77 on XCOMET. In LLM-based assessments, augmented models were favored over seed fine-tuned counterparts in about 49% of judgments.", "conclusion": "VietMix and the augmentation methodology enhance ecological validity in neural MT evaluations and provide a framework for addressing code-mixed translation challenges across other low-resource language pairs."}}
{"id": "2505.23843", "pdf": "https://arxiv.org/pdf/2505.23843", "abs": "https://arxiv.org/abs/2505.23843", "authors": ["Wenhan Dong", "Tianyi Hu", "Jingyi Zheng", "Zhen Sun", "Yuemeng Zhao", "Yule Liu", "Xinlei He", "Xinyi Huang"], "title": "Evaluation Hallucination in Multi-Round Incomplete Information Lateral-Driven Reasoning Tasks", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Multi-round incomplete information tasks are crucial for evaluating the\nlateral thinking capabilities of large language models (LLMs). Currently,\nresearch primarily relies on multiple benchmarks and automated evaluation\nmetrics to assess these abilities. However, our study reveals novel insights\ninto the limitations of existing methods, as they often yield misleading\nresults that fail to uncover key issues, such as shortcut-taking behaviors,\nrigid patterns, and premature task termination. These issues obscure the true\nreasoning capabilities of LLMs and undermine the reliability of evaluations. To\naddress these limitations, we propose a refined set of evaluation standards,\nincluding inspection of reasoning paths, diversified assessment metrics, and\ncomparative analyses with human performance.", "AI": {"tldr": "\u5f53\u524d\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u4fa7\u5411\u601d\u7ef4\u80fd\u529b\u7684\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u5982\u4ea7\u751f\u8bef\u5bfc\u7ed3\u679c\u3001\u65e0\u6cd5\u63ed\u793a\u5173\u952e\u95ee\u9898\u7b49\u3002\u4e3a\u6b64\uff0c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u5957\u6539\u8fdb\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5305\u62ec\u68c0\u67e5\u63a8\u7406\u8def\u5f84\u3001\u591a\u6837\u5316\u8bc4\u4f30\u6307\u6807\u548c\u4e0e\u4eba\u7c7b\u8868\u73b0\u7684\u6bd4\u8f83\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u5728\u591a\u8f6e\u6b21\u4e0d\u5b8c\u5168\u4fe1\u606f\u4efb\u52a1\u4e2d\u5bf9\u5927\u8bed\u8a00\u6a21\u578b\u4fa7\u5411\u601d\u7ef4\u80fd\u529b\u8bc4\u4f30\u65f6\u51fa\u73b0\u7684\u8bef\u5bfc\u7ed3\u679c\u548c\u9690\u85cf\u5173\u952e\u95ee\u9898\u7684\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u5957\u65b0\u7684\u8bc4\u4f30\u6807\u51c6\uff0c\u5305\u62ec\u68c0\u67e5\u63a8\u7406\u8def\u5f84\u3001\u91c7\u7528\u591a\u6837\u5316\u7684\u8bc4\u4f30\u6307\u6807\u4ee5\u53ca\u4e0e\u4eba\u7c7b\u8868\u73b0\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u3002", "result": "\u65b0\u6807\u51c6\u80fd\u591f\u66f4\u51c6\u786e\u5730\u63ed\u793a\u5927\u8bed\u8a00\u6a21\u578b\u7684\u771f\u5b9e\u63a8\u7406\u80fd\u529b\uff0c\u5e76\u63d0\u9ad8\u8bc4\u4f30\u7684\u53ef\u9760\u6027\u3002", "conclusion": "\u6539\u8fdb\u540e\u7684\u8bc4\u4f30\u6807\u51c6\u4e3a\u66f4\u5168\u9762\u548c\u53ef\u9760\u5730\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u7684\u4fa7\u5411\u601d\u7ef4\u80fd\u529b\u63d0\u4f9b\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2505.23848", "pdf": "https://arxiv.org/pdf/2505.23848", "abs": "https://arxiv.org/abs/2505.23848", "authors": ["Harvey Dam", "Jonas Knochelmann", "Vinu Joseph", "Ganesh Gopalakrishnan"], "title": "Derailing Non-Answers via Logit Suppression at Output Subspace Boundaries in RLHF-Aligned Language Models", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "We introduce a method to reduce refusal rates of large language models (LLMs)\non sensitive content without modifying model weights or prompts. Motivated by\nthe observation that refusals in certain models were often preceded by the\nspecific token sequence of a token marking the beginning of the\nchain-of-thought (CoT) block (<think>) followed by a double newline token\n(\\n\\n), we investigate the impact of two simple formatting adjustments during\ngeneration: suppressing \\n\\n after <think> and suppressing the end-of-sequence\ntoken after the end of the CoT block (</think>). Our method requires no\ndatasets, parameter changes, or training, relying solely on modifying token\nprobabilities during generation. In our experiments with official DeepSeek-R1\ndistillations, these interventions increased the proportion of substantive\nanswers to sensitive prompts without affecting performance on standard\nbenchmarks. Our findings suggest that refusal behaviors can be circumvented by\nblocking refusal subspaces at specific points in the generation process.", "AI": {"tldr": "A method to reduce refusal rates of LLMs on sensitive content is introduced, which makes simple formatting adjustments during generation without modifying model weights or prompts.", "motivation": "The motivation is based on the observation that refusals in certain models were often preceded by specific token sequences marking the beginning of the chain-of-thought (CoT) block (<think>) followed by a double newline token (\n\n).", "method": "The method involves two simple formatting adjustments: suppressing \\n\\n after <think> and suppressing the end-of-sequence token after the end of the CoT block (</think>). This relies solely on modifying token probabilities during generation.", "result": "Experiments with official DeepSeek-R1 distillations showed that these interventions increased the proportion of substantive answers to sensitive prompts without affecting performance on standard benchmarks.", "conclusion": "Refusal behaviors can be circumvented by blocking refusal subspaces at specific points in the generation process."}}
{"id": "2505.24477", "pdf": "https://arxiv.org/pdf/2505.24477", "abs": "https://arxiv.org/abs/2505.24477", "authors": ["LearnLM Team", "Abhinit Modi", "Aditya Srikanth Veerubhotla", "Aliya Rysbek", "Andrea Huber", "Ankit Anand", "Avishkar Bhoopchand", "Brett Wiltshire", "Daniel Gillick", "Daniel Kasenberg", "Eleni Sgouritsa", "Gal Elidan", "Hengrui Liu", "Holger Winnemoeller", "Irina Jurenka", "James Cohan", "Jennifer She", "Julia Wilkowski", "Kaiz Alarakyia", "Kevin R. McKee", "Komal Singh", "Lisa Wang", "Markus Kunesch", "Miruna P\u00eeslar", "Niv Efron", "Parsa Mahmoudieh", "Pierre-Alexandre Kamienny", "Sara Wiltberger", "Shakir Mohamed", "Shashank Agarwal", "Shubham Milind Phal", "Sun Jae Lee", "Theofilos Strinopoulos", "Wei-Jen Ko", "Yael Gold-Zamir", "Yael Haramaty", "Yannis Assael"], "title": "Evaluating Gemini in an arena for learning", "categories": ["cs.CY", "cs.AI", "cs.LG"], "comment": null, "summary": "Artificial intelligence (AI) is poised to transform education, but the\nresearch community lacks a robust, general benchmark to evaluate AI models for\nlearning. To assess state-of-the-art support for educational use cases, we ran\nan \"arena for learning\" where educators and pedagogy experts conduct blind,\nhead-to-head, multi-turn comparisons of leading AI models. In particular, $N =\n189$ educators drew from their experience to role-play realistic learning use\ncases, interacting with two models sequentially, after which $N = 206$ experts\njudged which model better supported the user's learning goals. The arena\nevaluated a slate of state-of-the-art models: Gemini 2.5 Pro, Claude 3.7\nSonnet, GPT-4o, and OpenAI o3. Excluding ties, experts preferred Gemini 2.5 Pro\nin 73.2% of these match-ups -- ranking it first overall in the arena. Gemini\n2.5 Pro also demonstrated markedly higher performance across key principles of\ngood pedagogy. Altogether, these results position Gemini 2.5 Pro as a leading\nmodel for learning.", "AI": {"tldr": "An 'arena for learning' was conducted to evaluate AI models in education, where educators and experts compared leading AI models. Among them, Gemini 2.5 Pro ranked first overall.", "motivation": "The research community lacks a robust benchmark to evaluate AI models for learning, so there is a need to assess state-of-the-art support for educational use cases.", "method": "An 'arena for learning' was used where educators and pedagogy experts conduct blind, head-to-head, multi-turn comparisons of leading AI models. Participants role-played realistic learning use cases and interacted with two models sequentially.", "result": "Experts preferred Gemini 2.5 Pro in 73.2% of match-ups, ranking it first overall in the arena. It also demonstrated higher performance across key principles of good pedagogy.", "conclusion": "Gemini 2.5 Pro is positioned as a leading model for learning in educational use cases."}}
{"id": "2505.24480", "pdf": "https://arxiv.org/pdf/2505.24480", "abs": "https://arxiv.org/abs/2505.24480", "authors": ["Fei Bai", "Yingqian Min", "Beichen Zhang", "Zhipeng Chen", "Wayne Xin Zhao", "Lei Fang", "Zheng Liu", "Zhongyuan Wang", "Ji-Rong Wen"], "title": "Towards Effective Code-Integrated Reasoning", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "Technical Report on Slow Thinking with LLMs: Code-Integrated\n  Reasoning", "summary": "In this paper, we investigate code-integrated reasoning, where models\ngenerate code when necessary and integrate feedback by executing it through a\ncode interpreter. To acquire this capability, models must learn when and how to\nuse external code tools effectively, which is supported by tool-augmented\nreinforcement learning (RL) through interactive learning. Despite its benefits,\ntool-augmented RL can still suffer from potential instability in the learning\ndynamics. In light of this challenge, we present a systematic approach to\nimproving the training effectiveness and stability of tool-augmented RL for\ncode-integrated reasoning. Specifically, we develop enhanced training\nstrategies that balance exploration and stability, progressively building\ntool-use capabilities while improving reasoning performance. Through extensive\nexperiments on five mainstream mathematical reasoning benchmarks, our model\ndemonstrates significant performance improvements over multiple competitive\nbaselines. Furthermore, we conduct an in-depth analysis of the mechanism and\neffect of code-integrated reasoning, revealing several key insights, such as\nthe extension of model's capability boundaries and the simultaneous improvement\nof reasoning efficiency through code integration. All data and code for\nreproducing this work are available at: https://github.com/RUCAIBox/CIR.", "AI": {"tldr": "\u672c\u7814\u7a76\u63a2\u8ba8\u4e86\u4ee3\u7801\u96c6\u6210\u63a8\u7406\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u63d0\u9ad8\u5de5\u5177\u589e\u5f3a\u578b\u5f3a\u5316\u5b66\u4e60\u5728\u4ee3\u7801\u96c6\u6210\u63a8\u7406\u4e2d\u7684\u8bad\u7ec3\u6548\u679c\u548c\u7a33\u5b9a\u6027\u3002\u5b9e\u9a8c\u8868\u660e\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u591a\u4e2a\u7ade\u4e89\u57fa\u7ebf\uff0c\u5e76\u63ed\u793a\u4e86\u4ee3\u7801\u96c6\u6210\u63a8\u7406\u7684\u82e5\u5e72\u5173\u952e\u89c1\u89e3\u3002", "motivation": "\u4ee3\u7801\u96c6\u6210\u63a8\u7406\u9700\u8981\u6a21\u578b\u5728\u5fc5\u8981\u65f6\u751f\u6210\u4ee3\u7801\u5e76\u901a\u8fc7\u4ee3\u7801\u89e3\u91ca\u5668\u6574\u5408\u53cd\u9988\uff0c\u4f46\u5de5\u5177\u589e\u5f3a\u578b\u5f3a\u5316\u5b66\u4e60\u5728\u5b66\u4e60\u52a8\u6001\u4e2d\u53ef\u80fd\u5b58\u5728\u6f5c\u5728\u7684\u4e0d\u7a33\u5b9a\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u589e\u5f3a\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5e73\u8861\u63a2\u7d22\u4e0e\u7a33\u5b9a\u6027\uff0c\u9010\u6b65\u6784\u5efa\u5de5\u5177\u4f7f\u7528\u80fd\u529b\u5e76\u63d0\u9ad8\u63a8\u7406\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u4e94\u4e2a\u4e3b\u6d41\u6570\u5b66\u63a8\u7406\u57fa\u51c6\u7684\u5e7f\u6cdb\u5b9e\u9a8c\uff0c\u6a21\u578b\u8868\u73b0\u51fa\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002\u6df1\u5165\u5206\u6790\u663e\u793a\uff0c\u4ee3\u7801\u96c6\u6210\u63a8\u7406\u6269\u5c55\u4e86\u6a21\u578b\u7684\u80fd\u529b\u8fb9\u754c\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u63a8\u7406\u6548\u7387\u3002", "conclusion": "\u672c\u7814\u7a76\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u65b9\u6cd5\u6765\u6539\u8fdb\u5de5\u5177\u589e\u5f3a\u578b\u5f3a\u5316\u5b66\u4e60\u7684\u8bad\u7ec3\u6548\u679c\u548c\u7a33\u5b9a\u6027\uff0c\u5c55\u793a\u4e86\u4ee3\u7801\u96c6\u6210\u63a8\u7406\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.24489", "pdf": "https://arxiv.org/pdf/2505.24489", "abs": "https://arxiv.org/abs/2505.24489", "authors": ["Anasse Boutayeb", "Iyad Lahsen-cherif", "Ahmed El Khadimi"], "title": "Deformable Attention Mechanisms Applied to Object Detection, case of Remote Sensing", "categories": ["cs.CV", "cs.AI"], "comment": "10 pages, 5 figures, paper accepted at the 29th International\n  Conference on Knowledge-Based and Intelligent Information and Engineering\n  Systems (KES 2025), Osaka, Japan", "summary": "Object detection has recently seen an interesting trend in terms of the most\ninnovative research work, this task being of particular importance in the field\nof remote sensing, given the consistency of these images in terms of\ngeographical coverage and the objects present. Furthermore, Deep Learning (DL)\nmodels, in particular those based on Transformers, are especially relevant for\nvisual computing tasks in general, and target detection in particular. Thus,\nthe present work proposes an application of Deformable-DETR model, a specific\narchitecture using deformable attention mechanisms, on remote sensing images in\ntwo different modes, especially optical and Synthetic Aperture Radar (SAR). To\nachieve this objective, two datasets are used, one optical, which is Pleiades\nAircraft dataset, and the other SAR, in particular SAR Ship Detection Dataset\n(SSDD). The results of a 10-fold stratified validation showed that the proposed\nmodel performed particularly well, obtaining an F1 score of 95.12% for the\noptical dataset and 94.54% for SSDD, while comparing these results with several\nmodels detections, especially those based on CNNs and transformers, as well as\nthose specifically designed to detect different object classes in remote\nsensing images.", "AI": {"tldr": "This paper explores the application of Deformable-DETR model using deformable attention mechanisms on remote sensing images in optical and SAR modes, achieving high F1 scores and comparing results with other models.", "motivation": "The motivation is to leverage the power of deep learning models, particularly transformer-based ones, for object detection tasks in remote sensing images due to their geographical coverage and present objects consistency.", "method": "The method involves applying the Deformable-DETR model on two datasets (Pleiades Aircraft dataset for optical and SAR Ship Detection Dataset for SAR) using a 10-fold stratified validation approach.", "result": "The model performed well with an F1 score of 95.12% for the optical dataset and 94.54% for SSDD, outperforming several CNNs and transformer-based models.", "conclusion": "Deformable-DETR model with deformable attention mechanisms is effective for object detection in remote sensing images across different modes."}}
{"id": "2505.23858", "pdf": "https://arxiv.org/pdf/2505.23858", "abs": "https://arxiv.org/abs/2505.23858", "authors": ["Aashwin Mishra", "Matt Seaberg", "Ryan Roussel", "Fred Poitevin", "Jana Thayer", "Daniel Ratner", "Auralee Edelen", "Apurva Mehta"], "title": "A Start To End Machine Learning Approach To Maximize Scientific Throughput From The LCLS-II-HE", "categories": ["physics.ins-det", "cs.LG", "hep-ex"], "comment": null, "summary": "With the increasing brightness of Light sources, including the\nDiffraction-Limited brightness upgrade of APS and the high-repetition-rate\nupgrade of LCLS, the proposed experiments therein are becoming increasingly\ncomplex. For instance, experiments at LCLS-II-HE will require the X-ray beam to\nbe within a fraction of a micron in diameter, with pointing stability of a few\nnanoradians, at the end of a kilometer-long electron accelerator, a\nhundred-meter-long undulator section, and tens of meters long X-ray optics.\nThis enhancement of brightness will increase the data production rate to rival\nthe largest data generators in the world. Without real-time active feedback\ncontrol and an optimized pipeline to transform measurements to scientific\ninformation and insights, researchers will drown in a deluge of mostly useless\ndata, and fail to extract the highly sophisticated insights that the recent\nbrightness upgrades promise.\n  In this article, we outline the strategy we are developing at SLAC to\nimplement Machine Learning driven optimization, automation and real-time\nknowledge extraction from the electron-injector at the start of the electron\naccelerator, to the multidimensional X-ray optical systems, and till the\nexperimental endstations and the high readout rate, multi-megapixel detectors\nat LCLS to deliver the design performance to the users. This is illustrated via\nexamples from Accelerator, Optics and End User applications.", "AI": {"tldr": "\u968f\u7740\u5149\u6e90\u4eae\u5ea6\u7684\u589e\u52a0\uff0c\u5305\u62ecAPS\u7684\u884d\u5c04\u6781\u9650\u4eae\u5ea6\u5347\u7ea7\u548cLCLS\u7684\u9ad8\u91cd\u590d\u9891\u7387\u5347\u7ea7\uff0c\u5176\u4e2d\u63d0\u51fa\u7684\u5b9e\u9a8c\u53d8\u5f97\u8d8a\u6765\u8d8a\u590d\u6742\u3002\u672c\u6587\u6982\u8ff0\u4e86\u6211\u4eec\u5728SLAC\u5f00\u53d1\u7684\u7b56\u7565\uff0c\u901a\u8fc7\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u4f18\u5316\u3001\u81ea\u52a8\u5316\u548c\u5b9e\u65f6\u77e5\u8bc6\u63d0\u53d6\uff0c\u4ece\u7535\u5b50\u52a0\u901f\u5668\u7684\u7535\u5b50\u6ce8\u5165\u5668\u5f00\u59cb\uff0c\u5230\u591a\u7ef4X\u5c04\u7ebf\u5149\u5b66\u7cfb\u7edf\uff0c\u518d\u5230LCLS\u7684\u5b9e\u9a8c\u7aef\u7ad9\u548c\u9ad8\u8bfb\u51fa\u7387\u3001\u591a\u5146\u50cf\u7d20\u63a2\u6d4b\u5668\uff0c\u4ee5\u5411\u7528\u6237\u63d0\u4f9b\u8bbe\u8ba1\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u5e94\u5bf9\u590d\u6742\u5b9e\u9a8c\u9700\u6c42\u7684\u589e\u957f\u4ee5\u53ca\u6d77\u91cf\u6570\u636e\u751f\u6210\u7684\u6311\u6218\uff0c\u9700\u8981\u5b9e\u73b0\u5b9e\u65f6\u4e3b\u52a8\u53cd\u9988\u63a7\u5236\u548c\u4f18\u5316\u7684\u6570\u636e\u5904\u7406\u7ba1\u9053\uff0c\u4ece\u800c\u907f\u514d\u7814\u7a76\u4eba\u5458\u88ab\u65e0\u7528\u6570\u636e\u6df9\u6ca1\uff0c\u5e76\u6210\u529f\u63d0\u53d6\u6700\u8fd1\u4eae\u5ea6\u5347\u7ea7\u6240\u627f\u8bfa\u7684\u9ad8\u5ea6\u590d\u6742\u89c1\u89e3\u3002", "method": "\u5728SLAC\u5f00\u53d1\u5e76\u5b9e\u65bd\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u4f18\u5316\u3001\u81ea\u52a8\u5316\u548c\u5b9e\u65f6\u77e5\u8bc6\u63d0\u53d6\u7b56\u7565\uff0c\u6db5\u76d6\u4ece\u7535\u5b50\u52a0\u901f\u5668\u7684\u7535\u5b50\u6ce8\u5165\u5668\u3001\u591a\u7ef4X\u5c04\u7ebf\u5149\u5b66\u7cfb\u7edf\u5230\u5b9e\u9a8c\u7aef\u7ad9\u548c\u9ad8\u8bfb\u51fa\u7387\u3001\u591a\u5146\u50cf\u7d20\u63a2\u6d4b\u5668\u7684\u6574\u4e2a\u8fc7\u7a0b\u3002", "result": "\u901a\u8fc7\u52a0\u901f\u5668\u3001\u5149\u5b66\u548c\u7ec8\u7aef\u7528\u6237\u5e94\u7528\u7684\u4f8b\u5b50\u8bf4\u660e\u4e86\u8be5\u7b56\u7565\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u8bbe\u8ba1\u6027\u80fd\u5e76\u6ee1\u8db3\u7528\u6237\u9700\u6c42\u3002", "conclusion": "\u673a\u5668\u5b66\u4e60\u9a71\u52a8\u7684\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u5e94\u5bf9\u672a\u6765\u5149\u6e90\u5b9e\u9a8c\u4e2d\u7684\u590d\u6742\u6027\u548c\u6570\u636e\u5904\u7406\u6311\u6218\uff0c\u786e\u4fdd\u5b9e\u9a8c\u7684\u6210\u529f\u548c\u79d1\u5b66\u76ee\u6807\u7684\u5b9e\u73b0\u3002"}}
{"id": "2505.24500", "pdf": "https://arxiv.org/pdf/2505.24500", "abs": "https://arxiv.org/abs/2505.24500", "authors": ["Guiyang Hou", "Xing Gao", "Yuchuan Wu", "Xiang Huang", "Wenqi Zhang", "Zhe Zheng", "Yongliang Shen", "Jialu Du", "Fei Huang", "Yongbin Li", "Weiming Lu"], "title": "TimeHC-RL: Temporal-aware Hierarchical Cognitive Reinforcement Learning for Enhancing LLMs' Social Intelligence", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 12 figures", "summary": "Recently, Large Language Models (LLMs) have made significant progress in\nIQ-related domains that require careful thinking, such as mathematics and\ncoding. However, enhancing LLMs' cognitive development in social domains,\nparticularly from a post-training perspective, remains underexplored.\nRecognizing that the social world follows a distinct timeline and requires a\nricher blend of cognitive modes (from intuitive reactions (System 1) and\nsurface-level thinking to deliberate thinking (System 2)) than mathematics,\nwhich primarily relies on System 2 cognition (careful, step-by-step reasoning),\nwe introduce Temporal-aware Hierarchical Cognitive Reinforcement Learning\n(TimeHC-RL) for enhancing LLMs' social intelligence. In our experiments, we\nsystematically explore improving LLMs' social intelligence and validate the\neffectiveness of the TimeHC-RL method, through five other post-training\nparadigms and two test-time intervention paradigms on eight datasets with\ndiverse data patterns. Experimental results reveal the superiority of our\nproposed TimeHC-RL method compared to the widely adopted System 2 RL method. It\ngives the 7B backbone model wings, enabling it to rival the performance of\nadvanced models like DeepSeek-R1 and OpenAI-O3. Additionally, the systematic\nexploration from post-training and test-time interventions perspectives to\nimprove LLMs' social intelligence has uncovered several valuable insights.", "AI": {"tldr": "This paper presents TimeHC-RL, a novel method to enhance LLMs' social intelligence by recognizing the distinct timeline and cognitive modes in social domains. Experiments show its superiority over System 2 RL method and enable a 7B model to match advanced models.", "motivation": "The motivation is the underexplored enhancement of LLMs' cognitive development in social domains from a post-training perspective, acknowledging the unique requirements of social cognition compared to mathematics or coding.", "method": "The method introduced is Temporal-aware Hierarchical Cognitive Reinforcement Learning (TimeHC-RL), designed to improve LLMs' social intelligence.", "result": "Experimental results demonstrate that TimeHC-RL outperforms the widely adopted System 2 RL method and allows a 7B model to rival advanced models like DeepSeek-R1 and OpenAI-O3.", "conclusion": "The conclusion drawn is that TimeHC-RL effectively enhances LLMs' social intelligence, and the exploration has uncovered valuable insights for improving LLMs through post-training and test-time interventions."}}
{"id": "2505.24503", "pdf": "https://arxiv.org/pdf/2505.24503", "abs": "https://arxiv.org/abs/2505.24503", "authors": ["Tzeh Yuan Neoh", "Jannik Peters", "Nicholas Teh"], "title": "Online Fair Division with Additional Information", "categories": ["cs.GT", "cs.AI"], "comment": null, "summary": "We study the problem of fairly allocating indivisible goods to agents in an\nonline setting, where goods arrive sequentially and must be allocated\nirrevocably to agents. Focusing on the popular fairness notions of\nenvy-freeness, proportionality, and maximin share fairness (and their\napproximate variants), we ask how the availability of information on future\ngoods influences the existence and approximability of fair allocations. In the\nabsence of any such information, we establish strong impossibility results,\ndemonstrating the inherent difficulty of achieving even approximate fairness\nguarantees. In contrast, we demonstrate that knowledge of additional\ninformation -- such as aggregate of each agent's total valuations\n(equivalently, normalized valuations) or the multiset of future goods values\n(frequency predictions) -- would enable the design of fairer online algorithms.\nGiven normalization information, we propose an algorithm that achieves stronger\nfairness guarantees than previously known results. Given frequency predictions,\nwe introduce a meta-algorithm that leverages frequency predictions to match the\nbest-known offline guarantees for a broad class of ''share-based'' fairness\nnotions. Our complementary impossibility results in each setting underscore\nboth the limitations imposed by uncertainty about future goods and the\npotential of leveraging structured information to achieve fairer outcomes in\nonline fair division.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u5728\u7ebf\u73af\u5883\u4e0b\u516c\u5e73\u5206\u914d\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u95ee\u9898\uff0c\u53d1\u73b0\u672a\u6765\u7269\u54c1\u4fe1\u606f\u7684\u53ef\u7528\u6027\u5f71\u54cd\u4e86\u516c\u5e73\u5206\u914d\u7684\u5b58\u5728\u6027\u548c\u8fd1\u4f3c\u6027\u3002\u5728\u6ca1\u6709\u4efb\u4f55\u6b64\u7c7b\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u5b9e\u73b0\u8fd1\u4f3c\u7684\u516c\u5e73\u4fdd\u8bc1\u662f\u975e\u5e38\u56f0\u96be\u7684\uff1b\u800c\u62e5\u6709\u989d\u5916\u7684\u4fe1\u606f\uff08\u5982\u5f52\u4e00\u5316\u4fe1\u606f\u6216\u9891\u7387\u9884\u6d4b\uff09\u53ef\u4ee5\u8bbe\u8ba1\u66f4\u516c\u5e73\u7684\u5728\u7ebf\u7b97\u6cd5\u3002", "motivation": "\u7814\u7a76\u5728\u7ebf\u73af\u5883\u4e0b\u516c\u5e73\u5206\u914d\u4e0d\u53ef\u5206\u5272\u7269\u54c1\u7684\u95ee\u9898\uff0c\u63a2\u8ba8\u672a\u6765\u7269\u54c1\u4fe1\u606f\u7684\u53ef\u7528\u6027\u5982\u4f55\u5f71\u54cd\u516c\u5e73\u5206\u914d\u7684\u5b58\u5728\u6027\u548c\u8fd1\u4f3c\u6027\u3002", "method": "1. \u5efa\u7acb\u5f3a\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff1a\u5728\u6ca1\u6709\u4efb\u4f55\u5173\u4e8e\u672a\u6765\u7269\u54c1\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u5c55\u793a\u5b9e\u73b0\u8fd1\u4f3c\u516c\u5e73\u4fdd\u8bc1\u7684\u56fa\u6709\u96be\u5ea6\u30022. \u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u5f52\u4e00\u5316\u4fe1\u606f\u7684\u7b97\u6cd5\uff1a\u8be5\u7b97\u6cd5\u6bd4\u4e4b\u524d\u5df2\u77e5\u7684\u7ed3\u679c\u63d0\u4f9b\u66f4\u5f3a\u7684\u516c\u5e73\u4fdd\u8bc1\u30023. \u5f15\u5165\u4e00\u4e2a\u5143\u7b97\u6cd5\uff1a\u5229\u7528\u9891\u7387\u9884\u6d4b\u5339\u914d\u6700\u4f73\u5df2\u77e5\u7684\u79bb\u7ebf\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u5e7f\u6cdb\u7684\u201c\u57fa\u4e8e\u4efd\u989d\u201d\u7684\u516c\u5e73\u6982\u5ff5\u3002", "result": "1. \u5728\u6ca1\u6709\u4efb\u4f55\u5173\u4e8e\u672a\u6765\u7269\u54c1\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\uff0c\u5efa\u7acb\u5f3a\u4e0d\u53ef\u80fd\u6027\u7ed3\u679c\uff0c\u5c55\u793a\u5b9e\u73b0\u8fd1\u4f3c\u516c\u5e73\u4fdd\u8bc1\u7684\u56fa\u6709\u96be\u5ea6\u30022. \u7ed9\u5b9a\u5f52\u4e00\u5316\u4fe1\u606f\u65f6\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5b9e\u73b0\u4e86\u6bd4\u4e4b\u524d\u66f4\u5f3a\u7684\u516c\u5e73\u4fdd\u8bc1\u30023. \u7ed9\u5b9a\u9891\u7387\u9884\u6d4b\u65f6\uff0c\u5143\u7b97\u6cd5\u80fd\u591f\u5339\u914d\u6700\u4f73\u5df2\u77e5\u7684\u79bb\u7ebf\u4fdd\u8bc1\u3002", "conclusion": "\u672a\u6765\u7269\u54c1\u4fe1\u606f\u7684\u4e0d\u786e\u5b9a\u6027\u5bf9\u516c\u5e73\u5206\u914d\u6784\u6210\u4e86\u9650\u5236\uff0c\u4f46\u5229\u7528\u7ed3\u6784\u5316\u4fe1\u606f\u53ef\u4ee5\u5b9e\u73b0\u66f4\u516c\u5e73\u7684\u7ed3\u679c\u3002"}}
{"id": "2505.23869", "pdf": "https://arxiv.org/pdf/2505.23869", "abs": "https://arxiv.org/abs/2505.23869", "authors": ["M. S\u00fczen"], "title": "Gibbs randomness-compression proposition: An efficient deep learning", "categories": ["stat.ML", "cs.LG"], "comment": "5 pages, 5 figures", "summary": "A proposition that connects randomness and compression put forward via Gibbs\nentropy over set of measurement vectors associated with a compression process.\nThe proposition states that a lossy compression process is equivalent to {\\it\ndirected randomness} that preserves information content. The proposition\noriginated from the observed behaviour in newly proposed {\\it Dual Tomographic\nCompression} (DTC) compress-train framework. This is akin to tomographic\nreconstruction of layer weight matrices via building compressed sensed\nprojections, so called {\\it weight rays}. This tomographic approach is applied\nto previous and next layers in a dual fashion, that triggers neuronal-level\npruning. This novel model compress-train scheme appear in iterative fashion and\nact as smart neural architecture search, Experiments demonstrated utility of\nthis dual-tomography producing state-of-the-art performance with efficient\ncompression during training, accelerating and supporting lottery ticket\nhypothesis. However, random compress-train iterations having similar\nperformance demonstrated the connection between randomness and compression from\nstatistical physics perspective, we formulated so called {\\it Gibbs\nrandomness-compression proposition}, signifying randomness-compression\nrelationship via Gibbs entropy. Practically, DTC framework provides a promising\napproach for massively energy and resource efficient deep learning training\napproach.", "AI": {"tldr": "This paper introduces the Gibbs randomness-compression proposition, which links randomness and compression through Gibbs entropy. The Dual Tomographic Compression (DTC) compress-train framework is proposed for neural network compression, enabling efficient training with state-of-the-art performance.", "motivation": "To explore the connection between randomness and compression in the context of neural network compression and to develop an energy and resource-efficient deep learning training approach.", "method": "The Dual Tomographic Compression (DTC) compress-train framework uses tomographic reconstruction of layer weight matrices via compressed sensed projections (weight rays), applied in a dual fashion to previous and next layers, triggering neuronal-level pruning.", "result": "Experiments demonstrated state-of-the-art performance with efficient compression during training, supporting the lottery ticket hypothesis. Random compress-train iterations showed similar performance, indicating a statistical physics perspective on the randomness-compression relationship.", "conclusion": "The DTC framework provides a promising approach for energy and resource-efficient deep learning training, underpinned by the Gibbs randomness-compression proposition."}}
{"id": "2505.23883", "pdf": "https://arxiv.org/pdf/2505.23883", "abs": "https://arxiv.org/abs/2505.23883", "authors": ["Jianyang Gu", "Samuel Stevens", "Elizabeth G Campolongo", "Matthew J Thompson", "Net Zhang", "Jiaman Wu", "Andrei Kopanev", "Zheda Mai", "Alexander E. White", "James Balhoff", "Wasila Dahdul", "Daniel Rubenstein", "Hilmar Lapp", "Tanya Berger-Wolf", "Wei-Lun Chao", "Yu Su"], "title": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Project page: https://imageomics.github.io/bioclip-2/", "summary": "Foundation models trained at scale exhibit remarkable emergent behaviors,\nlearning new capabilities beyond their initial training objectives. We find\nsuch emergent behaviors in biological vision models via large-scale contrastive\nvision-language training. To achieve this, we first curate TreeOfLife-200M,\ncomprising 214 million images of living organisms, the largest and most diverse\nbiological organism image dataset to date. We then train BioCLIP 2 on\nTreeOfLife-200M to distinguish different species. Despite the narrow training\nobjective, BioCLIP 2 yields extraordinary accuracy when applied to various\nbiological visual tasks such as habitat classification and trait prediction. We\nidentify emergent properties in the learned embedding space of BioCLIP 2. At\nthe inter-species level, the embedding distribution of different species aligns\nclosely with functional and ecological meanings (e.g., beak sizes and\nhabitats). At the intra-species level, instead of being diminished, the\nintra-species variations (e.g., life stages and sexes) are preserved and better\nseparated in subspaces orthogonal to inter-species distinctions. We provide\nformal proof and analyses to explain why hierarchical supervision and\ncontrastive objectives encourage these emergent properties. Crucially, our\nresults reveal that these properties become increasingly significant with\nlarger-scale training data, leading to a biologically meaningful embedding\nspace.", "AI": {"tldr": "\u901a\u8fc7\u5927\u89c4\u6a21\u5bf9\u6bd4\u89c6\u89c9-\u8bed\u8a00\u8bad\u7ec3\uff0c\u7814\u7a76\u5728\u751f\u7269\u89c6\u89c9\u6a21\u578b\u4e2d\u53d1\u73b0\u4e86\u7c7b\u4f3c\u57fa\u7840\u6a21\u578b\u7684\u65b0\u5174\u884c\u4e3a\u3002\u4f7f\u7528TreeOfLife-200M\u6570\u636e\u96c6\u8bad\u7ec3BioCLIP 2\u6a21\u578b\uff0c\u5728\u72ed\u7a84\u7684\u7269\u79cd\u533a\u5206\u4efb\u52a1\u4e4b\u5916\u5c55\u73b0\u51fa\u591a\u79cd\u751f\u7269\u89c6\u89c9\u4efb\u52a1\u4e0a\u7684\u5353\u8d8a\u6027\u80fd\uff0c\u5e76\u63ed\u793a\u4e86\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u5c42\u7ea7\u76d1\u7763\u548c\u5bf9\u6bd4\u76ee\u6807\u5982\u4f55\u4fc3\u8fdb\u8fd9\u4e9b\u65b0\u5174\u7279\u6027\u7684\u5f62\u6210\u3002", "motivation": "\u63a2\u7d22\u751f\u7269\u89c6\u89c9\u6a21\u578b\u662f\u5426\u53ef\u4ee5\u901a\u8fc7\u5927\u89c4\u6a21\u8bad\u7ec3\u5c55\u73b0\u7c7b\u4f3c\u57fa\u7840\u6a21\u578b\u7684\u65b0\u5174\u884c\u4e3a\uff0c\u7279\u522b\u662f\u5728\u89c6\u89c9-\u8bed\u8a00\u4efb\u52a1\u4e2d\u7684\u8868\u73b0\u3002", "method": "1. \u7b79\u5907TreeOfLife-200M\u6570\u636e\u96c6\uff0c\u5305\u542b2.14\u4ebf\u5f20\u751f\u7269\u56fe\u50cf\u3002\n2. \u4f7f\u7528\u8be5\u6570\u636e\u96c6\u8bad\u7ec3BioCLIP 2\u6a21\u578b\u4ee5\u533a\u5206\u4e0d\u540c\u7269\u79cd\u3002\n3. \u5206\u6790BioCLIP 2\u5728\u5176\u4ed6\u751f\u7269\u89c6\u89c9\u4efb\u52a1\uff08\u5982\u6816\u606f\u5730\u5206\u7c7b\u548c\u6027\u72b6\u9884\u6d4b\uff09\u4e2d\u7684\u8868\u73b0\u3002\n4. \u63a2\u8ba8\u5176\u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u7279\u6027\uff0c\u5305\u62ec\u79cd\u95f4\u548c\u79cd\u5185\u53d8\u5f02\u7684\u8868\u73b0\u3002\n5. \u63d0\u4f9b\u6b63\u5f0f\u8bc1\u660e\u548c\u5206\u6790\u89e3\u91ca\u4e3a\u4f55\u5206\u5c42\u76d1\u7763\u548c\u5bf9\u6bd4\u76ee\u6807\u4f1a\u4fc3\u8fdb\u8fd9\u4e9b\u7279\u6027\u3002", "result": "1. BioCLIP 2\u5728\u5404\u79cd\u751f\u7269\u89c6\u89c9\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5c3d\u7ba1\u5176\u8bad\u7ec3\u76ee\u6807\u4ec5\u9650\u4e8e\u533a\u5206\u7269\u79cd\u3002\n2. \u5d4c\u5165\u7a7a\u95f4\u4e2d\u7684\u79cd\u95f4\u5206\u5e03\u4e0e\u529f\u80fd\u548c\u751f\u6001\u5b66\u610f\u4e49\u5bc6\u5207\u76f8\u5173\u3002\n3. \u79cd\u5185\u53d8\u5f02\u5728\u4e0e\u79cd\u95f4\u533a\u5206\u6b63\u4ea4\u7684\u5b50\u7a7a\u95f4\u4e2d\u5f97\u4ee5\u4fdd\u7559\u5e76\u66f4\u597d\u5730\u533a\u5206\u3002\n4. \u968f\u7740\u8bad\u7ec3\u6570\u636e\u89c4\u6a21\u7684\u589e\u52a0\uff0c\u8fd9\u4e9b\u7279\u6027\u53d8\u5f97\u66f4\u52a0\u663e\u8457\u3002", "conclusion": "\u5927\u89c4\u6a21\u8bad\u7ec3\u6570\u636e\u548c\u5bf9\u6bd4\u76ee\u6807\u4fc3\u8fdb\u4e86\u751f\u7269\u89c6\u89c9\u6a21\u578b\u4e2d\u5177\u6709\u751f\u6001\u548c\u529f\u80fd\u610f\u4e49\u7684\u5d4c\u5165\u7a7a\u95f4\u7684\u5f62\u6210\uff0c\u63ed\u793a\u4e86\u7c7b\u4f3c\u57fa\u7840\u6a21\u578b\u7684\u65b0\u5174\u884c\u4e3a\u5728\u751f\u7269\u89c6\u89c9\u9886\u57df\u7684\u6f5c\u529b\u3002"}}
{"id": "2505.24523", "pdf": "https://arxiv.org/pdf/2505.24523", "abs": "https://arxiv.org/abs/2505.24523", "authors": ["Andrea Pedrotti", "Michele Papucci", "Cristiano Ciaccio", "Alessio Miaschi", "Giovanni Puccetti", "Felice Dell'Orletta", "Andrea Esuli"], "title": "Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted at Findings of ACL 2025", "summary": "Recent advancements in Generative AI and Large Language Models (LLMs) have\nenabled the creation of highly realistic synthetic content, raising concerns\nabout the potential for malicious use, such as misinformation and manipulation.\nMoreover, detecting Machine-Generated Text (MGT) remains challenging due to the\nlack of robust benchmarks that assess generalization to real-world scenarios.\nIn this work, we present a pipeline to test the resilience of state-of-the-art\nMGT detectors (e.g., Mage, Radar, LLM-DetectAIve) to linguistically informed\nadversarial attacks. To challenge the detectors, we fine-tune language models\nusing Direct Preference Optimization (DPO) to shift the MGT style toward\nhuman-written text (HWT). This exploits the detectors' reliance on stylistic\nclues, making new generations more challenging to detect. Additionally, we\nanalyze the linguistic shifts induced by the alignment and which features are\nused by detectors to detect MGT texts. Our results show that detectors can be\neasily fooled with relatively few examples, resulting in a significant drop in\ndetection performance. This highlights the importance of improving detection\nmethods and making them robust to unseen in-domain texts.", "AI": {"tldr": "Recent advancements in Generative AI and LLMs have enabled the creation of highly realistic synthetic content, raising concerns about malicious use. Detecting MGT remains challenging due to lack of robust benchmarks. This work presents a pipeline to test resilience of MGT detectors to adversarial attacks.", "motivation": "To address the challenges in detecting machine-generated text and highlight vulnerabilities in current detection methods.", "method": "Fine-tune language models using Direct Preference Optimization (DPO) to shift MGT style toward human-written text, making it harder for detectors to distinguish. Analyze linguistic shifts and features used by detectors.", "result": "Detectors can be easily fooled with relatively few examples, leading to a significant drop in detection performance.", "conclusion": "Improving detection methods and making them robust to unseen in-domain texts is crucial."}}
{"id": "2505.23962", "pdf": "https://arxiv.org/pdf/2505.23962", "abs": "https://arxiv.org/abs/2505.23962", "authors": ["Aurosweta Mahapatra", "Ismail Rasim Ulgen", "Abinay Reddy Naini", "Carlos Busso", "Berrak Sisman"], "title": "Can Emotion Fool Anti-spoofing?", "categories": ["eess.AS", "cs.LG", "cs.SD"], "comment": "Accepted to Interspeech 2025", "summary": "Traditional anti-spoofing focuses on models and datasets built on synthetic\nspeech with mostly neutral state, neglecting diverse emotional variations. As a\nresult, their robustness against high-quality, emotionally expressive synthetic\nspeech is uncertain. We address this by introducing EmoSpoof-TTS, a corpus of\nemotional text-to-speech samples. Our analysis shows existing anti-spoofing\nmodels struggle with emotional synthetic speech, exposing risks of\nemotion-targeted attacks. Even trained on emotional data, the models\nunderperform due to limited focus on emotional aspect and show performance\ndisparities across emotions. This highlights the need for emotion-focused\nanti-spoofing paradigm in both dataset and methodology. We propose GEM, a gated\nensemble of emotion-specialized models with a speech emotion recognition gating\nnetwork. GEM performs effectively across all emotions and neutral state,\nimproving defenses against spoofing attacks. We release the EmoSpoof-TTS\nDataset: https://emospoof-tts.github.io/Dataset/", "AI": {"tldr": "The paper introduces EmoSpoof-TTS, a corpus of emotional text-to-speech samples, revealing existing anti-spoofing models' weakness against emotional synthetic speech and proposing GEM, an emotion-focused anti-spoofing model.", "motivation": "Traditional anti-spoofing methods mainly focus on neutral synthetic speech and neglect diverse emotional variations, leading to uncertain robustness against high-quality, emotionally expressive synthetic speech.", "method": "Introduced EmoSpoof-TTS corpus for analysis and proposed GEM, a gated ensemble of emotion-specialized models with a speech emotion recognition gating network.", "result": "Existing anti-spoofing models struggle with emotional synthetic speech even when trained on emotional data, while GEM performs effectively across all emotions and neutral state.", "conclusion": "There is a need for emotion-focused anti-spoofing paradigm in both dataset and methodology, and GEM improves defenses against spoofing attacks."}}
{"id": "2505.23964", "pdf": "https://arxiv.org/pdf/2505.23964", "abs": "https://arxiv.org/abs/2505.23964", "authors": ["Jonas Elsborg", "Tejs Vegge", "Arghya Bhowmik"], "title": "Acoustic Classification of Maritime Vessels using Learnable Filterbanks", "categories": ["cs.SD", "cs.LG", "eess.AS"], "comment": "9 pages, 5 figures, 2 tables", "summary": "Reliably monitoring and recognizing maritime vessels based on acoustic\nsignatures is complicated by the variability of different recording scenarios.\nA robust classification framework must be able to generalize across diverse\nacoustic environments and variable source-sensor distances. To this end, we\npresent a deep learning model with robust performance across different\nrecording scenarios. Using a trainable spectral front-end and temporal feature\nencoder to learn a Gabor filterbank, the model can dynamically emphasize\ndifferent frequency components. Trained on the VTUAD hydrophone recordings from\nthe Strait of Georgia, our model, CATFISH, achieves a state-of-the-art 96.63 %\npercent test accuracy across varying source-sensor distances, surpassing the\nprevious benchmark by over 12 percentage points. We present the model, justify\nour architectural choices, analyze the learned Gabor filters, and perform\nablation studies on sensor data fusion and attention-based pooling.", "AI": {"tldr": "CATFISH is a deep learning model for recognizing maritime vessels based on acoustic signatures, achieving 96.63% test accuracy.", "motivation": "Reliably monitoring and recognizing maritime vessels based on acoustic signatures is complicated by the variability of different recording scenarios.", "method": "Using a trainable spectral front-end and temporal feature encoder to learn a Gabor filterbank, the model can dynamically emphasize different frequency components.", "result": "Trained on the VTUAD hydrophone recordings from the Strait of Georgia, our model, CATFISH, achieves a state-of-the-art 96.63 % percent test accuracy across varying source-sensor distances, surpassing the previous benchmark by over 12 percentage points.", "conclusion": "The authors present the model, justify their architectural choices, analyze the learned Gabor filters, and perform ablation studies on sensor data fusion and attention-based pooling."}}
{"id": "2505.24539", "pdf": "https://arxiv.org/pdf/2505.24539", "abs": "https://arxiv.org/abs/2505.24539", "authors": ["Celia Cintas", "Miriam Rateike", "Erik Miehling", "Elizabeth Daly", "Skyler Speakman"], "title": "Localizing Persona Representations in LLMs", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "We present a study on how and where personas -- defined by distinct sets of\nhuman characteristics, values, and beliefs -- are encoded in the representation\nspace of large language models (LLMs). Using a range of dimension reduction and\npattern recognition methods, we first identify the model layers that show the\ngreatest divergence in encoding these representations. We then analyze the\nactivations within a selected layer to examine how specific personas are\nencoded relative to others, including their shared and distinct embedding\nspaces. We find that, across multiple pre-trained decoder-only LLMs, the\nanalyzed personas show large differences in representation space only within\nthe final third of the decoder layers. We observe overlapping activations for\nspecific ethical perspectives -- such as moral nihilism and utilitarianism --\nsuggesting a degree of polysemy. In contrast, political ideologies like\nconservatism and liberalism appear to be represented in more distinct regions.\nThese findings help to improve our understanding of how LLMs internally\nrepresent information and can inform future efforts in refining the modulation\nof specific human traits in LLM outputs. Warning: This paper includes\npotentially offensive sample statements.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u7814\u7a76\u4e86\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\u4e0d\u540c\u4eba\u683c\u7279\u5f81\u7684\u7f16\u7801\u65b9\u5f0f\uff0c\u53d1\u73b0\u6a21\u578b\u6700\u540e\u4e00\u90e8\u5206\u89e3\u7801\u5c42\u4e2d\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002\u4f26\u7406\u89c2\u70b9\u53ef\u80fd\u5b58\u5728\u591a\u4e49\u6027\uff0c\u800c\u653f\u6cbb\u610f\u8bc6\u5f62\u6001\u5219\u76f8\u5bf9\u660e\u786e\u3002", "motivation": "\u4e86\u89e3\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5982\u4f55\u7f16\u7801\u4eba\u7c7b\u7279\u6027\u3001\u4ef7\u503c\u89c2\u548c\u4fe1\u4ef0\uff0c\u6709\u52a9\u4e8e\u4f18\u5316\u6a21\u578b\u5bf9\u7279\u5b9a\u4eba\u7c7b\u7279\u8d28\u7684\u8868\u8fbe\u3002", "method": "\u4f7f\u7528\u964d\u7ef4\u548c\u6a21\u5f0f\u8bc6\u522b\u65b9\u6cd5\u5206\u6790\u591a\u4e2a\u9884\u8bad\u7ec3\u7684\u4ec5\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5404\u5c42\u6fc0\u6d3b\u60c5\u51b5\uff0c\u6bd4\u8f83\u4e0d\u540c\u4eba\u683c\u7279\u5f81\u5728\u8868\u793a\u7a7a\u95f4\u4e2d\u7684\u7f16\u7801\u3002", "result": "\u5728\u591a\u4e2a\u9884\u8bad\u7ec3\u7684\u4ec5\u89e3\u7801\u5668\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e2d\uff0c\u4e0d\u540c\u4eba\u683c\u7279\u5f81\u7684\u8868\u793a\u7a7a\u95f4\u5dee\u5f02\u4e3b\u8981\u96c6\u4e2d\u5728\u89e3\u7801\u5668\u7684\u6700\u540e\u4e00\u90e8\u5206\u3002\u9053\u5fb7\u865a\u65e0\u4e3b\u4e49\u548c\u529f\u5229\u4e3b\u4e49\u7b49\u4f26\u7406\u89c2\u70b9\u8868\u73b0\u51fa\u91cd\u53e0\u7684\u6fc0\u6d3b\u6a21\u5f0f\uff0c\u800c\u4fdd\u5b88\u4e3b\u4e49\u548c\u81ea\u7531\u4e3b\u4e49\u7b49\u653f\u6cbb\u610f\u8bc6\u5f62\u6001\u5219\u5206\u5e03\u5728\u66f4\u72ec\u7acb\u7684\u533a\u57df\u3002", "conclusion": "\u8fd9\u4e9b\u7ed3\u679c\u589e\u8fdb\u4e86\u6211\u4eec\u5bf9\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5185\u90e8\u4fe1\u606f\u8868\u793a\u7684\u7406\u89e3\uff0c\u5e76\u4e3a\u672a\u6765\u6539\u8fdb\u6a21\u578b\u5bf9\u7279\u5b9a\u4eba\u7c7b\u7279\u8d28\u7684\u8c03\u8282\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2505.24541", "pdf": "https://arxiv.org/pdf/2505.24541", "abs": "https://arxiv.org/abs/2505.24541", "authors": ["Xin He", "Xumeng Han", "Longhui Wei", "Lingxi Xie", "Qi Tian"], "title": "Mixpert: Mitigating Multimodal Learning Conflicts with Efficient Mixture-of-Vision-Experts", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Multimodal large language models (MLLMs) require a nuanced interpretation of\ncomplex image information, typically leveraging a vision encoder to perceive\nvarious visual scenarios. However, relying solely on a single vision encoder to\nhandle diverse task domains proves difficult and inevitably leads to conflicts.\nRecent work enhances data perception by directly integrating multiple\ndomain-specific vision encoders, yet this structure adds complexity and limits\nthe potential for joint optimization. In this paper, we introduce Mixpert, an\nefficient mixture-of-vision-experts architecture that inherits the joint\nlearning advantages from a single vision encoder while being restructured into\na multi-expert paradigm for task-specific fine-tuning across different visual\ntasks. Additionally, we design a dynamic routing mechanism that allocates input\nimages to the most suitable visual expert. Mixpert effectively alleviates\ndomain conflicts encountered by a single vision encoder in multi-task learning\nwith minimal additional computational cost, making it more efficient than\nmultiple encoders. Furthermore, Mixpert integrates seamlessly into any MLLM,\nwith experimental results demonstrating substantial performance gains across\nvarious tasks.", "AI": {"tldr": "Mixpert is an efficient mixture-of-vision-experts architecture that enhances MLLMs by inheriting joint learning advantages from a single vision encoder and incorporating a multi-expert paradigm for task-specific fine-tuning, while a dynamic routing mechanism ensures optimal input allocation.", "motivation": "Multimodal large language models (MLLMs) face challenges in interpreting complex image information using a single vision encoder due to domain conflicts. Integrating multiple domain-specific vision encoders enhances data perception but adds complexity and limits joint optimization.", "method": "The paper introduces Mixpert, which combines the benefits of a single vision encoder with a multi-expert paradigm for task-specific fine-tuning across different visual tasks. A dynamic routing mechanism is designed to allocate input images to the most suitable visual expert.", "result": "Mixpert effectively alleviates domain conflicts in multi-task learning with minimal additional computational cost, making it more efficient than using multiple encoders. It integrates seamlessly into any MLLM and demonstrates substantial performance gains across various tasks.", "conclusion": "Mixpert offers an efficient solution for enhancing MLLMs' ability to handle complex image information by addressing domain conflicts and maintaining computational efficiency."}}
{"id": "2505.24544", "pdf": "https://arxiv.org/pdf/2505.24544", "abs": "https://arxiv.org/abs/2505.24544", "authors": ["Wei Zhong", "Manasa Bharadwaj", "Yixiao Wang", "Nikhil Verma", "Yipeng Ji", "Chul Lee"], "title": "Cross-Attention Speculative Decoding", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Speculative decoding (SD) is a widely adopted approach for accelerating\ninference in large language models (LLMs), particularly when the draft and\ntarget models are well aligned. However, state-of-the-art SD methods typically\nrely on tightly coupled, self-attention-based Transformer decoders, often\naugmented with auxiliary pooling or fusion layers. This coupling makes them\nincreasingly complex and harder to generalize across different models. We\npresent Budget EAGLE (Beagle), the first, to our knowledge,\ncross-attention-based Transformer decoder SD model that achieves performance on\npar with leading self-attention SD models (EAGLE-v2) while eliminating the need\nfor pooling or auxiliary components, simplifying the architecture, improving\ntraining efficiency, and maintaining stable memory usage during training-time\nsimulation. To enable effective training of this novel architecture, we propose\nTwo-Stage Block-Attention Training, a new method that achieves training\nstability and convergence efficiency in block-level attention scenarios.\nExtensive experiments across multiple LLMs and datasets show that Beagle\nachieves competitive inference speedups and higher training efficiency than\nEAGLE-v2, offering a strong alternative for architectures in speculative\ndecoding.", "AI": {"tldr": "The paper introduces Budget EAGLE (Beagle), a cross-attention-based Transformer decoder for speculative decoding (SD) in large language models. It simplifies the architecture, improves training efficiency, and maintains stable memory usage. A new training method, Two-Stage Block-Attention Training, is proposed to ensure stability and convergence efficiency.", "motivation": "To address the complexity and lack of generalization in state-of-the-art speculative decoding methods that rely on tightly coupled, self-attention-based Transformer decoders.", "method": "Introduced Beagle, a cross-attention-based Transformer decoder SD model, and Two-Stage Block-Attention Training, a novel training method for block-level attention scenarios.", "result": "Beagle achieves competitive inference speedups and higher training efficiency than EAGLE-v2 across multiple LLMs and datasets.", "conclusion": "Beagle offers a strong alternative for architectures in speculative decoding with its simplified architecture and improved training efficiency."}}
{"id": "2505.23980", "pdf": "https://arxiv.org/pdf/2505.23980", "abs": "https://arxiv.org/abs/2505.23980", "authors": ["Bayu Adhi Tama", "Mansa Krishna", "Homayra Alam", "Mostafa Cham", "Omar Faruque", "Gong Cheng", "Jianwu Wang", "Mathieu Morlighem", "Vandana Janeja"], "title": "DeepTopoNet: A Framework for Subglacial Topography Estimation on the Greenland Ice Sheets", "categories": ["cs.CV", "cs.LG", "eess.IV"], "comment": "Submitted to SIGSPATIAL 2025", "summary": "Understanding Greenland's subglacial topography is critical for projecting\nthe future mass loss of the ice sheet and its contribution to global sea-level\nrise. However, the complex and sparse nature of observational data,\nparticularly information about the bed topography under the ice sheet,\nsignificantly increases the uncertainty in model projections. Bed topography is\ntraditionally measured by airborne ice-penetrating radar that measures the ice\nthickness directly underneath the aircraft, leaving data gap of tens of\nkilometers in between flight lines. This study introduces a deep learning\nframework, which we call as DeepTopoNet, that integrates radar-derived ice\nthickness observations and BedMachine Greenland data through a novel dynamic\nloss-balancing mechanism. Among all efforts to reconstruct bed topography,\nBedMachine has emerged as one of the most widely used datasets, combining mass\nconservation principles and ice thickness measurements to generate\nhigh-resolution bed elevation estimates. The proposed loss function adaptively\nadjusts the weighting between radar and BedMachine data, ensuring robustness in\nareas with limited radar coverage while leveraging the high spatial resolution\nof BedMachine predictions i.e. bed estimates. Our approach incorporates\ngradient-based and trend surface features to enhance model performance and\nutilizes a CNN architecture designed for subgrid-scale predictions. By\nsystematically testing on the Upernavik Isstr{\\o}m) region, the model achieves\nhigh accuracy, outperforming baseline methods in reconstructing subglacial\nterrain. This work demonstrates the potential of deep learning in bridging\nobservational gaps, providing a scalable and efficient solution to inferring\nsubglacial topography.", "AI": {"tldr": "This paper presents DeepTopoNet, a deep learning framework that integrates radar-derived ice thickness observations and BedMachine Greenland data through a novel dynamic loss-balancing mechanism to reconstruct bed topography under the Greenland ice sheet.", "motivation": "The complex and sparse nature of observational data, particularly information about the bed topography under the ice sheet, significantly increases the uncertainty in model projections. Traditional methods like airborne ice-penetrating radar leave large data gaps.", "method": "The study introduces DeepTopoNet, which incorporates gradient-based and trend surface features, uses a CNN architecture for subgrid-scale predictions, and employs a loss function that adaptively adjusts the weighting between radar and BedMachine data.", "result": "By systematically testing on the Upernavik Isstr{\\o}m region, the model achieves high accuracy, outperforming baseline methods in reconstructing subglacial terrain.", "conclusion": "This work demonstrates the potential of deep learning in bridging observational gaps and provides a scalable and efficient solution to inferring subglacial topography."}}
{"id": "2505.24553", "pdf": "https://arxiv.org/pdf/2505.24553", "abs": "https://arxiv.org/abs/2505.24553", "authors": ["Ye Eun Chun", "Taeyoon Hwang", "Seung-won Hwang", "Byung-Hak Kim"], "title": "CREFT: Sequential Multi-Agent LLM for Character Relation Extraction", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Understanding complex character relations is crucial for narrative analysis\nand efficient script evaluation, yet existing extraction methods often fail to\nhandle long-form narratives with nuanced interactions. To address this\nchallenge, we present CREFT, a novel sequential framework leveraging\nspecialized Large Language Model (LLM) agents. First, CREFT builds a base\ncharacter graph through knowledge distillation, then iteratively refines\ncharacter composition, relation extraction, role identification, and group\nassignments. Experiments on a curated Korean drama dataset demonstrate that\nCREFT significantly outperforms single-agent LLM baselines in both accuracy and\ncompleteness. By systematically visualizing character networks, CREFT\nstreamlines narrative comprehension and accelerates script review -- offering\nsubstantial benefits to the entertainment, publishing, and educational sectors.", "AI": {"tldr": "CREFT is a new framework using specialized LLM agents to analyze complex character relations in narratives, outperforming single-agent models and aiding script evaluation.", "motivation": "Existing methods struggle with extracting character relations in long-form narratives with subtle interactions.", "method": "CREFT builds a base character graph via knowledge distillation then refines character composition, relation extraction, role identification, and group assignments iteratively.", "result": "Experiments on Korean drama dataset show CREFT surpasses single-agent LLMs in accuracy and completeness.", "conclusion": "CREFT enhances narrative understanding and accelerates script review, benefiting entertainment, publishing, and education sectors."}}
{"id": "2505.24554", "pdf": "https://arxiv.org/pdf/2505.24554", "abs": "https://arxiv.org/abs/2505.24554", "authors": ["Anna Sofia Lippolis", "Minh Davide Ragagni", "Paolo Ciancarini", "Andrea Giovanni Nuzzolese", "Valentina Presutti"], "title": "Bench4KE: Benchmarking Automated Competency Question Generation", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "The availability of Large Language Models (LLMs) presents a unique\nopportunity to reinvigorate research on Knowledge Engineering (KE) automation,\na trend already evident in recent efforts developing LLM-based methods and\ntools for the automatic generation of Competency Questions (CQs). However, the\nevaluation of these tools lacks standardisation. This undermines the\nmethodological rigour and hinders the replication and comparison of results. To\naddress this gap, we introduce Bench4KE, an extensible API-based benchmarking\nsystem for KE automation. Its first release focuses on evaluating tools that\ngenerate CQs automatically. CQs are natural language questions used by ontology\nengineers to define the functional requirements of an ontology. Bench4KE\nprovides a curated gold standard consisting of CQ datasets from four real-world\nontology projects. It uses a suite of similarity metrics to assess the quality\nof the CQs generated. We present a comparative analysis of four recent CQ\ngeneration systems, which are based on LLMs, establishing a baseline for future\nresearch. Bench4KE is also designed to accommodate additional KE automation\ntasks, such as SPARQL query generation, ontology testing and drafting. Code and\ndatasets are publicly available under the Apache 2.0 license.", "AI": {"tldr": "The paper introduces Bench4KE, an API-based benchmarking system for Knowledge Engineering automation, focusing on evaluating tools that automatically generate Competency Questions (CQs). It provides a gold standard dataset and uses similarity metrics to assess CQ quality. A comparative analysis of four LLM-based CQ generation systems is presented, establishing a baseline for future research.", "motivation": "The motivation behind this paper is the lack of standardization in evaluating tools for automatic generation of Competency Questions (CQs), which undermines methodological rigour and hinders replication and comparison of results.", "method": "The authors introduce Bench4KE, an extensible API-based benchmarking system for Knowledge Engineering automation. It includes a curated gold standard of CQ datasets from real-world ontology projects and uses various similarity metrics to evaluate CQ quality.", "result": "A comparative analysis of four recent CQ generation systems based on LLMs was conducted, providing insights into their performance and establishing a baseline for future research.", "conclusion": "Bench4KE addresses the gap in standardizing the evaluation of KE automation tools, particularly those generating CQs. The system is designed to be extensible to other KE automation tasks, and its resources are publicly available."}}
{"id": "2505.24006", "pdf": "https://arxiv.org/pdf/2505.24006", "abs": "https://arxiv.org/abs/2505.24006", "authors": ["Agnideep Aich", "Sameera Hewage", "Md Monzur Murshed", "Ashit Baran Aich", "Amanda Mayeaux", "Asim K. Dey", "Kumer P. Das", "Bruce Wade"], "title": "A2 Copula-Driven Spatial Bayesian Neural Network For Modeling Non-Gaussian Dependence: A Simulation Study", "categories": ["stat.ME", "cs.LG", "stat.ML", "62H12, 62P10, 65C20, 62F15, 68T07"], "comment": null, "summary": "In this paper, we introduce the A2 Copula Spatial Bayesian Neural Network\n(A2-SBNN), a predictive spatial model designed to map coordinates to continuous\nfields while capturing both typical spatial patterns and extreme dependencies.\nBy embedding the dual-tail novel Archimedean copula viz. A2 directly into the\nnetwork's weight initialization, A2-SBNN naturally models complex spatial\nrelationships, including rare co-movements in the data. The model is trained\nthrough a calibration-driven process combining Wasserstein loss, moment\nmatching, and correlation penalties to refine predictions and manage\nuncertainty. Simulation results show that A2-SBNN consistently delivers high\naccuracy across a wide range of dependency strengths, offering a new, effective\nsolution for spatial data modeling beyond traditional Gaussian-based\napproaches.", "AI": {"tldr": "The paper introduces A2-SBNN, a spatial model using Archimedean copula in weight initialization for modeling complex spatial relationships and extreme dependencies. It is trained with Wasserstein loss, moment matching, and correlation penalties.", "motivation": "To develop a predictive spatial model that can map coordinates to continuous fields while capturing both typical spatial patterns and extreme dependencies beyond traditional Gaussian-based approaches.", "method": "Introduce A2 Copula Spatial Bayesian Neural Network (A2-SBNN) which embeds the dual-tail novel Archimedean copula directly into the network's weight initialization. The model is trained through a calibration-driven process combining Wasserstein loss, moment matching, and correlation penalties.", "result": "Simulation results indicate that A2-SBNN consistently delivers high accuracy across a wide range of dependency strengths.", "conclusion": "A2-SBNN offers a new, effective solution for spatial data modeling."}}
{"id": "2505.24575", "pdf": "https://arxiv.org/pdf/2505.24575", "abs": "https://arxiv.org/abs/2505.24575", "authors": ["Hyuntak Kim", "Byung-Hak Kim"], "title": "NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to the main track of ACL 2025", "summary": "Summarizing long-form narratives--such as books, movies, and TV\nscripts--requires capturing intricate plotlines, character interactions, and\nthematic coherence, a task that remains challenging for existing LLMs. We\nintroduce NexusSum, a multi-agent LLM framework for narrative summarization\nthat processes long-form text through a structured, sequential\npipeline--without requiring fine-tuning. Our approach introduces two key\ninnovations: (1) Dialogue-to-Description Transformation: A narrative-specific\npreprocessing method that standardizes character dialogue and descriptive text\ninto a unified format, improving coherence. (2) Hierarchical Multi-LLM\nSummarization: A structured summarization pipeline that optimizes chunk\nprocessing and controls output length for accurate, high-quality summaries. Our\nmethod establishes a new state-of-the-art in narrative summarization, achieving\nup to a 30.0% improvement in BERTScore (F1) across books, movies, and TV\nscripts. These results demonstrate the effectiveness of multi-agent LLMs in\nhandling long-form content, offering a scalable approach for structured\nsummarization in diverse storytelling domains.", "AI": {"tldr": "NexusSum is a multi-agent LLM framework for narrative summarization which introduces Dialogue-to-Description Transformation and Hierarchical Multi-LLM Summarization, achieving up to 30.0% improvement in BERTScore (F1).", "motivation": "Existing LLMs face challenges in summarizing long-form narratives due to intricate plotlines, character interactions, and thematic coherence.", "method": "The method includes two key innovations: Dialogue-to-Description Transformation that standardizes character dialogue and descriptive text into a unified format; and Hierarchical Multi-LLM Summarization that optimizes chunk processing and controls output length.", "result": "This method establishes a new state-of-the-art in narrative summarization with up to 30.0% improvement in BERTScore (F1) across books, movies, and TV scripts.", "conclusion": "NexusSum demonstrates the effectiveness of multi-agent LLMs in handling long-form content and offers a scalable approach for structured summarization in diverse storytelling domains."}}
{"id": "2505.24016", "pdf": "https://arxiv.org/pdf/2505.24016", "abs": "https://arxiv.org/abs/2505.24016", "authors": ["Matthew Raffel", "Victor Agostinelli", "Lizhong Chen"], "title": "BeaverTalk: Oregon State University's IWSLT 2025 Simultaneous Speech Translation System", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at IWSLT 2025", "summary": "This paper discusses the construction, fine-tuning, and deployment of\nBeaverTalk, a cascaded system for speech-to-text translation as part of the\nIWSLT 2025 simultaneous translation task. The system architecture employs a VAD\nsegmenter for breaking a speech stream into segments, Whisper Large V2 for\nautomatic speech recognition (ASR), and Gemma 3 12B for simultaneous\ntranslation. Regarding the simultaneous translation LLM, it is fine-tuned via\nlow-rank adaptors (LoRAs) for a conversational prompting strategy that\nleverages a single prior-sentence memory bank from the source language as\ncontext. The cascaded system participated in the English$\\rightarrow$German and\nEnglish$\\rightarrow$Chinese language directions for both the low and high\nlatency regimes. In particular, on the English$\\rightarrow$German task, the\nsystem achieves a BLEU of 24.64 and 27.83 at a StreamLAAL of 1837.86 and\n3343.73, respectively. Then, on the English$\\rightarrow$Chinese task, the\nsystem achieves a BLEU of 34.07 and 37.23 at a StreamLAAL of 2216.99 and\n3521.35, respectively.", "AI": {"tldr": "This paper discusses the construction, fine-tuning, and deployment of BeaverTalk, a cascaded system for speech-to-text translation.", "motivation": "To develop an effective system for simultaneous speech-to-text translation in multiple language directions.", "method": "The system architecture employs a VAD segmenter for breaking a speech stream into segments, Whisper Large V2 for automatic speech recognition (ASR), and Gemma 3 12B for simultaneous translation. Fine-tuned via low-rank adaptors (LoRAs) for a conversational prompting strategy.", "result": "On the English\u2192German task, BLEU scores are 24.64 and 27.83 at different StreamLAALs. On the English\u2192Chinese task, BLEU scores are 34.07 and 37.23 at different StreamLAALs.", "conclusion": "BeaverTalk is a successfully constructed, fine-tuned, and deployed cascaded system for speech-to-text translation."}}
{"id": "2505.24032", "pdf": "https://arxiv.org/pdf/2505.24032", "abs": "https://arxiv.org/abs/2505.24032", "authors": ["Sergei S. Kuzmin", "Ivan V. Dyakonov", "Stanislav S. Straupe"], "title": "Leveraging machine learning features for linear optical interferometer control", "categories": ["quant-ph", "cs.LG", "physics.optics"], "comment": "8 pages, 8 figures", "summary": "We have developed an algorithm that constructs a model of a reconfigurable\noptical interferometer, independent of specific architectural constraints. The\nprogramming of unitary transformations on the interferometer's optical modes\nrelies on either an analytical method for deriving the unitary matrix from a\nset of phase shifts or an optimization routine when such decomposition is not\navailable. Our algorithm employs a supervised learning approach, aligning the\ninterferometer model with a training set derived from the device being studied.\nA straightforward optimization procedure leverages this trained model to\ndetermine the phase shifts of the interferometer with a specific architecture,\nobtaining the required unitary transformation. This approach enables the\neffective tuning of interferometers without requiring a precise analytical\nsolution, paving the way for the exploration of new interferometric circuit\narchitectures.", "AI": {"tldr": "An algorithm for constructing a model of a reconfigurable optical interferometer is developed, which uses supervised learning and optimization to determine phase shifts for unitary transformations without needing precise analytical solutions.", "motivation": "To create a model of a reconfigurable optical interferometer that is independent of specific architectural constraints and can effectively tune interferometers without requiring a precise analytical solution.", "method": "The algorithm employs a supervised learning approach to align the interferometer model with a training set derived from the device being studied. Then, an optimization procedure is used to determine the phase shifts of the interferometer with a specific architecture to obtain the required unitary transformation.", "result": "This approach allows for the effective tuning of interferometers without needing a precise analytical solution, opening up possibilities for exploring new interferometric circuit architectures.", "conclusion": "The developed algorithm successfully constructs a model of a reconfigurable optical interferometer using supervised learning and optimization, allowing for exploration of new interferometric circuit architectures."}}
{"id": "2505.24593", "pdf": "https://arxiv.org/pdf/2505.24593", "abs": "https://arxiv.org/abs/2505.24593", "authors": ["Junzhuo Li", "Bo Wang", "Xiuze Zhou", "Peijie Jiang", "Jia Liu", "Xuming Hu"], "title": "Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis", "categories": ["cs.CL", "cs.AI", "cs.LG"], "comment": "ACL 2025", "summary": "The interpretability of Mixture-of-Experts (MoE) models, especially those\nwith heterogeneous designs, remains underexplored. Existing attribution methods\nfor dense models fail to capture dynamic routing-expert interactions in sparse\nMoE architectures. To address this issue, we propose a cross-level attribution\nalgorithm to analyze sparse MoE architectures (Qwen 1.5-MoE, OLMoE,\nMixtral-8x7B) against dense models (Qwen 1.5-7B, Llama-7B, Mixtral-7B). Results\nshow MoE models achieve 37% higher per-layer efficiency via a \"mid-activation,\nlate-amplification\" pattern: early layers screen experts, while late layers\nrefine knowledge collaboratively. Ablation studies reveal a \"basic-refinement\"\nframework--shared experts handle general tasks (entity recognition), while\nrouted experts specialize in domain-specific processing (geographic\nattributes). Semantic-driven routing is evidenced by strong correlations\nbetween attention heads and experts (r=0.68), enabling task-aware coordination.\nNotably, architectural depth dictates robustness: deep Qwen 1.5-MoE mitigates\nexpert failures (e.g., 43% MRR drop in geographic tasks when blocking top-10\nexperts) through shared expert redundancy, whereas shallow OLMoE suffers severe\ndegradation (76% drop). Task sensitivity further guides design: core-sensitive\ntasks (geography) require concentrated expertise, while distributed-tolerant\ntasks (object attributes) leverage broader participation. These insights\nadvance MoE interpretability, offering principles to balance efficiency,\nspecialization, and robustness.", "AI": {"tldr": "MoE\u6a21\u578b\u901a\u8fc7\"\u4e2d\u671f\u6fc0\u6d3b\uff0c\u540e\u671f\u653e\u5927\"\u6a21\u5f0f\u5b9e\u73b0\u6bcf\u5c42\u6548\u7387\u63d0\u9ad837%\uff0c\u6df1\u5ea6\u67b6\u6784\u63d0\u5347\u9c81\u68d2\u6027\uff0c\u4efb\u52a1\u654f\u611f\u6027\u6307\u5bfc\u8bbe\u8ba1\u3002", "motivation": "\u73b0\u6709\u7684\u5f52\u56e0\u65b9\u6cd5\u65e0\u6cd5\u6355\u6349\u7a00\u758fMoE\u67b6\u6784\u4e2d\u52a8\u6001\u8def\u7531-\u4e13\u5bb6\u4ea4\u4e92\uff0c\u7279\u522b\u662f\u5728\u5f02\u6784\u8bbe\u8ba1\u7684MoE\u6a21\u578b\u4e2d\u7684\u89e3\u91ca\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8de8\u5c42\u6b21\u5f52\u56e0\u7b97\u6cd5\uff0c\u7528\u4e8e\u5206\u6790\u7a00\u758fMoE\u67b6\u6784\uff08Qwen 1.5-MoE\u3001OLMoE\u3001Mixtral-8x7B\uff09\u4e0e\u5bc6\u96c6\u6a21\u578b\uff08Qwen 1.5-7B\u3001Llama-7B\u3001Mixtral-7B\uff09\u7684\u5bf9\u6bd4\u8868\u73b0\u3002", "result": "MoE\u6a21\u578b\u901a\u8fc7\"\u4e2d\u671f\u6fc0\u6d3b\uff0c\u540e\u671f\u653e\u5927\"\u6a21\u5f0f\u5728\u6bcf\u5c42\u6548\u7387\u4e0a\u63d0\u9ad8\u4e8637%\uff1b\u6d88\u878d\u7814\u7a76\u8868\u660e\u5171\u4eab\u4e13\u5bb6\u5904\u7406\u4e00\u822c\u4efb\u52a1\uff0c\u8def\u7531\u4e13\u5bb6\u4e13\u6ce8\u4e8e\u7279\u5b9a\u9886\u57df\u5904\u7406\uff1b\u67b6\u6784\u6df1\u5ea6\u51b3\u5b9a\u4e86\u6a21\u578b\u7684\u9c81\u68d2\u6027\uff1b\u4efb\u52a1\u654f\u611f\u6027\u8fdb\u4e00\u6b65\u6307\u5bfc\u4e86\u6a21\u578b\u8bbe\u8ba1\u3002", "conclusion": "\u8fd9\u4e9b\u53d1\u73b0\u63a8\u8fdb\u4e86MoE\u6a21\u578b\u7684\u53ef\u89e3\u91ca\u6027\uff0c\u5e76\u63d0\u4f9b\u4e86\u5e73\u8861\u6548\u7387\u3001\u4e13\u4e1a\u5316\u548c\u9c81\u68d2\u6027\u7684\u539f\u5219\u3002"}}
{"id": "2505.24033", "pdf": "https://arxiv.org/pdf/2505.24033", "abs": "https://arxiv.org/abs/2505.24033", "authors": ["Yasaman Jafari", "Zixian Wang", "Leon Bergen", "Taylor Berg-Kirkpatrick"], "title": "The Surprising Soupability of Documents in State Space Models", "categories": ["cs.CL", "cs.CE", "cs.LG"], "comment": null, "summary": "We investigate whether hidden states from Structured State Space Models\n(SSMs) can be merged post-hoc to support downstream reasoning. Inspired by\nmodel souping, we propose a strategy where documents are encoded independently\nand their representations are pooled -- via simple operations like averaging --\ninto a single context state. This approach, which we call document souping,\nenables modular encoding and reuse without reprocessing the full input for each\nquery. We finetune Mamba2 models to produce soupable representations and find\nthat they support multi-hop QA, sparse retrieval, and long-document reasoning\nwith strong accuracy. On HotpotQA, souping ten independently encoded documents\nnearly matches the performance of a cross-encoder trained on the same inputs.", "AI": {"tldr": "\u901a\u8fc7\u5c06\u9690\u85cf\u72b6\u6001\u5408\u5e76\uff0c\u7814\u7a76\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\uff08SSMs\uff09\u662f\u5426\u53ef\u4ee5\u652f\u6301\u4e0b\u6e38\u63a8\u7406\uff0c\u5e76\u63d0\u51fa\u6587\u6863\u6c64\u65b9\u6cd5\uff0c\u5b9e\u73b0\u6a21\u5757\u5316\u7f16\u7801\u548c\u91cd\u7528\uff0c\u5b9e\u9a8c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u591a\u8df3\u95ee\u7b54\u3001\u7a00\u758f\u68c0\u7d22\u548c\u957f\u6587\u6863\u63a8\u7406\u65b9\u9762\u5177\u6709\u9ad8\u51c6\u786e\u6027\u3002", "motivation": "\u7814\u7a76\u9690\u85cf\u72b6\u6001\u4ece\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u80fd\u5426\u5728\u4e8b\u540e\u88ab\u5408\u5e76\u4ee5\u652f\u6301\u4e0b\u6e38\u63a8\u7406\u3002", "method": "\u53d7\u6a21\u578b\u6c64\u7684\u542f\u53d1\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7b56\u7565\uff0c\u5373\u6587\u6863\u72ec\u7acb\u7f16\u7801\u5e76\u901a\u8fc7\u7b80\u5355\u64cd\u4f5c\uff08\u5982\u5e73\u5747\uff09\u5c06\u5176\u8868\u793a\u6c47\u96c6\u5230\u4e00\u4e2a\u5355\u4e00\u7684\u72b6\u6001\u3002\u8fd9\u79cd\u65b9\u6cd5\u88ab\u79f0\u4e3a\u6587\u6863\u6c64\uff0c\u5b83\u80fd\u591f\u5728\u4e0d\u91cd\u65b0\u5904\u7406\u6574\u4e2a\u8f93\u5165\u7684\u60c5\u51b5\u4e0b\u8fdb\u884c\u6a21\u5757\u5316\u7f16\u7801\u548c\u91cd\u7528\u3002", "result": "\u5fae\u8c03\u540e\u7684Mamba2\u6a21\u578b\u751f\u6210\u53ef\u6c64\u8868\u793a\uff0c\u652f\u6301\u591a\u8df3\u95ee\u7b54\u3001\u7a00\u758f\u68c0\u7d22\u548c\u957f\u6587\u6863\u63a8\u7406\uff0c\u5e76\u4e14\u5728HotpotQA\u6570\u636e\u96c6\u4e0a\uff0c\u5bf9\u5341\u4e2a\u72ec\u7acb\u7f16\u7801\u7684\u6587\u6863\u8fdb\u884c\u6c64\u64cd\u4f5c\u51e0\u4e4e\u8fbe\u5230\u4e86\u4e0e\u5728\u540c\u4e00\u8f93\u5165\u4e0a\u8bad\u7ec3\u7684\u4ea4\u53c9\u7f16\u7801\u5668\u76f8\u540c\u7684\u6027\u80fd\u3002", "conclusion": "\u6587\u6863\u6c64\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5730\u652f\u6301\u4e0b\u6e38\u4efb\u52a1\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u9ad8\u7684\u51c6\u786e\u6027\u548c\u6548\u7387\u3002"}}
{"id": "2505.24038", "pdf": "https://arxiv.org/pdf/2505.24038", "abs": "https://arxiv.org/abs/2505.24038", "authors": ["L\u00e9o And\u00e9ol", "Luca Mossina", "Adrien Mazoyer", "S\u00e9bastien Gerchinovitz"], "title": "Conformal Object Detection by Sequential Risk Control", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": "28 pages, 11 figures", "summary": "Recent advances in object detectors have led to their adoption for industrial\nuses. However, their deployment in critical applications is hindered by the\ninherent lack of reliability of neural networks and the complex structure of\nobject detection models. To address these challenges, we turn to Conformal\nPrediction, a post-hoc procedure which offers statistical guarantees that are\nvalid for any dataset size, without requiring prior knowledge on the model or\ndata distribution. Our contribution is manifold: first, we formally define the\nproblem of Conformal Object Detection (COD) and introduce a novel method,\nSequential Conformal Risk Control (SeqCRC), that extends the statistical\nguarantees of Conformal Risk Control (CRC) to two sequential tasks with two\nparameters, as required in the COD setting. Then, we propose loss functions and\nprediction sets suited to applying CRC to different applications and\ncertification requirements. Finally, we present a conformal toolkit, enabling\nreplication and further exploration of our methods. Using this toolkit, we\nperform extensive experiments, yielding a benchmark that validates the\ninvestigated methods and emphasizes trade-offs and other practical\nconsequences.", "AI": {"tldr": "Recent advances in object detectors have led to their adoption for industrial uses. However, their deployment in critical applications is hindered by the inherent lack of reliability of neural networks and the complex structure of object detection models. To address these challenges, we turn to Conformal Prediction.", "motivation": "The motivation of this paper is to improve the reliability of object detection models in critical applications, addressing the issues caused by the inherent lack of reliability of neural networks and the complex structure of object detection models.", "method": "The authors formally define the problem of Conformal Object Detection (COD) and introduce a novel method, Sequential Conformal Risk Control (SeqCRC), that extends the statistical guarantees of Conformal Risk Control (CRC) to two sequential tasks with two parameters. They also propose loss functions and prediction sets suited to applying CRC to different applications and certification requirements.", "result": "The authors present a conformal toolkit that enables replication and further exploration of their methods. Through extensive experiments, they yield a benchmark that validates the investigated methods and emphasizes trade-offs and other practical consequences.", "conclusion": "This paper addresses the challenges in deploying object detectors in critical applications by introducing SeqCRC and providing a conformal toolkit for further research."}}
{"id": "2505.24616", "pdf": "https://arxiv.org/pdf/2505.24616", "abs": "https://arxiv.org/abs/2505.24616", "authors": ["Nikita Martynov", "Anastasia Mordasheva", "Dmitriy Gorbetskiy", "Danil Astafurov", "Ulyana Isaeva", "Elina Basyrova", "Sergey Skachkov", "Victoria Berestova", "Nikolay Ivanov", "Valeriia Zanina", "Alena Fenogenova"], "title": "Eye of Judgement: Dissecting the Evaluation of Russian-speaking LLMs with POLLUX", "categories": ["cs.CL", "cs.AI"], "comment": "179 pages", "summary": "We introduce POLLUX, a comprehensive open-source benchmark designed to\nevaluate the generative capabilities of large language models (LLMs) in\nRussian. Our main contribution is a novel evaluation methodology that enhances\nthe interpretability of LLM assessment. For each task type, we define a set of\ndetailed criteria and develop a scoring protocol where models evaluate\nresponses and provide justifications for their ratings. This enables\ntransparent, criteria-driven evaluation beyond traditional resource-consuming,\nside-by-side human comparisons. POLLUX includes a detailed, fine-grained\ntaxonomy of 35 task types covering diverse generative domains such as code\ngeneration, creative writing, and practical assistant use cases, totaling 2,100\nmanually crafted and professionally authored prompts. Each task is categorized\nby difficulty (easy/medium/hard), with experts constructing the dataset\nentirely from scratch. We also release a family of LLM-as-a-Judge (7B and 32B)\nevaluators trained for nuanced assessment of generative outputs. This approach\nprovides scalable, interpretable evaluation and annotation tools for model\ndevelopment, effectively replacing costly and less precise human judgments.", "AI": {"tldr": "The paper presents POLLUX, an open-source benchmark for evaluating Russian large language models with a novel methodology including detailed criteria and scoring protocols.", "motivation": "To create a more interpretable, scalable evaluation system for large language models in Russian that reduces reliance on human judgments.", "method": "Developed a taxonomy of 35 task types, provided detailed criteria and a scoring protocol where models evaluate each other's responses, introduced LLM-as-a-Judge evaluators (7B and 32B) for nuanced assessment.", "result": "POLLUX includes 2,100 manually crafted prompts categorized by difficulty and provides tools for transparent, criteria-driven evaluation beyond traditional human comparisons.", "conclusion": "POLLUX offers a comprehensive, open-source benchmark and evaluation methodology for Russian LLMs, enhancing interpretability and reducing costs associated with human evaluations."}}
{"id": "2505.24062", "pdf": "https://arxiv.org/pdf/2505.24062", "abs": "https://arxiv.org/abs/2505.24062", "authors": ["Kamyar Barakati", "Yu Liu", "Hiroshi Funakubo", "Sergei V. Kalinin"], "title": "Exploring Domain Wall Pinning in Ferroelectrics via Automated High Throughput AFM", "categories": ["cond-mat.mtrl-sci", "cs.CV", "cs.LG", "physics.app-ph"], "comment": "17 pages, 6 figures", "summary": "Domain-wall dynamics in ferroelectric materials are strongly\nposition-dependent since each polar interface is locked into a unique local\nmicrostructure. This necessitates spatially resolved studies of the\nwall-pinning using scanning-probe microscopy techniques. The pinning centers\nand preexisting domain walls are usually sparse within image plane, precluding\nthe use of dense hyperspectral imaging modes and requiring time-consuming human\nexperimentation. Here, a large area epitaxial PbTiO$_3$ film on cubic KTaO$_3$\nwere investigated to quantify the electric field driven dynamics of the\npolar-strain domain structures using ML-controlled automated Piezoresponse\nForce Microscopy. Analysis of 1500 switching events reveals that domain wall\ndisplacement depends not only on field parameters but also on the local\nferroelectric-ferroelastic configuration. For example, twin boundaries in\npolydomains regions like a$_1^-$/$c^+$ $\\parallel$ a$_2^-$/$c^-$ stay pinned up\nto a certain level of bias magnitude and change only marginally as the bias\nincreases from 20V to 30V, whereas single variant boundaries like a$_2^+$/$c^+$\n$\\parallel$ a$_2^-$/$c^-$ stack are already activated at 20V. These statistics\non the possible ferroelectric and ferroelastic wall orientations, together with\nthe automated, high-throughput AFM workflow, can be distilled into a predictive\nmap that links domain configurations to pulse parameters. This\nmicrostructure-specific rule set forms the foundation for designing\nferroelectric memories.", "AI": {"tldr": "This paper uses ML-controlled automated Piezoresponse Force Microscopy to study the electric field driven dynamics of polar-strain domain structures in a large area epitaxial PbTiO3 film on cubic KTaO3. Analysis of 1500 switching events reveals that domain wall displacement depends not only on field parameters but also on the local ferroelectric-ferroelastic configuration.", "motivation": "Domain-wall dynamics in ferroelectric materials are strongly position-dependent, necessitating spatially resolved studies of the wall-pinning using scanning-probe microscopy techniques.", "method": "Investigation of a large area epitaxial PbTiO3 film on cubic KTaO3 using ML-controlled automated Piezoresponse Force Microscopy to quantify the electric field driven dynamics of the polar-strain domain structures.", "result": "Analysis of 1500 switching events reveals that domain wall displacement depends not only on field parameters but also on the local ferroelectric-ferroelastic configuration.", "conclusion": "The statistics on the possible ferroelectric and ferroelastic wall orientations, together with the automated, high-throughput AFM workflow, can be distilled into a predictive map that links domain configurations to pulse parameters, forming the foundation for designing ferroelectric memories."}}
{"id": "2505.24065", "pdf": "https://arxiv.org/pdf/2505.24065", "abs": "https://arxiv.org/abs/2505.24065", "authors": ["Isaiah A. Moses", "Chen Chen", "Joan M. Redwing", "Wesley F. Reinhart"], "title": "Cross-Modal Characterization of Thin Film MoS$_2$ Using Generative Models", "categories": ["cond-mat.mtrl-sci", "cs.LG", "physics.app-ph"], "comment": "36 pages, 10 figures, 10 tables", "summary": "The growth and characterization of materials using empirical optimization\ntypically requires a significant amount of expert time, experience, and\nresources. Several complementary characterization methods are routinely\nperformed to determine the quality and properties of a grown sample. Machine\nlearning (ML) can support the conventional approaches by using historical data\nto guide and provide speed and efficiency to the growth and characterization of\nmaterials. Specifically, ML can provide quantitative information from\ncharacterization data that is typically obtained from a different modality. In\nthis study, we have investigated the feasibility of projecting the quantitative\nmetric from microscopy measurements, such as atomic force microscopy (AFM),\nusing data obtained from spectroscopy measurements, like Raman spectroscopy.\nGenerative models were also trained to generate the full and specific features\nof the Raman and photoluminescence spectra from each other and the AFM images\nof the thin film MoS$_2$. The results are promising and have provided a\nfoundational guide for the use of ML for the cross-modal characterization of\nmaterials for their accelerated, efficient, and cost-effective discovery.", "AI": {"tldr": "The paper explores using machine learning to project quantitative metrics from one characterization method to another, speeding up material growth and characterization. Generative models were trained to translate between Raman spectroscopy, photoluminescence spectra, and AFM images of MoS$_2$ thin films, with promising results.", "motivation": "Material growth and characterization typically require significant expert time, experience, and resources. Conventional methods involve multiple characterization techniques to determine sample quality and properties. Machine learning could enhance these processes by leveraging historical data to provide speed and efficiency.", "method": "Investigated projecting quantitative metric from microscopy measurements (AFM) using spectroscopy data (Raman). Trained generative models to generate features of Raman and photoluminescence spectra from each other and AFM images of MoS$_2$ thin films.", "result": "Generative models successfully translated between different modalities (Raman, photoluminescence, AFM). The approach provided a foundational guide for using ML in cross-modal material characterization.", "conclusion": "Machine learning, particularly generative models, shows promise in accelerating, enhancing efficiency, and reducing costs in material characterization through cross-modal data translation."}}
{"id": "2505.24625", "pdf": "https://arxiv.org/pdf/2505.24625", "abs": "https://arxiv.org/abs/2505.24625", "authors": ["Duo Zheng", "Shijia Huang", "Yanyang Li", "Liwei Wang"], "title": "Learning from Videos for 3D World: Enhancing MLLMs with 3D Vision Geometry Priors", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Previous research has investigated the application of Multimodal Large\nLanguage Models (MLLMs) in understanding 3D scenes by interpreting them as\nvideos. These approaches generally depend on comprehensive 3D data inputs, such\nas point clouds or reconstructed Bird's-Eye View (BEV) maps. In our research,\nwe advance this field by enhancing the capability of MLLMs to understand and\nreason in 3D spaces directly from video data, without the need for additional\n3D input. We propose a novel and efficient method, the Video-3D Geometry Large\nLanguage Model (VG LLM). Our approach employs a 3D visual geometry encoder that\nextracts 3D prior information from video sequences. This information is\nintegrated with visual tokens and fed into the MLLM. Extensive experiments have\nshown that our method has achieved substantial improvements in various tasks\nrelated to 3D scene understanding and spatial reasoning, all directly learned\nfrom video sources. Impressively, our 4B model, which does not rely on explicit\n3D data inputs, achieves competitive results compared to existing\nstate-of-the-art methods, and even surpasses the Gemini-1.5-Pro in the\nVSI-Bench evaluations.", "AI": {"tldr": "The paper presents VG LLM, a method that enables MLLMs to understand 3D spaces from video data without additional 3D inputs, showing improvements in 3D scene understanding and spatial reasoning tasks.", "motivation": "Current methods for understanding 3D scenes using MLLMs rely on comprehensive 3D data inputs like point clouds or BEV maps. The research aims to eliminate the need for such additional 3D inputs.", "method": "The proposed method, VG LLM, uses a 3D visual geometry encoder to extract 3D prior information from video sequences. This information is combined with visual tokens and processed by the MLLM.", "result": "Experiments indicate significant improvements in various tasks related to 3D scene understanding and spatial reasoning. Notably, the 4B model achieves competitive results compared to state-of-the-art methods and surpasses Gemini-1.5-Pro in VSI-Bench evaluations.", "conclusion": "VG LLM successfully enhances MLLMs' capability to understand and reason in 3D spaces directly from video data, demonstrating its potential in advancing 3D scene understanding."}}
{"id": "2505.24097", "pdf": "https://arxiv.org/pdf/2505.24097", "abs": "https://arxiv.org/abs/2505.24097", "authors": ["Victor Li", "Baiting Chen", "Yuzhen Mao", "Qi Lei", "Zhun Deng"], "title": "Performative Risk Control: Calibrating Models for Reliable Deployment under Performativity", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Calibrating blackbox machine learning models to achieve risk control is\ncrucial to ensure reliable decision-making. A rich line of literature has been\nstudying how to calibrate a model so that its predictions satisfy explicit\nfinite-sample statistical guarantees under a fixed, static, and unknown\ndata-generating distribution. However, prediction-supported decisions may\ninfluence the outcome they aim to predict, a phenomenon named performativity of\npredictions, which is commonly seen in social science and economics. In this\npaper, we introduce Performative Risk Control, a framework to calibrate models\nto achieve risk control under performativity with provable theoretical\nguarantees. Specifically, we provide an iteratively refined calibration\nprocess, where we ensure the predictions are improved and risk-controlled\nthroughout the process. We also study different types of risk measures and\nchoices of tail bounds. Lastly, we demonstrate the effectiveness of our\nframework by numerical experiments on the task of predicting credit default\nrisk. To the best of our knowledge, this work is the first one to study\nstatistically rigorous risk control under performativity, which will serve as\nan important safeguard against a wide range of strategic manipulation in\ndecision-making processes.", "AI": {"tldr": "This paper introduces Performative Risk Control, a framework for calibrating machine learning models to achieve risk control under performativity with theoretical guarantees. It provides an iterative calibration process and demonstrates effectiveness in predicting credit default risk.", "motivation": "Calibrating blackbox machine learning models is crucial for reliable decision-making, but existing methods do not account for the performativity of predictions where decisions influence outcomes.", "method": "The paper proposes Performative Risk Control, an iteratively refined calibration process that ensures predictions are improved and risk-controlled. It studies different risk measures and tail bounds.", "result": "The framework demonstrates effectiveness in numerical experiments on predicting credit default risk.", "conclusion": "This work is the first to study statistically rigorous risk control under performativity, providing a safeguard against strategic manipulation in decision-making processes."}}
{"id": "2505.24630", "pdf": "https://arxiv.org/pdf/2505.24630", "abs": "https://arxiv.org/abs/2505.24630", "authors": ["Junyi Li", "Hwee Tou Ng"], "title": "The Hallucination Dilemma: Factuality-Aware Reinforcement Learning for Large Reasoning Models", "categories": ["cs.CL", "cs.AI"], "comment": null, "summary": "Large language models (LLMs) have significantly advanced in reasoning tasks\nthrough reinforcement learning (RL) optimization, achieving impressive\ncapabilities across various challenging benchmarks. However, our empirical\nanalysis reveals a critical drawback: reasoning-oriented RL fine-tuning\nsignificantly increases the prevalence of hallucinations. We theoretically\nanalyze the RL training dynamics, identifying high-variance gradient,\nentropy-induced randomness, and susceptibility to spurious local optima as key\nfactors leading to hallucinations. To address this drawback, we propose\nFactuality-aware Step-wise Policy Optimization (FSPO), an innovative RL\nfine-tuning algorithm incorporating explicit factuality verification at each\nreasoning step. FSPO leverages automated verification against given evidence to\ndynamically adjust token-level advantage values, incentivizing factual\ncorrectness throughout the reasoning process. Experiments across mathematical\nreasoning and hallucination benchmarks using Qwen2.5 and Llama models\ndemonstrate that FSPO effectively reduces hallucinations while enhancing\nreasoning accuracy, substantially improving both reliability and performance.", "AI": {"tldr": "Large language models have advanced reasoning capabilities through RL optimization, but suffer from increased hallucinations. This paper proposes FSPO, an algorithm that incorporates factuality verification to reduce hallucinations and improve reasoning accuracy.", "motivation": "To address the issue of increased hallucinations in large language models caused by reasoning-oriented reinforcement learning fine-tuning.", "method": "FSPO (Factuality-aware Step-wise Policy Optimization), which involves explicit factuality verification at each reasoning step and dynamically adjusts token-level advantage values based on automated verification against given evidence.", "result": "Experiments using Qwen2.5 and Llama models demonstrate that FSPO effectively reduces hallucinations while enhancing reasoning accuracy across mathematical reasoning and hallucination benchmarks.", "conclusion": "FSPO substantially improves both reliability and performance of large language models in reasoning tasks."}}
{"id": "2505.24638", "pdf": "https://arxiv.org/pdf/2505.24638", "abs": "https://arxiv.org/abs/2505.24638", "authors": ["Zahid Hassan Tushar", "Adeleke Ademakinwa", "Jianwu Wang", "Zhibo Zhang", "Sanjay Purushotham"], "title": "Cloud Optical Thickness Retrievals Using Angle Invariant Attention Based Deep Learning Models", "categories": ["cs.CV", "cs.AI"], "comment": "6 pages, 7 figures, to be published in 2025 IEEE International\n  Conference on Image Processing (ICIP)", "summary": "Cloud Optical Thickness (COT) is a critical cloud property influencing\nEarth's climate, weather, and radiation budget. Satellite radiance measurements\nenable global COT retrieval, but challenges like 3D cloud effects, viewing\nangles, and atmospheric interference must be addressed to ensure accurate\nestimation. Traditionally, the Independent Pixel Approximation (IPA) method,\nwhich treats individual pixels independently, has been used for COT estimation.\nHowever, IPA introduces significant bias due to its simplified assumptions.\nRecently, deep learning-based models have shown improved performance over IPA\nbut lack robustness, as they are sensitive to variations in radiance intensity,\ndistortions, and cloud shadows. These models also introduce substantial errors\nin COT estimation under different solar and viewing zenith angles. To address\nthese challenges, we propose a novel angle-invariant, attention-based deep\nmodel called Cloud-Attention-Net with Angle Coding (CAAC). Our model leverages\nattention mechanisms and angle embeddings to account for satellite viewing\ngeometry and 3D radiative transfer effects, enabling more accurate retrieval of\nCOT. Additionally, our multi-angle training strategy ensures angle invariance.\nThrough comprehensive experiments, we demonstrate that CAAC significantly\noutperforms existing state-of-the-art deep learning models, reducing cloud\nproperty retrieval errors by at least a factor of nine.", "AI": {"tldr": "The paper proposes a new model named Cloud-Attention-Net with Angle Coding (CAAC) to improve the accuracy of Cloud Optical Thickness (COT) estimation by addressing limitations of previous methods.", "motivation": "Current methods for estimating COT, including the Independent Pixel Approximation (IPA) and existing deep learning models, have significant biases and lack robustness due to simplified assumptions or sensitivity to variations in radiance intensity, distortions, cloud shadows, and different solar and viewing zenith angles.", "method": "The proposed method is a novel angle-invariant, attention-based deep model called Cloud-Attention-Net with Angle Coding (CAAC). It incorporates attention mechanisms and angle embeddings to consider satellite viewing geometry and 3D radiative transfer effects. A multi-angle training strategy is also used to ensure angle invariance.", "result": "Comprehensive experiments show that CAAC significantly outperforms existing state-of-the-art deep learning models, reducing cloud property retrieval errors by at least a factor of nine.", "conclusion": "CAAC addresses the challenges in COT estimation related to 3D cloud effects, viewing angles, and atmospheric interference, providing a more accurate and robust solution compared to previous methods."}}
{"id": "2505.24108", "pdf": "https://arxiv.org/pdf/2505.24108", "abs": "https://arxiv.org/abs/2505.24108", "authors": ["Alina Devkota", "Annahita Amireskandari", "Joel Palko", "Shyam Thakkar", "Donald Adjeroh", "Xiajun Jiang", "Binod Bhattarai", "Prashnna K. Gyawali"], "title": "Federated Foundation Model for GI Endoscopy Images", "categories": ["cs.CV", "cs.LG", "I.2.10; I.4; I.5"], "comment": "11 pages, 11 figures, submitted to BHI2025", "summary": "Gastrointestinal (GI) endoscopy is essential in identifying GI tract\nabnormalities in order to detect diseases in their early stages and improve\npatient outcomes. Although deep learning has shown success in supporting GI\ndiagnostics and decision-making, these models require curated datasets with\nlabels that are expensive to acquire. Foundation models offer a promising\nsolution by learning general-purpose representations, which can be finetuned\nfor specific tasks, overcoming data scarcity. Developing foundation models for\nmedical imaging holds significant potential, but the sensitive and protected\nnature of medical data presents unique challenges. Foundation model training\ntypically requires extensive datasets, and while hospitals generate large\nvolumes of data, privacy restrictions prevent direct data sharing, making\nfoundation model training infeasible in most scenarios. In this work, we\npropose a FL framework for training foundation models for gastroendoscopy\nimaging, enabling data to remain within local hospital environments while\ncontributing to a shared model. We explore several established FL algorithms,\nassessing their suitability for training foundation models without relying on\ntask-specific labels, conducting experiments in both homogeneous and\nheterogeneous settings. We evaluate the trained foundation model on three\ncritical downstream tasks--classification, detection, and segmentation--and\ndemonstrate that it achieves improved performance across all tasks,\nhighlighting the effectiveness of our approach in a federated,\nprivacy-preserving setting.", "AI": {"tldr": "The paper proposes a Federated Learning (FL) framework for training foundation models on gastroendoscopy imaging, allowing data to stay in local hospital environments while contributing to a shared model. It explores FL algorithms and evaluates the trained model on classification, detection, and segmentation tasks.", "motivation": "Gastrointestinal endoscopy is crucial for early disease detection, but deep learning models require expensive labeled datasets. Foundation models can be fine-tuned for specific tasks but face challenges due to privacy restrictions on medical data.", "method": "A FL framework is proposed to train foundation models for gastroendoscopy imaging. Several established FL algorithms are explored and assessed for their suitability without task-specific labels. Experiments are conducted in both homogeneous and heterogeneous settings.", "result": "The trained foundation model shows improved performance across three downstream tasks: classification, detection, and segmentation.", "conclusion": "The FL framework effectively trains foundation models for gastroendoscopy imaging in a federated, privacy-preserving setting, overcoming data scarcity and privacy issues."}}
{"id": "2505.24640", "pdf": "https://arxiv.org/pdf/2505.24640", "abs": "https://arxiv.org/abs/2505.24640", "authors": ["Jens-Joris Decorte", "Jeroen Van Hautte", "Chris Develder", "Thomas Demeester"], "title": "Efficient Text Encoders for Labor Market Analysis", "categories": ["cs.CL", "cs.AI"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Labor market analysis relies on extracting insights from job advertisements,\nwhich provide valuable yet unstructured information on job titles and\ncorresponding skill requirements. While state-of-the-art methods for skill\nextraction achieve strong performance, they depend on large language models\n(LLMs), which are computationally expensive and slow. In this paper, we propose\n\\textbf{ConTeXT-match}, a novel contrastive learning approach with token-level\nattention that is well-suited for the extreme multi-label classification task\nof skill classification. \\textbf{ConTeXT-match} significantly improves skill\nextraction efficiency and performance, achieving state-of-the-art results with\na lightweight bi-encoder model. To support robust evaluation, we introduce\n\\textbf{Skill-XL}, a new benchmark with exhaustive, sentence-level skill\nannotations that explicitly address the redundancy in the large label space.\nFinally, we present \\textbf{JobBERT V2}, an improved job title normalization\nmodel that leverages extracted skills to produce high-quality job title\nrepresentations. Experiments demonstrate that our models are efficient,\naccurate, and scalable, making them ideal for large-scale, real-time labor\nmarket analysis.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5ConTeXT-match\uff0c\u7528\u4e8e\u6280\u80fd\u5206\u7c7b\u4efb\u52a1\uff0c\u63d0\u9ad8\u4e86\u6280\u80fd\u63d0\u53d6\u7684\u6548\u7387\u548c\u6027\u80fd\u3002\u540c\u65f6\u5f15\u5165\u4e86Skill-XL\u57fa\u51c6\u548cJobBERT V2\u6a21\u578b\uff0c\u5206\u522b\u7528\u4e8e\u9c81\u68d2\u8bc4\u4f30\u548c\u5de5\u4f5c\u6807\u9898\u89c4\u8303\u5316\u3002\u5b9e\u9a8c\u8868\u660e\u8fd9\u4e9b\u6a21\u578b\u5728\u5927\u89c4\u6a21\u5b9e\u65f6\u52b3\u52a8\u529b\u5e02\u573a\u5206\u6790\u4e2d\u5177\u6709\u9ad8\u6548\u3001\u51c6\u786e\u548c\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5f53\u524d\u6700\u5148\u8fdb\u7684\u6280\u80fd\u63d0\u53d6\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\uff0c\u4f46\u8fd9\u4e9b\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u901f\u5ea6\u6162\u3002", "method": "\u63d0\u51fa\u4e86ConTeXT-match\uff0c\u4e00\u79cd\u5e26\u6709\u6807\u8bb0\u7ea7\u522b\u6ce8\u610f\u529b\u7684\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u6280\u80fd\u5206\u7c7b\u7684\u6781\u7aef\u591a\u6807\u7b7e\u5206\u7c7b\u4efb\u52a1\uff1b\u5f15\u5165\u4e86Skill-XL\u4f5c\u4e3a\u65b0\u7684\u57fa\u51c6\uff0c\u5305\u542b\u8be6\u5c3d\u7684\u53e5\u5b50\u7ea7\u6280\u80fd\u6807\u6ce8\uff1b\u8fd8\u63d0\u51fa\u4e86JobBERT V2\u6a21\u578b\uff0c\u5229\u7528\u63d0\u53d6\u7684\u6280\u80fd\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u5de5\u4f5c\u6807\u9898\u8868\u793a\u3002", "result": "ConTeXT-match\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8f7b\u91cf\u7ea7\u53cc\u7f16\u7801\u5668\u6a21\u578b\u7684\u9ad8\u6548\u6027\u3002Skill-XL\u4e3a\u6280\u80fd\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6807\u51c6\u3002JobBERT V2\u5728\u5de5\u4f5c\u6807\u9898\u89c4\u8303\u5316\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6a21\u578b\u5728\u6548\u7387\u3001\u51c6\u786e\u6027\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u7528\u4e8e\u5927\u89c4\u6a21\u5b9e\u65f6\u52b3\u52a8\u529b\u5e02\u573a\u5206\u6790\u3002"}}
{"id": "2505.24117", "pdf": "https://arxiv.org/pdf/2505.24117", "abs": "https://arxiv.org/abs/2505.24117", "authors": ["Ananya Omanwar", "Fady Alajaji", "Tam\u00e1s Linder"], "title": "Bounds on the Excess Minimum Risk via Generalized Information Divergence Measures", "categories": ["cs.IT", "cs.LG", "math.IT"], "comment": null, "summary": "Given finite-dimensional random vectors $Y$, $X$, and $Z$ that form a Markov\nchain in that order (i.e., $Y \\to X \\to Z$), we derive upper bounds on the\nexcess minimum risk using generalized information divergence measures. Here,\n$Y$ is a target vector to be estimated from an observed feature vector $X$ or\nits stochastically degraded version $Z$. The excess minimum risk is defined as\nthe difference between the minimum expected loss in estimating $Y$ from $X$ and\nfrom $Z$. We present a family of bounds that generalize the mutual information\nbased bound of Gy\\\"orfi et al. (2023), using the R\\'enyi and\n$\\alpha$-Jensen-Shannon divergences, as well as Sibson's mutual information.\nOur bounds are similar to those developed by Modak et al. (2021) and Aminian et\nal. (2024) for the generalization error of learning algorithms. However, unlike\nthese works, our bounds do not require the sub-Gaussian parameter to be\nconstant and therefore apply to a broader class of joint distributions over\n$Y$, $X$, and $Z$. We also provide numerical examples under both constant and\nnon-constant sub-Gaussianity assumptions, illustrating that our generalized\ndivergence based bounds can be tighter than the one based on mutual information\nfor certain regimes of the parameter $\\alpha$.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5728\u9a6c\u5c14\u53ef\u592b\u94fe\u6761\u4ef6\u4e0b\uff0c\u57fa\u4e8e\u5e7f\u4e49\u4fe1\u606f\u6563\u5ea6\u6d4b\u5ea6\u7684\u6700\u5c0f\u98ce\u9669\u8fc7\u5269\u7684\u4e0a\u754c\u3002\u901a\u8fc7\u4f7f\u7528R\u00e9nyi\u3001\u03b1-Jensen-Shannon\u6563\u5ea6\u548cSibson\u4e92\u4fe1\u606f\uff0c\u63d0\u51fa\u4e86\u6bd4\u4f20\u7edf\u4e92\u4fe1\u606f\u65b9\u6cd5\u66f4\u5e7f\u6cdb\u7684\u8fb9\u754c\uff0c\u5e76\u8bc1\u660e\u5728\u67d0\u4e9b\u53c2\u6570\u03b1\u7684\u533a\u95f4\u5185\uff0c\u8fd9\u4e9b\u8fb9\u754c\u53ef\u4ee5\u66f4\u7d27\u81f4\u3002", "motivation": "\u63a2\u8ba8\u5728\u968f\u673a\u53d8\u91cfY\u3001X\u548cZ\u5f62\u6210\u9a6c\u5c14\u53ef\u592b\u94fe\u7684\u60c5\u51b5\u4e0b\uff0c\u4ece\u89c2\u5bdf\u5230\u7684\u7279\u5f81\u5411\u91cf\u4f30\u8ba1\u76ee\u6807\u5411\u91cf\u65f6\u7684\u98ce\u9669\u5dee\u5f02\uff0c\u4ee5\u53ca\u5982\u4f55\u5229\u7528\u5e7f\u4e49\u4fe1\u606f\u6563\u5ea6\u6d4b\u5ea6\u6765\u91cf\u5316\u8fd9\u79cd\u5dee\u5f02\u3002", "method": "\u91c7\u7528R\u00e9nyi\u3001\u03b1-Jensen-Shannon\u6563\u5ea6\u53caSibson\u4e92\u4fe1\u606f\u7b49\u5e7f\u4e49\u4fe1\u606f\u6563\u5ea6\u6d4b\u5ea6\uff0c\u63a8\u5bfc\u51fa\u5173\u4e8e\u6700\u5c0f\u98ce\u9669\u8fc7\u5269\u7684\u4e0a\u754c\u3002\u8fd9\u4e9b\u65b9\u6cd5\u63a8\u5e7f\u4e86\u57fa\u4e8e\u4e92\u4fe1\u606f\u7684\u65b9\u6cd5\uff0c\u5e76\u4e14\u4e0d\u9700\u8981\u5047\u8bbesub-Gaussian\u53c2\u6570\u4e3a\u5e38\u6570\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u7cfb\u5217\u65b0\u7684\u8fb9\u754c\u6761\u4ef6\uff0c\u8fd9\u4e9b\u8fb9\u754c\u4e0d\u4ec5\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u8054\u5408\u5206\u5e03\uff0c\u800c\u4e14\u5728\u7279\u5b9a\u53c2\u6570\u03b1\u7684\u8303\u56f4\u5185\uff0c\u76f8\u8f83\u4e8e\u4f20\u7edf\u7684\u4e92\u4fe1\u606f\u65b9\u6cd5\u8868\u73b0\u5f97\u66f4\u52a0\u7cbe\u786e\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u5e7f\u4e49\u4fe1\u606f\u6563\u5ea6\u6d4b\u5ea6\uff0c\u6210\u529f\u5730\u6269\u5c55\u4e86\u5bf9\u6700\u5c0f\u98ce\u9669\u8fc7\u5269\u7684\u7406\u89e3\uff0c\u5e76\u63d0\u4f9b\u4e86\u5728\u66f4\u5e7f\u6cdb\u5206\u5e03\u4e0a\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2505.24649", "pdf": "https://arxiv.org/pdf/2505.24649", "abs": "https://arxiv.org/abs/2505.24649", "authors": ["Huu-Thien Tran", "Thanh-Dat Truong", "Khoa Luu"], "title": "BIMA: Bijective Maximum Likelihood Learning Approach to Hallucination Prediction and Mitigation in Large Vision-Language Models", "categories": ["cs.CV", "cs.AI"], "comment": "CVPRW 2025, 8 pages, 4 figures", "summary": "Large vision-language models have become widely adopted to advance in various\ndomains. However, developing a trustworthy system with minimal interpretable\ncharacteristics of large-scale models presents a significant challenge. One of\nthe most prevalent terms associated with the fallacy functions caused by these\nsystems is hallucination, where the language model generates a response that\ndoes not correspond to the visual content. To mitigate this problem, several\napproaches have been developed, and one prominent direction is to ameliorate\nthe decoding process. In this paper, we propose a new Bijective Maximum\nLikelihood Learning (BIMA) approach to hallucination mitigation using\nnormalizing flow theories. The proposed BIMA method can efficiently mitigate\nthe hallucination problem in prevailing vision-language models, resulting in\nsignificant improvements. Notably, BIMA achieves the average F1 score of 85.06%\non POPE benchmark and remarkably reduce CHAIRS and CHAIRI by 7.6% and 2.6%,\nrespectively. To the best of our knowledge, this is one of the first studies\nthat contemplates the bijection means to reduce hallucination induced by large\nvision-language models.", "AI": {"tldr": "A new method called Bijective Maximum Likelihood Learning (BIMA) is proposed to reduce hallucination in large vision-language models, achieving significant improvements.", "motivation": "Large vision-language models suffer from the problem of hallucination, where responses do not correspond to visual content. There is a need for methods to mitigate this issue effectively.", "method": "The paper introduces BIMA, which uses normalizing flow theories to improve the decoding process and thus mitigate hallucination in vision-language models.", "result": "BIMA achieves an average F1 score of 85.06% on the POPE benchmark, and reduces CHAIRS and CHAIRI by 7.6% and 2.6%, respectively.", "conclusion": "This study is among the first to explore bijection as a means to reduce hallucination in large vision-language models, offering significant improvements."}}
{"id": "2505.24132", "pdf": "https://arxiv.org/pdf/2505.24132", "abs": "https://arxiv.org/abs/2505.24132", "authors": ["Kai Fukami", "Ryo Araki"], "title": "Information-theoretic machine learning for time-varying mode decomposition of separated airfoil wakes", "categories": ["physics.flu-dyn", "cs.LG", "physics.comp-ph"], "comment": null, "summary": "We perform an information-theoretic mode decomposition for separated wakes\naround a wing. The current data-driven approach based on a neural network\nreferred to as deep sigmoidal flow enables the extraction of an informative\ncomponent from a given flow field snapshot with respect to a target variable at\na future time stamp, thereby capturing the causality as a time-varying modal\nstructure. We consider three examples of separated flows around a NACA0012\nairfoil, namely, 1. laminar periodic wake at post-stall angles of attack, 2.\nstrong vortex-airfoil interactions, and 3. a turbulent wake in a\nspanwise-periodic domain. The present approach reveals informative vortical\nstructures associated with a time-varying lift response. For the periodic\nshedding cases, the informative structures vary in time corresponding to the\nfluctuation level from their mean values. With the second example of\nvortex-airfoil interactions, how the effect of vortex gust on a wing emerges in\nthe lift response over time is identified in an interpretable manner.\nFurthermore, for the case of turbulent wake, the present model highlights\nstructures near the wing and vortex cores as informative components based\nsolely on the information metric without any prior knowledge of aerodynamics\nand length scales. This study provides causality-based insights into a range of\nunsteady aerodynamic problems.", "AI": {"tldr": "An information-theoretic mode decomposition method using deep sigmoidal flow neural network is developed to extract causality-based insights from separated wakes around a wing for different flow scenarios.", "motivation": "To uncover causality-based insights into unsteady aerodynamic problems by extracting informative components from flow field data with respect to future target variables.", "method": "The method employs an information-theoretic mode decomposition based on a deep sigmoidal flow neural network. It processes flow field snapshots to extract components informative of a target variable at a future time, revealing time-varying modal structures.", "result": "Informative vortical structures associated with time-varying lift responses are identified in three examples: laminar periodic wake, strong vortex-airfoil interactions, and turbulent wake. The model highlights structures near the wing and vortex cores without prior aerodynamic knowledge.", "conclusion": "This study successfully reveals causality-based insights into various unsteady aerodynamic problems through the developed data-driven approach."}}
{"id": "2505.24671", "pdf": "https://arxiv.org/pdf/2505.24671", "abs": "https://arxiv.org/abs/2505.24671", "authors": ["Dayeon Ki", "Rachel Rudinger", "Tianyi Zhou", "Marine Carpuat"], "title": "Multiple LLM Agents Debate for Equitable Cultural Alignment", "categories": ["cs.CL", "cs.AI"], "comment": "37 pages, 18 figures", "summary": "Large Language Models (LLMs) need to adapt their predictions to diverse\ncultural contexts to benefit diverse communities across the world. While\nprevious efforts have focused on single-LLM, single-turn approaches, we propose\nto exploit the complementary strengths of multiple LLMs to promote cultural\nadaptability. We introduce a Multi-Agent Debate framework, where two LLM-based\nagents debate over a cultural scenario and collaboratively reach a final\ndecision. We propose two variants: one where either LLM agents exclusively\ndebate and another where they dynamically choose between self-reflection and\ndebate during their turns. We evaluate these approaches on 7 open-weight LLMs\n(and 21 LLM combinations) using the NormAd-ETI benchmark for social etiquette\nnorms in 75 countries. Experiments show that debate improves both overall\naccuracy and cultural group parity over single-LLM baselines. Notably,\nmulti-agent debate enables relatively small LLMs (7-9B) to achieve accuracies\ncomparable to that of a much larger model (27B parameters).", "AI": {"tldr": "\u901a\u8fc7\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u5229\u7528\u591a\u4e2a\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u4e92\u8865\u4f18\u52bf\uff0c\u63d0\u9ad8\u6587\u5316\u9002\u5e94\u6027\uff0c\u5b9e\u9a8c\u8868\u660e\u8fa9\u8bba\u63d0\u9ad8\u4e86\u6574\u4f53\u51c6\u786e\u6027\u548c\u6587\u5316\u7fa4\u4f53\u5e73\u7b49\u6027\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u9700\u8981\u9002\u5e94\u4e0d\u540c\u7684\u6587\u5316\u80cc\u666f\uff0c\u4f46\u4e4b\u524d\u7684\u5c1d\u8bd5\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e00\u6a21\u578b\u3001\u5355\u8f6e\u6b21\u7684\u65b9\u6cd5\u4e0a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\uff0c\u4e24\u4e2a\u57fa\u4e8eLLM\u7684\u667a\u80fd\u4f53\u5728\u4e00\u4e2a\u6587\u5316\u573a\u666f\u4e2d\u8fdb\u884c\u8fa9\u8bba\u5e76\u534f\u540c\u8fbe\u6210\u6700\u7ec8\u51b3\u5b9a\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e24\u79cd\u53d8\u4f53\uff1a\u4e00\u79cd\u662fLLM\u667a\u80fd\u4f53\u72ec\u5360\u8fa9\u8bba\uff0c\u53e6\u4e00\u79cd\u662f\u5728\u81ea\u6211\u53cd\u601d\u548c\u8fa9\u8bba\u4e4b\u95f4\u52a8\u6001\u9009\u62e9\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u8fa9\u8bba\u5728\u6574\u4f53\u51c6\u786e\u6027\u548c\u6587\u5316\u7fa4\u4f53\u5e73\u7b49\u65b9\u9762\u90fd\u4f18\u4e8e\u5355\u4e00LLM\u57fa\u7ebf\u3002\u503c\u5f97\u6ce8\u610f\u7684\u662f\uff0c\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u4f7f\u76f8\u5bf9\u8f83\u5c0f\u7684LLM\uff087-9B\uff09\u80fd\u591f\u8fbe\u5230\u4e0e\u5927\u5f97\u591a\u7684\u6a21\u578b\uff0827B\u53c2\u6570\uff09\u76f8\u5f53\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u591a\u667a\u80fd\u4f53\u8fa9\u8bba\u6846\u67b6\u80fd\u6709\u6548\u63d0\u9ad8LLM\u7684\u6587\u5316\u9002\u5e94\u6027\uff0c\u7279\u522b\u662f\u5728\u51c6\u786e\u6027\u548c\u6587\u5316\u516c\u5e73\u6027\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.24134", "pdf": "https://arxiv.org/pdf/2505.24134", "abs": "https://arxiv.org/abs/2505.24134", "authors": ["Ricardo Baptista", "Andrew M. Stuart", "Son Tran"], "title": "A Mathematical Perspective On Contrastive Learning", "categories": ["stat.ML", "cs.CV", "cs.LG"], "comment": "44 pages, 15 figures", "summary": "Multimodal contrastive learning is a methodology for linking different data\nmodalities; the canonical example is linking image and text data. The\nmethodology is typically framed as the identification of a set of encoders, one\nfor each modality, that align representations within a common latent space. In\nthis work, we focus on the bimodal setting and interpret contrastive learning\nas the optimization of (parameterized) encoders that define conditional\nprobability distributions, for each modality conditioned on the other,\nconsistent with the available data. This provides a framework for multimodal\nalgorithms such as crossmodal retrieval, which identifies the mode of one of\nthese conditional distributions, and crossmodal classification, which is\nsimilar to retrieval but includes a fine-tuning step to make it task specific.\n  The framework we adopt also gives rise to crossmodal generative models. This\nprobabilistic perspective suggests two natural generalizations of contrastive\nlearning: the introduction of novel probabilistic loss functions, and the use\nof alternative metrics for measuring alignment in the common latent space. We\nstudy these generalizations of the classical approach in the multivariate\nGaussian setting. In this context we view the latent space identification as a\nlow-rank matrix approximation problem. This allows us to characterize the\ncapabilities of loss functions and alignment metrics to approximate natural\nstatistics, such as conditional means and covariances; doing so yields novel\nvariants on contrastive learning algorithms for specific mode-seeking and for\ngenerative tasks. The framework we introduce is also studied through numerical\nexperiments on multivariate Gaussians, the labeled MNIST dataset, and on a data\nassimilation application arising in oceanography.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u53c2\u6570\u5316\u7f16\u7801\u5668\u5b9a\u4e49\u6761\u4ef6\u6982\u7387\u5206\u5e03\uff0c\u5e76\u7814\u7a76\u4e86\u5176\u5728\u591a\u79cd\u4efb\u52a1\u4e2d\u7684\u5e94\u7528\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u4e8e\u5c06\u4e0d\u540c\u6a21\u6001\u7684\u6570\u636e\u5bf9\u9f50\u5230\u4e00\u4e2a\u5171\u540c\u7684\u6f5c\u5728\u7a7a\u95f4\u4e2d\uff0c\u4f46\u5c1a\u672a\u5145\u5206\u5229\u7528\u6982\u7387\u89c6\u89d2\u6765\u6539\u8fdb\u635f\u5931\u51fd\u6570\u548c\u5bf9\u9f50\u5ea6\u91cf\u3002", "method": "\u4f5c\u8005\u5c06\u5bf9\u6bd4\u5b66\u4e60\u89e3\u91ca\u4e3a\u4f18\u5316\uff08\u53c2\u6570\u5316\uff09\u7f16\u7801\u5668\uff0c\u8fd9\u4e9b\u7f16\u7801\u5668\u5b9a\u4e49\u4e86\u6bcf\u4e2a\u6a21\u6001\u57fa\u4e8e\u53e6\u4e00\u4e2a\u6a21\u6001\u7684\u6761\u4ef6\u6982\u7387\u5206\u5e03\u3002\u5e76\u63d0\u51fa\u4e86\u4e24\u79cd\u81ea\u7136\u7684\u5bf9\u6bd4\u5b66\u4e60\u6cdb\u5316\uff1a\u5f15\u5165\u65b0\u7684\u6982\u7387\u635f\u5931\u51fd\u6570\u548c\u4f7f\u7528\u66ff\u4ee3\u5ea6\u91cf\u6765\u6d4b\u91cf\u5171\u540c\u6f5c\u5728\u7a7a\u95f4\u4e2d\u7684\u5bf9\u9f50\u60c5\u51b5\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6846\u67b6\u5728\u591a\u53d8\u91cf\u9ad8\u65af\u5206\u5e03\u3001MNIST\u6570\u636e\u96c6\u4ee5\u53ca\u6d77\u6d0b\u5b66\u4e2d\u7684\u6570\u636e\u540c\u5316\u5e94\u7528\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u66f4\u597d\u5730\u8fd1\u4f3c\u81ea\u7136\u7edf\u8ba1\u91cf\u5982\u6761\u4ef6\u5747\u503c\u548c\u534f\u65b9\u5dee\u3002", "conclusion": "\u63d0\u51fa\u7684\u6982\u7387\u89c6\u89d2\u4e0b\u7684\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u4e0d\u4ec5\u9002\u7528\u4e8e\u8de8\u6a21\u6001\u68c0\u7d22\u548c\u5206\u7c7b\u4efb\u52a1\uff0c\u8fd8\u53ef\u4ee5\u751f\u6210\u8de8\u6a21\u6001\u751f\u6210\u6a21\u578b\uff0c\u4e3a\u8fdb\u4e00\u6b65\u6539\u8fdb\u5bf9\u6bd4\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2505.24681", "pdf": "https://arxiv.org/pdf/2505.24681", "abs": "https://arxiv.org/abs/2505.24681", "authors": ["Katalin Feher", "Marton Demeter"], "title": "Generative Knowledge Production Pipeline Driven by Academic Influencers", "categories": ["cs.CY", "cs.AI", "cs.HC", "cs.SI", "1.2, J.4, K.4"], "comment": "15 pages, 1 figure, 2 tables, Horizon Europe NGI funding", "summary": "Generative AI transforms knowledge production, validation, and dissemination,\nraising academic integrity and credibility concerns. This study examines 53\nacademic influencer videos that reached 5.3 million viewers to identify an\nemerging, structured, implementation-ready pipeline balancing originality,\nethical compliance, and human-AI collaboration despite the disruptive impacts.\nFindings highlight generative AI's potential to automate publication workflows\nand democratize participation in knowledge production while challenging\ntraditional scientific norms. Academic influencers emerge as key intermediaries\nin this paradigm shift, connecting bottom-up practices with institutional\npolicies to improve adaptability. Accordingly, the study proposes a generative\npublication production pipeline and a policy framework for co-intelligence\nadaptation and reinforcing credibility-centered standards in AI-powered\nresearch. These insights support scholars, educators, and policymakers in\nunderstanding AI's transformative impact by advocating responsible and\ninnovation-driven knowledge production. Additionally, they reveal pathways for\nautomating best practices, optimizing scholarly workflows, and fostering\ncreativity in academic research and publication.", "AI": {"tldr": "Generative AI changes knowledge production and validation, causing academic integrity concerns. This study explores 53 academic influencer videos with 5.3 million viewers to develop a pipeline balancing originality, ethics, and human-AI collaboration. Findings show generative AI can automate workflows and democratize participation while challenging norms. Academic influencers are key intermediaries in this shift. The study proposes a generative publication pipeline and policy framework for responsible AI-powered research.", "motivation": "To address the challenges and opportunities brought by generative AI in academic knowledge production, validation, and dissemination, particularly concerning academic integrity and credibility.", "method": "Examining 53 academic influencer videos that reached 5.3 million viewers to identify a structured pipeline for balancing originality, ethical compliance, and human-AI collaboration.", "result": "Generative AI has potential to automate publication workflows and democratize knowledge production while challenging traditional scientific norms. Academic influencers play a crucial role as intermediaries in this paradigm shift.", "conclusion": "The study proposes a generative publication production pipeline and policy framework to support responsible and innovation-driven knowledge production, revealing pathways for automating best practices, optimizing workflows, and fostering creativity in academic research."}}
{"id": "2505.24683", "pdf": "https://arxiv.org/pdf/2505.24683", "abs": "https://arxiv.org/abs/2505.24683", "authors": ["Dayeon Ki", "Kevin Duh", "Marine Carpuat"], "title": "Should I Share this Translation? Evaluating Quality Feedback for User Reliance on Machine Translation", "categories": ["cs.CL", "cs.AI"], "comment": "22 pages, 7 figures", "summary": "As people increasingly use AI systems in work and daily life, feedback\nmechanisms that help them use AI responsibly are urgently needed, particularly\nin settings where users are not equipped to assess the quality of AI\npredictions. We study a realistic Machine Translation (MT) scenario where\nmonolingual users decide whether to share an MT output, first without and then\nwith quality feedback. We compare four types of quality feedback: explicit\nfeedback that directly give users an assessment of translation quality using 1)\nerror highlights and 2) LLM explanations, and implicit feedback that helps\nusers compare MT inputs and outputs through 3) backtranslation and 4)\nquestion-answer (QA) tables. We find that all feedback types, except error\nhighlights, significantly improve both decision accuracy and appropriate\nreliance. Notably, implicit feedback, especially QA tables, yields\nsignificantly greater gains than explicit feedback in terms of decision\naccuracy, appropriate reliance, and user perceptions, receiving the highest\nratings for helpfulness and trust, and the lowest for mental burden.", "AI": {"tldr": "In a study on Machine Translation (MT) systems, researchers examined four types of quality feedback - explicit (error highlights and LLM explanations) and implicit (backtranslation and QA tables). They found that all but error highlights improved decision accuracy and reliance. Implicit feedback, particularly QA tables, outperformed explicit feedback in decision accuracy, appropriate reliance, and user perceptions.", "motivation": "To address the urgent need for feedback mechanisms that help users utilize AI responsibly, especially in situations where users cannot easily assess the quality of AI predictions themselves.", "method": "A study was conducted in a realistic Machine Translation scenario where monolingual users decide whether to share MT outputs. Four types of quality feedback were compared: explicit feedback (error highlights, LLM explanations) and implicit feedback (backtranslation, QA tables).", "result": "All feedback types except error highlights significantly improve decision accuracy and appropriate reliance. Implicit feedback, especially QA tables, yielded greater gains than explicit feedback in terms of decision accuracy, appropriate reliance, and user perceptions.", "conclusion": "Implicit feedback mechanisms are more effective than explicit ones in improving users' decision-making regarding AI-generated content, being perceived as more helpful and trustworthy while imposing less mental burden."}}
{"id": "2505.24161", "pdf": "https://arxiv.org/pdf/2505.24161", "abs": "https://arxiv.org/abs/2505.24161", "authors": ["Zijie Xu", "Tong Bu", "Zecheng Hao", "Jianhao Ding", "Zhaofei Yu"], "title": "Proxy Target: Bridging the Gap Between Discrete Spiking Neural Networks and Continuous Control", "categories": ["cs.NE", "cs.LG"], "comment": null, "summary": "Spiking Neural Networks (SNNs) offer low-latency and energy-efficient\ndecision making through neuromorphic hardware, making them compelling for\nReinforcement Learning (RL) in resource-constrained edge devices. Recent\nstudies in this field directly replace Artificial Neural Networks (ANNs) by\nSNNs in existing RL frameworks, overlooking whether the RL algorithm is\nsuitable for SNNs. However, most RL algorithms in continuous control are\ndesigned tailored to ANNs, including the target network soft updates mechanism,\nwhich conflict with the discrete, non-differentiable dynamics of SNN spikes. We\nidentify that this mismatch destabilizes SNN training in continuous control\ntasks. To bridge this gap between discrete SNN and continuous control, we\npropose a novel proxy target framework. The continuous and differentiable\ndynamics of the proxy target enable smooth updates, bypassing the\nincompatibility of SNN spikes, stabilizing the RL algorithms. Since the proxy\nnetwork operates only during training, the SNN retains its energy efficiency\nduring deployment without inference overhead. Extensive experiments on\ncontinuous control benchmarks demonstrate that compared to vanilla SNNs, the\nproxy target framework enables SNNs to achieve up to 32% higher performance\nacross different spiking neurons. Notably, we are the first to surpass ANN\nperformance in continuous control with simple Leaky-Integrate-and-Fire (LIF)\nneurons. This work motivates a new class of SNN-friendly RL algorithms tailored\nto SNN's characteristics, paving the way for neuromorphic agents that combine\nhigh performance with low power consumption.", "AI": {"tldr": "\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u73b0\u6709\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u4e0e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNN\uff09\u5b58\u5728\u4e0d\u5339\u914d\u95ee\u9898\uff0c\u5bfc\u81f4SNN\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4ee3\u7406\u76ee\u6807\u6846\u67b6\uff0c\u89e3\u51b3\u4e86SNN\u79bb\u6563\u3001\u4e0d\u53ef\u5fae\u7684\u7279\u6027\u4e0e\u73b0\u6709\u7b97\u6cd5\u4e4b\u95f4\u7684\u51b2\u7a81\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86SNN\u7684\u6027\u80fd\uff0c\u5e76\u9996\u6b21\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u8d85\u8d8a\u4e86\u4f20\u7edfANN\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u5728\u5f3a\u5316\u5b66\u4e60\u9886\u57df\u4e2d\uff0c\u76f4\u63a5\u7528SNN\u66ff\u4ee3ANN\u7684\u65b9\u6cd5\u5ffd\u7565\u4e86RL\u7b97\u6cd5\u662f\u5426\u9002\u5408SNN\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\uff0c\u8fd9\u79cd\u4e0d\u5339\u914d\u4f1a\u5bfc\u81f4SNN\u8bad\u7ec3\u4e0d\u7a33\u5b9a\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u4ee3\u7406\u76ee\u6807\u6846\u67b6\uff0c\u5229\u7528\u8fde\u7eed\u4e14\u53ef\u5fae\u7684\u52a8\u6001\u66f4\u65b0\u673a\u5236\uff0c\u7ed5\u8fc7\u4e86SNN\u5c16\u5cf0\u7684\u4e0d\u517c\u5bb9\u6027\uff0c\u7a33\u5b9a\u4e86RL\u7b97\u6cd5\u3002\u6b64\u65b9\u6cd5\u4ec5\u5728\u8bad\u7ec3\u65f6\u4f7f\u7528\u4ee3\u7406\u7f51\u7edc\uff0c\u90e8\u7f72\u65f6\u4ecd\u4fdd\u7559SNN\u7684\u80fd\u91cf\u6548\u7387\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684SNN\uff0c\u4ee3\u7406\u76ee\u6807\u6846\u67b6\u80fd\u591f\u4f7fSNN\u5728\u4e0d\u540c\u7c7b\u578b\u7684\u8109\u51b2\u795e\u7ecf\u5143\u4e0a\u63d0\u5347\u9ad8\u8fbe32%\u7684\u6027\u80fd\uff0c\u5e76\u4e14\u9996\u6b21\u5728\u8fde\u7eed\u63a7\u5236\u4efb\u52a1\u4e2d\u4f7f\u7528\u7b80\u5355\u7684LIF\u795e\u7ecf\u5143\u8d85\u8d8a\u4e86ANN\u7684\u6027\u80fd\u3002", "conclusion": "\u672c\u7814\u7a76\u4e3a\u8bbe\u8ba1\u66f4\u9002\u5408SNN\u7279\u6027\u7684\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u63a8\u52a8\u4e86\u517c\u5177\u9ad8\u6027\u80fd\u548c\u4f4e\u529f\u8017\u7684\u7c7b\u8111\u8ba1\u7b97\u4ee3\u7406\u7684\u53d1\u5c55\u3002"}}
{"id": "2505.24174", "pdf": "https://arxiv.org/pdf/2505.24174", "abs": "https://arxiv.org/abs/2505.24174", "authors": ["Ryota Miyano", "Yuki Arase"], "title": "Adaptive LoRA Merge with Parameter Pruning for Low-Resource Generation", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted at ACL2025 Findings", "summary": "This study proposes a simple yet effective LoRA merge method to achieve LLM\nadaptation for low-resource language generation tasks. The LoRA merge\ntechnique, which integrates multiple LoRA modules trained on different tasks,\nhas gained attention as an effective and efficient approach for adapting LLMs\nto target tasks. However, previous methods are limited in adaptability as they\nkeep the LoRA parameters frozen. Additionally, the low-resource problem has\nbeen out of their scope. We propose a LoRA merge method that updates and prunes\nLoRA parameters through fine-tuning with minimal target task data, which allows\nfiner-grained adjustments of LoRA parameters and enhancement of task\nadaptability. Extensive experiments have been conducted taking summarization as\na benchmark task. Our datasets cover various domains and multiple languages of\nEnglish and Japanese. The results confirm that the proposed method achieves\nsignificant and consistent improvements in task adaptability over the previous\nmethods.", "AI": {"tldr": "This study proposes an improved LoRA merge method for LLM adaptation in low-resource language generation tasks, which updates and prunes LoRA parameters via fine-tuning with minimal target task data, showing significant improvements in task adaptability.", "motivation": "The motivation is to address the limitations of previous LoRA merge methods that keep LoRA parameters frozen and do not focus on low-resource scenarios, aiming to enhance task adaptability for low-resource language generation.", "method": "The proposed method involves updating and pruning LoRA parameters through fine-tuning using minimal target task data, allowing finer-grained adjustments of LoRA parameters.", "result": "Extensive experiments on summarization tasks across various domains and multiple languages (English and Japanese) demonstrate significant and consistent improvements in task adaptability compared to previous methods.", "conclusion": "The improved LoRA merge method successfully enhances task adaptability for low-resource language generation tasks, outperforming prior approaches."}}
{"id": "2505.24701", "pdf": "https://arxiv.org/pdf/2505.24701", "abs": "https://arxiv.org/abs/2505.24701", "authors": ["Tejul Pandit", "Meet Raval", "Dhvani Upadhyay"], "title": "Multi-Domain ABSA Conversation Dataset Generation via LLMs for Real-World Evaluation and Model Comparison", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 3 figures, 5 tables, 6th International Conference on\n  Natural Language Computing and AI (NLCAI 2025), ISBN : 978-1-923107-59-5,\n  Computer Science & Information Technology (CS & IT), ISSN : 2231 - 5403,\n  Volume 15, Number 10, May 2025", "summary": "Aspect-Based Sentiment Analysis (ABSA) offers granular insights into opinions\nbut often suffers from the scarcity of diverse, labeled datasets that reflect\nreal-world conversational nuances. This paper presents an approach for\ngenerating synthetic ABSA data using Large Language Models (LLMs) to address\nthis gap. We detail the generation process aimed at producing data with\nconsistent topic and sentiment distributions across multiple domains using\nGPT-4o. The quality and utility of the generated data were evaluated by\nassessing the performance of three state-of-the-art LLMs (Gemini 1.5 Pro,\nClaude 3.5 Sonnet, and DeepSeek-R1) on topic and sentiment classification\ntasks. Our results demonstrate the effectiveness of the synthetic data,\nrevealing distinct performance trade-offs among the models: DeepSeekR1 showed\nhigher precision, Gemini 1.5 Pro and Claude 3.5 Sonnet exhibited strong recall,\nand Gemini 1.5 Pro offered significantly faster inference. We conclude that\nLLM-based synthetic data generation is a viable and flexible method for\ncreating valuable ABSA resources, facilitating research and model evaluation\nwithout reliance on limited or inaccessible real-world labeled data.", "AI": {"tldr": "The paper proposes using Large Language Models (LLMs) to generate synthetic Aspect-Based Sentiment Analysis (ABSA) data, addressing the lack of diverse labeled datasets. Evaluations on three LLMs reveal their distinct performance trade-offs in topic and sentiment classification tasks. Synthetic data proves effective for ABSA research.", "motivation": "Aspect-Based Sentiment Analysis requires diverse labeled datasets reflecting real-world conversational nuances, but such datasets are scarce.", "method": "Synthetic ABSA data is generated using GPT-4o, ensuring consistent topic and sentiment distributions across multiple domains. Three state-of-the-art LLMs are then evaluated on topic and sentiment classification tasks using this synthetic data.", "result": "The synthetic data effectively supports ABSA tasks, with each LLM showing different strengths: DeepSeekR1 has higher precision, Gemini 1.5 Pro and Claude 3.5 Sonnet have strong recall, and Gemini 1.5 Pro provides faster inference.", "conclusion": "Using LLMs to generate synthetic ABSA data is a viable and flexible method, promoting ABSA research and model evaluation without needing limited real-world labeled data."}}
{"id": "2505.24203", "pdf": "https://arxiv.org/pdf/2505.24203", "abs": "https://arxiv.org/abs/2505.24203", "authors": ["Jiarui Lu", "Xiaoyin Chen", "Stephen Zhewen Lu", "Aur\u00e9lie Lozano", "Vijil Chenthamarakshan", "Payel Das", "Jian Tang"], "title": "Aligning Protein Conformation Ensemble Generation with Physical Feedback", "categories": ["q-bio.BM", "cs.LG"], "comment": "Published as a conference paper at ICML 2025", "summary": "Protein dynamics play a crucial role in protein biological functions and\nproperties, and their traditional study typically relies on time-consuming\nmolecular dynamics (MD) simulations conducted in silico. Recent advances in\ngenerative modeling, particularly denoising diffusion models, have enabled\nefficient accurate protein structure prediction and conformation sampling by\nlearning distributions over crystallographic structures. However, effectively\nintegrating physical supervision into these data-driven approaches remains\nchallenging, as standard energy-based objectives often lead to intractable\noptimization. In this paper, we introduce Energy-based Alignment (EBA), a\nmethod that aligns generative models with feedback from physical models,\nefficiently calibrating them to appropriately balance conformational states\nbased on their energy differences. Experimental results on the MD ensemble\nbenchmark demonstrate that EBA achieves state-of-the-art performance in\ngenerating high-quality protein ensembles. By improving the physical\nplausibility of generated structures, our approach enhances model predictions\nand holds promise for applications in structural biology and drug discovery.", "AI": {"tldr": "\u672c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aEnergy-based Alignment (EBA)\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u751f\u6210\u6a21\u578b\u548c\u7269\u7406\u6a21\u578b\u7684\u53cd\u9988\uff0c\u6709\u6548\u63d0\u9ad8\u4e86\u751f\u6210\u9ad8\u8d28\u91cf\u86cb\u767d\u8d28\u7ed3\u6784\u96c6\u5408\u7684\u80fd\u529b\uff0c\u5728\u5206\u5b50\u52a8\u529b\u5b66\u96c6\u6210\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u7ed3\u6784\u751f\u7269\u5b66\u548c\u836f\u7269\u53d1\u73b0\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002", "motivation": "\u86cb\u767d\u8d28\u52a8\u529b\u5b66\u5bf9\u5176\u751f\u7269\u529f\u80fd\u548c\u7279\u6027\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u7814\u7a76\u4f9d\u8d56\u8017\u65f6\u7684\u5206\u5b50\u52a8\u529b\u5b66(MD)\u6a21\u62df\u3002\u5c3d\u7ba1\u751f\u6210\u6a21\u578b\uff08\u5982\u53bb\u566a\u6269\u6563\u6a21\u578b\uff09\u5728\u9884\u6d4b\u86cb\u767d\u8d28\u7ed3\u6784\u548c\u6784\u8c61\u91c7\u6837\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u5982\u4f55\u6709\u6548\u5730\u5c06\u7269\u7406\u76d1\u7763\u6574\u5408\u5230\u8fd9\u4e9b\u6570\u636e\u9a71\u52a8\u7684\u65b9\u6cd5\u4e2d\u4ecd\u7136\u662f\u4e00\u4e2a\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e86Energy-based Alignment (EBA)\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u5c06\u751f\u6210\u6a21\u578b\u4e0e\u7269\u7406\u6a21\u578b\u7684\u53cd\u9988\u5bf9\u9f50\uff0c\u901a\u8fc7\u80fd\u91cf\u5dee\u5f02\u9ad8\u6548\u6821\u51c6\u4ee5\u5e73\u8861\u6784\u8c61\u72b6\u6001\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cEBA\u5728MD\u96c6\u6210\u57fa\u51c6\u4e0a\u751f\u6210\u9ad8\u8d28\u91cf\u86cb\u767d\u8d28\u96c6\u5408\u7684\u8868\u73b0\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6c34\u5e73\uff0c\u63d0\u5347\u4e86\u751f\u6210\u7ed3\u6784\u7684\u7269\u7406\u5408\u7406\u6027\u3002", "conclusion": "EBA\u65b9\u6cd5\u901a\u8fc7\u6539\u8fdb\u751f\u6210\u7ed3\u6784\u7684\u7269\u7406\u5408\u7406\u6027\uff0c\u589e\u5f3a\u4e86\u6a21\u578b\u9884\u6d4b\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5728\u7ed3\u6784\u751f\u7269\u5b66\u548c\u836f\u7269\u53d1\u73b0\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2505.24222", "pdf": "https://arxiv.org/pdf/2505.24222", "abs": "https://arxiv.org/abs/2505.24222", "authors": ["Fangyikang Wang", "Hubery Yin", "Lei Qian", "Yinan Li", "Shaobin Zhuang", "Huminhao Zhu", "Yilin Zhang", "Yanlong Tang", "Chao Zhang", "Hanbin Zhao", "Hui Qian", "Chen Li"], "title": "Unleashing High-Quality Image Generation in Diffusion Sampling Using Second-Order Levenberg-Marquardt-Langevin", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "The diffusion models (DMs) have demonstrated the remarkable capability of\ngenerating images via learning the noised score function of data distribution.\nCurrent DM sampling techniques typically rely on first-order Langevin dynamics\nat each noise level, with efforts concentrated on refining inter-level\ndenoising strategies. While leveraging additional second-order Hessian geometry\nto enhance the sampling quality of Langevin is a common practice in Markov\nchain Monte Carlo (MCMC), the naive attempts to utilize Hessian geometry in\nhigh-dimensional DMs lead to quadratic-complexity computational costs,\nrendering them non-scalable. In this work, we introduce a novel\nLevenberg-Marquardt-Langevin (LML) method that approximates the diffusion\nHessian geometry in a training-free manner, drawing inspiration from the\ncelebrated Levenberg-Marquardt optimization algorithm. Our approach introduces\ntwo key innovations: (1) A low-rank approximation of the diffusion Hessian,\nleveraging the DMs' inherent structure and circumventing explicit\nquadratic-complexity computations; (2) A damping mechanism to stabilize the\napproximated Hessian. This LML approximated Hessian geometry enables the\ndiffusion sampling to execute more accurate steps and improve the image\ngeneration quality. We further conduct a theoretical analysis to substantiate\nthe approximation error bound of low-rank approximation and the convergence\nproperty of the damping mechanism. Extensive experiments across multiple\npretrained DMs validate that the LML method significantly improves image\ngeneration quality, with negligible computational overhead.", "AI": {"tldr": "The paper introduces Levenberg-Marquardt-Langevin (LML) method that approximates the diffusion Hessian geometry in a training-free manner with two key innovations, which significantly improves image generation quality with negligible computational overhead.", "motivation": "Current DM sampling techniques typically rely on first-order Langevin dynamics at each noise level and naive attempts to utilize Hessian geometry in high-dimensional DMs lead to quadratic-complexity computational costs. Thus, there is a need for an efficient method to approximate the diffusion Hessian geometry.", "method": "The LML method introduces two key innovations: (1) A low-rank approximation of the diffusion Hessian leveraging the DMs' inherent structure and circumventing explicit quadratic-complexity computations; (2) A damping mechanism to stabilize the approximated Hessian.", "result": "Extensive experiments across multiple pretrained DMs validate that the LML method significantly improves image generation quality, with negligible computational overhead.", "conclusion": "The LML approximated Hessian geometry enables the diffusion sampling to execute more accurate steps and improve the image generation quality."}}
{"id": "2505.24238", "pdf": "https://arxiv.org/pdf/2505.24238", "abs": "https://arxiv.org/abs/2505.24238", "authors": ["Bowen Dong", "Minheng Ni", "Zitong Huang", "Guanglei Yang", "Wangmeng Zuo", "Lei Zhang"], "title": "MIRAGE: Assessing Hallucination in Multimodal Reasoning Chains of MLLM", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Multimodal hallucination in multimodal large language models (MLLMs)\nrestricts the correctness of MLLMs. However, multimodal hallucinations are\nmulti-sourced and arise from diverse causes. Existing benchmarks fail to\nadequately distinguish between perception-induced hallucinations and\nreasoning-induced hallucinations. This failure constitutes a significant issue\nand hinders the diagnosis of multimodal reasoning failures within MLLMs. To\naddress this, we propose the {\\dataset} benchmark, which isolates reasoning\nhallucinations by constructing questions where input images are correctly\nperceived by MLLMs yet reasoning errors persist. {\\dataset} introduces\nmulti-granular evaluation metrics: accuracy, factuality, and LLMs hallucination\nscore for hallucination quantification. Our analysis reveals that (1) the model\nscale, data scale, and training stages significantly affect the degree of\nlogical, fabrication, and factual hallucinations; (2) current MLLMs show no\neffective improvement on spatial hallucinations caused by misinterpreted\nspatial relationships, indicating their limited visual reasoning capabilities;\nand (3) question types correlate with distinct hallucination patterns,\nhighlighting targeted challenges and potential mitigation strategies. To\naddress these challenges, we propose {\\method}, a method that combines\ncurriculum reinforcement fine-tuning to encourage models to generate\nlogic-consistent reasoning chains by stepwise reducing learning difficulty, and\ncollaborative hint inference to reduce reasoning complexity. {\\method}\nestablishes a baseline on {\\dataset}, and reduces the logical hallucinations in\noriginal base models.", "AI": {"tldr": "Multimodal hallucination in MLLMs is a problem that this paper addresses by proposing a new benchmark called \\{dataset\\} and a method called \\{method\\}. This benchmark can distinguish between perception-induced and reasoning-induced hallucinations, and the method reduces logical hallucinations.", "motivation": "The motivation of this paper is to address the issue of multimodal hallucinations in MLLMs, which restricts their correctness. Existing benchmarks fail to adequately distinguish between different types of hallucinations, hindering the diagnosis of multimodal reasoning failures.", "method": "The proposed method, \\{method\\}, combines curriculum reinforcement fine-tuning and collaborative hint inference. It encourages models to generate logic-consistent reasoning chains by stepwise reducing learning difficulty and reduces reasoning complexity.", "result": "The analysis shows that model scale, data scale, and training stages significantly affect the degree of logical, fabrication, and factual hallucinations. Current MLLMs have limited visual reasoning capabilities regarding spatial hallucinations. Question types correlate with distinct hallucination patterns. The proposed method establishes a baseline on the \\{dataset\\} benchmark and reduces logical hallucinations in original base models.", "conclusion": "This paper concludes that the proposed \\{dataset\\} benchmark effectively isolates reasoning hallucinations and the proposed \\{method\\} reduces logical hallucinations in MLLMs."}}
{"id": "2505.24716", "pdf": "https://arxiv.org/pdf/2505.24716", "abs": "https://arxiv.org/abs/2505.24716", "authors": ["Christopher Buss", "Mahdis Safari", "Arash Termehchy", "Stefan Lee", "David Maier"], "title": "Towards Scalable Schema Mapping using Large Language Models", "categories": ["cs.DB", "cs.AI"], "comment": null, "summary": "The growing need to integrate information from a large number of diverse\nsources poses significant scalability challenges for data integration systems.\nThese systems often rely on manually written schema mappings, which are\ncomplex, source-specific, and costly to maintain as sources evolve. While\nrecent advances suggest that large language models (LLMs) can assist in\nautomating schema matching by leveraging both structural and natural language\ncues, key challenges remain. In this paper, we identify three core issues with\nusing LLMs for schema mapping: (1) inconsistent outputs due to sensitivity to\ninput phrasing and structure, which we propose methods to address through\nsampling and aggregation techniques; (2) the need for more expressive mappings\n(e.g., GLaV), which strain the limited context windows of LLMs; and (3) the\ncomputational cost of repeated LLM calls, which we propose to mitigate through\nstrategies like data type prefiltering.", "AI": {"tldr": "The paper explores challenges and proposes solutions for using LLMs in schema mapping within data integration systems.", "motivation": "To address scalability challenges in data integration systems caused by reliance on manually written schema mappings, which are complex, source-specific, and costly to maintain.", "method": "Identifying three core issues with using LLMs for schema mapping and proposing methods such as sampling and aggregation techniques, more expressive mappings (e.g., GLaV), and strategies like data type prefiltering.", "result": "Provides approaches to handle inconsistent outputs, limited context windows, and high computational costs when using LLMs for schema mapping.", "conclusion": "Using LLMs for schema mapping in data integration systems is promising but requires addressing key challenges related to output consistency, mapping expressiveness, and computational efficiency."}}
{"id": "2505.24244", "pdf": "https://arxiv.org/pdf/2505.24244", "abs": "https://arxiv.org/abs/2505.24244", "authors": ["Nir Endy", "Idan Daniel Grosbard", "Yuval Ran-Milo", "Yonatan Slutzky", "Itay Tshuva", "Raja Giryes"], "title": "Mamba Knockout for Unraveling Factual Information Flow", "categories": ["cs.CL", "cs.LG"], "comment": "Accepted to ACL 2025", "summary": "This paper investigates the flow of factual information in Mamba State-Space\nModel (SSM)-based language models. We rely on theoretical and empirical\nconnections to Transformer-based architectures and their attention mechanisms.\nExploiting this relationship, we adapt attentional interpretability techniques\noriginally developed for Transformers--specifically, the Attention Knockout\nmethodology--to both Mamba-1 and Mamba-2. Using them we trace how information\nis transmitted and localized across tokens and layers, revealing patterns of\nsubject-token information emergence and layer-wise dynamics. Notably, some\nphenomena vary between mamba models and Transformer based models, while others\nappear universally across all models inspected--hinting that these may be\ninherent to LLMs in general. By further leveraging Mamba's structured\nfactorization, we disentangle how distinct \"features\" either enable\ntoken-to-token information exchange or enrich individual tokens, thus offering\na unified lens to understand Mamba internal operations.", "AI": {"tldr": "This paper explores the flow of factual information in Mamba SSM-based language models by adapting attentional interpretability techniques from Transformers, revealing patterns of information transmission and dynamics, as well as differences and similarities between Mamba and Transformer models.", "motivation": "To understand how factual information flows within Mamba State-Space Model based language models and compare it with Transformer-based architectures.", "method": "Adapt the Attention Knockout methodology, originally developed for Transformers, to Mamba-1 and Mamba-2 models. Trace information transmission across tokens and layers, disentangle 'features' that enable token-to-token information exchange or enrich individual tokens using Mamba's structured factorization.", "result": "Revealed patterns of subject-token information emergence and layer-wise dynamics. Identified phenomena that vary between Mamba and Transformer models, as well as those that are universal across all inspected models.", "conclusion": "The study offers a unified perspective on Mamba internal operations and suggests that some observed phenomena may be inherent to large language models in general."}}
{"id": "2505.24281", "pdf": "https://arxiv.org/pdf/2505.24281", "abs": "https://arxiv.org/abs/2505.24281", "authors": ["Yang Sui", "Qi Xu", "Yang Bai", "Annie Qu"], "title": "Multi-task Learning for Heterogeneous Data via Integrating Shared and Task-Specific Encodings", "categories": ["stat.ML", "cs.LG", "stat.ME"], "comment": null, "summary": "Multi-task learning (MTL) has become an essential machine learning tool for\naddressing multiple learning tasks simultaneously and has been effectively\napplied across fields such as healthcare, marketing, and biomedical research.\nHowever, to enable efficient information sharing across tasks, it is crucial to\nleverage both shared and heterogeneous information. Despite extensive research\non MTL, various forms of heterogeneity, including distribution and posterior\nheterogeneity, present significant challenges. Existing methods often fail to\naddress these forms of heterogeneity within a unified framework. In this paper,\nwe propose a dual-encoder framework to construct a heterogeneous latent factor\nspace for each task, incorporating a task-shared encoder to capture common\ninformation across tasks and a task-specific encoder to preserve unique task\ncharacteristics. Additionally, we explore the intrinsic similarity structure of\nthe coefficients corresponding to learned latent factors, allowing for adaptive\nintegration across tasks to manage posterior heterogeneity. We introduce a\nunified algorithm that alternately learns the task-specific and task-shared\nencoders and coefficients. In theory, we investigate the excess risk bound for\nthe proposed MTL method using local Rademacher complexity and apply it to a new\nbut related task. Through simulation studies, we demonstrate that the proposed\nmethod outperforms existing data integration methods across various settings.\nFurthermore, the proposed method achieves superior predictive performance for\ntime to tumor doubling across five distinct cancer types in PDX data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u53cc\u7f16\u7801\u5668\u6846\u67b6\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u65b9\u6cd5\uff0c\u901a\u8fc7\u7edf\u4e00\u7b97\u6cd5\u89e3\u51b3\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5e76\u5728\u7406\u8bba\u548c\u5b9e\u9a8c\u4e0a\u8bc1\u660e\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u5c3d\u7ba1\u591a\u4efb\u52a1\u5b66\u4e60\uff08MTL\uff09\u88ab\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u5185\u5904\u7406\u5404\u79cd\u5f62\u5f0f\u7684\u5f02\u8d28\u6027\uff0c\u5982\u5206\u5e03\u548c\u540e\u9a8c\u5f02\u8d28\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53cc\u7f16\u7801\u5668\u6846\u67b6\uff0c\u5305\u542b\u4efb\u52a1\u5171\u4eab\u7f16\u7801\u5668\u548c\u4efb\u52a1\u7279\u5b9a\u7f16\u7801\u5668\uff0c\u7528\u4e8e\u6355\u6349\u5171\u540c\u4fe1\u606f\u548c\u4fdd\u7559\u72ec\u7279\u4efb\u52a1\u7279\u5f81\uff1b\u63a2\u7d22\u4e86\u4e0e\u5b66\u4e60\u5230\u7684\u6f5c\u5728\u56e0\u7d20\u76f8\u5bf9\u5e94\u7684\u7cfb\u6570\u7684\u5185\u5728\u76f8\u4f3c\u6027\u7ed3\u6784\uff0c\u5141\u8bb8\u8de8\u4efb\u52a1\u81ea\u9002\u5e94\u96c6\u6210\u4ee5\u7ba1\u7406\u540e\u9a8c\u5f02\u8d28\u6027\uff1b\u5f15\u5165\u4e86\u4e00\u4e2a\u7edf\u4e00\u7b97\u6cd5\u4ea4\u66ff\u5b66\u4e60\u4efb\u52a1\u7279\u5b9a\u548c\u4efb\u52a1\u5171\u4eab\u7f16\u7801\u5668\u53ca\u7cfb\u6570\u3002", "result": "\u7406\u8bba\u4e0a\uff0c\u7814\u7a76\u4e86\u63d0\u51fa\u7684MTL\u65b9\u6cd5\u7684\u8fc7\u91cf\u98ce\u9669\u754c\u9650\uff0c\u5e76\u5c06\u5176\u5e94\u7528\u4e8e\u65b0\u4f46\u76f8\u5173\u7684\u4efb\u52a1\uff1b\u901a\u8fc7\u6a21\u62df\u7814\u7a76\u8bc1\u660e\u8be5\u65b9\u6cd5\u5728\u4e0d\u540c\u8bbe\u7f6e\u4e0b\u4f18\u4e8e\u73b0\u6709\u7684\u6570\u636e\u96c6\u6210\u65b9\u6cd5\uff1b\u5728PDX\u6570\u636e\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5bf9\u4e94\u79cd\u4e0d\u540c\u764c\u75c7\u7c7b\u578b\u7684\u80bf\u7624\u500d\u589e\u65f6\u95f4\u9884\u6d4b\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53cc\u7f16\u7801\u5668\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u591a\u4efb\u52a1\u5b66\u4e60\u4e2d\u7684\u5f02\u8d28\u6027\u95ee\u9898\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u8272\u3002"}}
{"id": "2505.24754", "pdf": "https://arxiv.org/pdf/2505.24754", "abs": "https://arxiv.org/abs/2505.24754", "authors": ["Yingchaojie Feng", "Yiqun Sun", "Yandong Sun", "Minfeng Zhu", "Qiang Huang", "Anthony K. H. Tung", "Wei Chen"], "title": "Don't Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation", "categories": ["cs.CL", "cs.AI", "cs.IR"], "comment": "Accepted to ACL 2025", "summary": "In this work, we investigate an important task named instruction-following\ntext embedding, which generates dynamic text embeddings that adapt to user\ninstructions, highlighting specific attributes of text. Despite recent\nadvancements, existing approaches suffer from significant computational\noverhead, as they require re-encoding the entire corpus for each new\ninstruction. To address this challenge, we propose GSTransform, a novel\ninstruction-following text embedding framework based on Guided Space\nTransformation. Our key observation is that instruction-relevant information is\ninherently encoded in generic embeddings but remains underutilized. Instead of\nrepeatedly encoding the corpus for each instruction, GSTransform is a\nlightweight transformation mechanism that adapts pre-computed embeddings in\nreal time to align with user instructions, guided by a small amount of text\ndata with instruction-focused label annotation. We conduct extensive\nexperiments on three instruction-awareness downstream tasks across nine\nreal-world datasets, demonstrating that GSTransform improves\ninstruction-following text embedding quality over state-of-the-art methods\nwhile achieving dramatic speedups of 6~300x in real-time processing on\nlarge-scale datasets. The source code is available at\nhttps://github.com/YingchaojieFeng/GSTransform.", "AI": {"tldr": "The paper proposes GSTransform, a novel framework for instruction-following text embedding that improves quality and achieves significant speedups over existing methods.", "motivation": "Existing approaches for instruction-following text embedding suffer from high computational overhead as they require re-encoding the entire corpus for each new instruction.", "method": "GSTransform is based on Guided Space Transformation. It uses a lightweight transformation mechanism to adapt pre-computed embeddings in real time according to user instructions, guided by a small amount of text data with instruction-focused label annotation.", "result": "Extensive experiments on three instruction-awareness downstream tasks across nine real-world datasets show that GSTransform improves instruction-following text embedding quality over state-of-the-art methods while achieving dramatic speedups of 6~300x in real-time processing on large-scale datasets.", "conclusion": "GSTransform provides a more efficient way to generate dynamic text embeddings that adapt to user instructions, significantly improving both the quality and speed of instruction-following text embedding."}}
{"id": "2505.24296", "pdf": "https://arxiv.org/pdf/2505.24296", "abs": "https://arxiv.org/abs/2505.24296", "authors": ["Quinn Lanners", "Cynthia Rudin", "Alexander Volfovsky", "Harsh Parikh"], "title": "Data Fusion for Partial Identification of Causal Effects", "categories": ["stat.ME", "cs.LG", "econ.EM"], "comment": null, "summary": "Data fusion techniques integrate information from heterogeneous data sources\nto improve learning, generalization, and decision making across data sciences.\nIn causal inference, these methods leverage rich observational data to improve\ncausal effect estimation, while maintaining the trustworthiness of randomized\ncontrolled trials. Existing approaches often relax the strong no unobserved\nconfounding assumption by instead assuming exchangeability of counterfactual\noutcomes across data sources. However, when both assumptions simultaneously\nfail - a common scenario in practice - current methods cannot identify or\nestimate causal effects. We address this limitation by proposing a novel\npartial identification framework that enables researchers to answer key\nquestions such as: Is the causal effect positive or negative? and How severe\nmust assumption violations be to overturn this conclusion? Our approach\nintroduces interpretable sensitivity parameters that quantify assumption\nviolations and derives corresponding causal effect bounds. We develop doubly\nrobust estimators for these bounds and operationalize breakdown frontier\nanalysis to understand how causal conclusions change as assumption violations\nincrease. We apply our framework to the Project STAR study, which investigates\nthe effect of classroom size on students' third-grade standardized test\nperformance. Our analysis reveals that the Project STAR results are robust to\nsimultaneous violations of key assumptions, both on average and across various\nsubgroups of interest. This strengthens confidence in the study's conclusions\ndespite potential unmeasured biases in the data.", "AI": {"tldr": "\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u90e8\u5206\u8bc6\u522b\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u89e3\u91ca\u7684\u654f\u611f\u6027\u53c2\u6570\u91cf\u5316\u5047\u8bbe\u8fdd\u53cd\u60c5\u51b5\uff0c\u5e76\u5f97\u51fa\u56e0\u679c\u6548\u5e94\u754c\u9650\uff0c\u5e94\u7528\u8be5\u6846\u67b6\u4e8eProject STAR\u7814\u7a76\u4e2d\u53d1\u73b0\u5176\u7ed3\u679c\u5bf9\u5173\u952e\u5047\u8bbe\u7684\u540c\u65f6\u8fdd\u53cd\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u878d\u5408\u6280\u672f\u5728\u56e0\u679c\u63a8\u65ad\u4e2d\u65e0\u6cd5\u5e94\u5bf9\u540c\u65f6\u5b58\u5728\u672a\u89c2\u6d4b\u6df7\u6742\u548c\u53cd\u4e8b\u5b9e\u7ed3\u679c\u4e0d\u53ef\u4ea4\u6362\u7684\u60c5\u51b5\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b0\u65b9\u6cd5\u6765\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u90e8\u5206\u8bc6\u522b\u6846\u67b6\uff0c\u5f15\u5165\u4e86\u53ef\u89e3\u91ca\u7684\u654f\u611f\u6027\u53c2\u6570\u4ee5\u91cf\u5316\u5047\u8bbe\u8fdd\u53cd\u7684\u7a0b\u5ea6\uff0c\u5e76\u63a8\u5bfc\u51fa\u76f8\u5e94\u7684\u56e0\u679c\u6548\u5e94\u754c\u9650\u3002\u8fd8\u5f00\u53d1\u4e86\u53cc\u91cd\u7a33\u5065\u4f30\u8ba1\u5668\uff0c\u5e76\u5c06\u65ad\u88c2\u524d\u6cbf\u5206\u6790\u64cd\u4f5c\u5316\uff0c\u4ee5\u4e86\u89e3\u968f\u7740\u5047\u8bbe\u8fdd\u53cd\u7a0b\u5ea6\u589e\u52a0\u56e0\u679c\u7ed3\u8bba\u7684\u53d8\u5316\u3002", "result": "\u5c06\u8be5\u6846\u67b6\u5e94\u7528\u4e8eProject STAR\u7814\u7a76\u4e2d\uff0c\u53d1\u73b0\u5176\u7ed3\u679c\u5728\u5e73\u5747\u503c\u4e0a\u4ee5\u53ca\u5728\u5404\u4e2a\u611f\u5174\u8da3\u7684\u5b50\u7fa4\u4f53\u4e2d\u90fd\u5bf9\u5173\u952e\u5047\u8bbe\u7684\u540c\u65f6\u8fdd\u53cd\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u589e\u5f3a\u4e86\u5bf9Project STAR\u7814\u7a76\u7ed3\u8bba\u7684\u4fe1\u5fc3\uff0c\u5373\u4f7f\u6570\u636e\u53ef\u80fd\u5b58\u5728\u672a\u6d4b\u91cf\u7684\u504f\u5dee\u3002"}}
{"id": "2505.24759", "pdf": "https://arxiv.org/pdf/2505.24759", "abs": "https://arxiv.org/abs/2505.24759", "authors": ["Mu Qiao"], "title": "Unsupervised Evolutionary Cell Type Matching via Entropy-Minimized Optimal Transport", "categories": ["q-bio.QM", "cs.AI", "cs.LG"], "comment": null, "summary": "Identifying evolutionary correspondences between cell types across species is\na fundamental challenge in comparative genomics and evolutionary biology.\nExisting approaches often rely on either reference-based matching, which\nimposes asymmetry by designating one species as the reference, or\nprojection-based matching, which may increase computational complexity and\nobscure biological interpretability at the cell-type level. Here, we present\nOT-MESH, an unsupervised computational framework leveraging entropy-regularized\noptimal transport (OT) to systematically determine cross-species cell type\nhomologies. Our method uniquely integrates the Minimize Entropy of Sinkhorn\n(MESH) technique to refine the OT plan. It begins by selecting genes with high\nSignal-to-Noise Ratio (SNR) to capture the most informative features, from\nwhich a cost matrix is constructed using cosine distances between cell-type\ncentroids. Importantly, the MESH procedure iteratively refines the cost matrix,\nleading to a transport plan with significantly enhanced sparsity and\ninterpretability of the resulting correspondence matrices. Applied to retinal\nbipolar cells (BCs) and retinal ganglion cells (RGCs) from mouse and macaque,\nOT-MESH accurately recovers known evolutionary relationships and uncovers novel\ncorrespondences, one of which was independently validated experimentally. Thus,\nour framework offers a principled, scalable, symmetric, and interpretable\nsolution for evolutionary cell type mapping, facilitating deeper insights into\ncellular specialization and conservation across species.", "AI": {"tldr": "The paper presents OT-MESH, an unsupervised computational framework using entropy-regularized optimal transport to identify cross-species cell type homologies. It accurately recovers known evolutionary relationships and uncovers novel correspondences.", "motivation": "Identifying evolutionary correspondences between cell types across species is a fundamental challenge in comparative genomics and evolutionary biology. Existing approaches have limitations such as asymmetry or increased computational complexity.", "method": "OT-MESH uniquely integrates the Minimize Entropy of Sinkhorn (MESH) technique to refine the OT plan. It selects genes with high Signal-to-Noise Ratio (SNR) to capture the most informative features, constructs a cost matrix using cosine distances between cell-type centroids, and iteratively refines the cost matrix for enhanced sparsity and interpretability.", "result": "Applied to retinal bipolar cells (BCs) and retinal ganglion cells (RGCs) from mouse and macaque, OT-MESH accurately recovers known evolutionary relationships and uncovers novel correspondences, one of which was independently validated experimentally.", "conclusion": "OT-MESH offers a principled, scalable, symmetric, and interpretable solution for evolutionary cell type mapping, facilitating deeper insights into cellular specialization and conservation across species."}}
{"id": "2505.24311", "pdf": "https://arxiv.org/pdf/2505.24311", "abs": "https://arxiv.org/abs/2505.24311", "authors": ["Yi Gu"], "title": "Equilibrium Distribution for t-Distributed Stochastic Neighbor Embedding with Generalized Kernels", "categories": ["stat.ML", "cs.LG", "math.PR", "math.ST", "stat.TH", "60"], "comment": null, "summary": "T-distributed stochastic neighbor embedding (t-SNE) is a well-known algorithm\nfor visualizing high-dimensional data by finding low-dimensional\nrepresentations. In this paper, we study the convergence of t-SNE with\ngeneralized kernels and extend the results of Auffinger and Fletcher in 2023.\nOur work starts by giving a concrete formulation of generalized input and\noutput kernels. Then we prove that under certain conditions, the t-SNE\nalgorithm converges to an equilibrium distribution for a wide range of input\nand output kernels as the number of data points diverges.", "AI": {"tldr": "\u7814\u7a76\u4e86\u5e26\u5e7f\u4e49\u6838\u7684t-SNE\u7b97\u6cd5\u7684\u6536\u655b\u6027\uff0c\u5e76\u6269\u5c55\u4e86\u4e4b\u524d\u7684\u7814\u7a76\u6210\u679c\u3002", "motivation": "\u5c3d\u7ba1t-SNE\u662f\u7528\u4e8e\u9ad8\u7ef4\u6570\u636e\u53ef\u89c6\u5316\u7684\u77e5\u540d\u7b97\u6cd5\uff0c\u4f46\u5bf9\u4e8e\u5e26\u5e7f\u4e49\u6838\u7684t-SNE\u7b97\u6cd5\u7684\u6536\u655b\u6027\u7814\u7a76\u5c1a\u4e0d\u5145\u5206\u3002", "method": "\u901a\u8fc7\u7ed9\u51fa\u5e7f\u4e49\u8f93\u5165\u548c\u8f93\u51fa\u6838\u7684\u5177\u4f53\u516c\u5f0f\uff0c\u5e76\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u5206\u6790t-SNE\u7b97\u6cd5\u7684\u884c\u4e3a\u3002", "result": "\u8bc1\u660e\u4e86\u5728\u6570\u636e\u70b9\u6570\u91cf\u8d8b\u4e8e\u65e0\u7a77\u65f6\uff0ct-SNE\u7b97\u6cd5\u6536\u655b\u5230\u4e00\u4e2a\u5e73\u8861\u5206\u5e03\u3002", "conclusion": "\u8fd9\u4e00\u7ed3\u679c\u8868\u660et-SNE\u7b97\u6cd5\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\uff0c\u5c24\u5176\u662f\u5728\u5904\u7406\u4e0d\u540c\u7c7b\u578b\u7684\u6570\u636e\u6838\u65f6\u3002"}}
{"id": "2505.24327", "pdf": "https://arxiv.org/pdf/2505.24327", "abs": "https://arxiv.org/abs/2505.24327", "authors": ["Jingjing Liu", "Jiashun Jin", "Xianchao Xiu", "Jianhua Zhang", "Wanquan Liu"], "title": "STAR-Net: An Interpretable Model-Aided Network for Remote Sensing Image Denoising", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Remote sensing image (RSI) denoising is an important topic in the field of\nremote sensing. Despite the impressive denoising performance of RSI denoising\nmethods, most current deep learning-based approaches function as black boxes\nand lack integration with physical information models, leading to limited\ninterpretability. Additionally, many methods may struggle with insufficient\nattention to non-local self-similarity in RSI and require tedious tuning of\nregularization parameters to achieve optimal performance, particularly in\nconventional iterative optimization approaches. In this paper, we first propose\na novel RSI denoising method named sparse tensor-aided representation network\n(STAR-Net), which leverages a low-rank prior to effectively capture the\nnon-local self-similarity within RSI. Furthermore, we extend STAR-Net to a\nsparse variant called STAR-Net-S to deal with the interference caused by\nnon-Gaussian noise in original RSI for the purpose of improving robustness.\nDifferent from conventional iterative optimization, we develop an alternating\ndirection method of multipliers (ADMM)-guided deep unrolling network, in which\nall regularization parameters can be automatically learned, thus inheriting the\nadvantages of both model-based and deep learning-based approaches and\nsuccessfully addressing the above-mentioned shortcomings. Comprehensive\nexperiments on synthetic and real-world datasets demonstrate that STAR-Net and\nSTAR-Net-S outperform state-of-the-art RSI denoising methods.", "AI": {"tldr": "The paper proposes STAR-Net and STAR-Net-S for RSI denoising, leveraging non-local self-similarity and low-rank prior while integrating physical models with deep learning. It also introduces an ADMM-guided unrolling network to automate parameter tuning.", "motivation": "To address the lack of interpretability in current deep learning-based RSI denoising methods and their insufficient attention to non-local self-similarity, as well as the need for tedious tuning of regularization parameters in conventional iterative optimization approaches.", "method": "STAR-Net uses a low-rank prior to capture non-local self-similarity in RSIs. STAR-Net-S is a sparse variant designed to handle non-Gaussian noise. An ADMM-guided deep unrolling network is developed to automatically learn all regularization parameters, combining model-based and deep learning-based advantages.", "result": "Comprehensive experiments on both synthetic and real-world datasets show that STAR-Net and STAR-Net-S outperform state-of-the-art RSI denoising methods.", "conclusion": "STAR-Net and STAR-Net-S effectively denoise RSIs by leveraging non-local self-similarity and low-rank priors, while the ADMM-guided unrolling network automates parameter tuning, leading to superior performance."}}
{"id": "2505.24765", "pdf": "https://arxiv.org/pdf/2505.24765", "abs": "https://arxiv.org/abs/2505.24765", "authors": ["Srikanth Thudumu", "Jason Fisher", "Hung Du"], "title": "Supervised Quantum Machine Learning: A Future Outlook from Qubits to Enterprise Applications", "categories": ["quant-ph", "cs.AI"], "comment": "Future outlook and roadmap of QML with 7 pages and 1 figure", "summary": "Supervised Quantum Machine Learning (QML) represents an intersection of\nquantum computing and classical machine learning, aiming to use quantum\nresources to support model training and inference. This paper reviews recent\ndevelopments in supervised QML, focusing on methods such as variational quantum\ncircuits, quantum neural networks, and quantum kernel methods, along with\nhybrid quantum-classical workflows. We examine recent experimental studies that\nshow partial indications of quantum advantage and describe current limitations\nincluding noise, barren plateaus, scalability issues, and the lack of formal\nproofs of performance improvement over classical methods. The main contribution\nis a ten-year outlook (2025-2035) that outlines possible developments in\nsupervised QML, including a roadmap describing conditions under which QML may\nbe used in applied research and enterprise systems over the next decade.", "AI": {"tldr": "This paper reviews recent developments in supervised Quantum Machine Learning (QML), focusing on methods like variational quantum circuits, quantum neural networks, and quantum kernel methods. It examines experimental studies showing partial quantum advantage, describes current limitations, and provides a ten-year outlook for possible developments in supervised QML.", "motivation": "To explore the intersection of quantum computing and classical machine learning by reviewing recent advancements in supervised QML and providing insights into its future potential.", "method": "Reviewing recent developments in supervised QML methods such as variational quantum circuits, quantum neural networks, and quantum kernel methods along with hybrid quantum-classical workflows. Examining experimental studies that indicate quantum advantage and identifying current limitations including noise, barren plateaus, scalability issues, and lack of formal proofs.", "result": "The review highlights partial indications of quantum advantage from recent experimental studies while outlining the challenges such as noise, barren plateaus, scalability issues, and the need for formal proofs of performance improvement over classical methods.", "conclusion": "A ten-year outlook (2025-2035) is provided, detailing possible developments in supervised QML and presenting a roadmap for its use in applied research and enterprise systems under specific conditions."}}
{"id": "2505.24333", "pdf": "https://arxiv.org/pdf/2505.24333", "abs": "https://arxiv.org/abs/2505.24333", "authors": ["Alessio Giorlandino", "Sebastian Goldt"], "title": "Two failure modes of deep transformers and how to avoid them: a unified theory of signal propagation at initialisation", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.LG"], "comment": null, "summary": "Finding the right initialisation for neural networks is crucial to ensure\nsmooth training and good performance. In transformers, the wrong initialisation\ncan lead to one of two failure modes of self-attention layers: rank collapse,\nwhere all tokens collapse into similar representations, and entropy collapse,\nwhere highly concentrated attention scores lead to training instability. While\nthe right initialisation has been extensively studied in feed-forward networks,\nan exact description of signal propagation through a full transformer block has\nso far been lacking. Here, we provide an analytical theory of signal\npropagation through vanilla transformer blocks with self-attention layers,\nlayer normalisation, skip connections and ReLU MLP. To treat the self-attention\nlayer, we draw on a formal parallel with the Random Energy Model from\nstatistical physics. We identify and characterise two regimes governed by the\nvariance of the query and key initialisations: a low-variance regime, where we\nrecover the known rank collapse behaviour; and a previously unexplored\nhigh-variance regime, where signal is preserved but \\textit{entropy collapse}\noccurs. In the low-variance regime, we calculate the critical strength for the\nresidual connection to ensure signal propagation. Our theory yields\ntrainability diagrams that identify the correct choice of initialisation\nhyper-parameters for a given architecture. Experiments with BERT-style models\ntrained on TinyStories validate our predictions. Our theoretical framework\ngives a unified perspective on the two failure modes of self-attention and\ngives quantitative predictions on the scale of both weights and residual\nconnections that guarantees smooth training.", "AI": {"tldr": "\u5728\u53d8\u538b\u5668\u5757\u4e2d\uff0c\u4fe1\u53f7\u4f20\u64ad\u7684\u5206\u6790\u7406\u8bba\u63ed\u793a\u4e86\u81ea\u6211\u5173\u6ce8\u5c42\u7684\u4e24\u79cd\u521d\u59cb\u72b6\u6001\u6a21\u5f0f\uff1a\u4f4e\u5dee\u5f02\u6a21\u5f0f\u4e0b\u7684\u79e9\u5d29\u6e83\u548c\u9ad8\u5dee\u5f02\u6a21\u5f0f\u4e0b\u7684\u71b5\u5d29\u6e83\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u8bad\u7ec3\u56fe\u8868\u4ee5\u786e\u5b9a\u7ed9\u5b9a\u67b6\u6784\u7684\u6b63\u786e\u521d\u59cb\u8d85\u53c2\u6570\u9009\u62e9\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u9884\u6d4b\u3002", "motivation": "\u627e\u5230\u795e\u7ecf\u7f51\u7edc\u7684\u6b63\u786e\u521d\u59cb\u5316\u5bf9\u4e8e\u786e\u4fdd\u5e73\u7a33\u8bad\u7ec3\u548c\u826f\u597d\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u7136\u800c\uff0c\u5728\u53d8\u538b\u5668\u4e2d\u9519\u8bef\u7684\u521d\u59cb\u5316\u4f1a\u5bfc\u81f4\u81ea\u6ce8\u610f\u529b\u5c42\u7684\u5931\u8d25\u6a21\u5f0f\uff0c\u5982\u79e9\u5d29\u6e83\u6216\u71b5\u5d29\u6e83\u3002\u867d\u7136\u524d\u9988\u7f51\u7edc\u7684\u6b63\u786e\u521d\u59cb\u5316\u5df2\u88ab\u5e7f\u6cdb\u7814\u7a76\uff0c\u4f46\u5bf9\u5b8c\u6574\u53d8\u538b\u5668\u5757\u7684\u4fe1\u53f7\u4f20\u64ad\u7684\u786e\u5207\u63cf\u8ff0\u5c1a\u4e0d\u660e\u786e\u3002", "method": "\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5173\u4e8e\u901a\u8fc7\u5177\u6709\u81ea\u6ce8\u610f\u5c42\u3001\u5c42\u5f52\u4e00\u5316\u3001\u8df3\u8fc7\u8fde\u63a5\u548cReLU MLP\u7684\u666e\u901a\u53d8\u538b\u5668\u5757\u7684\u4fe1\u53f7\u4f20\u64ad\u7684\u5206\u6790\u7406\u8bba\u3002\u901a\u8fc7\u4e0e\u7edf\u8ba1\u7269\u7406\u5b66\u4e2d\u7684\u968f\u673a\u80fd\u91cf\u6a21\u578b\u8fdb\u884c\u5f62\u5f0f\u4e0a\u7684\u5e73\u884c\u5904\u7406\uff0c\u8bc6\u522b\u5e76\u63cf\u8ff0\u4e86\u7531\u67e5\u8be2\u548c\u952e\u521d\u59cb\u5316\u7684\u65b9\u5dee\u63a7\u5236\u7684\u4e24\u4e2a\u5236\u5ea6\uff1a\u4f4e\u65b9\u5dee\u5236\u5ea6\uff08\u6062\u590d\u5df2\u77e5\u7684\u79e9\u5d29\u6e83\u884c\u4e3a\uff09\u548c\u9ad8\u65b9\u5dee\u5236\u5ea6\uff08\u4fe1\u53f7\u5f97\u4ee5\u4fdd\u5b58\u4f46\u53d1\u751f\u71b5\u5d29\u6e83\uff09\u3002", "result": "\u7406\u8bba\u8ba1\u7b97\u51fa\u4e86\u4f4e\u65b9\u5dee\u5236\u5ea6\u4e0b\u786e\u4fdd\u4fe1\u53f7\u4f20\u64ad\u7684\u6b8b\u5dee\u8fde\u63a5\u7684\u5173\u952e\u5f3a\u5ea6\uff0c\u5e76\u751f\u6210\u4e86\u53ef\u8bad\u7ec3\u6027\u56fe\uff0c\u4ee5\u8bc6\u522b\u7ed9\u5b9a\u67b6\u6784\u7684\u6b63\u786e\u521d\u59cb\u5316\u8d85\u53c2\u6570\u9009\u62e9\u3002\u4f7f\u7528TinyStories\u8bad\u7ec3\u7684BERT\u98ce\u683c\u6a21\u578b\u7684\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u9884\u6d4b\u3002", "conclusion": "\u8be5\u7406\u8bba\u6846\u67b6\u4e3a\u81ea\u6ce8\u610f\u529b\u7684\u4e24\u79cd\u5931\u8d25\u6a21\u5f0f\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u89c2\u70b9\uff0c\u5e76\u7ed9\u51fa\u4e86\u4fdd\u8bc1\u5e73\u7a33\u8bad\u7ec3\u7684\u6743\u91cd\u548c\u6b8b\u5dee\u8fde\u63a5\u89c4\u6a21\u7684\u5b9a\u91cf\u9884\u6d4b\u3002"}}
{"id": "2505.24767", "pdf": "https://arxiv.org/pdf/2505.24767", "abs": "https://arxiv.org/abs/2505.24767", "authors": ["Nabasmita Talukdar", "Xiaodan Zhang", "Shreya Paithankar", "Hui Wang", "Bin Chen"], "title": "A survey of using EHR as real-world evidence for discovering and validating new drug indications", "categories": ["stat.AP", "cs.AI"], "comment": null, "summary": "Electronic Health Records (EHRs) have been increasingly used as real-world\nevidence (RWE) to support the discovery and validation of new drug indications.\nThis paper surveys current approaches to EHR-based drug repurposing, covering\ndata sources, processing methodologies, and representation techniques. It\ndiscusses study designs and statistical frameworks for evaluating drug\nefficacy. Key challenges in validation are discussed, with emphasis on the role\nof large language models (LLMs) and target trial emulation. By synthesizing\nrecent developments and methodological advances, this work provides a\nfoundational resource for researchers aiming to translate real-world data into\nactionable drug-repurposing evidence.", "AI": {"tldr": "The paper explores the use of Electronic Health Records (EHRs) as real-world evidence for drug repurposing, discussing data sources, methodologies, representation techniques, study designs, and statistical frameworks. It highlights challenges in validation and the role of large language models and target trial emulation.", "motivation": "There is a need to effectively utilize Electronic Health Records (EHRs) as real-world evidence to support the discovery and validation of new drug indications through drug repurposing.", "method": "The paper surveys current approaches to EHR-based drug repurposing by covering data sources, processing methodologies, representation techniques, study designs, and statistical frameworks for evaluating drug efficacy.", "result": "The work synthesizes recent developments and methodological advances in using EHRs for drug repurposing, providing insights into the key challenges in validation including the role of large language models and target trial emulation.", "conclusion": "This paper serves as a foundational resource for researchers aiming to leverage real-world data from EHRs into actionable evidence for drug repurposing."}}
{"id": "2505.24786", "pdf": "https://arxiv.org/pdf/2505.24786", "abs": "https://arxiv.org/abs/2505.24786", "authors": ["Eran Bamani Beeri", "Eden Nissinman", "Avishai Sintov"], "title": "DiG-Net: Enhancing Quality of Life through Hyper-Range Dynamic Gesture Recognition in Assistive Robotics", "categories": ["cs.RO", "cs.AI", "cs.CV"], "comment": "arXiv admin note: substantial text overlap with arXiv:2411.18413", "summary": "Dynamic hand gestures play a pivotal role in assistive human-robot\ninteraction (HRI), facilitating intuitive, non-verbal communication,\nparticularly for individuals with mobility constraints or those operating\nrobots remotely. Current gesture recognition methods are mostly limited to\nshort-range interactions, reducing their utility in scenarios demanding robust\nassistive communication from afar. In this paper, we introduce a novel approach\ndesigned specifically for assistive robotics, enabling dynamic gesture\nrecognition at extended distances of up to 30 meters, thereby significantly\nimproving accessibility and quality of life. Our proposed Distance-aware\nGesture Network (DiG-Net) effectively combines Depth-Conditioned Deformable\nAlignment (DADA) blocks with Spatio-Temporal Graph modules, enabling robust\nprocessing and classification of gesture sequences captured under challenging\nconditions, including significant physical attenuation, reduced resolution, and\ndynamic gesture variations commonly experienced in real-world assistive\nenvironments. We further introduce the Radiometric Spatio-Temporal Depth\nAttenuation Loss (RSTDAL), shown to enhance learning and strengthen model\nrobustness across varying distances. Our model demonstrates significant\nperformance improvement over state-of-the-art gesture recognition frameworks,\nachieving a recognition accuracy of 97.3% on a diverse dataset with challenging\nhyper-range gestures. By effectively interpreting gestures from considerable\ndistances, DiG-Net significantly enhances the usability of assistive robots in\nhome healthcare, industrial safety, and remote assistance scenarios, enabling\nseamless and intuitive interactions for users regardless of physical\nlimitations", "AI": {"tldr": "This paper presents DiG-Net, a novel approach for dynamic gesture recognition in assistive robotics up to 30 meters away, using DADA blocks and Spatio-Temporal Graph modules. The model achieves 97.3% accuracy on challenging gestures.", "motivation": "Dynamic hand gestures are crucial for human-robot interaction, especially for those with mobility constraints or operating robots remotely. Existing methods struggle with long-range interactions.", "method": "The Distance-aware Gesture Network (DiG-Net) combines Depth-Conditioned Deformable Alignment (DADA) blocks with Spatio-Temporal Graph modules. It also uses the Radiometric Spatio-Temporal Depth Attenuation Loss (RSTDAL) to enhance learning and robustness across varying distances.", "result": "DiG-Net shows significant performance improvement over state-of-the-art gesture recognition frameworks, achieving a recognition accuracy of 97.3% on a diverse dataset with challenging hyper-range gestures.", "conclusion": "DiG-Net enhances the usability of assistive robots in various scenarios such as home healthcare, industrial safety, and remote assistance, allowing seamless interactions regardless of physical limitations."}}
{"id": "2505.24340", "pdf": "https://arxiv.org/pdf/2505.24340", "abs": "https://arxiv.org/abs/2505.24340", "authors": ["Gilles Quentin Hacheme", "Girmaw Abebe Tadesse", "Caleb Robinson", "Akram Zaytar", "Rahul Dodhia", "Juan M. Lavista Ferres"], "title": "GeoVision Labeler: Zero-Shot Geospatial Classification with Vision and Language Models", "categories": ["cs.CV", "cs.CL", "cs.LG", "I.2.10; I.2.7; I.4.8; I.5.3"], "comment": null, "summary": "Classifying geospatial imagery remains a major bottleneck for applications\nsuch as disaster response and land-use monitoring-particularly in regions where\nannotated data is scarce or unavailable. Existing tools (e.g., RS-CLIP) that\nclaim zero-shot classification capabilities for satellite imagery nonetheless\nrely on task-specific pretraining and adaptation to reach competitive\nperformance. We introduce GeoVision Labeler (GVL), a strictly zero-shot\nclassification framework: a vision Large Language Model (vLLM) generates rich,\nhuman-readable image descriptions, which are then mapped to user-defined\nclasses by a conventional Large Language Model (LLM). This modular, and\ninterpretable pipeline enables flexible image classification for a large range\nof use cases. We evaluated GVL across three benchmarks-SpaceNet v7, UC Merced,\nand RESISC45. It achieves up to 93.2% zero-shot accuracy on the binary\nBuildings vs. No Buildings task on SpaceNet v7. For complex multi-class\nclassification tasks (UC Merced, RESISC45), we implemented a recursive\nLLM-driven clustering to form meta-classes at successive depths, followed by\nhierarchical classification-first resolving coarse groups, then finer\ndistinctions-to deliver competitive zero-shot performance. GVL is open-sourced\nat https://github.com/microsoft/geo-vision-labeler to catalyze adoption in\nreal-world geospatial workflows.", "AI": {"tldr": "The paper presents GeoVision Labeler (GVL), a strictly zero-shot classification framework for geospatial imagery. It uses a vision Large Language Model (vLLM) to generate image descriptions, which are then mapped to user-defined classes by a conventional Large Language Model (LLM). GVL achieves up to 93.2% zero-shot accuracy on binary tasks and implements recursive LLM-driven clustering for multi-class classification tasks.", "motivation": "Classifying geospatial imagery is challenging, especially in regions with scarce or unavailable annotated data. Existing tools claiming zero-shot capabilities still rely on task-specific pretraining and adaptation to reach competitive performance.", "method": "GVL is a modular pipeline where a vLLM generates rich, human-readable image descriptions. These descriptions are then mapped to user-defined classes by an LLM. For complex multi-class tasks, a recursive LLM-driven clustering forms meta-classes at successive depths, followed by hierarchical classification.", "result": "GVL achieves up to 93.2% zero-shot accuracy on the binary Buildings vs. No Buildings task on SpaceNet v7. It delivers competitive zero-shot performance on complex multi-class classification tasks using hierarchical classification.", "conclusion": "GVL is a flexible and interpretable pipeline for zero-shot classification of geospatial imagery, enabling a wide range of use cases. The framework is open-sourced to encourage adoption in real-world geospatial workflows."}}
{"id": "2505.24788", "pdf": "https://arxiv.org/pdf/2505.24788", "abs": "https://arxiv.org/abs/2505.24788", "authors": ["Houjun Liu", "John Bauer", "Christopher D. Manning"], "title": "Drop Dropout on Single-Epoch Language Model Pretraining", "categories": ["cs.CL", "cs.AI"], "comment": "Accepted to ACL Findings; 5 pages, 2 figures, 4 pages of appendix", "summary": "Originally, dropout was seen as a breakthrough regularization technique that\nreduced overfitting and improved performance in almost all applications of deep\nlearning by reducing overfitting. Yet, single-epoch pretraining tasks common to\nmodern LLMs yield minimal overfitting, leading to dropout not being used for\nlarge LLMs. Nevertheless, no thorough empirical investigation has been done on\nthe role of dropout in LM pretraining. Through experiments in single-epoch\npretraining of both masked (BERT) and autoregressive (Pythia 160M and 1.4B) LMs\nwith varying levels of dropout, we find that downstream performance in language\nmodeling, morpho-syntax (BLiMP), question answering (SQuAD), and\nnatural-language inference (MNLI) improves when dropout is not applied during\npretraining. We additionally find that the recently-introduced \"early dropout\"\nalso degrades performance over applying no dropout at all. We further\ninvestigate the models' editability, and find that models trained without\ndropout are more successful in gradient-based model editing (MEND) and\nequivalent in representation-based model editing (ReFT). Therefore, we advocate\nto drop dropout during single-epoch pretraining.", "AI": {"tldr": "In single-epoch pretraining for LLMs, dropout and early dropout degrade downstream performance in various tasks and model editability. Thus, dropout should be avoided in such pretraining.", "motivation": "To investigate the role of dropout in single-epoch pretraining of language models, given its traditional effectiveness in reducing overfitting but minimal use in large LLMs due to low overfitting.", "method": "Conduct experiments on single-epoch pretraining of masked (BERT) and autoregressive (Pythia 160M and 1.4B) LMs with different levels of dropout, including no dropout and early dropout.", "result": "Downstream performance in language modeling, morpho-syntax, question answering, and natural-language inference improves when no dropout is applied during pretraining. Early dropout also degrades performance compared to no dropout. Models trained without dropout are more successful in gradient-based model editing and equivalent in representation-based model editing.", "conclusion": "Dropout should be avoided during single-epoch pretraining of LLMs."}}
{"id": "2505.24428", "pdf": "https://arxiv.org/pdf/2505.24428", "abs": "https://arxiv.org/abs/2505.24428", "authors": ["Xu Wang", "Zihao Li", "Benyou Wang", "Yan Hu", "Difan Zou"], "title": "Model Unlearning via Sparse Autoencoder Subspace Guided Projections", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "Large language models (LLMs) store vast amounts of information, making them\npowerful yet raising privacy and safety concerns when selective knowledge\nremoval is required. Existing unlearning strategies, ranging from\ngradient-based fine-tuning and model editing to sparse autoencoder (SAE)\nsteering, either lack interpretability or fail to provide a robust defense\nagainst adversarial prompts. We propose SAE-Guided Subspace Projection\nUnlearning (SSPU), a novel framework that leverages SAE features to drive\ntargeted updates in the model's parameter space, enabling precise,\ninterpretable, and robust unlearning. SSPU's three-stage pipeline performs\ndata-driven layer and feature selection, subspace construction via QR\ndecomposition, and constrained optimization that controls activations into an\n\"irrelevant\" subspace while preserving retained knowledge. Overall, we use SAE\nfeatures to construct a subspace that supervises unlearning, refining the loss\nand adding a regularization term to guide interpretable parameter updates. In\nexperiments on the WMDP-Cyber forget set and three utility benchmarks (MMLU,\nTruthfulQA, GSM8K), SSPU reduces harmful knowledge accuracy by 3.22% compared\nto the strongest baseline. It also improves adversarial robustness, lowering\nmalicious accuracy under jailbreak prompts compared to baselines. Our findings\nexpose the limitations of prior unlearning methods and demonstrate how\ninterpretable subspace-guided optimization can achieve robust, controllable\nmodel behavior.", "AI": {"tldr": "SSPU is a new framework that uses SAE features for precise, interpretable, and robust unlearning in LLMs. It reduces harmful knowledge accuracy and improves adversarial robustness compared to baselines.", "motivation": "Existing unlearning strategies either lack interpretability or fail to provide robust defense against adversarial prompts in LLMs.", "method": "SSPU's three-stage pipeline performs data-driven layer and feature selection, subspace construction via QR decomposition, and constrained optimization controlling activations into an 'irrelevant' subspace while preserving retained knowledge.", "result": "In experiments on the WMDP-Cyber forget set and three utility benchmarks (MMLU, TruthfulQA, GSM8K), SSPU reduces harmful knowledge accuracy by 3.22% compared to the strongest baseline. It also improves adversarial robustness, lowering malicious accuracy under jailbreak prompts compared to baselines.", "conclusion": "The findings expose the limitations of prior unlearning methods and demonstrate how interpretable subspace-guided optimization can achieve robust, controllable model behavior."}}
{"id": "2505.24808", "pdf": "https://arxiv.org/pdf/2505.24808", "abs": "https://arxiv.org/abs/2505.24808", "authors": ["Wenhao Ding", "Sushant Veer", "Yuxiao Chen", "Yulong Cao", "Chaowei Xiao", "Marco Pavone"], "title": "RealDrive: Retrieval-Augmented Driving with Diffusion Models", "categories": ["cs.RO", "cs.AI"], "comment": null, "summary": "Learning-based planners generate natural human-like driving behaviors by\nlearning to reason about nuanced interactions from data, overcoming the rigid\nbehaviors that arise from rule-based planners. Nonetheless, data-driven\napproaches often struggle with rare, safety-critical scenarios and offer\nlimited controllability over the generated trajectories. To address these\nchallenges, we propose RealDrive, a Retrieval-Augmented Generation (RAG)\nframework that initializes a diffusion-based planning policy by retrieving the\nmost relevant expert demonstrations from the training dataset. By interpolating\nbetween current observations and retrieved examples through a denoising\nprocess, our approach enables fine-grained control and safe behavior across\ndiverse scenarios, leveraging the strong prior provided by the retrieved\nscenario. Another key insight we produce is that a task-relevant retrieval\nmodel trained with planning-based objectives results in superior planning\nperformance in our framework compared to a task-agnostic retriever.\nExperimental results demonstrate improved generalization to long-tail events\nand enhanced trajectory diversity compared to standard learning-based planners\n-- we observe a 40% reduction in collision rate on the Waymo Open Motion\ndataset with RAG.", "AI": {"tldr": "RealDrive\u662f\u4e00\u79cd\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\u7684\u89c4\u5212\u65b9\u6cd5\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u76f8\u5173\u4e13\u5bb6\u6f14\u793a\u6765\u521d\u59cb\u5316\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u7b56\u7565\uff0c\u4ece\u800c\u5728\u5404\u79cd\u573a\u666f\u4e2d\u5b9e\u73b0\u7cbe\u7ec6\u63a7\u5236\u548c\u5b89\u5168\u884c\u4e3a\u3002\u5b9e\u9a8c\u8868\u660e\uff0c\u4e0e\u6807\u51c6\u5b66\u4e60\u578b\u89c4\u5212\u5668\u76f8\u6bd4\uff0cRealDrive\u51cf\u5c11\u4e8640%\u7684\u78b0\u649e\u7387\u3002", "motivation": "\u6570\u636e\u9a71\u52a8\u7684\u5b66\u4e60\u578b\u89c4\u5212\u5668\u867d\u7136\u80fd\u751f\u6210\u81ea\u7136\u7684\u4eba\u7c7b\u9a7e\u9a76\u884c\u4e3a\uff0c\u4f46\u5728\u5904\u7406\u7a00\u6709\u3001\u5b89\u5168\u5173\u952e\u573a\u666f\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u5e76\u4e14\u5bf9\u751f\u6210\u8f68\u8ff9\u7684\u53ef\u63a7\u6027\u6709\u9650\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aRealDrive\u7684\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4f7f\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u8bad\u7ec3\u6570\u636e\u96c6\u4e2d\u68c0\u7d22\u6700\u76f8\u5173\u7684\u4e13\u5bb6\u6f14\u793a\u6765\u521d\u59cb\u5316\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u7b56\u7565\u3002\u5e76\u901a\u8fc7\u53bb\u566a\u8fc7\u7a0b\u5728\u5f53\u524d\u89c2\u6d4b\u548c\u68c0\u7d22\u793a\u4f8b\u4e4b\u95f4\u8fdb\u884c\u63d2\u503c\uff0c\u5229\u7528\u68c0\u7d22\u5230\u7684\u60c5\u666f\u63d0\u4f9b\u7684\u5f3a\u5148\u9a8c\u77e5\u8bc6\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u57fa\u4e8e\u89c4\u5212\u76ee\u6807\u8bad\u7ec3\u7684\u4efb\u52a1\u76f8\u5173\u68c0\u7d22\u6a21\u578b\u6bd4\u4efb\u52a1\u65e0\u5173\u68c0\u7d22\u5668\u8868\u73b0\u51fa\u66f4\u4f18\u7684\u89c4\u5212\u6027\u80fd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u6807\u51c6\u5b66\u4e60\u578b\u89c4\u5212\u5668\u76f8\u6bd4\uff0cRealDrive\u5728Waymo Open Motion\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u957f\u5c3e\u4e8b\u4ef6\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u548c\u66f4\u9ad8\u7684\u8f68\u8ff9\u591a\u6837\u6027\uff0c\u5e76\u5c06\u78b0\u649e\u7387\u964d\u4f4e\u4e8640%\u3002", "conclusion": "RealDrive\u901a\u8fc7\u7ed3\u5408\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u6846\u67b6\u548c\u57fa\u4e8e\u6269\u6563\u7684\u89c4\u5212\u7b56\u7565\uff0c\u5728\u63d0\u9ad8\u5b89\u5168\u6027\u7684\u540c\u65f6\u589e\u5f3a\u4e86\u5bf9\u751f\u6210\u8f68\u8ff9\u7684\u63a7\u5236\u80fd\u529b\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u89c4\u5212\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u65b9\u6cd5\u3002"}}
{"id": "2505.24443", "pdf": "https://arxiv.org/pdf/2505.24443", "abs": "https://arxiv.org/abs/2505.24443", "authors": ["Heejo Kong", "Sung-Jin Kim", "Gunho Jung", "Seong-Whan Lee"], "title": "Diversify and Conquer: Open-set Disagreement for Robust Semi-supervised Learning with Outliers", "categories": ["cs.CV", "cs.LG"], "comment": "Accepted by IEEE Transactions on Neural Networks and Learning Systems\n  (TNNLS)", "summary": "Conventional semi-supervised learning (SSL) ideally assumes that labeled and\nunlabeled data share an identical class distribution, however in practice, this\nassumption is easily violated, as unlabeled data often includes unknown class\ndata, i.e., outliers. The outliers are treated as noise, considerably degrading\nthe performance of SSL models. To address this drawback, we propose a novel\nframework, Diversify and Conquer (DAC), to enhance SSL robustness in the\ncontext of open-set semi-supervised learning. In particular, we note that\nexisting open-set SSL methods rely on prediction discrepancies between inliers\nand outliers from a single model trained on labeled data. This approach can be\neasily failed when the labeled data is insufficient, leading to performance\ndegradation that is worse than naive SSL that do not account for outliers. In\ncontrast, our approach exploits prediction disagreements among multiple models\nthat are differently biased towards the unlabeled distribution. By leveraging\nthe discrepancies arising from training on unlabeled data, our method enables\nrobust outlier detection even when the labeled data is underspecified. Our key\ncontribution is constructing a collection of differently biased models through\na single training process. By encouraging divergent heads to be differently\nbiased towards outliers while making consistent predictions for inliers, we\nexploit the disagreement among these heads as a measure to identify unknown\nconcepts. Our code is available at https://github.com/heejokong/DivCon.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u6846\u67b6Diversify and Conquer (DAC)\uff0c\u4ee5\u589e\u5f3a\u534a\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u5728\u5f00\u653e\u96c6\u534a\u76d1\u7763\u5b66\u4e60\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u6807\u8bb0\u6570\u636e\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u6784\u5efa\u4e00\u7ec4\u4e0d\u540c\u504f\u5dee\u7684\u6a21\u578b\uff0c\u5229\u7528\u5b83\u4eec\u5728\u672a\u6807\u8bb0\u6570\u636e\u8bad\u7ec3\u65f6\u7684\u9884\u6d4b\u5dee\u5f02\uff0c\u5b9e\u73b0\u5bf9\u5916\u90e8\u672a\u77e5\u7c7b\u522b\u7684\u9c81\u68d2\u68c0\u6d4b\u3002", "motivation": "\u4f20\u7edf\u7684\u534a\u76d1\u7763\u5b66\u4e60\uff08SSL\uff09\u5047\u8bbe\u6807\u8bb0\u548c\u672a\u6807\u8bb0\u6570\u636e\u5177\u6709\u76f8\u540c\u7684\u7c7b\u522b\u5206\u5e03\uff0c\u4f46\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u672a\u6807\u8bb0\u6570\u636e\u901a\u5e38\u5305\u542b\u672a\u77e5\u7c7b\u522b\u7684\u6570\u636e\uff08\u5373\u5916\u90e8\u6570\u636e\u6216\u5f02\u5e38\u503c\uff09\uff0c\u8fd9\u4f1a\u663e\u8457\u964d\u4f4eSSL\u6a21\u578b\u7684\u6027\u80fd\u3002\u73b0\u6709\u7684\u5f00\u653e\u96c6SSL\u65b9\u6cd5\u4f9d\u8d56\u4e8e\u5355\u4e2a\u6a21\u578b\u5bf9\u5185\u90e8\u6570\u636e\u548c\u5916\u90e8\u6570\u636e\u7684\u9884\u6d4b\u5dee\u5f02\uff0c\u5f53\u6807\u8bb0\u6570\u636e\u4e0d\u8db3\u65f6\u5bb9\u6613\u5931\u8d25\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002", "method": "DAC\u6846\u67b6\u7684\u6838\u5fc3\u601d\u60f3\u662f\u901a\u8fc7\u5355\u4e00\u8bad\u7ec3\u8fc7\u7a0b\u6784\u5efa\u4e00\u7ec4\u5177\u6709\u4e0d\u540c\u504f\u5dee\u7684\u6a21\u578b\u3002\u8fd9\u4e9b\u6a21\u578b\u5728\u5bf9\u5f85\u5916\u90e8\u6570\u636e\u65f6\u8868\u73b0\u51fa\u4e0d\u540c\u7684\u504f\u5411\uff0c\u800c\u5728\u5185\u90e8\u6570\u636e\u4e0a\u4fdd\u6301\u4e00\u81f4\u7684\u9884\u6d4b\u3002\u901a\u8fc7\u9f13\u52b1\u6a21\u578b\u7684\u4e0d\u540c\u5934\u90e8\u7ed3\u6784\u5bf9\u5916\u90e8\u6570\u636e\u4ea7\u751f\u5206\u6b67\uff0c\u540c\u65f6\u5bf9\u5185\u90e8\u6570\u636e\u4fdd\u6301\u4e00\u81f4\u6027\uff0c\u5229\u7528\u8fd9\u4e9b\u5934\u90e8\u4e4b\u95f4\u7684\u5206\u6b67\u4f5c\u4e3a\u8861\u91cf\u6807\u51c6\u6765\u8bc6\u522b\u672a\u77e5\u6982\u5ff5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728\u6807\u8bb0\u6570\u636e\u4e0d\u8db3\u7684\u60c5\u51b5\u4e0b\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u5bf9\u5916\u90e8\u6570\u636e\u7684\u9c81\u68d2\u68c0\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u7684\u5f00\u653e\u96c6SSL\u65b9\u6cd5\u4ee5\u53ca\u4e0d\u8003\u8651\u5916\u90e8\u6570\u636e\u7684\u6734\u7d20SSL\u65b9\u6cd5\u3002", "conclusion": "DAC\u6846\u67b6\u4e3a\u89e3\u51b3\u5f00\u653e\u96c6\u534a\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u5916\u90e8\u6570\u636e\u95ee\u9898\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u6807\u8bb0\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u3002\u901a\u8fc7\u6784\u5efa\u4e00\u7ec4\u5177\u6709\u4e0d\u540c\u504f\u5dee\u7684\u6a21\u578b\uff0c\u8be5\u65b9\u6cd5\u63d0\u9ad8\u4e86SSL\u5728\u5b58\u5728\u672a\u77e5\u7c7b\u522b\u65f6\u7684\u9c81\u68d2\u6027\u3002"}}
{"id": "2505.24464", "pdf": "https://arxiv.org/pdf/2505.24464", "abs": "https://arxiv.org/abs/2505.24464", "authors": ["Manojlo Vukovic", "Dusan Jakovetic", "Dragana Bajovic", "Soummya Kar"], "title": "Distributed gradient methods under heavy-tailed communication noise", "categories": ["math.OC", "cs.LG", "90C25, 65K05"], "comment": "This work has been submitted to the IEEE for possible publication", "summary": "We consider a standard distributed optimization problem in which networked\nnodes collaboratively minimize the sum of their locally known convex costs. For\nthis setting, we address for the first time the fundamental problem of design\nand analysis of distributed methods to solve the above problem when inter-node\ncommunication is subject to \\emph{heavy-tailed} noise. Heavy-tailed noise is\nhighly relevant and frequently arises in densely deployed wireless sensor and\nInternet of Things (IoT) networks. Specifically, we design a distributed\ngradient-type method that features a carefully balanced mixed time-scale\ntime-varying consensus and gradient contribution step sizes and a bounded\nnonlinear operator on the consensus update to limit the effect of heavy-tailed\nnoise. Assuming heterogeneous strongly convex local costs with mutually\ndifferent minimizers that are arbitrarily far apart, we show that the proposed\nmethod converges to a neighborhood of the network-wide problem solution in the\nmean squared error (MSE) sense, and we also characterize the corresponding\nconvergence rate. We further show that the asymptotic MSE can be made\narbitrarily small through consensus step-size tuning, possibly at the cost of\nslowing down the transient error decay. Numerical experiments corroborate our\nfindings and demonstrate the resilience of the proposed method to heavy-tailed\n(and infinite variance) communication noise. They also show that existing\ndistributed methods, designed for finite-communication-noise-variance settings,\nfail in the presence of infinite variance noise.", "AI": {"tldr": "The paper proposes a distributed gradient-type method for minimizing the sum of locally known convex costs in networked nodes with heavy-tailed noise.", "motivation": "Existing distributed methods fail in the presence of infinite variance noise, so this paper aims to design and analyze distributed methods for solving optimization problems when inter-node communication is subject to heavy-tailed noise.", "method": "A distributed gradient-type method is designed with carefully balanced mixed time-scale time-varying consensus and gradient contribution step sizes and a bounded nonlinear operator on the consensus update to limit the effect of heavy-tailed noise.", "result": "The proposed method converges to a neighborhood of the network-wide problem solution in the mean squared error (MSE) sense, and the corresponding convergence rate is characterized. The asymptotic MSE can be made arbitrarily small through consensus step-size tuning, possibly at the cost of slowing down the transient error decay.", "conclusion": "Numerical experiments demonstrate the resilience of the proposed method to heavy-tailed (and infinite variance) communication noise, while existing distributed methods fail in the presence of infinite variance noise."}}
{"id": "2505.24830", "pdf": "https://arxiv.org/pdf/2505.24830", "abs": "https://arxiv.org/abs/2505.24830", "authors": ["Juraj Vladika", "Annika Domres", "Mai Nguyen", "Rebecca Moser", "Jana Nano", "Felix Busch", "Lisa C. Adams", "Keno K. Bressem", "Denise Bernhardt", "Stephanie E. Combs", "Kai J. Borm", "Florian Matthes", "Jan C. Peeken"], "title": "Improving Reliability and Explainability of Medical Question Answering through Atomic Fact Checking in Retrieval-Augmented LLMs", "categories": ["cs.CL", "cs.AI"], "comment": "11 pages, 4 figures", "summary": "Large language models (LLMs) exhibit extensive medical knowledge but are\nprone to hallucinations and inaccurate citations, which pose a challenge to\ntheir clinical adoption and regulatory compliance. Current methods, such as\nRetrieval Augmented Generation, partially address these issues by grounding\nanswers in source documents, but hallucinations and low fact-level\nexplainability persist. In this work, we introduce a novel atomic fact-checking\nframework designed to enhance the reliability and explainability of LLMs used\nin medical long-form question answering. This method decomposes LLM-generated\nresponses into discrete, verifiable units called atomic facts, each of which is\nindependently verified against an authoritative knowledge base of medical\nguidelines. This approach enables targeted correction of errors and direct\ntracing to source literature, thereby improving the factual accuracy and\nexplainability of medical Q&A. Extensive evaluation using multi-reader\nassessments by medical experts and an automated open Q&A benchmark demonstrated\nsignificant improvements in factual accuracy and explainability. Our framework\nachieved up to a 40% overall answer improvement and a 50% hallucination\ndetection rate. The ability to trace each atomic fact back to the most relevant\nchunks from the database provides a granular, transparent explanation of the\ngenerated responses, addressing a major gap in current medical AI applications.\nThis work represents a crucial step towards more trustworthy and reliable\nclinical applications of LLMs, addressing key prerequisites for clinical\napplication and fostering greater confidence in AI-assisted healthcare.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u533b\u7597\u9886\u57df\u5e94\u7528\u65f6\u5b58\u5728\u5e7b\u89c9\u548c\u4e0d\u51c6\u786e\u5f15\u7528\u7684\u95ee\u9898\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u539f\u5b50\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6\uff0c\u5c06LLM\u751f\u6210\u7684\u54cd\u5e94\u5206\u89e3\u4e3a\u53ef\u9a8c\u8bc1\u7684\u5355\u5143\uff0c\u5e76\u4e0e\u6743\u5a01\u533b\u5b66\u77e5\u8bc6\u5e93\u8fdb\u884c\u72ec\u7acb\u9a8c\u8bc1\uff0c\u4ece\u800c\u63d0\u9ad8\u4e86\u533b\u7597\u957f\u7bc7\u95ee\u7b54\u4e2dLLM\u7684\u53ef\u9760\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002\u8be5\u6846\u67b6\u663e\u8457\u6539\u5584\u4e86\u4e8b\u5b9e\u51c6\u786e\u6027\uff0c\u5e76\u80fd\u8ffd\u6eaf\u5230\u6e90\u6587\u732e\u3002", "motivation": "\u5c3d\u7ba1LLMs\u62e5\u6709\u5e7f\u6cdb\u7684\u533b\u5b66\u77e5\u8bc6\uff0c\u4f46\u5176\u6613\u4ea7\u751f\u5e7b\u89c9\u548c\u4e0d\u51c6\u786e\u5f15\u7528\u7684\u7279\u70b9\u963b\u788d\u4e86\u5176\u5728\u4e34\u5e8a\u4e2d\u7684\u5e94\u7528\u548c\u76d1\u7ba1\u5408\u89c4\u3002\u73b0\u6709\u7684\u65b9\u6cd5\u5982\u68c0\u7d22\u589e\u5f3a\u751f\u6210\u867d\u90e8\u5206\u89e3\u51b3\u4e86\u8fd9\u4e9b\u95ee\u9898\uff0c\u4f46\u4ecd\u5b58\u5728\u5e7b\u89c9\u548c\u4f4e\u4e8b\u5b9e\u5c42\u9762\u53ef\u89e3\u91ca\u6027\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u539f\u5b50\u4e8b\u5b9e\u6838\u67e5\u6846\u67b6\uff0c\u5c06LLM\u751f\u6210\u7684\u54cd\u5e94\u5206\u89e3\u4e3a\u79bb\u6563\u3001\u53ef\u9a8c\u8bc1\u7684\u5355\u5143\uff08\u79f0\u4e3a\u539f\u5b50\u4e8b\u5b9e\uff09\uff0c\u5e76\u9488\u5bf9\u6743\u5a01\u533b\u5b66\u6307\u5357\u77e5\u8bc6\u5e93\u5bf9\u6bcf\u4e2a\u539f\u5b50\u4e8b\u5b9e\u8fdb\u884c\u72ec\u7acb\u9a8c\u8bc1\u3002\u6b64\u65b9\u6cd5\u5141\u8bb8\u5bf9\u9519\u8bef\u8fdb\u884c\u9488\u5bf9\u6027\u7ea0\u6b63\uff0c\u5e76\u76f4\u63a5\u8ffd\u6eaf\u5230\u6e90\u6587\u732e\u3002", "result": "\u901a\u8fc7\u591a\u8bfb\u8005\u8bc4\u4f30\u548c\u81ea\u52a8\u5316\u5f00\u653e\u95ee\u7b54\u57fa\u51c6\u6d4b\u8bd5\uff0c\u8bc1\u660e\u4e86\u8be5\u6846\u67b6\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u53ef\u89e3\u91ca\u6027\u65b9\u9762\u7684\u663e\u8457\u6539\u8fdb\u3002\u6846\u67b6\u603b\u4f53\u7b54\u6848\u6539\u8fdb\u7387\u9ad8\u8fbe40%\uff0c\u5e7b\u89c9\u68c0\u6d4b\u7387\u8fbe\u523050%\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u662f\u671d\u7740\u66f4\u503c\u5f97\u4fe1\u8d56\u548c\u53ef\u9760\u7684\u4e34\u5e8aLLM\u5e94\u7528\u8fc8\u51fa\u7684\u91cd\u8981\u4e00\u6b65\uff0c\u89e3\u51b3\u4e86\u5f53\u524d\u533b\u7597AI\u5e94\u7528\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff0c\u589e\u5f3a\u4e86\u5bf9AI\u8f85\u52a9\u533b\u7597\u7684\u4fe1\u5fc3\u3002"}}
{"id": "2505.24838", "pdf": "https://arxiv.org/pdf/2505.24838", "abs": "https://arxiv.org/abs/2505.24838", "authors": ["Brandon Man", "Ghadi Nehme", "Md Ferdous Alam", "Faez Ahmed"], "title": "VideoCAD: A Large-Scale Video Dataset for Learning UI Interactions and 3D Reasoning from CAD Software", "categories": ["cs.CV", "cs.AI"], "comment": null, "summary": "Computer-Aided Design (CAD) is a time-consuming and complex process,\nrequiring precise, long-horizon user interactions with intricate 3D interfaces.\nWhile recent advances in AI-driven user interface (UI) agents show promise,\nmost existing datasets and methods focus on short, low-complexity tasks in\nmobile or web applications, failing to capture the demands of professional\nengineering tools. In this work, we introduce VideoCAD, the first attempt at\nengineering UI interaction learning for precision tasks. Specifically, VideoCAD\nis a large-scale synthetic dataset consisting of over 41K annotated video\nrecordings of CAD operations, generated using an automated framework for\ncollecting high-fidelity UI action data from human-made CAD designs. Compared\nto existing datasets, VideoCAD offers an order of magnitude higher complexity\nin UI interaction learning for real-world engineering tasks, having up to a 20x\nlonger time horizon than other datasets. We show two important downstream\napplications of VideoCAD: learning UI interactions from professional precision\n3D CAD tools and a visual question-answering (VQA) benchmark designed to\nevaluate multimodal large language models' (LLM) spatial reasoning and video\nunderstanding abilities. To learn the UI interactions, we propose\nVideoCADFormer - a state-of-the-art model in learning CAD interactions directly\nfrom video, which outperforms multiple behavior cloning baselines. Both\nVideoCADFormer and the VQA benchmark derived from VideoCAD reveal key\nchallenges in the current state of video-based UI understanding, including the\nneed for precise action grounding, multi-modal and spatial reasoning, and\nlong-horizon dependencies.", "AI": {"tldr": "\u672c\u7814\u7a76\u4ecb\u7ecd\u4e86VideoCAD\uff0c\u4e00\u4e2a\u5927\u89c4\u6a21\u7684\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc741K\u4e2a\u6807\u6ce8\u7684CAD\u64cd\u4f5c\u89c6\u9891\u8bb0\u5f55\uff0c\u7528\u4e8e\u5de5\u7a0bUI\u4ea4\u4e92\u5b66\u4e60\u3002VideoCAD\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6570\u91cf\u7ea7\u66f4\u9ad8\u7684\u590d\u6742\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u4e24\u4e2a\u4e0b\u6e38\u5e94\u7528\uff1a\u5b66\u4e60\u4e13\u4e1a\u7cbe\u5ea63D CAD\u5de5\u5177\u7684UI\u4ea4\u4e92\u548c\u8bc4\u4f30\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u548c\u89c6\u9891\u7406\u89e3\u80fd\u529b\u7684VQA\u57fa\u51c6\u3002\u4e3a\u6b64\uff0c\u6211\u4eec\u63d0\u51fa\u4e86VideoCADFormer\uff0c\u5b83\u5728\u76f4\u63a5\u4ece\u89c6\u9891\u5b66\u4e60CAD\u4ea4\u4e92\u65b9\u9762\u8868\u73b0\u51fa\u8272\u3002", "motivation": "\u73b0\u6709\u7684\u6570\u636e\u96c6\u548c\u65b9\u6cd5\u4e3b\u8981\u96c6\u4e2d\u5728\u79fb\u52a8\u6216Web\u5e94\u7528\u7a0b\u5e8f\u4e2d\u7684\u77ed\u65f6\u95f4\u3001\u4f4e\u590d\u6742\u6027\u4efb\u52a1\u4e0a\uff0c\u65e0\u6cd5\u6ee1\u8db3\u4e13\u4e1a\u5de5\u7a0b\u5de5\u5177\u7684\u9700\u6c42\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u66f4\u590d\u6742\u7684\u6570\u636e\u96c6\u6765\u6355\u6349\u771f\u5b9e\u4e16\u754c\u5de5\u7a0b\u4efb\u52a1\u7684\u9700\u6c42\u3002", "method": "\u7814\u7a76\u8005\u4eec\u5f15\u5165\u4e86VideoCAD\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc741K\u4e2a\u6807\u6ce8\u7684CAD\u64cd\u4f5c\u89c6\u9891\u8bb0\u5f55\u3002\u8fd8\u63d0\u51fa\u4e86VideoCADFormer\u6a21\u578b\uff0c\u7528\u4e8e\u4ece\u89c6\u9891\u4e2d\u5b66\u4e60CAD\u4ea4\u4e92\u3002\u5e76\u901a\u8fc7VQA\u57fa\u51c6\u6d4b\u8bd5\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u7a7a\u95f4\u63a8\u7406\u548c\u89c6\u9891\u7406\u89e3\u80fd\u529b\u3002", "result": "VideoCAD\u6570\u636e\u96c6\u63d0\u4f9b\u4e86\u6bd4\u73b0\u6709\u6570\u636e\u96c6\u9ad8\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u590d\u6742\u6027\uff0c\u5177\u6709\u957f\u8fbe20\u500d\u7684\u65f6\u95f4\u8de8\u5ea6\u3002VideoCADFormer\u6a21\u578b\u5728\u5b66\u4e60CAD\u4ea4\u4e92\u65b9\u9762\u4f18\u4e8e\u591a\u4e2a\u884c\u4e3a\u514b\u9686\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "VideoCAD\u548cVideoCADFormer\u63ed\u793a\u4e86\u5f53\u524d\u57fa\u4e8e\u89c6\u9891\u7684UI\u7406\u89e3\u72b6\u6001\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u7cbe\u786e\u7684\u52a8\u4f5c\u5b9a\u4f4d\u3001\u591a\u6a21\u6001\u548c\u7a7a\u95f4\u63a8\u7406\u4ee5\u53ca\u957f\u65f6\u95f4\u4f9d\u8d56\u6027\u7684\u9700\u6c42\u3002"}}
{"id": "2505.24840", "pdf": "https://arxiv.org/pdf/2505.24840", "abs": "https://arxiv.org/abs/2505.24840", "authors": ["Yuwen Tan", "Yuan Qing", "Boqing Gong"], "title": "Vision LLMs Are Bad at Hierarchical Visual Understanding, and LLMs Are the Bottleneck", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "comment": "28 pages, 13 figures", "summary": "This paper reveals that many state-of-the-art large language models (LLMs)\nlack hierarchical knowledge about our visual world, unaware of even\nwell-established biology taxonomies. This shortcoming makes LLMs a bottleneck\nfor vision LLMs' hierarchical visual understanding (e.g., recognizing Anemone\nFish but not Vertebrate). We arrive at these findings using about one million\nfour-choice visual question answering (VQA) tasks constructed from six\ntaxonomies and four image datasets. Interestingly, finetuning a vision LLM\nusing our VQA tasks reaffirms LLMs' bottleneck effect to some extent because\nthe VQA tasks improve the LLM's hierarchical consistency more than the vision\nLLM's. We conjecture that one cannot make vision LLMs understand visual\nconcepts fully hierarchical until LLMs possess corresponding taxonomy\nknowledge.", "AI": {"tldr": "\u5c3d\u7ba1\u5f53\u524d\u6700\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u89c6\u89c9\u7406\u89e3\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\uff0c\u4f46\u901a\u8fc7\u4f7f\u7528\u5927\u91cf\u6784\u5efa\u7684\u89c6\u89c9\u95ee\u7b54\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\uff0c\u53ef\u4ee5\u5728\u4e00\u5b9a\u7a0b\u5ea6\u4e0a\u6539\u5584\u5176\u5c42\u6b21\u4e00\u81f4\u6027\u3002\u7136\u800c\uff0c\u8981\u8ba9\u89c6\u89c9LLMs\u5b8c\u5168\u7406\u89e3\u89c6\u89c9\u6982\u5ff5\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u5fc5\u987b\u4f7fLLMs\u5177\u5907\u76f8\u5e94\u7684\u5206\u7c7b\u77e5\u8bc6\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\u8bb8\u591a\u5148\u8fdb\u7684\u5927\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u7f3a\u4e4f\u5bf9\u89c6\u89c9\u4e16\u754c\u7684\u5c42\u6b21\u77e5\u8bc6\uff0c\u751a\u81f3\u4e0d\u4e86\u89e3\u5df2\u5efa\u7acb\u7684\u751f\u7269\u5206\u7c7b\u6cd5\u3002\u8fd9\u79cd\u7f3a\u9677\u4f7f\u5f97LLMs\u6210\u4e3a\u89c6\u89c9LLMs\u5b9e\u73b0\u5c42\u6b21\u89c6\u89c9\u7406\u89e3\u7684\u74f6\u9888\u3002", "method": "\u5229\u7528\u6765\u81ea\u516d\u4e2a\u5206\u7c7b\u6cd5\u548c\u56db\u4e2a\u56fe\u50cf\u6570\u636e\u96c6\u7684\u5927\u7ea6\u4e00\u767e\u4e07\u4e2a\u56db\u9009\u4e00\u89c6\u89c9\u95ee\u7b54\uff08VQA\uff09\u4efb\u52a1\u6765\u63ed\u793a\u8fd9\u4e9b\u53d1\u73b0\u3002\u5e76\u5bf9\u89c6\u89c9LLM\u4f7f\u7528\u8fd9\u4e9bVQA\u4efb\u52a1\u8fdb\u884c\u5fae\u8c03\uff0c\u9a8c\u8bc1LLMs\u7684\u74f6\u9888\u6548\u5e94\u3002", "result": "\u5fae\u8c03\u540e\u7684\u89c6\u89c9LLM\u5728\u67d0\u79cd\u7a0b\u5ea6\u4e0a\u518d\u6b21\u786e\u8ba4\u4e86LLMs\u7684\u74f6\u9888\u6548\u5e94\uff0c\u56e0\u4e3a\u8fd9\u4e9bVQA\u4efb\u52a1\u63d0\u9ad8\u4e86LLM\u7684\u5c42\u6b21\u4e00\u81f4\u6027\u6bd4\u89c6\u89c9LLM\u66f4\u591a\u3002\u63a8\u6d4b\u53ea\u6709\u5f53LLMs\u5177\u5907\u76f8\u5e94\u7684\u5206\u7c7b\u77e5\u8bc6\u65f6\uff0c\u624d\u80fd\u4f7f\u89c6\u89c9LLMs\u5145\u5206\u7406\u89e3\u89c6\u89c9\u6982\u5ff5\u7684\u5c42\u6b21\u7ed3\u6784\u3002", "conclusion": "\u4e3a\u4e86\u4f7f\u89c6\u89c9LLMs\u80fd\u591f\u5168\u9762\u7406\u89e3\u89c6\u89c9\u6982\u5ff5\u7684\u5c42\u6b21\u7ed3\u6784\uff0c\u5fc5\u987b\u8d4b\u4e88LLMs\u76f8\u5e94\u7684\u5206\u7c7b\u77e5\u8bc6\u3002\u8fd9\u8868\u660e\uff0c\u672a\u6765\u7684\u7814\u7a76\u9700\u8981\u5173\u6ce8\u5982\u4f55\u589e\u5f3aLLMs\u7684\u5206\u7c7b\u77e5\u8bc6\uff0c\u4ee5\u514b\u670d\u8fd9\u4e00\u74f6\u9888\u3002"}}
{"id": "2505.24853", "pdf": "https://arxiv.org/pdf/2505.24853", "abs": "https://arxiv.org/abs/2505.24853", "authors": ["Zhao Mandi", "Yifan Hou", "Dieter Fox", "Yashraj Narang", "Ajay Mandlekar", "Shuran Song"], "title": "DexMachina: Functional Retargeting for Bimanual Dexterous Manipulation", "categories": ["cs.RO", "cs.AI", "cs.LG"], "comment": null, "summary": "We study the problem of functional retargeting: learning dexterous\nmanipulation policies to track object states from human hand-object\ndemonstrations. We focus on long-horizon, bimanual tasks with articulated\nobjects, which is challenging due to large action space, spatiotemporal\ndiscontinuities, and embodiment gap between human and robot hands. We propose\nDexMachina, a novel curriculum-based algorithm: the key idea is to use virtual\nobject controllers with decaying strength: an object is first driven\nautomatically towards its target states, such that the policy can gradually\nlearn to take over under motion and contact guidance. We release a simulation\nbenchmark with a diverse set of tasks and dexterous hands, and show that\nDexMachina significantly outperforms baseline methods. Our algorithm and\nbenchmark enable a functional comparison for hardware designs, and we present\nkey findings informed by quantitative and qualitative results. With the recent\nsurge in dexterous hand development, we hope this work will provide a useful\nplatform for identifying desirable hardware capabilities and lower the barrier\nfor contributing to future research. Videos and more at\nhttps://project-dexmachina.github.io/", "AI": {"tldr": "The paper introduces DexMachina, a curriculum-based algorithm for learning dexterous manipulation policies from human hand-object demonstrations, focusing on long-horizon, bimanual tasks with articulated objects. It uses virtual object controllers to help the policy learn gradually and significantly outperforms baseline methods.", "motivation": "To address the challenge of learning dexterous manipulation policies for robots from human hand-object demonstrations, particularly in complex, long-horizon, bimanual tasks with articulated objects that involve large action spaces, spatiotemporal discontinuities, and differences between human and robot hand capabilities.", "method": "Propose DexMachina, a novel curriculum-based algorithm that employs virtual object controllers with decreasing strength over time. Initially, an object is driven automatically toward its target state, allowing the policy to progressively learn control under motion and contact guidance.", "result": "DexMachina shows significant improvement over baseline methods when tested on a diverse set of tasks involving dexterous hands in a simulation benchmark.", "conclusion": "This work provides a useful platform for comparing hardware designs and identifying desirable capabilities in dexterous robotic hands, potentially lowering barriers for future research contributions."}}
{"id": "2505.24487", "pdf": "https://arxiv.org/pdf/2505.24487", "abs": "https://arxiv.org/abs/2505.24487", "authors": ["Nicholas Cartocci", "Antonios E. Gkikakis", "Darwin G. Caldwell", "Jes\u00fas Ortiz"], "title": "Real-time Fall Prevention system for the Next-generation of Workers", "categories": ["eess.SP", "cs.LG"], "comment": null, "summary": "Developing a general-purpose wearable real-time fall-detection system is\nstill a challenging task, especially for healthy and strong subjects, such as\nindustrial workers that work in harsh environments. In this work, we present a\nhybrid approach for fall detection and prevention, which uses the dynamic model\nof an inverted pendulum to generate simulations of falling that are then fed to\na deep learning framework. The output is a signal to activate a fall mitigation\nmechanism when the subject is at risk of harm. The advantage of this approach\nis that abstracted models can be used to efficiently generate training data for\nthousands of different subjects with different falling initial conditions,\nsomething that is practically impossible with real experiments. This approach\nis suitable for a specific type of fall, where the subjects fall without\nchanging their initial configuration significantly, and it is the first step\ntoward a general-purpose wearable device, with the aim of reducing\nfall-associated injuries in industrial environments, which can improve the\nsafety of workers.", "AI": {"tldr": "This paper proposes a hybrid approach for fall detection and prevention using inverted pendulum simulations and deep learning, aiming to reduce fall-related injuries in industrial settings.", "motivation": "Developing an effective wearable real-time fall-detection system is challenging, particularly for healthy individuals in harsh environments. Traditional methods struggle to generate sufficient training data for diverse scenarios.", "method": "A hybrid approach combining an inverted pendulum dynamic model to simulate falls and a deep learning framework to process these simulations. The system outputs signals to activate fall mitigation mechanisms when necessary.", "result": "The method can efficiently generate training data for numerous subjects under various initial conditions, addressing the limitation of real-world experiments. It targets specific types of falls where initial configurations remain largely unchanged.", "conclusion": "This hybrid approach represents a significant step towards creating a general-purpose wearable device for reducing fall-associated injuries in industrial environments, enhancing worker safety."}}
{"id": "2505.24864", "pdf": "https://arxiv.org/pdf/2505.24864", "abs": "https://arxiv.org/abs/2505.24864", "authors": ["Mingjie Liu", "Shizhe Diao", "Ximing Lu", "Jian Hu", "Xin Dong", "Yejin Choi", "Jan Kautz", "Yi Dong"], "title": "ProRL: Prolonged Reinforcement Learning Expands Reasoning Boundaries in Large Language Models", "categories": ["cs.CL", "cs.AI"], "comment": "26 pages, 17 figures", "summary": "Recent advances in reasoning-centric language models have highlighted\nreinforcement learning (RL) as a promising method for aligning models with\nverifiable rewards. However, it remains contentious whether RL truly expands a\nmodel's reasoning capabilities or merely amplifies high-reward outputs already\nlatent in the base model's distribution, and whether continually scaling up RL\ncompute reliably leads to improved reasoning performance. In this work, we\nchallenge prevailing assumptions by demonstrating that prolonged RL (ProRL)\ntraining can uncover novel reasoning strategies that are inaccessible to base\nmodels, even under extensive sampling. We introduce ProRL, a novel training\nmethodology that incorporates KL divergence control, reference policy\nresetting, and a diverse suite of tasks. Our empirical analysis reveals that\nRL-trained models consistently outperform base models across a wide range of\npass@k evaluations, including scenarios where base models fail entirely\nregardless of the number of attempts. We further show that reasoning boundary\nimprovements correlates strongly with task competence of base model and\ntraining duration, suggesting that RL can explore and populate new regions of\nsolution space over time. These findings offer new insights into the conditions\nunder which RL meaningfully expands reasoning boundaries in language models and\nestablish a foundation for future work on long-horizon RL for reasoning. We\nrelease model weights to support further research:\nhttps://huggingface.co/nvidia/Nemotron-Research-Reasoning-Qwen-1.5B", "AI": {"tldr": "The paper challenges assumptions about reinforcement learning (RL) in language models, introducing ProRL which uncovers novel reasoning strategies through prolonged training.", "motivation": "To investigate whether prolonged RL training can expand a model's reasoning capabilities beyond amplifying high-reward outputs already present in the base model and to determine if continually scaling up RL compute leads to improved reasoning performance.", "method": "ProRL, a novel training methodology incorporating KL divergence control, reference policy resetting, and a diverse suite of tasks.", "result": "RL-trained models outperform base models across various pass@k evaluations, even in scenarios where base models fail regardless of attempts. Reasoning boundary improvements correlate with base model competence and training duration.", "conclusion": "ProRL demonstrates that prolonged RL training can uncover novel reasoning strategies inaccessible to base models and provides insights into conditions under which RL expands reasoning boundaries in language models."}}
{"id": "2505.24527", "pdf": "https://arxiv.org/pdf/2505.24527", "abs": "https://arxiv.org/abs/2505.24527", "authors": ["Simone Cammarasana", "Giuseppe Patan\u00e8"], "title": "Optimal Density Functions for Weighted Convolution in Learning Models", "categories": ["cs.CV", "cs.LG", "42A85"], "comment": "5 figures, 5 tables, 21 pages", "summary": "The paper introduces the weighted convolution, a novel approach to the\nconvolution for signals defined on regular grids (e.g., 2D images) through the\napplication of an optimal density function to scale the contribution of\nneighbouring pixels based on their distance from the central pixel. This choice\ndiffers from the traditional uniform convolution, which treats all neighbouring\npixels equally. Our weighted convolution can be applied to convolutional neural\nnetwork problems to improve the approximation accuracy. Given a convolutional\nnetwork, we define a framework to compute the optimal density function through\na minimisation model. The framework separates the optimisation of the\nconvolutional kernel weights (using stochastic gradient descent) from the\noptimisation of the density function (using DIRECT-L). Experimental results on\na learning model for an image-to-image task (e.g., image denoising) show that\nthe weighted convolution significantly reduces the loss (up to 53% improvement)\nand increases the test accuracy compared to standard convolution. While this\nmethod increases execution time by 11%, it is robust across several\nhyperparameters of the learning model. Future work will apply the weighted\nconvolution to real-case 2D and 3D image convolutional learning problems.", "AI": {"tldr": "The paper proposes weighted convolution, a new method for processing signals on regular grids like images. It uses an optimal density function to weigh neighboring pixels by distance, differing from traditional uniform convolution. The authors develop a framework to compute this function and show that it improves accuracy in image-to-image tasks such as denoising, with up to 53% loss reduction. Although execution time increases by 11%, the method is robust across various hyperparameters. Future research will explore its application in real-case 2D and 3D image problems.", "motivation": "To improve the approximation accuracy of convolutional neural networks by developing a more sophisticated approach to convolution that considers the varying importance of neighboring pixels.", "method": "Introduce weighted convolution using an optimal density function to scale pixel contributions based on their distance from the central pixel. Define a framework to optimize both the convolutional kernel weights via stochastic gradient descent and the density function via DIRECT-L.", "result": "Weighted convolution significantly reduces loss (up to 53%) and increases test accuracy compared to standard convolution in image-to-image tasks. The method is robust across different hyperparameters but increases execution time by 11%.", "conclusion": "Weighted convolution offers significant improvements in performance for convolutional neural network tasks, despite a modest increase in computational cost. It has potential applications in real-world 2D and 3D image processing problems."}}
{"id": "2505.24867", "pdf": "https://arxiv.org/pdf/2505.24867", "abs": "https://arxiv.org/abs/2505.24867", "authors": ["Ujjwal Upadhyay", "Mukul Ranjan", "Zhiqiang Shen", "Mohamed Elhoseiny"], "title": "Time Blindness: Why Video-Language Models Can't See What Humans Can?", "categories": ["cs.CV", "cs.AI"], "comment": "Project page at https://timeblindness.github.io/", "summary": "Recent advances in vision-language models (VLMs) have made impressive strides\nin understanding spatio-temporal relationships in videos. However, when spatial\ninformation is obscured, these models struggle to capture purely temporal\npatterns. We introduce $\\textbf{SpookyBench}$, a benchmark where information is\nencoded solely in temporal sequences of noise-like frames, mirroring natural\nphenomena from biological signaling to covert communication. Interestingly,\nwhile humans can recognize shapes, text, and patterns in these sequences with\nover 98% accuracy, state-of-the-art VLMs achieve 0% accuracy. This performance\ngap highlights a critical limitation: an over-reliance on frame-level spatial\nfeatures and an inability to extract meaning from temporal cues. Furthermore,\nwhen trained in data sets with low spatial signal-to-noise ratios (SNR),\ntemporal understanding of models degrades more rapidly than human perception,\nespecially in tasks requiring fine-grained temporal reasoning. Overcoming this\nlimitation will require novel architectures or training paradigms that decouple\nspatial dependencies from temporal processing. Our systematic analysis shows\nthat this issue persists across model scales and architectures. We release\nSpookyBench to catalyze research in temporal pattern recognition and bridge the\ngap between human and machine video understanding. Dataset and code has been\nmade available on our project website: https://timeblindness.github.io/.", "AI": {"tldr": "\u5c3d\u7ba1\u6700\u8fd1\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08VLMs\uff09\u5728\u7406\u89e3\u89c6\u9891\u4e2d\u7684\u65f6\u7a7a\u5173\u7cfb\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5f53\u7a7a\u95f4\u4fe1\u606f\u88ab\u906e\u6321\u65f6\uff0c\u8fd9\u4e9b\u6a21\u578b\u96be\u4ee5\u6355\u6349\u7eaf\u7cb9\u7684\u65f6\u95f4\u6a21\u5f0f\u3002\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5SpookyBench\uff0c\u5176\u4e2d\u4fe1\u606f\u4ec5\u7f16\u7801\u5728\u7c7b\u4f3c\u566a\u58f0\u5e27\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\u3002\u7814\u7a76\u53d1\u73b0\uff0c\u4eba\u7c7b\u53ef\u4ee5\u4ee5\u8d85\u8fc798%\u7684\u51c6\u786e\u7387\u8bc6\u522b\u8fd9\u4e9b\u5e8f\u5217\u4e2d\u7684\u5f62\u72b6\u3001\u6587\u672c\u548c\u6a21\u5f0f\uff0c\u800c\u6700\u5148\u8fdb\u7684VLMs\u51c6\u786e\u7387\u4e3a0%\u3002\u8fd9\u8868\u660e\u4e86\u6a21\u578b\u8fc7\u5ea6\u4f9d\u8d56\u5e27\u7ea7\u7a7a\u95f4\u7279\u5f81\u4ee5\u53ca\u65e0\u6cd5\u4ece\u65f6\u95f4\u7ebf\u7d22\u4e2d\u63d0\u53d6\u610f\u4e49\u7684\u5173\u952e\u9650\u5236\u3002\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\uff0c\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e00\u95ee\u9898\u5728\u4e0d\u540c\u89c4\u6a21\u548c\u67b6\u6784\u7684\u6a21\u578b\u4e2d\u90fd\u5b58\u5728\u3002\u4e3a\u4e86\u89e3\u51b3\u8fd9\u4e2a\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u67b6\u6784\u6216\u8bad\u7ec3\u8303\u5f0f\u6765\u5c06\u7a7a\u95f4\u4f9d\u8d56\u6027\u4e0e\u65f6\u95f4\u5904\u7406\u5206\u79bb\u3002", "motivation": "\u73b0\u6709\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u7a7a\u95f4\u4fe1\u606f\u88ab\u906e\u6321\u7684\u60c5\u51b5\u4e0b\uff0c\u96be\u4ee5\u6355\u6349\u7eaf\u7cb9\u7684\u65f6\u95f4\u6a21\u5f0f\uff0c\u8fd9\u63ed\u793a\u4e86\u6a21\u578b\u5728\u65f6\u95f4\u7406\u89e3\u4e0a\u7684\u5c40\u9650\u6027\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u4e2a\u4e13\u95e8\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u548c\u6539\u8fdb\u6a21\u578b\u5728\u65f6\u95f4\u6a21\u5f0f\u8bc6\u522b\u65b9\u9762\u7684\u80fd\u529b\u3002", "method": "\u5f15\u5165\u4e86\u4e00\u4e2a\u540d\u4e3aSpookyBench\u7684\u65b0\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5176\u4e2d\u4fe1\u606f\u4ec5\u7f16\u7801\u5728\u7c7b\u4f3c\u566a\u58f0\u5e27\u7684\u65f6\u95f4\u5e8f\u5217\u4e2d\u3002\u8be5\u57fa\u51c6\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5728\u4f4e\u7a7a\u95f4\u4fe1\u566a\u6bd4\u6570\u636e\u96c6\u4e2d\u7684\u65f6\u95f4\u7406\u89e3\u80fd\u529b\uff0c\u5e76\u4e0e\u4eba\u7c7b\u7684\u8868\u73b0\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4eba\u7c7b\u80fd\u591f\u4ee5\u8d85\u8fc798%\u7684\u51c6\u786e\u7387\u8bc6\u522bSpookyBench\u4e2d\u7684\u5f62\u72b6\u3001\u6587\u672c\u548c\u6a21\u5f0f\uff0c\u800c\u6700\u5148\u8fdb\u7684VLMs\u51c6\u786e\u7387\u4e3a0%\u3002\u6b64\u5916\uff0c\u6a21\u578b\u5728\u65f6\u95f4\u7406\u89e3\u65b9\u9762\u7684\u8868\u73b0\u968f\u7740\u4efb\u52a1\u590d\u6742\u6027\u7684\u589e\u52a0\u800c\u8fc5\u901f\u4e0b\u964d\uff0c\u800c\u4eba\u7c7b\u611f\u77e5\u5219\u4fdd\u6301\u76f8\u5bf9\u7a33\u5b9a\u3002", "conclusion": "\u5f53\u524d\u7684\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\u5728\u65f6\u95f4\u6a21\u5f0f\u8bc6\u522b\u65b9\u9762\u5b58\u5728\u663e\u8457\u7f3a\u9677\uff0c\u8fd9\u9700\u8981\u901a\u8fc7\u65b0\u7684\u67b6\u6784\u6216\u8bad\u7ec3\u65b9\u6cd5\u6765\u89e3\u51b3\u3002\u4f5c\u8005\u53d1\u5e03\u4e86SpookyBench\u4ee5\u63a8\u52a8\u76f8\u5173\u7814\u7a76\uff0c\u5e76\u7f29\u5c0f\u4eba\u7c7b\u4e0e\u673a\u5668\u5728\u89c6\u9891\u7406\u89e3\u65b9\u9762\u7684\u65f6\u95f4\u8ba4\u77e5\u5dee\u8ddd\u3002"}}
{"id": "2505.24528", "pdf": "https://arxiv.org/pdf/2505.24528", "abs": "https://arxiv.org/abs/2505.24528", "authors": ["Pedram Ghamisi", "Weikang Yu", "Xiaokang Zhang", "Aldino Rizaldy", "Jian Wang", "Chufeng Zhou", "Richard Gloaguen", "Gustau Camps-Valls"], "title": "Geospatial Foundation Models to Enable Progress on Sustainable Development Goals", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "Foundation Models (FMs) are large-scale, pre-trained AI systems that have\nrevolutionized natural language processing and computer vision, and are now\nadvancing geospatial analysis and Earth Observation (EO). They promise improved\ngeneralization across tasks, scalability, and efficient adaptation with minimal\nlabeled data. However, despite the rapid proliferation of geospatial FMs, their\nreal-world utility and alignment with global sustainability goals remain\nunderexplored. We introduce SustainFM, a comprehensive benchmarking framework\ngrounded in the 17 Sustainable Development Goals with extremely diverse tasks\nranging from asset wealth prediction to environmental hazard detection. This\nstudy provides a rigorous, interdisciplinary assessment of geospatial FMs and\noffers critical insights into their role in attaining sustainability goals. Our\nfindings show: (1) While not universally superior, FMs often outperform\ntraditional approaches across diverse tasks and datasets. (2) Evaluating FMs\nshould go beyond accuracy to include transferability, generalization, and\nenergy efficiency as key criteria for their responsible use. (3) FMs enable\nscalable, SDG-grounded solutions, offering broad utility for tackling complex\nsustainability challenges. Critically, we advocate for a paradigm shift from\nmodel-centric development to impact-driven deployment, and emphasize metrics\nsuch as energy efficiency, robustness to domain shifts, and ethical\nconsiderations.", "AI": {"tldr": "Foundation Models (FMs) have shown promise in geospatial analysis and Earth Observation, but their real-world utility for sustainability goals is underexplored. This study introduces SustainFM, a benchmarking framework based on the 17 Sustainable Development Goals, to assess geospatial FMs. The findings indicate that FMs often outperform traditional methods, should be evaluated beyond accuracy, and can offer scalable solutions for sustainability challenges. A shift from model-centric development to impact-driven deployment is advocated.", "motivation": "To comprehensively evaluate the real-world utility and alignment of geospatial Foundation Models with global sustainability goals, which has been underexplored despite the rapid proliferation of such models.", "method": "Introduction of SustainFM, a benchmarking framework grounded in the 17 Sustainable Development Goals, to provide an interdisciplinary assessment of geospatial FMs across extremely diverse tasks.", "result": "(1) FMs often outperform traditional approaches across diverse tasks and datasets; (2) Evaluation criteria for FMs should include transferability, generalization, and energy efficiency; (3) FMs enable scalable, SDG-grounded solutions.", "conclusion": "There is a need for a paradigm shift from model-centric development to impact-driven deployment, considering metrics like energy efficiency, robustness, and ethical implications."}}
{"id": "2505.24872", "pdf": "https://arxiv.org/pdf/2505.24872", "abs": "https://arxiv.org/abs/2505.24872", "authors": ["Zilin Xiao", "Jaywon Koo", "Siru Ouyang", "Jefferson Hernandez", "Yu Meng", "Vicente Ordonez"], "title": "ProxyThinker: Test-Time Guidance through Small Visual Reasoners", "categories": ["cs.CV", "cs.AI", "cs.CL"], "comment": null, "summary": "Recent advancements in reinforcement learning with verifiable rewards have\npushed the boundaries of the visual reasoning capabilities in large\nvision-language models (LVLMs). However, training LVLMs with reinforcement\nfine-tuning (RFT) is computationally expensive, posing a significant challenge\nto scaling model size. In this work, we propose ProxyThinker, an inference-time\ntechnique that enables large models to inherit the visual reasoning\ncapabilities from small, slow-thinking visual reasoners without any training.\nBy subtracting the output distributions of base models from those of RFT\nreasoners, ProxyThinker modifies the decoding dynamics and successfully elicits\nthe slow-thinking reasoning demonstrated by the emerged sophisticated behaviors\nsuch as self-verification and self-correction. ProxyThinker consistently boosts\nperformance on challenging visual benchmarks on spatial, mathematical, and\nmulti-disciplinary reasoning, enabling untuned base models to compete with the\nperformance of their full-scale RFT counterparts. Furthermore, our\nimplementation efficiently coordinates multiple language models with\nparallelism techniques and achieves up to 38 $\\times$ faster inference compared\nto previous decoding-time methods, paving the way for the practical deployment\nof ProxyThinker. Code is available at\nhttps://github.com/MrZilinXiao/ProxyThinker.", "AI": {"tldr": "ProxyThinker\u662f\u4e00\u79cd\u63a8\u7406\u65f6\u6280\u672f\uff0c\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u8ba9\u5927\u578b\u6a21\u578b\u7ee7\u627f\u5c0f\u578b\u89c6\u89c9\u63a8\u7406\u5668\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002\u901a\u8fc7\u4fee\u6539\u89e3\u7801\u52a8\u6001\uff0cProxyThinker\u6210\u529f\u6fc0\u53d1\u4e86\u590d\u6742\u7684\u81ea\u6211\u9a8c\u8bc1\u548c\u81ea\u6211\u4fee\u6b63\u884c\u4e3a\uff0c\u5e76\u5728\u591a\u4e2a\u89c6\u89c9\u57fa\u51c6\u4e0a\u63d0\u9ad8\u4e86\u6027\u80fd\u3002\u6b64\u5916\uff0c\u5176\u5b9e\u73b0\u65b9\u5f0f\u6bd4\u4ee5\u524d\u7684\u65b9\u6cd5\u5feb38\u500d\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "motivation": "\u5c3d\u7ba1\u5f3a\u5316\u5b66\u4e60\u63a8\u52a8\u4e86\u5927\u578b\u89c6\u89c9-\u8bed\u8a00\u6a21\u578b\uff08LVLMs\uff09\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u7684\u53d1\u5c55\uff0c\u4f46\u4f7f\u7528\u5f3a\u5316\u5fae\u8c03\uff08RFT\uff09\u8bad\u7ec3LVLMs\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\uff0c\u96be\u4ee5\u6269\u5c55\u6a21\u578b\u89c4\u6a21\u3002\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u7684\u6280\u672f\u6765\u63d0\u5347\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aProxyThinker\u7684\u63a8\u7406\u65f6\u6280\u672f\uff0c\u901a\u8fc7\u4eceRFT\u63a8\u7406\u5668\u7684\u8f93\u51fa\u5206\u5e03\u4e2d\u51cf\u53bb\u57fa\u7840\u6a21\u578b\u7684\u8f93\u51fa\u5206\u5e03\uff0c\u4fee\u6539\u89e3\u7801\u52a8\u6001\uff0c\u4ece\u800c\u6fc0\u53d1\u590d\u6742\u7684\u884c\u4e3a\u5982\u81ea\u6211\u9a8c\u8bc1\u548c\u81ea\u6211\u4fee\u6b63\u3002\u540c\u65f6\uff0c\u8be5\u65b9\u6cd5\u5229\u7528\u5e76\u884c\u6280\u672f\u534f\u8c03\u591a\u4e2a\u8bed\u8a00\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u63a8\u7406\u901f\u5ea6\u3002", "result": "ProxyThinker\u5728\u7a7a\u95f4\u3001\u6570\u5b66\u548c\u8de8\u5b66\u79d1\u63a8\u7406\u7b49\u5177\u6709\u6311\u6218\u6027\u7684\u89c6\u89c9\u57fa\u51c6\u4e0a\u4e00\u81f4\u63d0\u5347\u4e86\u6027\u80fd\uff0c\u4f7f\u672a\u8c03\u6574\u7684\u57fa\u7840\u6a21\u578b\u80fd\u591f\u4e0e\u5168\u89c4\u6a21RFT\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002\u5e76\u4e14\u5176\u63a8\u7406\u901f\u5ea6\u6bd4\u5148\u524d\u7684\u65b9\u6cd5\u5feb38\u500d\u3002", "conclusion": "ProxyThinker\u65e0\u9700\u8bad\u7ec3\u5373\u53ef\u589e\u5f3a\u5927\u578b\u6a21\u578b\u7684\u89c6\u89c9\u63a8\u7406\u80fd\u529b\uff0c\u4e14\u5728\u591a\u4e2a\u63a8\u7406\u4efb\u52a1\u4e0a\u8868\u73b0\u51fa\u8272\uff0c\u5176\u5b9e\u73b0\u65b9\u5f0f\u9ad8\u6548\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u94fa\u5e73\u4e86\u9053\u8def\u3002"}}
{"id": "2505.24556", "pdf": "https://arxiv.org/pdf/2505.24556", "abs": "https://arxiv.org/abs/2505.24556", "authors": ["Gabriel V Cardoso", "Mike Pereira"], "title": "Predictive posterior sampling from non-stationnary Gaussian process priors via Diffusion models with application to climate data", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Bayesian models based on Gaussian processes (GPs) offer a flexible framework\nto predict spatially distributed variables with uncertainty. But the use of\nnonstationary priors, often necessary for capturing complex spatial patterns,\nmakes sampling from the predictive posterior distribution (PPD) computationally\nintractable. In this paper, we propose a two-step approach based on diffusion\ngenerative models (DGMs) to mimic PPDs associated with non-stationary GP\npriors: we replace the GP prior by a DGM surrogate, and leverage recent\nadvances on training-free guidance algorithms for DGMs to sample from the\ndesired posterior distribution. We apply our approach to a rich non-stationary\nGP prior from which exact posterior sampling is untractable and validate that\nthe issuing distributions are close to their GP counterpart using several\nstatistical metrics. We also demonstrate how one can fine-tune the trained DGMs\nto target specific parts of the GP prior. Finally we apply the proposed\napproach to solve inverse problems arising in environmental sciences, thus\nyielding state-of-the-art predictions.", "AI": {"tldr": "The paper proposes a two-step approach using diffusion generative models (DGMs) to mimic predictive posterior distributions (PPDs) for non-stationary Gaussian process priors, enabling state-of-the-art predictions in environmental science inverse problems.", "motivation": "Bayesian models with Gaussian processes provide a flexible framework for predicting spatially distributed variables with uncertainty. However, using nonstationary priors, which are often necessary for capturing complex spatial patterns, makes sampling from the predictive posterior distribution computationally intractable.", "method": "A two-step approach based on diffusion generative models (DGMs) is proposed: replacing the GP prior by a DGM surrogate and leveraging training-free guidance algorithms for DGMs to sample from the desired posterior distribution.", "result": "The approach was applied to a non-stationary GP prior where exact posterior sampling is untractable, validating that the issuing distributions are close to their GP counterpart using several statistical metrics. Additionally, trained DGMs can be fine-tuned to target specific parts of the GP prior. The method yields state-of-the-art predictions when applied to inverse problems in environmental sciences.", "conclusion": "The proposed two-step approach based on DGMs successfully mimics PPDs associated with non-stationary GP priors, overcoming computational intractability and providing state-of-the-art predictions in environmental science inverse problems."}}
{"id": "2505.24619", "pdf": "https://arxiv.org/pdf/2505.24619", "abs": "https://arxiv.org/abs/2505.24619", "authors": ["Vittorio Torri", "Machteld J. Boonstra", "Marielle C. van de Veerdonk", "Deborah N. Kalkman", "Alicia Uijl", "Francesca Ieva", "Ameen Abu-Hanna", "Folkert W. Asselbergs", "Iacer Calixto"], "title": "Interpretable phenotyping of Heart Failure patients with Dutch discharge letters", "categories": ["cs.CL", "cs.LG", "68T50", "I.2.7; J.3"], "comment": "43 pages, 8 figures", "summary": "Objective: Heart failure (HF) patients present with diverse phenotypes\naffecting treatment and prognosis. This study evaluates models for phenotyping\nHF patients based on left ventricular ejection fraction (LVEF) classes, using\nstructured and unstructured data, assessing performance and interpretability.\n  Materials and Methods: The study analyzes all HF hospitalizations at both\nAmsterdam UMC hospitals (AMC and VUmc) from 2015 to 2023 (33,105\nhospitalizations, 16,334 patients). Data from AMC were used for model training,\nand from VUmc for external validation. The dataset was unlabelled and included\ntabular clinical measurements and discharge letters. Silver labels for LVEF\nclasses were generated by combining diagnosis codes, echocardiography results,\nand textual mentions. Gold labels were manually annotated for 300 patients for\ntesting. Multiple Transformer-based (black-box) and Aug-Linear (white-box)\nmodels were trained and compared with baselines on structured and unstructured\ndata. To evaluate interpretability, two clinicians annotated 20 discharge\nletters by highlighting information they considered relevant for LVEF\nclassification. These were compared to SHAP and LIME explanations from\nblack-box models and the inherent explanations of Aug-Linear models.\n  Results: BERT-based and Aug-Linear models, using discharge letters alone,\nachieved the highest classification results (AUC=0.84 for BERT, 0.81 for\nAug-Linear on external validation), outperforming baselines. Aug-Linear\nexplanations aligned more closely with clinicians' explanations than post-hoc\nexplanations on black-box models.\n  Conclusions: Discharge letters emerged as the most informative source for\nphenotyping HF patients. Aug-Linear models matched black-box performance while\nproviding clinician-aligned interpretability, supporting their use in\ntransparent clinical decision-making.", "AI": {"tldr": "The paper explores models for phenotyping heart failure patients based on LVEF classes using structured and unstructured data. It finds discharge letters to be the most informative source, with Aug-Linear models providing strong performance and interpretability.", "motivation": "To evaluate models for phenotyping heart failure patients based on left ventricular ejection fraction (LVEF) classes using both structured and unstructured data while assessing model performance and interpretability.", "method": "Analyzed HF hospitalizations data from two Amsterdam UMC hospitals from 2015 to 2023. Silver labels for LVEF classes were generated by combining diagnosis codes, echocardiography results, and textual mentions. Gold labels were manually annotated for testing. Both Transformer-based (black-box) and Aug-Linear (white-box) models were trained and compared with baselines on structured and unstructured data. Interpretability was evaluated by comparing clinician annotations with SHAP, LIME explanations, and inherent explanations of Aug-Linear models.", "result": "BERT-based and Aug-Linear models using discharge letters alone achieved the highest classification results (AUC=0.84 for BERT, 0.81 for Aug-Linear on external validation). Aug-Linear explanations aligned more closely with clinicians' explanations than post-hoc explanations on black-box models.", "conclusion": "Discharge letters are the most informative source for phenotyping HF patients. Aug-Linear models provide clinician-aligned interpretability and match black-box performance, supporting transparent clinical decision-making."}}
{"id": "2505.24650", "pdf": "https://arxiv.org/pdf/2505.24650", "abs": "https://arxiv.org/abs/2505.24650", "authors": ["Hariom Tatsat", "Ariye Shater"], "title": "Beyond the Black Box: Interpretability of LLMs in Finance", "categories": ["cs.CE", "cs.LG", "q-fin.ST"], "comment": "28 pages, 15 figures", "summary": "Large Language Models (LLMs) exhibit remarkable capabilities across a\nspectrum of tasks in financial services, including report generation, chatbots,\nsentiment analysis, regulatory compliance, investment advisory, financial\nknowledge retrieval, and summarization. However, their intrinsic complexity and\nlack of transparency pose significant challenges, especially in the highly\nregulated financial sector, where interpretability, fairness, and\naccountability are critical. As far as we are aware, this paper presents the\nfirst application in the finance domain of understanding and utilizing the\ninner workings of LLMs through mechanistic interpretability, addressing the\npressing need for transparency and control in AI systems. Mechanistic\ninterpretability is the most intuitive and transparent way to understand LLM\nbehavior by reverse-engineering their internal workings. By dissecting the\nactivations and circuits within these models, it provides insights into how\nspecific features or components influence predictions - making it possible not\nonly to observe but also to modify model behavior. In this paper, we explore\nthe theoretical aspects of mechanistic interpretability and demonstrate its\npractical relevance through a range of financial use cases and experiments,\nincluding applications in trading strategies, sentiment analysis, bias, and\nhallucination detection. While not yet widely adopted, mechanistic\ninterpretability is expected to become increasingly vital as adoption of LLMs\nincreases. Advanced interpretability tools can ensure AI systems remain\nethical, transparent, and aligned with evolving financial regulations. In this\npaper, we have put special emphasis on how these techniques can help unlock\ninterpretability requirements for regulatory and compliance purposes -\naddressing both current needs and anticipating future expectations from\nfinancial regulators globally.", "AI": {"tldr": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u91d1\u878d\u670d\u52a1\u9886\u57df\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u900f\u660e\u5ea6\u4e0d\u8db3\u3002\u672c\u6587\u9996\u6b21\u901a\u8fc7\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u7814\u7a76LLMs\u5728\u91d1\u878d\u9886\u57df\u7684\u5e94\u7528\uff0c\u63a2\u8ba8\u5176\u7406\u8bba\u4e0e\u5b9e\u8df5\u610f\u4e49\uff0c\u5e76\u5f3a\u8c03\u4e86\u5176\u5728\u76d1\u7ba1\u548c\u5408\u89c4\u65b9\u9762\u7684\u4f5c\u7528\u3002", "motivation": "\u5c3d\u7ba1LLMs\u5728\u91d1\u878d\u9886\u57df\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\uff0c\u4f46\u5176\u590d\u6742\u6027\u548c\u7f3a\u4e4f\u900f\u660e\u5ea6\u6210\u4e3a\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u9ad8\u5ea6\u76d1\u7ba1\u7684\u73af\u5883\u4e2d\u3002\u56e0\u6b64\uff0c\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u7406\u89e3\u5e76\u63a7\u5236\u8fd9\u4e9b\u6a21\u578b\u7684\u884c\u4e3a\uff0c\u4ee5\u786e\u4fdd\u5b83\u4eec\u7b26\u5408\u4f26\u7406\u3001\u900f\u660e\u4e14\u4e0e\u6cd5\u89c4\u4e00\u81f4\u3002", "method": "\u901a\u8fc7\u673a\u68b0\u53ef\u89e3\u91ca\u6027\uff08Mechanistic Interpretability\uff09\uff0c\u5373\u9006\u5411\u5de5\u7a0bLLMs\u7684\u5185\u90e8\u5de5\u4f5c\u539f\u7406\uff0c\u5206\u6790\u6fc0\u6d3b\u548c\u7535\u8def\uff0c\u4ece\u800c\u4e86\u89e3\u7279\u5b9a\u7279\u5f81\u6216\u7ec4\u4ef6\u5982\u4f55\u5f71\u54cd\u9884\u6d4b\uff0c\u5e76\u53ef\u80fd\u8c03\u6574\u6a21\u578b\u884c\u4e3a\u3002", "result": "\u5c55\u793a\u4e86\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5728\u591a\u4e2a\u91d1\u878d\u7528\u4f8b\u4e2d\u7684\u5b9e\u9645\u76f8\u5173\u6027\uff0c\u5305\u62ec\u4ea4\u6613\u7b56\u7565\u3001\u60c5\u611f\u5206\u6790\u3001\u504f\u5dee\u548c\u5e7b\u89c9\u68c0\u6d4b\u7b49\uff0c\u5e76\u5f3a\u8c03\u5176\u5728\u672a\u6765AI\u7cfb\u7edf\u4e2d\u4fdd\u6301\u4f26\u7406\u548c\u900f\u660e\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u968f\u7740LLMs\u7684\u666e\u53ca\uff0c\u673a\u68b0\u53ef\u89e3\u91ca\u6027\u5c06\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u5b83\u53ef\u4ee5\u5e2e\u52a9\u6ee1\u8db3\u5f53\u524d\u548c\u672a\u6765\u7684\u76d1\u7ba1\u9700\u6c42\uff0c\u786e\u4fddAI\u7cfb\u7edf\u4e0e\u91d1\u878d\u6cd5\u89c4\u4fdd\u6301\u4e00\u81f4\u3002"}}
{"id": "2505.24668", "pdf": "https://arxiv.org/pdf/2505.24668", "abs": "https://arxiv.org/abs/2505.24668", "authors": ["Jonghyun Ham", "Maximilian Fleissner", "Debarghya Ghoshdastidar"], "title": "Impact of Bottleneck Layers and Skip Connections on the Generalization of Linear Denoising Autoencoders", "categories": ["stat.ML", "cs.LG"], "comment": null, "summary": "Modern deep neural networks exhibit strong generalization even in highly\noverparameterized regimes. Significant progress has been made to understand\nthis phenomenon in the context of supervised learning, but for unsupervised\ntasks such as denoising, several open questions remain. While some recent works\nhave successfully characterized the test error of the linear denoising problem,\nthey are limited to linear models (one-layer network). In this work, we focus\non two-layer linear denoising autoencoders trained under gradient flow,\nincorporating two key ingredients of modern deep learning architectures: A\nlow-dimensional bottleneck layer that effectively enforces a rank constraint on\nthe learned solution, as well as the possibility of a skip connection that\nbypasses the bottleneck. We derive closed-form expressions for all critical\npoints of this model under product regularization, and in particular describe\nits global minimizer under the minimum-norm principle. From there, we derive\nthe test risk formula in the overparameterized regime, both for models with and\nwithout skip connections. Our analysis reveals two interesting phenomena:\nFirstly, the bottleneck layer introduces an additional complexity measure akin\nto the classical bias-variance trade-off -- increasing the bottleneck width\nreduces bias but introduces variance, and vice versa. Secondly, skip connection\ncan mitigate the variance in denoising autoencoders -- especially when the\nmodel is mildly overparameterized. We further analyze the impact of skip\nconnections in denoising autoencoder using random matrix theory and support our\nclaims with numerical evidence.", "AI": {"tldr": "\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u4e2d\u7684\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u5728\u8fc7\u53c2\u6570\u5316 regime \u4e0b\u7684\u6cdb\u5316\u884c\u4e3a\u7814\u7a76\uff0c\u5305\u62ec\u74f6\u9888\u5c42\u548c\u8df3\u8dc3\u8fde\u63a5\u5bf9\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6d4b\u8bd5\u98ce\u9669\u7684\u5f71\u54cd\u3002", "motivation": "\u5c3d\u7ba1\u5df2\u7ecf\u5bf9\u76d1\u7763\u5b66\u4e60\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u73b0\u8c61\u6709\u4e86\u663e\u8457\u7406\u89e3\uff0c\u4f46\u5bf9\u4e8e\u65e0\u76d1\u7763\u4efb\u52a1\uff08\u5982\u53bb\u566a\uff09\u4ecd\u5b58\u5728\u8bb8\u591a\u672a\u89e3\u95ee\u9898\u3002\u672c\u6587\u8bd5\u56fe\u901a\u8fc7\u5206\u6790\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u6765\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\u3002", "method": "\u7814\u7a76\u4e86\u5728\u68af\u5ea6\u6d41\u4e0b\u8bad\u7ec3\u7684\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u5305\u542b\u74f6\u9888\u5c42\u548c\u53ef\u80fd\u7684\u8df3\u8dc3\u8fde\u63a5\u3002\u63a8\u5bfc\u4e86\u8be5\u6a21\u578b\u5728\u4e58\u79ef\u6b63\u5219\u5316\u4e0b\u7684\u6240\u6709\u4e34\u754c\u70b9\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u63cf\u8ff0\u4e86\u5176\u5168\u5c40\u6700\u5c0f\u503c\u3002\u8fdb\u4e00\u6b65\u63a8\u5bfc\u4e86\u8fc7\u53c2\u6570\u5316 regime \u4e0b\u7684\u6d4b\u8bd5\u98ce\u9669\u516c\u5f0f\uff0c\u5206\u6790\u4e86\u74f6\u9888\u5c42\u548c\u8df3\u8dc3\u8fde\u63a5\u5bf9\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6d4b\u8bd5\u98ce\u9669\u7684\u5f71\u54cd\u3002", "result": "\u53d1\u73b0\u4e86\u4e24\u4e2a\u6709\u8da3\u7684\u73b0\u8c61\uff1a1) \u74f6\u9888\u5c42\u5f15\u5165\u4e86\u4e00\u4e2a\u7c7b\u4f3c\u4e8e\u7ecf\u5178\u504f\u5dee-\u65b9\u5dee\u6743\u8861\u7684\u590d\u6742\u5ea6\u5ea6\u91cf\uff1b2) \u8df3\u8dc3\u8fde\u63a5\u53ef\u4ee5\u51cf\u8f7b\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\u4e2d\u7684\u65b9\u5dee\uff0c\u7279\u522b\u662f\u5728\u6a21\u578b\u8f7b\u5fae\u8fc7\u53c2\u6570\u5316\u65f6\u3002\u4f7f\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u8fdb\u4e00\u6b65\u5206\u6790\u4e86\u8df3\u8dc3\u8fde\u63a5\u7684\u5f71\u54cd\uff0c\u5e76\u7528\u6570\u503c\u8bc1\u636e\u652f\u6301\u4e86\u8fd9\u4e9b\u7ed3\u8bba\u3002", "conclusion": "\u672c\u6587\u901a\u8fc7\u5206\u6790\u4e24\u5c42\u7ebf\u6027\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668\uff0c\u63ed\u793a\u4e86\u74f6\u9888\u5c42\u548c\u8df3\u8dc3\u8fde\u63a5\u5bf9\u6a21\u578b\u590d\u6742\u5ea6\u548c\u6cdb\u5316\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3a\u7406\u89e3\u73b0\u4ee3\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u5728\u65e0\u76d1\u7763\u4efb\u52a1\u4e2d\u7684\u6cdb\u5316\u884c\u4e3a\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2505.24704", "pdf": "https://arxiv.org/pdf/2505.24704", "abs": "https://arxiv.org/abs/2505.24704", "authors": ["Hideaki Kim", "Tomoharu Iwata", "Akinori Fujino"], "title": "K$^2$IE: Kernel Method-based Kernel Intensity Estimators for Inhomogeneous Poisson Processes", "categories": ["stat.ML", "cs.LG"], "comment": "Accepted to ICML 2025", "summary": "Kernel method-based intensity estimators, formulated within reproducing\nkernel Hilbert spaces (RKHSs), and classical kernel intensity estimators (KIEs)\nhave been among the most easy-to-implement and feasible methods for estimating\nthe intensity functions of inhomogeneous Poisson processes. While both\napproaches share the term \"kernel\", they are founded on distinct theoretical\nprinciples, each with its own strengths and limitations. In this paper, we\npropose a novel regularized kernel method for Poisson processes based on the\nleast squares loss and show that the resulting intensity estimator involves a\nspecialized variant of the representer theorem: it has the dual coefficient of\nunity and coincides with classical KIEs. This result provides new theoretical\ninsights into the connection between classical KIEs and kernel method-based\nintensity estimators, while enabling us to develop an efficient KIE by\nleveraging advanced techniques from RKHS theory. We refer to the proposed model\nas the kernel method-based kernel intensity estimator (K$^2$IE). Through\nexperiments on synthetic datasets, we show that K$^2$IE achieves comparable\npredictive performance while significantly surpassing the state-of-the-art\nkernel method-based estimator in computational efficiency.", "AI": {"tldr": "The paper introduces K$^2$IE, a novel regularized kernel method for Poisson processes that combines the least squares loss with RKHS theory. It shares dual coefficient properties with classical KIEs and demonstrates superior computational efficiency without sacrificing predictive performance in experiments on synthetic datasets.", "motivation": "To bridge the gap between classical kernel intensity estimators (KIEs) and kernel method-based intensity estimators within reproducing kernel Hilbert spaces (RKHSs), while enhancing computational efficiency.", "method": "A new regularized kernel method is proposed for Poisson processes based on the least squares loss. This method utilizes RKHS theory and results in an intensity estimator that aligns with a specialized variant of the representer theorem, sharing properties with classical KIEs.", "result": "K$^2$IE achieves comparable predictive performance to existing methods but significantly improves computational efficiency over state-of-the-art kernel method-based estimators.", "conclusion": "The proposed K$^2$IE model not only provides new theoretical insights into the relationship between classical KIEs and kernel method-based intensity estimators but also offers practical advantages in terms of computational efficiency."}}
{"id": "2505.24727", "pdf": "https://arxiv.org/pdf/2505.24727", "abs": "https://arxiv.org/abs/2505.24727", "authors": ["Xiaochen Zhang", "Haoyi Xiong"], "title": "Knockoff-Guided Compressive Sensing: A Statistical Machine Learning Framework for Support-Assured Signal Recovery", "categories": ["stat.ML", "cs.LG", "eess.SP"], "comment": null, "summary": "This paper introduces a novel Knockoff-guided compressive sensing framework,\nreferred to as \\TheName{}, which enhances signal recovery by leveraging precise\nfalse discovery rate (FDR) control during the support identification phase.\nUnlike LASSO, which jointly performs support selection and signal estimation\nwithout explicit error control, our method guarantees FDR control in finite\nsamples, enabling more reliable identification of the true signal support. By\nseparating and controlling the support recovery process through statistical\nKnockoff filters, our framework achieves more accurate signal reconstruction,\nespecially in challenging scenarios where traditional methods fail. We\nestablish theoretical guarantees demonstrating how FDR control directly ensures\nrecovery performance under weaker conditions than traditional $\\ell_1$-based\ncompressive sensing methods, while maintaining accurate signal reconstruction.\nExtensive numerical experiments demonstrate that our proposed Knockoff-based\nmethod consistently outperforms LASSO-based and other state-of-the-art\ncompressive sensing techniques. In simulation studies, our method improves\nF1-score by up to 3.9x over baseline methods, attributed to principled false\ndiscovery rate (FDR) control and enhanced support recovery. The method also\nconsistently yields lower reconstruction and relative errors. We further\nvalidate the framework on real-world datasets, where it achieves top downstream\npredictive performance across both regression and classification tasks, often\nnarrowing or even surpassing the performance gap relative to uncompressed\nsignals. These results establish \\TheName{} as a robust and practical\nalternative to existing approaches, offering both theoretical guarantees and\nstrong empirical performance through statistically grounded support selection.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2505.24769", "pdf": "https://arxiv.org/pdf/2505.24769", "abs": "https://arxiv.org/abs/2505.24769", "authors": ["Claudia Merger", "Sebastian Goldt"], "title": "Generalization Dynamics of Linear Diffusion Models", "categories": ["stat.ML", "cond-mat.dis-nn", "cs.LG", "math.ST", "stat.TH"], "comment": null, "summary": "Diffusion models trained on finite datasets with $N$ samples from a target\ndistribution exhibit a transition from memorisation, where the model reproduces\ntraining examples, to generalisation, where it produces novel samples that\nreflect the underlying data distribution. Understanding this transition is key\nto characterising the sample efficiency and reliability of generative models,\nbut our theoretical understanding of this transition is incomplete. Here, we\nanalytically study the memorisation-to-generalisation transition in a simple\nmodel using linear denoisers, which allow explicit computation of test errors,\nsampling distributions, and Kullback-Leibler divergences between samples and\ntarget distribution. Using these measures, we predict that this transition\noccurs roughly when $N \\asymp d$, the dimension of the inputs. When $N$ is\nsmaller than the dimension of the inputs $d$, so that only a fraction of\nrelevant directions of variation are present in the training data, we\ndemonstrate how both regularization and early stopping help to prevent\noverfitting. For $N > d$, we find that the sampling distributions of linear\ndiffusion models approach their optimum (measured by the Kullback-Leibler\ndivergence) linearly with $d/N$, independent of the specifics of the data\ndistribution. Our work clarifies how sample complexity governs generalisation\nin a simple model of diffusion-based generative models and provides insight\ninto the training dynamics of linear denoisers.", "AI": {"tldr": "The paper explores the transition from memorization to generalization in diffusion models using linear denoisers, showing that this occurs when sample size $N$ is roughly equal to input dimension $d$, and examines how regularization and early stopping mitigate overfitting for $N < d$ while demonstrating optimal sampling distribution convergence for $N > d$.", "motivation": "To understand the transition from memorization to generalization in diffusion models trained on finite datasets, which is crucial for characterizing sample efficiency and reliability of generative models.", "method": "Analytical study of a simple model with linear denoisers allowing explicit computation of test errors, sampling distributions, and Kullback-Leibler divergences. Examines effects of regularization and early stopping, and studies behavior for both $N < d$ and $N > d$.", "result": "Predicts the transition from memorization to generalization occurs at $N \\asymp d$. For $N < d$, regularization and early stopping help prevent overfitting. For $N > d$, sampling distributions approach their optimum linearly with $d/N$.", "conclusion": "Clarifies the role of sample complexity in governing generalisation in simple diffusion-based generative models and provides insights into training dynamics of linear denoisers."}}
{"id": "2505.24781", "pdf": "https://arxiv.org/pdf/2505.24781", "abs": "https://arxiv.org/abs/2505.24781", "authors": ["Karim Abou-Moustafa"], "title": "Efficient Estimation of Regularized Tyler's M-Estimator Using Approximate LOOCV", "categories": ["stat.ML", "cs.CE", "cs.CV", "cs.LG", "eess.SP", "I.2.0; I.2.6"], "comment": "An extended version of a short article that appeared in 2023 IEEE\n  Workshop on Information Theory, Saint-Malo, France", "summary": "We consider the problem of estimating a regularization parameter, or a\nshrinkage coefficient $\\alpha \\in (0,1)$ for Regularized Tyler's M-estimator\n(RTME). In particular, we propose to estimate an optimal shrinkage coefficient\nby setting $\\alpha$ as the solution to a suitably chosen objective function;\nnamely the leave-one-out cross-validated (LOOCV) log-likelihood loss. Since\nLOOCV is computationally prohibitive even for moderate sample size $n$, we\npropose a computationally efficient approximation for the LOOCV log-likelihood\nloss that eliminates the need for invoking the RTME procedure $n$ times for\neach sample left out during the LOOCV procedure. This approximation yields an\n$O(n)$ reduction in the running time complexity for the LOOCV procedure, which\nresults in a significant speedup for computing the LOOCV estimate. We\ndemonstrate the efficiency and accuracy of the proposed approach on synthetic\nhigh-dimensional data sampled from heavy-tailed elliptical distributions, as\nwell as on real high-dimensional datasets for object recognition, face\nrecognition, and handwritten digit's recognition. Our experiments show that the\nproposed approach is efficient and consistently more accurate than other\nmethods in the literature for shrinkage coefficient estimation.", "AI": {"tldr": "The paper proposes an efficient approximation method for estimating the shrinkage coefficient \u03b1 in Regularized Tyler's M-estimator (RTME) by minimizing the leave-one-out cross-validated (LOOCV) log-likelihood loss, which significantly reduces computational complexity and demonstrates superior performance on both synthetic and real high-dimensional datasets.", "motivation": "The motivation of this paper is to address the computational challenge associated with estimating the shrinkage coefficient \u03b1 using LOOCV in RTME, especially when dealing with moderate or large sample sizes.", "method": "The authors propose a computationally efficient approximation for the LOOCV log-likelihood loss, eliminating the need to invoke the RTME procedure n times. This results in an O(n) reduction in running time complexity for the LOOCV procedure.", "result": "Experiments conducted on synthetic high-dimensional data from heavy-tailed elliptical distributions and real-world datasets for object, face, and handwritten digit recognition show that the proposed approach is efficient and consistently more accurate than other methods in the literature.", "conclusion": "The proposed method provides an efficient and accurate way to estimate the shrinkage coefficient \u03b1 in RTME, offering significant speedup compared to traditional LOOCV approaches."}}
{"id": "2505.24819", "pdf": "https://arxiv.org/pdf/2505.24819", "abs": "https://arxiv.org/abs/2505.24819", "authors": ["Haozhan Tang", "Tianyi Zhang", "Matthew Johnson-Roberson", "Weiming Zhi"], "title": "Bi-Manual Joint Camera Calibration and Scene Representation", "categories": ["cs.RO", "cs.CV", "cs.LG"], "comment": null, "summary": "Robot manipulation, especially bimanual manipulation, often requires setting\nup multiple cameras on multiple robot manipulators. Before robot manipulators\ncan generate motion or even build representations of their environments, the\ncameras rigidly mounted to the robot need to be calibrated. Camera calibration\nis a cumbersome process involving collecting a set of images, with each\ncapturing a pre-determined marker. In this work, we introduce the Bi-Manual\nJoint Calibration and Representation Framework (Bi-JCR). Bi-JCR enables\nmultiple robot manipulators, each with cameras mounted, to circumvent taking\nimages of calibration markers. By leveraging 3D foundation models for dense,\nmarker-free multi-view correspondence, Bi-JCR jointly estimates: (i) the\nextrinsic transformation from each camera to its end-effector, (ii) the\ninter-arm relative poses between manipulators, and (iii) a unified,\nscale-consistent 3D representation of the shared workspace, all from the same\ncaptured RGB image sets. The representation, jointly constructed from images\ncaptured by cameras on both manipulators, lives in a common coordinate frame\nand supports collision checking and semantic segmentation to facilitate\ndownstream bimanual coordination tasks. We empirically evaluate the robustness\nof Bi-JCR on a variety of tabletop environments, and demonstrate its\napplicability on a variety of downstream tasks.", "AI": {"tldr": "This paper presents Bi-JCR, a framework that allows multiple robot manipulators with cameras to bypass traditional calibration markers by using 3D foundation models for multi-view correspondence. It estimates extrinsic transformations, inter-arm relative poses, and creates a unified 3D workspace representation from RGB images.", "motivation": "The motivation is to simplify the camera calibration process in bimanual robot manipulation, which traditionally requires collecting images of pre-determined markers, making it cumbersome.", "method": "Bi-JCR leverages 3D foundation models for dense, marker-free multi-view correspondence. It jointly estimates the extrinsic transformation from each camera to its end-effector, the inter-arm relative poses between manipulators, and a unified, scale-consistent 3D representation of the shared workspace.", "result": "Empirical evaluations show the robustness of Bi-JCR on various tabletop environments and demonstrate its applicability on downstream tasks, supporting collision checking and semantic segmentation.", "conclusion": "Bi-JCR successfully circumvents the need for calibration markers and provides a unified 3D workspace representation that facilitates bimanual coordination tasks."}}
{"id": "2505.24848", "pdf": "https://arxiv.org/pdf/2505.24848", "abs": "https://arxiv.org/abs/2505.24848", "authors": ["Charig Yang", "Samiul Alam", "Shakhrul Iman Siam", "Michael J. Proulx", "Lambert Mathias", "Kiran Somasundaram", "Luis Pesqueira", "James Fort", "Sheroze Sheriffdeen", "Omkar Parkhi", "Carl Ren", "Mi Zhang", "Yuning Chai", "Richard Newcombe", "Hyo Jin Kim"], "title": "Reading Recognition in the Wild", "categories": ["cs.CV", "cs.LG"], "comment": null, "summary": "To enable egocentric contextual AI in always-on smart glasses, it is crucial\nto be able to keep a record of the user's interactions with the world,\nincluding during reading. In this paper, we introduce a new task of reading\nrecognition to determine when the user is reading. We first introduce the\nfirst-of-its-kind large-scale multimodal Reading in the Wild dataset,\ncontaining 100 hours of reading and non-reading videos in diverse and realistic\nscenarios. We then identify three modalities (egocentric RGB, eye gaze, head\npose) that can be used to solve the task, and present a flexible transformer\nmodel that performs the task using these modalities, either individually or\ncombined. We show that these modalities are relevant and complementary to the\ntask, and investigate how to efficiently and effectively encode each modality.\nAdditionally, we show the usefulness of this dataset towards classifying types\nof reading, extending current reading understanding studies conducted in\nconstrained settings to larger scale, diversity and realism. Code, model, and\ndata will be public.", "AI": {"tldr": "\u4e3a\u4e86\u5728\u59cb\u7ec8\u5f00\u542f\u7684\u667a\u80fd\u773c\u955c\u4e2d\u5b9e\u73b0\u81ea\u6211\u4e2d\u5fc3\u7684\u60c5\u5883AI\uff0c\u8bb0\u5f55\u7528\u6237\u4e0e\u4e16\u754c\u7684\u4e92\u52a8\uff08\u5305\u62ec\u9605\u8bfb\u65f6\uff09\u81f3\u5173\u91cd\u8981\u3002\u672c\u6587\u5f15\u5165\u4e86\u4e00\u9879\u65b0\u7684\u4efb\u52a1\u2014\u2014\u9605\u8bfb\u8bc6\u522b\uff0c\u4ee5\u5224\u65ad\u7528\u6237\u4f55\u65f6\u5728\u9605\u8bfb\uff0c\u5e76\u53d1\u5e03\u4e86\u5927\u89c4\u6a21\u591a\u6a21\u5f0f\u6570\u636e\u96c6Reading in the Wild\uff0c\u5305\u542b100\u5c0f\u65f6\u7684\u9605\u8bfb\u548c\u975e\u9605\u8bfb\u89c6\u9891\u3002\u7814\u7a76\u786e\u5b9a\u4e86\u4e09\u79cd\u53ef\u7528\u4e8e\u89e3\u51b3\u6b64\u4efb\u52a1\u7684\u6a21\u5f0f\uff08\u81ea\u6211\u4e2d\u5fc3RGB\u3001\u773c\u52a8\u8ffd\u8e2a\u3001\u5934\u90e8\u59ff\u6001\uff09\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u7684Transformer\u6a21\u578b\uff0c\u53ef\u4ee5\u5355\u72ec\u6216\u7ec4\u5408\u4f7f\u7528\u8fd9\u4e9b\u6a21\u5f0f\u6765\u6267\u884c\u4efb\u52a1\u3002\u8bc1\u660e\u4e86\u8fd9\u4e9b\u6a21\u5f0f\u5bf9\u4efb\u52a1\u7684\u76f8\u5173\u6027\u548c\u4e92\u8865\u6027\uff0c\u5e76\u63a2\u8ba8\u4e86\u5982\u4f55\u9ad8\u6548\u6709\u6548\u5730\u7f16\u7801\u6bcf\u4e2a\u6a21\u5f0f\u3002\u6b64\u5916\uff0c\u5c55\u793a\u4e86\u8be5\u6570\u636e\u96c6\u5728\u5206\u7c7b\u9605\u8bfb\u7c7b\u578b\u65b9\u9762\u7684\u5b9e\u7528\u6027\uff0c\u5c06\u76ee\u524d\u5728\u53d7\u9650\u73af\u5883\u4e2d\u8fdb\u884c\u7684\u9605\u8bfb\u7406\u89e3\u7814\u7a76\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u3001\u591a\u6837\u6027\u548c\u73b0\u5b9e\u6027\u3002\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u5c06\u516c\u5f00\u3002", "motivation": "\u5728\u667a\u80fd\u773c\u955c\u4e2d\u5b9e\u73b0\u81ea\u6211\u4e2d\u5fc3\u7684\u60c5\u5883AI\u9700\u8981\u80fd\u591f\u8bb0\u5f55\u7528\u6237\u4e0e\u4e16\u754c\u7684\u4e92\u52a8\uff0c\u5305\u62ec\u5728\u9605\u8bfb\u671f\u95f4\u7684\u4e92\u52a8\u3002\u8fd9\u4fc3\u4f7f\u4e86\u5bf9\u9605\u8bfb\u8bc6\u522b\u4efb\u52a1\u7684\u7814\u7a76\uff0c\u4ee5\u786e\u5b9a\u7528\u6237\u4f55\u65f6\u5728\u9605\u8bfb\u3002", "method": "1. \u521b\u5efa\u4e86\u4e00\u4e2a\u5927\u89c4\u6a21\u591a\u6a21\u5f0f\u6570\u636e\u96c6Reading in the Wild\uff0c\u5305\u542b100\u5c0f\u65f6\u7684\u9605\u8bfb\u548c\u975e\u9605\u8bfb\u89c6\u9891\u3002\n2. \u786e\u5b9a\u4e86\u4e09\u79cd\u6a21\u6001\uff08\u81ea\u6211\u4e2d\u5fc3RGB\u3001\u773c\u52a8\u8ffd\u8e2a\u3001\u5934\u90e8\u59ff\u6001\uff09\u7528\u4e8e\u89e3\u51b3\u9605\u8bfb\u8bc6\u522b\u4efb\u52a1\u3002\n3. \u63d0\u51fa\u4e86\u4e00\u79cd\u7075\u6d3b\u7684Transformer\u6a21\u578b\uff0c\u53ef\u4ee5\u5355\u72ec\u6216\u7ec4\u5408\u4f7f\u7528\u4e0a\u8ff0\u6a21\u6001\u6765\u6267\u884c\u4efb\u52a1\u3002\n4. \u63a2\u8ba8\u4e86\u5982\u4f55\u9ad8\u6548\u6709\u6548\u5730\u7f16\u7801\u6bcf\u4e2a\u6a21\u6001\u3002", "result": "\u7814\u7a76\u8868\u660e\uff0c\u6240\u9009\u7684\u4e09\u79cd\u6a21\u6001\u5bf9\u4e8e\u9605\u8bfb\u8bc6\u522b\u4efb\u52a1\u662f\u76f8\u5173\u4e14\u4e92\u8865\u7684\u3002\u63d0\u51fa\u7684Transformer\u6a21\u578b\u5728\u4f7f\u7528\u8fd9\u4e9b\u6a21\u6001\uff08\u5355\u72ec\u6216\u7ec4\u5408\uff09\u65f6\u8868\u73b0\u826f\u597d\u3002\u6b64\u5916\uff0c\u8be5\u6570\u636e\u96c6\u6709\u52a9\u4e8e\u5206\u7c7b\u9605\u8bfb\u7c7b\u578b\uff0c\u5c06\u9605\u8bfb\u7406\u89e3\u7814\u7a76\u6269\u5c55\u5230\u66f4\u5927\u89c4\u6a21\u3001\u591a\u6837\u6027\u548c\u73b0\u5b9e\u6027\u3002", "conclusion": "\u901a\u8fc7\u521b\u5efa\u5927\u89c4\u6a21\u591a\u6a21\u5f0f\u6570\u636e\u96c6\u548c\u63d0\u51fa\u7075\u6d3b\u7684Transformer\u6a21\u578b\uff0c\u672c\u6587\u6210\u529f\u5730\u89e3\u51b3\u4e86\u9605\u8bfb\u8bc6\u522b\u4efb\u52a1\u3002\u8fd9\u4e9b\u6210\u679c\u4e0d\u4ec5\u6709\u52a9\u4e8e\u60c5\u5883AI\u7684\u53d1\u5c55\uff0c\u8fd8\u63a8\u52a8\u4e86\u9605\u8bfb\u7406\u89e3\u7814\u7a76\u5411\u66f4\u5927\u89c4\u6a21\u3001\u66f4\u591a\u6837\u5316\u548c\u66f4\u771f\u5b9e\u7684\u573a\u666f\u53d1\u5c55\u3002\u4ee3\u7801\u3001\u6a21\u578b\u548c\u6570\u636e\u7684\u516c\u5f00\u5c06\u4fc3\u8fdb\u8fdb\u4e00\u6b65\u7684\u7814\u7a76\u3002"}}
{"id": "2505.24849", "pdf": "https://arxiv.org/pdf/2505.24849", "abs": "https://arxiv.org/abs/2505.24849", "authors": ["Jean Barbier", "Francesco Camilli", "Minh-Toan Nguyen", "Mauro Pastore", "Rudy Skerk"], "title": "Statistical mechanics of extensive-width Bayesian neural networks near interpolation", "categories": ["stat.ML", "cond-mat.dis-nn", "cond-mat.stat-mech", "cs.IT", "cs.LG", "math.IT"], "comment": "9 pages + appendices, 12 figures. This submission supersedes\n  arXiv:2501.18530", "summary": "For three decades statistical mechanics has been providing a framework to\nanalyse neural networks. However, the theoretically tractable models, e.g.,\nperceptrons, random features models and kernel machines, or multi-index models\nand committee machines with few neurons, remained simple compared to those used\nin applications. In this paper we help reducing the gap between practical\nnetworks and their theoretical understanding through a statistical physics\nanalysis of the supervised learning of a two-layer fully connected network with\ngeneric weight distribution and activation function, whose hidden layer is\nlarge but remains proportional to the inputs dimension. This makes it more\nrealistic than infinitely wide networks where no feature learning occurs, but\nalso more expressive than narrow ones or with fixed inner weights. We focus on\nthe Bayes-optimal learning in the teacher-student scenario, i.e., with a\ndataset generated by another network with the same architecture. We operate\naround interpolation, where the number of trainable parameters and of data are\ncomparable and feature learning emerges. Our analysis uncovers a rich\nphenomenology with various learning transitions as the number of data\nincreases. In particular, the more strongly the features (i.e., hidden neurons\nof the target) contribute to the observed responses, the less data is needed to\nlearn them. Moreover, when the data is scarce, the model only learns non-linear\ncombinations of the teacher weights, rather than \"specialising\" by aligning its\nweights with the teacher's. Specialisation occurs only when enough data becomes\navailable, but it can be hard to find for practical training algorithms,\npossibly due to statistical-to-computational~gaps.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7\u7edf\u8ba1\u7269\u7406\u5206\u6790\u4e86\u5177\u6709\u901a\u7528\u6743\u91cd\u5206\u5e03\u548c\u6fc0\u6d3b\u51fd\u6570\u7684\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u76d1\u7763\u5b66\u4e60\uff0c\u63ed\u793a\u4e86\u5728\u6570\u636e\u589e\u52a0\u65f6\u7684\u5404\u79cd\u5b66\u4e60\u8f6c\u53d8\u73b0\u8c61\u3002", "motivation": "\u5c3d\u7ba1\u7edf\u8ba1\u529b\u5b66\u4e3a\u795e\u7ecf\u7f51\u7edc\u63d0\u4f9b\u4e86\u5206\u6790\u6846\u67b6\uff0c\u4f46\u7406\u8bba\u53ef\u5904\u7406\u7684\u6a21\u578b\u76f8\u5bf9\u7b80\u5355\uff0c\u4e0e\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u7f51\u7edc\u5b58\u5728\u5dee\u8ddd\u3002\u56e0\u6b64\uff0c\u672c\u6587\u65e8\u5728\u7f29\u5c0f\u5b9e\u8df5\u7f51\u7edc\u4e0e\u5176\u7406\u8bba\u7406\u89e3\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002", "method": "\u4f5c\u8005\u7814\u7a76\u4e86\u4e00\u4e2a\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u7684\u76d1\u7763\u5b66\u4e60\u95ee\u9898\uff0c\u8be5\u7f51\u7edc\u5177\u6709\u901a\u7528\u6743\u91cd\u5206\u5e03\u548c\u6fc0\u6d3b\u51fd\u6570\uff0c\u9690\u85cf\u5c42\u8f83\u5927\u4f46\u4e0e\u8f93\u5165\u7ef4\u5ea6\u6210\u6bd4\u4f8b\u3002\u91cd\u70b9\u5728\u4e8e\u6559\u5e08-\u5b66\u751f\u573a\u666f\u4e0b\u7684\u8d1d\u53f6\u65af\u6700\u4f18\u5b66\u4e60\uff0c\u5e76\u63a2\u8ba8\u63d2\u503c\u533a\u57df\u5185\u7684\u7279\u5f81\u5b66\u4e60\u73b0\u8c61\u3002", "result": "\u968f\u7740\u6570\u636e\u91cf\u7684\u589e\u52a0\uff0c\u51fa\u73b0\u4e86\u5404\u79cd\u5b66\u4e60\u8f6c\u53d8\u3002\u5f53\u7279\u5f81\u5bf9\u89c2\u5bdf\u5230\u7684\u54cd\u5e94\u8d21\u732e\u8d8a\u5927\u65f6\uff0c\u6240\u9700\u7684\u5b66\u4e60\u6570\u636e\u8d8a\u5c11\u3002\u6b64\u5916\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u7684\u60c5\u51b5\u4e0b\uff0c\u6a21\u578b\u4ec5\u5b66\u4e60\u6559\u5e08\u6743\u91cd\u7684\u975e\u7ebf\u6027\u7ec4\u5408\uff0c\u800c\u975e\u901a\u8fc7\u5bf9\u5176\u6743\u91cd\u8fdb\u884c\u5bf9\u9f50\u5b9e\u73b0\u201c\u4e13\u4e1a\u5316\u201d\u3002\u53ea\u6709\u5f53\u6709\u8db3\u591f\u7684\u6570\u636e\u65f6\uff0c\u624d\u4f1a\u53d1\u751f\u4e13\u4e1a\u5316\uff0c\u4f46\u5b9e\u9645\u8bad\u7ec3\u7b97\u6cd5\u53ef\u80fd\u96be\u4ee5\u627e\u5230\u8fd9\u79cd\u72b6\u6001\uff0c\u53ef\u80fd\u662f\u7531\u4e8e\u7edf\u8ba1\u5230\u8ba1\u7b97\u7684\u5dee\u8ddd\u3002", "conclusion": "\u672c\u6587\u63ed\u793a\u4e86\u4e24\u5c42\u5168\u8fde\u63a5\u7f51\u7edc\u5728\u76d1\u7763\u5b66\u4e60\u4e2d\u7684\u4e30\u5bcc\u73b0\u8c61\u5b66\uff0c\u5f3a\u8c03\u4e86\u6570\u636e\u91cf\u5bf9\u7279\u5f81\u5b66\u4e60\u7684\u91cd\u8981\u6027\uff0c\u5e76\u6307\u51fa\u4e86\u5b9e\u9645\u8bad\u7ec3\u7b97\u6cd5\u9762\u4e34\u7684\u6311\u6218\u3002"}}
{"id": "2505.24852", "pdf": "https://arxiv.org/pdf/2505.24852", "abs": "https://arxiv.org/abs/2505.24852", "authors": ["Douwe den Blanken", "Charlotte Frenkel"], "title": "Chameleon: A MatMul-Free Temporal Convolutional Network Accelerator for End-to-End Few-Shot and Continual Learning from Sequential Data", "categories": ["cs.AR", "cs.LG", "C.3; B.6.0; B.7.0; I.2.6; B.5.0"], "comment": "14 pages, 7 figures", "summary": "On-device learning at the edge enables low-latency, private personalization\nwith improved long-term robustness and reduced maintenance costs. Yet,\nachieving scalable, low-power end-to-end on-chip learning, especially from\nreal-world sequential data with a limited number of examples, is an open\nchallenge. Indeed, accelerators supporting error backpropagation optimize for\nlearning performance at the expense of inference efficiency, while simplified\nlearning algorithms often fail to reach acceptable accuracy targets. In this\nwork, we present Chameleon, leveraging three key contributions to solve these\nchallenges. (i) A unified learning and inference architecture supports few-shot\nlearning (FSL), continual learning (CL) and inference at only 0.5% area\noverhead to the inference logic. (ii) Long temporal dependencies are\nefficiently captured with temporal convolutional networks (TCNs), enabling the\nfirst demonstration of end-to-end on-chip FSL and CL on sequential data and\ninference on 16-kHz raw audio. (iii) A dual-mode, matrix-multiplication-free\ncompute array allows either matching the power consumption of state-of-the-art\ninference-only keyword spotting (KWS) accelerators or enabling $4.3\\times$\nhigher peak GOPS. Fabricated in 40-nm CMOS, Chameleon sets new accuracy records\non Omniglot for end-to-end on-chip FSL (96.8%, 5-way 1-shot, 98.8%, 5-way\n5-shot) and CL (82.2% final accuracy for learning 250 classes with 10 shots),\nwhile maintaining an inference accuracy of 93.3% on the 12-class Google Speech\nCommands dataset at an extreme-edge power budget of 3.1 $\\mu$W.", "AI": {"tldr": "The paper introduces Chameleon, a system designed for on-device learning that addresses challenges in scalable, low-power end-to-end on-chip learning from sequential data. It achieves high accuracy in few-shot learning and continual learning while maintaining efficiency.", "motivation": "On-device learning at the edge is crucial for low-latency, private personalization with long-term robustness and reduced maintenance costs. However, current accelerators either prioritize learning performance over inference efficiency or fail to achieve acceptable accuracy.", "method": "Chameleon leverages three key contributions: (i) A unified learning and inference architecture supporting few-shot learning, continual learning, and inference with minimal area overhead. (ii) Temporal convolutional networks efficiently capture long temporal dependencies, enabling on-chip learning on sequential data and raw audio. (iii) A dual-mode, matrix-multiplication-free compute array that matches power consumption of state-of-the-art inference-only accelerators or provides higher peak GOPS.", "result": "Chameleon sets new accuracy records on Omniglot for end-to-end on-chip few-shot learning (96.8%, 5-way 1-shot; 98.8%, 5-way 5-shot) and continual learning (82.2% final accuracy for learning 250 classes with 10 shots). It also maintains an inference accuracy of 93.3% on the Google Speech Commands dataset at an extreme-edge power budget of 3.1 \u03bcW.", "conclusion": "Chameleon demonstrates significant advancements in on-device learning by achieving high accuracy in few-shot and continual learning scenarios while maintaining efficient power consumption, making it suitable for edge applications."}}
{"id": "2505.24858", "pdf": "https://arxiv.org/pdf/2505.24858", "abs": "https://arxiv.org/abs/2505.24858", "authors": ["Gabrielle Kaili-May Liu", "Gal Yona", "Avi Caciularu", "Idan Szpektor", "Tim G. J. Rudner", "Arman Cohan"], "title": "MetaFaith: Faithful Natural Language Uncertainty Expression in LLMs", "categories": ["cs.CL", "cs.LG"], "comment": null, "summary": "A critical component in the trustworthiness of LLMs is reliable uncertainty\ncommunication, yet LLMs often use assertive language when conveying false\nclaims, leading to over-reliance and eroded trust. We present the first\nsystematic study of $\\textit{faithful confidence calibration}$ of LLMs,\nbenchmarking models' ability to use linguistic expressions of uncertainty that\n$\\textit{faithfully reflect}$ their intrinsic uncertainty, across a\ncomprehensive array of models, datasets, and prompting strategies. Our results\ndemonstrate that LLMs largely fail at this task, and that existing\ninterventions are insufficient: standard prompt approaches provide only\nmarginal gains, and existing, factuality-based calibration techniques can even\nharm faithful calibration. To address this critical gap, we introduce\nMetaFaith, a novel prompt-based calibration approach inspired by human\nmetacognition. We show that MetaFaith robustly improves faithful calibration\nacross diverse models and task domains, enabling up to 61% improvement in\nfaithfulness and achieving an 83% win rate over original generations as judged\nby humans.", "AI": {"tldr": "The paper conducts the first systematic study on faithful confidence calibration of LLMs, finding that LLMs generally fail at this task and existing interventions are insufficient. It proposes MetaFaith, a prompt-based calibration method inspired by human metacognition, which significantly improves faithful calibration.", "motivation": "LLMs often use assertive language when conveying false claims, which can lead to over-reliance and eroded trust. There is a need for reliable uncertainty communication in LLMs.", "method": "The researchers conducted a comprehensive benchmarking study across various models, datasets, and prompting strategies to evaluate LLMs' ability to faithfully reflect their intrinsic uncertainty. They then introduced MetaFaith, a novel prompt-based calibration approach inspired by human metacognition.", "result": "MetaFaith robustly improves faithful calibration across diverse models and task domains, enabling up to 61% improvement in faithfulness and achieving an 83% win rate over original generations as judged by humans.", "conclusion": "MetaFaith addresses the critical gap in LLMs' ability to communicate uncertainty reliably, offering a significant advancement in faithful confidence calibration."}}
{"id": "2505.24871", "pdf": "https://arxiv.org/pdf/2505.24871", "abs": "https://arxiv.org/abs/2505.24871", "authors": ["Yiqing Liang", "Jielin Qiu", "Wenhao Ding", "Zuxin Liu", "James Tompkin", "Mengdi Xu", "Mengzhou Xia", "Zhengzhong Tu", "Laixi Shi", "Jiacheng Zhu"], "title": "MoDoMoDo: Multi-Domain Data Mixtures for Multimodal LLM Reinforcement Learning", "categories": ["cs.CV", "cs.CL", "cs.LG"], "comment": "Project Webpage: https://modomodo-rl.github.io/", "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently emerged as\na powerful paradigm for post-training large language models (LLMs), achieving\nstate-of-the-art performance on tasks with structured, verifiable answers.\nApplying RLVR to Multimodal LLMs (MLLMs) presents significant opportunities but\nis complicated by the broader, heterogeneous nature of vision-language tasks\nthat demand nuanced visual, logical, and spatial capabilities. As such,\ntraining MLLMs using RLVR on multiple datasets could be beneficial but creates\nchallenges with conflicting objectives from interaction among diverse datasets,\nhighlighting the need for optimal dataset mixture strategies to improve\ngeneralization and reasoning. We introduce a systematic post-training framework\nfor Multimodal LLM RLVR, featuring a rigorous data mixture problem formulation\nand benchmark implementation. Specifically, (1) We developed a multimodal RLVR\nframework for multi-dataset post-training by curating a dataset that contains\ndifferent verifiable vision-language problems and enabling multi-domain online\nRL learning with different verifiable rewards; (2) We proposed a data mixture\nstrategy that learns to predict the RL fine-tuning outcome from the data\nmixture distribution, and consequently optimizes the best mixture.\nComprehensive experiments showcase that multi-domain RLVR training, when\ncombined with mixture prediction strategies, can significantly boost MLLM\ngeneral reasoning capacities. Our best mixture improves the post-trained\nmodel's accuracy on out-of-distribution benchmarks by an average of 5.24%\ncompared to the same model post-trained with uniform data mixture, and by a\ntotal of 20.74% compared to the pre-finetuning baseline.", "AI": {"tldr": "Multimodal LLMs (MLLMs) can be effectively post-trained using Reinforcement Learning with Verifiable Rewards (RLVR) through a systematic framework that includes a data mixture strategy, significantly improving general reasoning and out-of-distribution accuracy.", "motivation": "To apply RLVR to MLLMs and address the challenges posed by the diverse and complex nature of vision-language tasks, which require nuanced capabilities. The aim is to improve generalization and reasoning by optimizing dataset mixture strategies during post-training.", "method": "(1) Developed a multimodal RLVR framework for multi-dataset post-training with a curated dataset containing verifiable vision-language problems, enabling multi-domain online RL learning. (2) Proposed a data mixture strategy that predicts RL fine-tuning outcomes from the data mixture distribution and optimizes for the best mixture.", "result": "Experiments show that combining multi-domain RLVR training with mixture prediction strategies boosts MLLM general reasoning capacities. The best data mixture improves out-of-distribution benchmark accuracy by 5.24% compared to uniform data mixtures and by 20.74% compared to pre-finetuning baselines.", "conclusion": "The systematic post-training framework for MLLMs using RLVR, including an optimized data mixture strategy, significantly enhances general reasoning and accuracy on unseen benchmarks."}}
